{"posts":[{"title":"CNIå·¥ä½œæµç¨‹","text":"CNI å³å®¹å™¨ç½‘ç»œæ¥å£ï¼Œé€šè¿‡ CNI èƒ½å¤Ÿä½¿ K8s æ”¯æŒä¸åŒçš„ç½‘ç»œæ¨¡å¼ã€‚ CNI å¸¸è§çš„å®ç°æ¨¡å¼å¤§è‡´åˆ†ä¸ºä¸¤ç§: overlay: é€šè¿‡éš§é“æ‰“é€šç½‘ç»œï¼Œä¸ä¾èµ–åº•å±‚ç½‘ç»œï¼Œå¦‚ calico underlay: é€šè¿‡åº•å±‚æ‰“é€šç½‘ç»œï¼Œå¼ºä¾èµ–åº•å±‚ç½‘ç»œï¼Œå¦‚ macvlan CNI å¦‚ä½•ä½¿ç”¨CNI çš„å®ç°é€šå¸¸éœ€è¦ä¸¤ä¸ªéƒ¨åˆ†: CNI äºŒè¿›åˆ¶æ–‡ä»¶å»é…ç½® Pod çš„ç½‘å¡å’Œ IP DaemonSet è¿›ç¨‹å»ç®¡ç† Pod ä¹‹é—´çš„ç½‘ç»œæ‰“é€š é…ç½® CNI é…ç½®æ–‡ä»¶(/etc/cni/net.d/*.conf) å®‰è£… CNI äºŒè¿›åˆ¶æ–‡ä»¶(/opt/cni/bin/*) èŠ‚ç‚¹ä¸Šåˆ›å»º Pod kubelet æ ¹æ® CNI é…ç½®æ–‡ä»¶æ‰§è¡Œ CNI äºŒè¿›åˆ¶æ–‡ä»¶ Pod ç½‘ç»œé…ç½®å®Œæˆ","link":"/2024/03/30/CNI%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/"},{"title":"CSIå·¥ä½œæµç¨‹","text":"CSI å³å®¹å™¨å­˜å‚¨æ¥å£ï¼Œå€ŸåŠ© CSI å°±å¯ä»¥å¾ˆå®¹æ˜“çš„ç»™å·¥ä½œè´Ÿè½½æä¾›å­˜å‚¨ä½¿ç”¨ã€‚K8s çš„å­˜å‚¨æ’ä»¶åˆåˆ†ä¸º in-tree å’Œ out-of-tree ä¸¤ç§ç±»å‹ï¼Œå‰è€…æ˜¯ä¸ K8s ä¸»åº“å…±åŒè¿­ä»£ç»´æŠ¤ï¼Œåè€…åˆ™æ˜¯ç‹¬ç«‹ç»´æŠ¤çš„å­˜å‚¨æ’ä»¶ã€‚ out-of-tree ç±»å‹çš„æ’ä»¶åˆ™æ˜¯é€šè¿‡ gRPC ä¸ K8s çš„ç»„ä»¶è¿›è¡Œäº¤äº’ï¼Œä¸ºäº†ç®€åŒ– CSI çš„å¼€å‘ä¸éƒ¨ç½²ï¼ŒK8s ä¹Ÿæä¾›äº†å¤šä¸ª sidecar ç»„ä»¶: node-driver-registrar: ç›‘å¬æ¥è‡ª kubelet çš„ gRPC è¯·æ±‚ï¼Œä» CSI driver è·å–é©±åŠ¨ç¨‹åºä¿¡æ¯ï¼ˆé€šè¿‡ NodeGetInfo æ–¹æ³•ï¼‰ï¼Œå¹¶ä½¿ç”¨ kubelet æ’ä»¶æ³¨å†Œæœºåˆ¶åœ¨è¯¥èŠ‚ç‚¹ä¸Šçš„ kubelet ä¸­å¯¹å…¶è¿›è¡Œæ³¨å†Œ provisioner: ç›‘å¬æ¥è‡ª kube-apiserver çš„ gRPC è¯·æ±‚ï¼Œç›‘å¬ PVC çš„åˆ›å»ºå’Œåˆ é™¤ï¼Œè°ƒç”¨ CSI driver åˆ›å»ºå’Œåˆ é™¤ PVï¼ˆé€šè¿‡ CreateVolume å’Œ Delete Volumeï¼‰æ–¹æ³• attacher: ç›‘å¬æ¥è‡ª kube-apiserver çš„ gRPC è¯·æ±‚ï¼Œç›‘å¬ volumeAttachment å¯¹è±¡å¹¶è§¦å‘ CSI æ‰§è¡Œ ControllerPublishVolume å’Œ ControllerUnpublishVolume çš„æ“ä½œ resizer: ç›‘å¬æ¥è‡ª kube-apiserver çš„ gRPC è¯·æ±‚ï¼Œç›‘å¬ PVC çš„ä¿®æ”¹ï¼Œè°ƒç”¨ CSI Controller æ‰§è¡Œ ExpandVolume æ–¹æ³•ï¼Œæ¥è°ƒæ•´ Volume çš„å¤§å° livenessProbe: æ£€æŸ¥ CSI ç¨‹åºçš„å¥åº·çŠ¶æ€ï¼Œå¦‚ä¸å¥åº·åˆ™ä¼šè¿›è¡Œé‡å¯ CSI å·¥ä½œæµç¨‹CSI çš„å·¥ä½œæµåˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µ: Provision/Delete Attach/Detach Mount/Unmount è¿™ä¸‰ä¸ªé˜¶æ®µä¼šç”¨åˆ° Sidecar ç»„ä»¶ï¼Œä¹Ÿä¼šç”¨åˆ° K8s çš„ PV Controller å’Œ AD Controller ç»„ä»¶ å½“ç„¶å¹¶ä¸æ˜¯æ‰€æœ‰çš„ CSI éƒ½ä¼šç»å†è¿™ä¸‰ä¸ªé˜¶æ®µï¼Œå¦‚ NFS CSI çš„å·¥ä½œæµå°±æ²¡æœ‰æ¶‰åŠ volumeAttachment Privision é˜¶æ®µåœ¨æ­¤é˜¶æ®µï¼ŒSidecar provisioner å’Œ PV Controller éƒ½ä¼šç›‘å¬ PVC èµ„æº å½“ PV Controller è§‚å¯Ÿåˆ°æ–°çš„ PVC è¢«åˆ›å»ºæ—¶ï¼Œå°±ä¼šå»åˆ¤æ–­æ˜¯å¦æœ‰ä¸ä¹‹åŒ¹é…çš„ in-tree æ’ä»¶ï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ¤å®šä¸º out-of-treeï¼Œå¹¶ä¸ºè¯¥ PVC æ·»åŠ  annotation provisioner è§‚å¯Ÿåˆ° PVC çš„ annotation ä¸è‡ªå·±çš„ CSI æ˜¯ç›¸åŒ¹é…çš„æ—¶å€™ï¼Œå°±ä¼šå»è°ƒç”¨ CreateVolume æ–¹æ³• å½“ CreateVolume è°ƒç”¨è¿”å›æˆåŠŸæ—¶ï¼Œprovisioner å°±ä¼šåˆ›å»º PV PV Controller ç›‘å¬åˆ°è¯¥ PV æ—¶ï¼Œå°±ä¼šå°†å…¶ä¸ PVC åšç»‘å®š Attach é˜¶æ®µåœ¨æ­¤é˜¶æ®µï¼Œä¼šå°†æ•°æ®å·é™„åœ¨ä¸€ä¸ªèŠ‚ç‚¹ä¸Š AD Controller ç›‘å¬åˆ° Pod è¢«è°ƒåº¦åˆ°æŸä¸ªèŠ‚ç‚¹åï¼Œä¼šè°ƒç”¨ in-tree å†…éƒ¨æ¥å£åˆ›å»º volumeAttachment èµ„æº attacher ç›‘å¬åˆ° volumeAttachment å°±ä¼šè°ƒç”¨ ControllerPublishVolume æ¥å£ å½“æ¥å£è¿”å›æˆåŠŸæ—¶å°±ä¼šå°† volumeAttachment èµ„æºçš„ status.attached è®¾ç½®ä¸º true Mount é˜¶æ®µåœ¨æ­¤é˜¶æ®µï¼Œä¼šå°†æ•°æ®å·æŒ‚è½½åˆ° Pod ä¸Š kubelet è§‚å¯Ÿåˆ° volumeAttachment èµ„æºçš„ status.attached è®¾ç½®ä¸º true æ—¶ï¼Œå°±ä¼šè°ƒç”¨ in-tree å†…éƒ¨æ¥å£è¿›è¡Œå®é™…çš„å·æŒ‚è½½æ“ä½œ Unmount é˜¶æ®µåœ¨æ­¤é˜¶æ®µï¼Œä¼šå°†æ•°æ®å·ä» Pod ä¸Šå–æ¶ˆæŒ‚è½½ kubelet ç›‘å¬åˆ°èŠ‚ç‚¹ä¸Šçš„ Pod è¢«åˆ é™¤ï¼Œå°±ä¼šè°ƒç”¨ in-tree å†…éƒ¨æ¥å£è¿›è¡Œå®é™…çš„å·å¸è½½æ“ä½œ Detach é˜¶æ®µåœ¨æ­¤é˜¶æ®µï¼Œä¼šå°†å¯¹åº”çš„ volumeAttachment èµ„æºåˆ é™¤ attacher ä¼šè®²è¢«åˆ é™¤ Pod å¯¹åº”çš„ volumeAttachment è¿›è¡Œåˆ é™¤ AD Controller ç›‘å¬åˆ° volumeAttachment è¢«åˆ é™¤åï¼Œä¼šå»æ›´æ–°èŠ‚ç‚¹çš„ status.volumesInUseï¼Œå°†å¯¹åº”çš„å·ä¿¡æ¯æ‘˜é™¤ Delete é˜¶æ®µåœ¨æ­¤é˜¶æ®µï¼Œä¼šåˆ¤æ–­ PV çš„å›æ”¶ç­–ç•¥è¿›è¡Œä¸åŒçš„æ“ä½œ provisioner è§‚å¯Ÿ PV çš„ persistentVolumeReclaimPolicyï¼Œå¦‚æœä¸º Retain åˆ™ä¿ç•™ï¼ŒDelete åˆ™åˆ é™¤","link":"/2024/03/30/CSI%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/"},{"title":"CoreDNSå’ŒNodeLocalDNSçš„åŸŸåè§£æ","text":"åœ¨ K8s ä¸­ï¼ŒDNS çš„è§£æä¸»è¦ç”¨è¿™ä¸¤ä¸ªå·¥å…·: CoreDNS: ä¸»è¦è´Ÿè´£é›†ç¾¤å†…éƒ¨åŸŸåè§£æ NodeLocalDNS: æä¾› DNS ç¼“å­˜ é¦–å…ˆçœ‹ä¸€ä¸‹é›†ç¾¤ä¸­èŠ‚ç‚¹çš„ /etc/resolv.conf é…ç½®æ–‡ä»¶ 123456789101112131415# æŒ‡å®šäº†æœç´¢åŸŸï¼Œå½“ä½¿ç”¨åŸŸåè§£æä¸»æœºåæ—¶ï¼Œå¦‚æœä¸»æœºåæ²¡æœ‰å®Œå…¨é™å®šï¼Œç³»ç»Ÿä¼šä¾æ¬¡å°è¯•åœ¨æŒ‡å®šçš„æœç´¢åŸŸä¸­è¿½åŠ æœç´¢åç¼€è¿›è¡Œè§£æ# ä¾‹å¦‚è§£æ testï¼Œåˆ™ä¼šå°è¯•è§£æ test.default.svc.cluster.local å’Œ test.svc.cluster.localsearch default.svc.cluster.local svc.cluster.local# nodelocaldns æœåŠ¡å™¨çš„åœ°å€ï¼Œå¦‚æœé›†ç¾¤ä¸­æ²¡æœ‰ nodelocaldnsï¼Œé‚£ä¹ˆè¿™ä¸ªåœ°å€å°±ä¼šæ›¿æ¢æˆ CoreDNS çš„ SVC ClusterIPnameserver 169.254.25.10# å…¶ä»– DNS æœåŠ¡å™¨åœ°å€nameserver 192.168.0.5nameserver 223.5.5.5# è§£æçš„åŸŸåæœ€å¤šåŒ…æ¶µ 2 ä¸ªç‚¹ï¼Œæœ€å¤šè¶…æ—¶ 2sï¼Œæœ€å¤šé‡è¯• 2 æ¬¡# å‡è®¾è§£æaï¼Œä¼šå°è¯•è¿½åŠ  default.svc.cluster.local å’Œ svc.cluster.local# å‡è®¾è§£æa.bï¼Œåˆ™ä¸ä¼šï¼Œé™¤é ndots &gt; 2options ndots:2 timeout:2 attempts:2 åœ¨ K8s ä¸­ï¼Œworkload çš„ dnsPolicy æœ‰å››ç§ç±»å‹: ClusterFirst: ä¸é…ç½®çš„é›†ç¾¤åŸŸåç¼€ä¸åŒ¹é…çš„ä»»ä½• DNS æŸ¥è¯¢ï¼ˆä¾‹å¦‚ â€œ","link":"/2024/03/30/CoreDNS%E5%92%8CNodeLocalDNS%E7%9A%84%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90/"},{"title":"Docker éƒ¨ç½² NeuVector","text":"Docker éƒ¨ç½² NeuVector é€‚ç”¨äºåšç®€å•çš„æµ‹è¯•ã€‚ éƒ¨ç½² allinone å®¹å™¨ï¼š 12345678910111213141516171819docker run -d --name allinone \\--pid=host \\--privileged \\ -e CLUSTER_JOIN_ADDR=172.16.0.1 \\ -e NV_PLATFORM_INFO=platform=Docker \\ -e CTRL_PERSIST_CONFIG=1 \\ -p 18300:18300 \\ -p 18301:18301 \\ -p 18400:18400 \\ -p 18401:18401 \\ -p 10443:10443 \\ -p 18301:18301/udp \\ -p 8443:8443 \\ -v /lib/modules:/lib/modules:ro \\ -v /var/neuvector:/var/neuvector \\ -v /var/run/docker.sock:/var/run/docker.sock:ro \\ -v /sys/fs/cgroup:/host/cgroup:ro \\ -v /proc:/host/proc:ro \\neuvector/allinone:5.4.0 éƒ¨ç½² scanner å®¹å™¨ï¼š 12345docker run -td --name scanner \\-e CLUSTER_JOIN_ADDR=172.16.0.1 \\-e NV_PLATFORM_INFO=platform=Docker \\-p 18402:18402 -v /var/run/docker.sock:/var/run/docker.sock:ro \\registry.cn-hangzhou.aliyuncs.com/rancher/mirrored-neuvector-scanner:latest","link":"/2024/11/07/Docker-%E9%83%A8%E7%BD%B2-NeuVector/"},{"title":"Elasticsearch ä½¿ç”¨éšè®°","text":"éƒ¨ç½² ECK Operatorï¼š 12kubectl create -f https://download.elastic.co/downloads/eck/2.16.1/crds.yamlkubectl apply -f https://download.elastic.co/downloads/eck/2.16.1/operator.yaml éƒ¨ç½²å•ç‚¹ ES é›†ç¾¤ï¼š 12345678910111213cat &lt;&lt;EOF | kubectl apply -f -apiVersion: elasticsearch.k8s.elastic.co/v1kind: Elasticsearchmetadata: name: quickstartspec: version: 8.17.1 nodeSets: - name: default count: 1 config: node.store.allow_mmap: falseEOF å¯¹é›†ç¾¤å‘èµ·è¯·æ±‚ï¼š 12PASSWORD=$(kubectl get secret quickstart-es-elastic-user -o go-template='{{.data.elastic | base64decode}}')curl -u &quot;elastic:$PASSWORD&quot; -k &quot;https://quickstart-es-http:9200&quot; éƒ¨ç½²é«˜å¯ç”¨ ES é›†ç¾¤ï¼š 123456789101112131415161718192021cat &lt;&lt;EOF | kubectl apply -f -apiVersion: elasticsearch.k8s.elastic.co/v1kind: Elasticsearchmetadata: name: quickstartspec: version: 8.17.1 nodeSets: - name: data-nodes count: 3 config: node.store.allow_mmap: false index.number_of_replicas: 1 - name: master-nodes count: 3 config: node.master: true node.data: false node.ingest: false heap.size: 2gEOF","link":"/2025/01/31/Elasticsearch-%E4%BD%BF%E7%94%A8%E9%9A%8F%E8%AE%B0/"},{"title":"ETCD å‡ºç°é«˜ç¢ç‰‡ç‡äº‹ä»¶è§£æ","text":"é›†ç¾¤é¢‘ç¹è§¦å‘ etcdDatabaseHighFragmentationRatio å‘Šè­¦, PrometheusRule å†…å®¹å¦‚ä¸‹ï¼š 123456789101112131415- alert: etcdDatabaseHighFragmentationRatio annotations: description: 'etcd cluster &quot;{{ $labels.job }}&quot;: database size in use on instance {{ $labels.instance }} is {{ $value | humanizePercentage }} of the actual allocated disk space, please run defragmentation (e.g. etcdctl defrag) to retrieve the unused fragmented disk space.' runbook_url: https://etcd.io/docs/v3.5/op-guide/maintenance/#defragmentation summary: etcd database size in use is less than 50% of the actual allocated storage. expr: (last_over_time(etcd_mvcc_db_total_size_in_use_in_bytes{job=~&quot;.*etcd.*&quot;}[5m]) / last_over_time(etcd_mvcc_db_total_size_in_bytes{job=~&quot;.*etcd.*&quot;}[5m])) &lt; 0.5 and etcd_mvcc_db_total_size_in_use_in_bytes{job=~&quot;.*etcd.*&quot;} &gt; 104857600 for: 10m labels: severity: warning ç›¸å…³æŒ‡æ ‡: etcd_server_quota_backend_bytesï¼šå½“å‰åç«¯å­˜å‚¨é…é¢å¤§å°ï¼ˆå­—èŠ‚ï¼‰ï¼Œé»˜è®¤ä¸º 2GB etcd_mvcc_db_total_size_in_bytesï¼šç‰©ç†åˆ†é…çš„åº•å±‚æ•°æ®åº“æ€»å¤§å°ï¼ˆå­—èŠ‚ï¼‰ï¼ŒåŒ…å«äº†æ•°æ®ï¼ˆå¦‚ keyspaceï¼‰å’Œç¢ç‰‡ï¼Œå³ DB SIZE etcd_mvcc_db_total_size_in_use_in_bytesï¼šé€»è¾‘ä¸Šæ­£åœ¨ä½¿ç”¨çš„åº•å±‚æ•°æ®åº“çš„æ€»å¤§å°ï¼ˆä»¥å­—èŠ‚ä¸ºå•ä½ï¼‰ï¼Œä¸åŒ…å«ç¢ç‰‡ ä¹Ÿå°±æ˜¯è¯´ quota-backend-bytes é…ç½®åï¼Œetcd_mvcc_db_total_size_in_bytes çš„å¤§å°å¹¶ä¸ä¼šæ ¹æ®è¿™ä¸ªå€¼è€Œå˜åŒ–ï¼Œä¼šå˜çš„æ˜¯ etcd_server_quota_backend_bytesï¼Œetcd_mvcc_db_total_size_in_bytes çš„å€¼æŒ‡çš„æ˜¯ DB SIZEï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å– DB SIZE 12ls -lrth ${etcd-data-dir}/member/snapetcdctl endpoint status -w table ä¸ºä»€ä¹ˆä¼šäº§ç”Ÿç¢ç‰‡? ETCD æ”¯æŒå¤šç‰ˆæœ¬å¹¶å‘æ§åˆ¶(MVCC)ï¼ŒåŒæ—¶ä¼šç²¾ç¡®è®°å½•å…¶ keyspace çš„å†å² å‹ç¼©æ“ä½œæ˜¯æ¸…é™¤å†å²è®°å½•çš„å”¯ä¸€æ–¹æ³•ï¼Œé€šå¸¸ç”¨ â€“auto-compaction-mode å’Œ â€“auto-compaction-retention æ¥å®ç°è‡ªåŠ¨å‹ç¼© ä½†å‹ç¼©æ“ä½œåçš„ç©ºé—²ç©ºé—´å¹¶ä¸ä¼šçœŸæ­£åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­é‡Šæ”¾ï¼Œè€Œæ˜¯ä¼šè¢« ETCD æ ‡è®°ä¸ºå¯ä½¿ç”¨çš„ç©ºé—²ç©ºé—´ï¼Œä¹Ÿå°±æ˜¯è¯´å‹ç¼©æ“ä½œåä»ç„¶ä¼šå ç”¨ç£ç›˜ç©ºé—´ è¦çœŸæ­£é‡Šæ”¾ï¼Œå°±éœ€è¦è¿›è¡Œç¢ç‰‡æ•´ç†ï¼Œå³ etcdctl defrag 1etcdctl defrag é‚£ä¹ˆé’ˆå¯¹ etcdDatabaseHighFragmentationRatio å‘Šè­¦çš„è§¦å‘ï¼Œè¦æ€ä¹ˆåˆ¤æ–­éœ€ä¸éœ€è¦è¿›è¡Œç¢ç‰‡æ¸…ç†? é€šè¿‡ etcd_server_quota_backend_bytes æŒ‡æ ‡æŸ¥çœ‹å®é™…é…é¢ é€šè¿‡æŒ‡æ ‡ etcd_mvcc_db_total_size_in_bytes æˆ–è€…å‘½ä»¤æ£€æŸ¥ DB SIZEï¼Œçœ‹æ˜¯å¦çœŸçš„å¾ˆå¤§ä¸”æ¥è¿‘äº quota-backend-bytesï¼Œå¦‚æœä¸æ˜¯åˆ™æ— éœ€æ‹…å¿ƒ å¦‚æœæ˜¯ï¼Œè·å–æ¯ç§èµ„æºçš„æ•°é‡ï¼ŒæŸ¥çœ‹æ˜¯ä»€ä¹ˆèµ„æºå¯¼è‡´ DB Size è¿™ä¹ˆå¤§ï¼Œç„¶åé€šè¿‡ç¢ç‰‡æ¸…ç†å°è¯•é‡Šæ”¾ç©ºé—´ï¼Œå¦‚æœé‡Šæ”¾åä»æ¥è¿‘äº quota-backend-bytesï¼Œé‚£ä¹ˆéœ€è¦è€ƒè™‘å¢åŠ é…é¢ 12etcdctl get /registry --prefix --keys-only | grep -v ^$ | awk -F '/' '{ h[$3]++ } END {for (k in h) print h[k], k}' | sort -nretcdctl defrag","link":"/2024/09/14/ETCD-%E5%87%BA%E7%8E%B0%E9%AB%98%E7%A2%8E%E7%89%87%E7%8E%87%E4%BA%8B%E4%BB%B6%E8%A7%A3%E6%9E%90/"},{"title":"Harvester ä½¿ç”¨éšè®°","text":"Harvester æ˜¯ SUSE çš„ä¸€æ¬¾å¼€æº HCI è§£å†³æ–¹æ¡ˆï¼ŒåŸºäº Kubernetes çš„ç°ä»£åŒ– HCI å¹³å°ï¼Œæ—¨åœ¨ç®€åŒ–è™šæ‹ŸåŒ–ç®¡ç†ï¼ŒåŒæ—¶ä¸äº‘åŸç”ŸæŠ€æœ¯æ— ç¼é›†æˆã€‚ Harvester å®‰è£…ä¸”å¯¹æ¥ Rancher åï¼Œå°±å¯ä»¥ç›´æ¥åœ¨ Rancher è¿›è¡Œè™šæ‹Ÿæœºçš„åˆ›å»º/åˆ é™¤ç­‰åŠ¨ä½œã€‚ å¦‚æœ Harvester é›†ç¾¤åªæœ‰ä¸€ä¸ªèŠ‚ç‚¹ï¼Œå› ä¸ºé»˜è®¤çš„ StorageClass å‰¯æœ¬ä¸º 3ï¼Œéœ€è¦åˆ›å»ºä¸€ä¸ª StorageClass ç”¨äºä»£æ›¿ã€‚ 1234567891011121314151617cat &lt;&lt;EOF | kubectl apply -f -allowVolumeExpansion: trueapiVersion: storage.k8s.io/v1kind: StorageClassmetadata: annotations: storageclass.beta.kubernetes.io/is-default-class: &quot;true&quot; storageclass.kubernetes.io/is-default-class: &quot;true&quot; name: harvester-longhorn-single-replicasparameters: migratable: &quot;true&quot; numberOfReplicas: &quot;1&quot; staleReplicaTimeout: &quot;30&quot;provisioner: driver.longhorn.ioreclaimPolicy: DeletevolumeBindingMode: ImmediateEOF ä¸Šä¼  ISO æ–‡ä»¶è™šæ‹Ÿæœºçš„åˆ›å»ºçš„å‰ææ˜¯éœ€è¦æœ‰ ISO æ–‡ä»¶ï¼ŒHarvester æ”¯æŒæœ¬åœ°ä¸Šä¼ å’Œé€šè¿‡äº’è”ç½‘ä¸‹è½½ä¸¤ç§æ–¹å¼ï¼š æ¸…å Ubuntu Cloud IMG åˆ›å»º Cluster Networkéœ€è¦ç»™ Harvester èŠ‚ç‚¹å‡†å¤‡å¤šä¸€å¼ ç½‘å¡ç»™è™šæ‹Ÿæœºç”¨ï¼š åˆ›å»º VM Network Bridgeä½¿ç”¨åˆšåˆšåˆ›å»ºçš„ Cluster Networkï¼š åˆ›å»º VM Cloud Config TemplateUser Dataï¼š 123456789101112131415161718192021222324252627282930#cloud-configpackage_update: truepackages: - qemu-guest-agentwrite_files: - path: /etc/sysctl.conf permissions: 0644 owner: root content: | net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 net.ipv6.conf.lo.disable_ipv6 = 1runcmd: - systemctl enable --now qemu-guest-agent.service - systemctl disable --now systemd-resolved.service - rm -rf /etc/resolv.conf - echo 'nameserver 172.16.16.12' &gt; /etc/resolv.conf - timedatectl set-timezone Asia/Shanghai - sysctl -pssh_authorized_keys: - ssh-rsa xxxsystem_info: default_user: name: ubuntu groups: users lock_passwd: false sudo: ALL=(ALL) NOPASSWD:ALL plain_text_passwd: 'ubuntu' homedir: /home/ubuntu shell: /bin/bash Network Dataï¼š 1234567891011network: version: 2 ethernets: enp1s0: dhcp4: false dhcp6: false addresses: - 172.16.16.132/24 routes: - to: default via: 172.16.16.1 åˆ›å»º VM åˆ›å»ºåï¼Œå³å¯ ssh åˆ°è™šæ‹Ÿæœºä¸­ï¼š ä½¿ç”¨ Harvester åˆ›å»º RKE2 é›†ç¾¤","link":"/2025/01/14/Harvester-%E4%BD%BF%E7%94%A8%E9%9A%8F%E8%AE%B0/"},{"title":"Istio ä½¿ç”¨éšè®°","text":"Istio æ˜¯ä¸€ç§å¼€æºæœåŠ¡ç½‘æ ¼ï¼Œä½¿ç”¨ä»£ç†æ‹¦æˆªæ‰€æœ‰ç½‘ç»œæµé‡ï¼Œå¯æ ¹æ®é…ç½®æä¾›å¹¿æ³›çš„åº”ç”¨ç¨‹åºæ„ŸçŸ¥åŠŸèƒ½ã€‚ å¸¸è§çš„ CRDï¼š VirtualServiceï¼šå®šä¹‰æœåŠ¡é—´æˆ–æœåŠ¡è‡³å¤–éƒ¨æµé‡çš„è·¯ç”±è§„åˆ™ï¼Œæ”¯æŒè¯·æ±‚åŒ¹é…ã€è·¯ç”±é€‰æ‹©ã€æµé‡åˆ†å‰²ã€é‡è¯•ã€è¶…æ—¶ç­‰ç­–ç•¥ã€‚ DestinationRuleï¼šå®šä¹‰ç›®æ ‡æœåŠ¡çš„æµé‡ç­–ç•¥ï¼Œæ¯”å¦‚è´Ÿè½½å‡è¡¡ã€è¿æ¥æ± ã€TLS é…ç½®ç­‰ã€‚æ¯ä¸ªç›®æ ‡æœåŠ¡çš„æµé‡ç­–ç•¥é€šè¿‡ DestinationRule é…ç½®åï¼Œå¯¹æ‰€æœ‰è¯·æ±‚ç”Ÿæ•ˆã€‚ Gatewayï¼šé…ç½®è¾¹ç¼˜ç½‘å…³çš„å…¥å£æµé‡è§„åˆ™ï¼Œä¾‹å¦‚å®šä¹‰å¤–éƒ¨æµé‡å¦‚ä½•è¿›å…¥æœåŠ¡ç½‘æ ¼ã€‚å®ƒå¯ä»¥ç”¨äº HTTPã€HTTPSã€TLS å’Œ TCP æµé‡ã€‚ ServiceEntryï¼šå°†å¤–éƒ¨æœåŠ¡å¼•å…¥åˆ° Istio ç½‘æ ¼ä¸­ï¼Œå…è®¸ Istio ç®¡ç†å’Œç›‘æ§è¿™äº›æœåŠ¡çš„æµé‡ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ä½¿ç”¨ ServiceEntry æ¥å¼•å…¥å¤–éƒ¨ APIï¼Œä½¿ç½‘æ ¼ä¸­çš„æœåŠ¡å¯ä»¥é€æ˜åœ°ä¸å¤–éƒ¨æœåŠ¡äº¤äº’ã€‚ åˆ›å»ºä¸€ä¸ª Nginxï¼Œç”¨äºæµ‹è¯•ï¼š 12kubectl create deployment nginx --image=nginx:mainlinekubectl expose deployment nginx --port=80 åˆ›å»º Gatewayï¼š selector åŒ¹é… istio-ingressgateway éƒ¨ç½²çš„ Podï¼Œé€šè¿‡è¯¥ç½‘å…³æ¥æ¥æ”¶å¤–éƒ¨æµé‡ã€‚ 12345678910111213141516apiVersion: networking.istio.io/v1beta1kind: Gatewaymetadata: name: http-gateway namespace: istio-systemspec: selector: # select the istio ingressgateway istio: ingressgateway servers: - hosts: - test.nginx.com port: name: http number: 80 protocol: HTTP åˆ›å»º VirtualServiceï¼š hosts å­—æ®µæŒ‡å®šäº†å¯ä»¥é€šè¿‡ test.nginx.com ä¸»æœºåè®¿é—®è¯¥æœåŠ¡çš„å¤–éƒ¨è¯·æ±‚ï¼Œæµé‡é€šè¿‡å®šä¹‰çš„ Gateway è¿›å…¥ã€‚VirtualService çš„ route å­—æ®µå°†æµé‡è·¯ç”±åˆ° nginx.default.svc.cluster.localã€‚ 1234567891011121314151617apiVersion: networking.istio.io/v1beta1kind: VirtualServicemetadata: name: nginx-virtualservice namespace: defaultspec: gateways: # select the gateway created above - http-gateway.istio-system.svc.cluster.local hosts: - test.nginx.com http: - route: - destination: host: nginx.default.svc.cluster.local port: number: 80 åˆ›å»º DestinationRuleï¼š trafficPolicy ä¸­å®šä¹‰äº†è´Ÿè½½å‡è¡¡ç­–ç•¥ä¸º LEAST_CONNï¼Œå³æœ€å°è¿æ¥æ•°ç­–ç•¥ã€‚DestinationRule çš„ host å¿…é¡»åŒ¹é… VirtualService ä¸­çš„ destinationã€‚ 12345678910apiVersion: networking.istio.io/v1beta1kind: DestinationRulemetadata: name: nginx-destination-rule namespace: defaultspec: host: nginx.default.svc.cluster.local trafficPolicy: loadBalancer: simple: LEAST_CONN é€šè¿‡ Istio Ingress Gateway è®¿é—® Nginxï¼š 1curl -H &quot;Host: test.nginx.com&quot; http://&lt;istio-ingressgateway-cluster-ip&gt;/","link":"/2024/11/08/Istio-%E4%BD%BF%E7%94%A8%E9%9A%8F%E8%AE%B0/"},{"title":"Docker éƒ¨ç½² Rancher æŒ‡å®šé•œåƒä»“åº“","text":"docker å¯åŠ¨çš„ rancher é»˜è®¤ä¼šèµ°å…¬ç½‘è·å–é•œåƒï¼Œæ·»åŠ äº† CATTLE_SYSTEM_DEFAULT_REGISTRY çš„è¯ï¼Œhelm-operation ä½¿ç”¨çš„ rancher/shell ç­‰è¿˜æ˜¯ä¼šèµ°åˆ°å…¬ç½‘ï¼Œå¦‚æœè¦æ‰€æœ‰é•œåƒéƒ½æ˜¯ç”¨ private registryï¼Œå¯ä»¥é€šè¿‡ä¸‹é¢çš„æ–¹å¼ã€‚ å‡†å¤‡ private registry è®¤è¯çš„é…ç½®æ–‡ä»¶å’Œ k3s é…ç½®æ–‡ä»¶ï¼š 123456789101112131415mkdir -p /etc/rancher/k3scat &lt;&lt;EOF &gt; /etc/rancher/k3s/registries.yamlconfigs: &quot;harbor.warnerchen.com&quot;: auth: username: xxx password: xxx tls: insecure_skip_verify: trueEOFcat &lt;&lt;EOF &gt; /etc/rancher/k3s/config.yamlsystem-default-registry: harbor.warnerchen.comEOF å¯åŠ¨ rancherï¼š 123456789docker run -d --restart=unless-stopped --name rancher \\ -v /var/lib/rancher:/var/lib/rancher \\ -v /etc/rancher/k3s/registries.yaml:/etc/rancher/k3s/registries.yaml:ro \\ -v /etc/rancher/k3s/config.yaml:/etc/rancher/k3s/config.yaml:ro \\ -e CATTLE_BOOTSTRAP_PASSWORD=xxx \\ -e CATTLE_SYSTEM_DEFAULT_REGISTRY=harbor.warnerchen.com \\ -p 80:80 -p 443:443 \\ --privileged \\ harbor.warnerchen.com/prime/rancher:v2.7.15-ent","link":"/2024/11/28/Docker-%E9%83%A8%E7%BD%B2-Rancher-%E6%8C%87%E5%AE%9A%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/"},{"title":"NeuVector çš„ Zero Draft ä¸ Basic æ¨¡å¼","text":"NeuVector æœ‰ Zero-drift å’Œ Basic ä¸¤ç§æ¨¡å¼ï¼Œè€Œ Zero-drift æ¨¡å¼æ˜¯é»˜è®¤æ¨¡å¼ï¼Œæ ¹æ®ä¸€ä¸ª Nginx æ¥ä½œä¸ºæµ‹è¯•æ¡ˆä¾‹ï¼Œè§‚å¯Ÿä¸¤ç§æ¨¡å¼ä¸‹ Process Profile Rules çš„æ•ˆæœã€‚ Zero-drift æ¨¡å¼Discoveråœ¨ Discover ä¸‹ï¼ŒNV ä¼šè‡ªåŠ¨å­¦ä¹ å®¹å™¨è¿è¡Œä¸­çš„è¿›ç¨‹å¹¶ç”Ÿæˆ Process Profile Rules è‹¥å‘ç°æœªæˆæƒè¿›ç¨‹ï¼Œä¼šè§¦å‘å‘Šè­¦ ä½†ä¸è‡ªåŠ¨ç”Ÿæˆ File Access Rulesï¼Œåªæœ‰åœ¨ç³»ç»Ÿé»˜è®¤ç›‘æ§çš„ç›®å½•å†…è¿›è¡Œæ–‡ä»¶å¢åˆ æ”¹æŸ¥ç­‰åŠ¨ä½œæ‰ä¼šè§¦å‘å‘Šè­¦ MonitorMonitor ä¸ Discover ç±»ä¼¼ï¼Œä»»ä½•ä¸ç¬¦åˆ Process Profile Rules çš„æ´»åŠ¨éƒ½ä¼šå‘å‡ºè­¦å‘Šï¼Œä½†ä¸ä¼šé˜»æ­¢æ“ä½œ Protectåœ¨ Protect ä¸‹ï¼Œå¯¹æœªè¢«æˆæƒçš„è¿›ç¨‹å’Œæ–‡ä»¶æ´»åŠ¨è¿›è¡Œå¼ºåˆ¶é˜»æ­¢å¹¶å‘å‡ºå‘Šè­¦ 123root@test:~# kubectl exec -it nginx-57b989859-bbh9j -- bashexec /usr/bin/bash: operation not permittedcommand terminated with exit code 1 Basic æ¨¡å¼Discoverä¸ Zero-drift ç±»ä¼¼ï¼Œä¼šå­¦ä¹ å®¹å™¨è¿›ç¨‹ï¼Œä½†ä¸ä¼šå¯¹å®¹å™¨ä¸­çš„æ–°è¿›ç¨‹å‘å‡ºå‘Šè­¦ï¼Œåè€Œä¼šè‡ªåŠ¨å­¦ä¹ è¿™äº›æ–°è¿›ç¨‹ï¼Œä¹Ÿå°±æ˜¯è¯´åœ¨è¯¥æ¨¡å¼ä¸‹æ‰€æœ‰çš„è¿›ç¨‹æ´»åŠ¨éƒ½æ˜¯è¢«å…è®¸çš„ï¼›æ–‡ä»¶ç›‘æ§çš„è§„åˆ™ä¸ Zero-drift ç›¸åŒä¸ä¼šè‡ªåŠ¨ç”Ÿæˆ Monitorä¸ä¼šå­¦ä¹ æ–°è¿›ç¨‹ï¼Œä»»ä½•æœªè¢«å…è®¸çš„è¿›ç¨‹æ´»åŠ¨éƒ½ä¼šè§¦å‘å‘Šè­¦ Protectè¡Œä¸ºä¸ Zero-drift Protect ç›¸åŒï¼Œç¦æ­¢ä»»ä½•æœªè¢«å…è®¸çš„è¿›ç¨‹æ´»åŠ¨ï¼Œå¹¶è§¦å‘å‘Šè­¦ ç»“è®ºNeuVector çš„ Zero-drift æ¨¡å¼å’Œ Basic æ¨¡å¼ä¸»è¦åŒºåˆ«åœ¨äº Discover æ¨¡å¼ä¸‹çš„è¡Œä¸ºã€‚Zero-drift æ›´ä¸ºä¸¥æ ¼ï¼Œç¡®ä¿å®¹å™¨ä»…è¿è¡Œé•œåƒä¸­å®šä¹‰çš„è¿›ç¨‹ï¼Œä¸å…è®¸ä»»ä½•æ–°çš„è¿›ç¨‹è¿è¡Œã€‚è€Œ Basic æ¨¡å¼åˆ™æ›´çµæ´»ï¼Œå…è®¸ NeuVector å­¦ä¹ å®¹å™¨å†…çš„æ–°è¿›ç¨‹ï¼Œå¹¶æ ¹æ®è¿™äº›æ–°æ´»åŠ¨è‡ªåŠ¨ç”Ÿæˆè§„åˆ™ã€‚ä¸¤ç§æ¨¡å¼åœ¨ Monitor å’Œ Protect æ¨¡å¼ä¸‹éƒ½ä¼šå¯¹å®¹å™¨çš„è¿›ç¨‹å’Œæ–‡ä»¶æ´»åŠ¨è¿›è¡Œç›‘æ§å’Œé˜²æŠ¤ã€‚ Zero-drift æ¨¡å¼ Discoverï¼šZero-drift ä¼šè‡ªåŠ¨åˆ†æå’Œå­¦ä¹ å®¹å™¨é•œåƒä¸­å…è®¸çš„è¿›ç¨‹ï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆ Process Profile Rulesï¼Œç¡®ä¿å®¹å™¨åªè¿è¡Œåœ¨é•œåƒå†…å®šä¹‰çš„è¿›ç¨‹ã€‚å¦‚æœå®¹å™¨å†…æœ‰å…¶ä»–éé•œåƒå®šä¹‰çš„è¿›ç¨‹å¯åŠ¨ï¼ŒNeuVector ä¼šå‘å‡ºå‘Šè­¦ã€‚æ–‡ä»¶è®¿é—®ç›‘æ§åˆ™åªé’ˆå¯¹ NV é»˜è®¤çš„ç›‘æ§ç›®å½•ï¼Œä¸”ä¸ä¼šè‡ªåŠ¨ç”Ÿæˆ File Access Rulesã€‚è¿™ç§æ¨¡å¼æ›´ä¸¥æ ¼åœ°æ§åˆ¶å®¹å™¨è¡Œä¸ºï¼Œå°¤å…¶é€‚ç”¨äºéœ€è¦é«˜å®‰å…¨æ€§çš„åœºæ™¯ã€‚ Monitorï¼šå’Œ Discover ç›¸ä¼¼ï¼ŒNeuVector ä¼šæŒç»­ç›‘æ§å®¹å™¨å†…çš„è¿›ç¨‹å’Œæ–‡ä»¶æ´»åŠ¨ï¼Œä½†ä¸ä¼šé˜»æ­¢æ´»åŠ¨ï¼Œåªä¼šå‘å‡ºè­¦å‘Šã€‚å¦‚æœæœ‰ä»»ä½•ä¸è§„åˆ™ä¸åŒ¹é…çš„è¿›ç¨‹æˆ–æ–‡ä»¶æ“ä½œï¼Œéƒ½ä¼šè§¦å‘å‘Šè­¦ã€‚ Protectï¼šåœ¨ Protect ä¸‹ï¼ŒZero-drift ä¼šé˜»æ­¢ä»»ä½•ä¸è§„åˆ™ä¸åŒ¹é…çš„è¿›ç¨‹æˆ–æ–‡ä»¶æ“ä½œï¼Œç¡®ä¿å®¹å™¨è¿è¡Œç¯å¢ƒçš„å®‰å…¨ã€‚å¦‚æœå‘ç°æœªæˆæƒçš„è¿›ç¨‹æˆ–æ–‡ä»¶æ´»åŠ¨ï¼ŒNeuVector ä¼šç«‹å³é˜»æ­¢å¹¶å‘å‡ºå‘Šè­¦ã€‚ Basic æ¨¡å¼ Discoverï¼šBasic æ¨¡å¼ä¹Ÿä¼šè‡ªåŠ¨å­¦ä¹ å®¹å™¨è¿è¡Œçš„è¿›ç¨‹ï¼Œå¹¶ç”Ÿæˆ Process Profile Rulesï¼Œä½†ä¸ Zero-drift æ¨¡å¼ä¸åŒï¼ŒBasic æ¨¡å¼ä¸ä¼šé™åˆ¶æ–°è¿›ç¨‹çš„è¿è¡Œï¼Œå³ä¾¿æœ‰éé•œåƒå®šä¹‰çš„è¿›ç¨‹å¯åŠ¨ï¼ŒNeuVector ä¹Ÿä¸ä¼šç«‹å³å‘å‡ºå‘Šè­¦ï¼Œåè€Œä¼šè‡ªåŠ¨å­¦ä¹ è¿™äº›æ–°è¿›ç¨‹ï¼Œåˆ›å»ºç›¸åº”çš„è§„åˆ™ã€‚æ–‡ä»¶ç›‘æ§çš„è§„åˆ™åˆ™ä¸ Zero-drift æ¨¡å¼ç›¸åŒï¼Œä¾èµ–äºç³»ç»Ÿé»˜è®¤çš„ç›‘æ§ç›®å½•ã€‚è¯¥æ¨¡å¼æ›´çµæ´»ï¼Œé€‚ç”¨äºéœ€è¦åŠ¨æ€è°ƒæ•´å®¹å™¨è¿›ç¨‹çš„åœºæ™¯ã€‚ Monitorï¼šåœ¨ Monitor ä¸‹ï¼ŒBasic æ¨¡å¼ä¸å†ç»§ç»­å­¦ä¹ æ–°çš„è¿›ç¨‹æ´»åŠ¨ï¼Œä»»ä½•æœªç»æˆæƒçš„è¿›ç¨‹æ“ä½œéƒ½ä¼šè§¦å‘å‘Šè­¦ã€‚ Protectï¼šåœ¨ Protect ä¸‹ï¼ŒBasic æ¨¡å¼å’Œ Zero-drift æ¨¡å¼çš„è¡Œä¸ºä¸€è‡´ï¼ŒNeuVector ä¼šé˜»æ­¢ä»»ä½•æœªè¢«æˆæƒçš„è¿›ç¨‹å’Œæ–‡ä»¶æ´»åŠ¨ï¼Œå¹¶å‘å‡ºå‘Šè­¦ã€‚","link":"/2024/10/21/NeuVector-%E7%9A%84-Zero-Draft-%E4%B8%8E-Basic-%E6%A8%A1%E5%BC%8F/"},{"title":"Ollama + Open WebUI ä½¿ç”¨éšè®°","text":"Ollama æ˜¯ç®€åŒ–æœ¬åœ°è®¾å¤‡ä¸Šå¤§å‹è¯­è¨€æ¨¡å‹ (LLM) å®‰è£…å’Œç®¡ç†çš„å¹³å°ï¼Œè€Œ Open WebUI æ˜¯ Ollama LLM è¿è¡Œç¨‹åºçš„å¯æ‰©å±•ç½‘ç»œç”¨æˆ·ç•Œé¢ã€‚ Ollamaåœ¨ Kubernetes ä¸Šéƒ¨ç½² Ollamaï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566helm repo add ollama-helm https://otwld.github.io/ollama-helm/helm repo updatecat &lt;&lt;EOF &gt; ollama-values.yamlreplicaCount: 1knative: enabled: falseimage: repository: ollama/ollama pullPolicy: IfNotPresentollama: gpu: enabled: true type: 'nvidia' number: 1 nvidiaResource: &quot;nvidia.com/gpu&quot; mig: enabled: false models: pull: [] run: [] create: [] insecure: falseserviceAccount: create: true automount: trueruntimeClassName: &quot;nvidia&quot;service: type: ClusterIP port: 11434 nodePort: 31434 loadBalancerIP:ingress: enabled: falselivenessProbe: enabled: true path: / initialDelaySeconds: 60 periodSeconds: 10 timeoutSeconds: 5 failureThreshold: 6 successThreshold: 1readinessProbe: enabled: true path: / initialDelaySeconds: 30 periodSeconds: 5 timeoutSeconds: 3 failureThreshold: 6 successThreshold: 1autoscaling: enabled: falsepersistentVolume: enabled: true accessModes: - ReadWriteOnce size: 10Gi storageClass: &quot;longhorn&quot;updateStrategy: type: &quot;Recreate&quot;hostIPC: falsehostPID: falsehostNetwork: falseEOFhelm -n ollama upgrade --install ollama ollama-helm/ollama -f ollama-values.yaml --version 1.7.0 ä¸‹è½½ deepseek-r1:1.5b æ¨¡å‹å¹¶è¿è¡Œï¼š è°ƒç”¨ API è¿è¡Œï¼š 1234567891011121314151617181920212223242526272829303132333435root@rke2-cilium-01:~/ai-related# curl -s -X POST http://&lt;ollama-svc-ip&gt;:11434/api/generate -d '{ &quot;model&quot;: &quot;deepseek-r1:1.5b&quot;, &quot;prompt&quot;: &quot;ä½ å¥½?&quot;, &quot;stream&quot;: false }' | jq{ &quot;model&quot;: &quot;deepseek-r1:1.5b&quot;, &quot;created_at&quot;: &quot;2025-02-27T04:46:43.19616833Z&quot;, &quot;response&quot;: &quot;&lt;think&gt;\\n\\n&lt;/think&gt;\\n\\næ‚¨å¥½ï¼å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„ï¼Ÿ&quot;, &quot;done&quot;: true, &quot;done_reason&quot;: &quot;stop&quot;, &quot;context&quot;: [ 151644, 108386, 30, 151645, 151648, 271, 151649, 271, 111308, 6313, 112169, 102804, 47874, 1773, 109194, 104139, 111728, 101214, 11319 ], &quot;total_duration&quot;: 3243229672, &quot;load_duration&quot;: 2905513629, &quot;prompt_eval_count&quot;: 5, &quot;prompt_eval_duration&quot;: 82000000, &quot;eval_count&quot;: 16, &quot;eval_duration&quot;: 253000000} Open WebUIåœ¨ Kubernetes ä¸Šéƒ¨ç½² Open WebUIï¼š 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152helm repo add open-webui https://helm.openwebui.com/helm repo updatecat &lt;&lt;EOF &gt; open-webui-values.yamlollama: enabled: false fullnameOverride: &quot;open-webui-ollama&quot;pipelines: enabled: falsetika: enabled: falseollamaUrls: - http://ollama.ollama.svc.cluster.local:11434ollamaUrlsFromExtraEnv: falsewebsocket: enabled: falseredis-cluster: enabled: falseclusterDomain: cluster.localreplicaCount: 1image: repository: harbor.warnerchen.com/open-webui/open-webui pullPolicy: &quot;IfNotPresent&quot;serviceAccount: enable: true automountServiceAccountToken: falsemanagedCertificate: enabled: falseingress: enabled: true class: &quot;nginx&quot; tls: false host: &quot;open-webui.warnerchen.com&quot;persistence: enabled: true size: 2Gi accessModes: - ReadWriteOnce storageClass: &quot;longhorn&quot;service: type: ClusterIP port: 80 containerPort: 8080openaiBaseApiUrl: &quot;https://api.openai.com/v1&quot;extraEnvVars: - name: OPENAI_API_KEY value: &quot;0p3n-w3bu!&quot; - name: WEBUI_AUTH value: &quot;False&quot;EOFhelm -n ollama upgrade --install open-webui open-webui/open-webui -f open-webui-values.yaml --version 5.20.0 è®¿é—® Open WebUIï¼š","link":"/2025/02/27/Ollama-Open-WebUI-%E4%BD%BF%E7%94%A8%E9%9A%8F%E8%AE%B0/"},{"title":"K8sç»™å‘½åç©ºé—´è®¾ç½®ä¸“äº«èŠ‚ç‚¹","text":"æ˜¯æŒ‡åœ¨ç‰¹å®šå‘½åç©ºé—´ä¸‹éƒ¨ç½²çš„ Pod éƒ½ä¼šè¢«è°ƒåº¦åˆ°æŒ‡å®šæ ‡ç­¾çš„èŠ‚ç‚¹ä¸Šï¼Œè¿™ä¸ªåŠŸèƒ½éœ€è¦åœ¨ kube-apiserver æ·»åŠ  PodNodeSelector å‚æ•°ï¼š 1234567891011apiVersion: v1kind: Podmetadata: labels: component: kube-apiserver tier: control-plane name: kube-apiserver namespace: kube-system... - --enable-admission-plugins=NodeRestriction,PodNodeSelector... ç„¶åç»™å‘½åç©ºé—´æ·»åŠ  annotation 12345apiVersion: v1kind: Namespacemetadata: annotations: scheduler.alpha.kubernetes.io/node-selector: test.io/app=true","link":"/2024/03/30/K8s%E7%BB%99%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4%E8%AE%BE%E7%BD%AE%E4%B8%93%E4%BA%AB%E8%8A%82%E7%82%B9/"},{"title":"Podæ˜¯æ€ä¹ˆè¯ç”Ÿçš„","text":"K8s æœ¬èº«ä¸æä¾›å®¹å™¨åˆ›å»ºçš„å®ç°ï¼Œå®¹å™¨çš„åˆ›å»ºæ˜¯é€šè¿‡ CRI æ¥å£è°ƒç”¨å¤–éƒ¨æ’ä»¶å®ç°çš„ï¼Œå¸¸è§çš„ CRI æœ‰è¿™å‡ ç§: docker containerd cri-dockerd Pod æ˜¯å¦‚ä½•è¢«åˆ›å»ºå‡ºæ¥çš„ å®¢æˆ·ç«¯é€šè¿‡ kubectl ç­‰å°†åˆ›å»º pod çš„è¯·æ±‚å‘é€ç»™ kube-apiserver kube-apiserver å°† pod ä¿¡æ¯å†™å…¥ etcdï¼Œetcd å°†å†™å…¥çš„ç»“æœè¿”å›ç»™ kube-apiserverï¼Œç„¶å kube-apiserver å†è¿”å›ç»™å®¢æˆ·ç«¯ kube-scheduler é€šè¿‡ kube-apiserver çš„ watch æ¥å£ï¼Œè·å–åˆ°æœªè¢«è°ƒåº¦çš„ pod ä¿¡æ¯ï¼Œæ ¹æ®è°ƒåº¦ç®—æ³•é€‰æ‹©é›†ç¾¤å†…çš„ä¸€ä¸ªèŠ‚ç‚¹ï¼Œç„¶åå°†èŠ‚ç‚¹ä¿¡æ¯å‘é€ç»™ kube-apiserver kube-apiserver å°†è¿™ä¸ª pod å’ŒèŠ‚ç‚¹çš„ç»‘å®šä¿¡æ¯å†™å…¥åˆ° etcdï¼Œetcd å°†ç»“æœè¿”å›ç»™ kube-apiserver kubelet é€šè¿‡ kube-apiserver çš„ watch æ¥å£ï¼Œè·å–åˆ°æœ¬èŠ‚ç‚¹æœ‰åˆ›å»º pod çš„ä¿¡æ¯ï¼Œç„¶åä¼šè°ƒç”¨ CRI åˆ›å»ºå®¹å™¨ï¼Œå¹¶å°† pod çš„è¿è¡ŒçŠ¶æ€å‘é€ç»™ kube-apiserver kube-apiserver å°† pod çŠ¶æ€ä¿¡æ¯æ›´æ–°åˆ° etcd","link":"/2024/03/11/Pod%E6%98%AF%E6%80%8E%E4%B9%88%E8%AF%9E%E7%94%9F%E7%9A%84/"},{"title":"RKE1 ETCD å‡ºç° request cluster id mismatch é—®é¢˜ä¿®å¤è®°å½•","text":"å½“é›†ç¾¤ä¸­ä¸‰ä¸ª Control Plane èŠ‚ç‚¹çš„ ETCD å‡ºç° request cluster ID mismatch é—®é¢˜æ—¶ï¼Œå¯ä»¥ä¿ç•™ä¸€ä¸ª ETCD å®ä¾‹é€šè¿‡ --force-new-cluster å‚æ•°é‡å»ºé›†ç¾¤ï¼Œç„¶åå†å°†å…¶ä»–ä¸¤ä¸ªèŠ‚ç‚¹çš„ ETCD å®ä¾‹åŠ å…¥é›†ç¾¤ã€‚ é€šè¿‡ docker rename çš„æ–¹å¼ä¿ç•™ç¬¬äºŒ/ä¸‰å° Control Plane èŠ‚ç‚¹çš„ ETCD 12docker stop etcddocker rename etcd etcd-old å¤‡ä»½ç¬¬ä¸€å° Control Plane èŠ‚ç‚¹çš„ ETCD å¯åŠ¨å‘½ä»¤ 1234docker run --rm -v /var/run/docker.sock:/var/run/docker.sock assaflavie/runlike:latest etcd# ä»¥ä¸‹ä¸º ETCD å¯åŠ¨å‘½ä»¤docker run --name=etcd --hostname=test001 --env=ETCDCTL_API=3 --env=ETCDCTL_CACERT=/etc/kubernetes/ssl/kube-ca.pem --env=ETCDCTL_CERT=/etc/kubernetes/ssl/kube-etcd-172-16-0-106.pem --env=ETCDCTL_KEY=/etc/kubernetes/ssl/kube-etcd-172-16-0-106-key.pem --env=ETCDCTL_ENDPOINTS=https://127.0.0.1:2379 --env=ETCD_UNSUPPORTED_ARCH=x86_64 --volume=/var/lib/etcd:/var/lib/rancher/etcd/:z --volume=/etc/kubernetes:/etc/kubernetes:z --network=host --restart=always --label='io.rancher.rke.container.name=etcd' --runtime=runc --detach=true registry.cn-hangzhou.aliyuncs.com/rancher/mirrored-coreos-etcd:v3.4.15-rancher1 /usr/local/bin/etcd --listen-peer-urls=https://0.0.0.0:2380 --trusted-ca-file=/etc/kubernetes/ssl/kube-ca.pem --peer-trusted-ca-file=/etc/kubernetes/ssl/kube-ca.pem --key-file=/etc/kubernetes/ssl/kube-etcd-172-16-0-106-key.pem --peer-cert-file=/etc/kubernetes/ssl/kube-etcd-172-16-0-106.pem --peer-key-file=/etc/kubernetes/ssl/kube-etcd-172-16-0-106-key.pem --peer-client-cert-auth=true --initial-advertise-peer-urls=https://172.16.0.106:2380 --heartbeat-interval=500 --cert-file=/etc/kubernetes/ssl/kube-etcd-172-16-0-106.pem --advertise-client-urls=https://172.16.0.106:2379 --cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 --initial-cluster=etcd-rke1-server-0=https://172.16.0.106:2380,etcd-rke1-server-1=https://172.16.0.105:2380,etcd-rke1-server-2=https://172.16.0.104:2380 --initial-cluster-state=new --client-cert-auth=true --listen-client-urls=https://0.0.0.0:2379 --initial-cluster-token=etcd-cluster-1 --name=etcd-rke1-server-0 --enable-v2=true --election-timeout=5000 --data-dir=/var/lib/rancher/etcd/ åœæ­¢ç¬¬ä¸€å° Control Plane èŠ‚ç‚¹çš„ ETCD 12docker stop etcddocker rename etcd etcd-old ä¿®æ”¹å…ˆå‰ä¿å­˜çš„ ETCD å¯åŠ¨å‘½ä»¤ï¼Œåœ¨ initial-cluster å‚æ•°ä¸­åˆ é™¤ç¬¬äºŒ/ä¸‰å° Control Plane èŠ‚ç‚¹çš„ ETCD ä¿¡æ¯ï¼Œå¹¶åœ¨æœ€åæ·»åŠ  --force-new-cluster å‚æ•°ï¼Œç„¶åæ‰§è¡Œï¼Œå¦‚æœå¯åŠ¨åä»ç„¶æŠ¥ request cluster ID mismatch çš„é”™è¯¯ï¼Œå¯ä»¥é‡å¤å¤šå‡ æ¬¡ 1docker run --name=etcd --hostname=test001 --env=ETCDCTL_API=3 --env=ETCDCTL_CACERT=/etc/kubernetes/ssl/kube-ca.pem --env=ETCDCTL_CERT=/etc/kubernetes/ssl/kube-etcd-172-16-0-106.pem --env=ETCDCTL_KEY=/etc/kubernetes/ssl/kube-etcd-172-16-0-106-key.pem --env=ETCDCTL_ENDPOINTS=https://127.0.0.1:2379 --env=ETCD_UNSUPPORTED_ARCH=x86_64 --volume=/var/lib/etcd:/var/lib/rancher/etcd/:z --volume=/etc/kubernetes:/etc/kubernetes:z --network=host --restart=always --label='io.rancher.rke.container.name=etcd' --runtime=runc --detach=true registry.cn-hangzhou.aliyuncs.com/rancher/mirrored-coreos-etcd:v3.4.15-rancher1 /usr/local/bin/etcd --listen-peer-urls=https://0.0.0.0:2380 --trusted-ca-file=/etc/kubernetes/ssl/kube-ca.pem --peer-trusted-ca-file=/etc/kubernetes/ssl/kube-ca.pem --key-file=/etc/kubernetes/ssl/kube-etcd-172-16-0-106-key.pem --peer-cert-file=/etc/kubernetes/ssl/kube-etcd-172-16-0-106.pem --peer-key-file=/etc/kubernetes/ssl/kube-etcd-172-16-0-106-key.pem --peer-client-cert-auth=true --initial-advertise-peer-urls=https://172.16.0.106:2380 --heartbeat-interval=500 --cert-file=/etc/kubernetes/ssl/kube-etcd-172-16-0-106.pem --advertise-client-urls=https://172.16.0.106:2379 --cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 --initial-cluster=etcd-rke1-server-0=https://172.16.0.106:2380 --initial-cluster-state=new --client-cert-auth=true --listen-client-urls=https://0.0.0.0:2379 --initial-cluster-token=etcd-cluster-1 --name=etcd-rke1-server-0 --enable-v2=true --election-timeout=5000 --data-dir=/var/lib/rancher/etcd/ --force-new-cluster å¯åŠ¨å®Œæ¯•åæ£€æŸ¥ ETCD é›†ç¾¤çŠ¶æ€ 12docker exec -it -e ETCDCTL_API=3 etcd etcdctl member list -w tabledocker exec -it -e ETCDCTL_API=3 etcd etcdctl endpoint status --cluster -w table åœ¨ç¬¬ä¸€å° Control Plane èŠ‚ç‚¹ä¸Šæ·»åŠ  ETCD Member 123456789MEMBER_IP=172.16.0.105MEMBER_NAME=&quot;rke1-server-1&quot;docker exec -it etcd etcdctl member add etcd-$MEMBER_NAME --peer-urls=https://$MEMBER_IP:2380# æ‰§è¡Œå®Œå‘½ä»¤åï¼Œä¸‹é¢çš„é…ç½®éœ€è¦ä¿ç•™ï¼Œåç»­èŠ‚ç‚¹å¯åŠ¨ ETCD æ—¶éœ€è¦ä½¿ç”¨ETCD_NAME=&quot;etcd-rke1-server-1&quot;ETCD_INITIAL_CLUSTER=&quot;etcd-rke1-server-0=https://172.16.0.106:2380,etcd-rke1-server-1=https://172.16.0.105:2380&quot;ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://172.16.0.105:2380&quot;ETCD_INITIAL_CLUSTER_STATE=&quot;existing&quot; ç„¶ååœ¨ç¬¬äºŒå° Control Plane èŠ‚ç‚¹ï¼Œè¿›è¡Œæ¢å¤ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# å¤‡ä»½æ•°æ®mv /var/lib/etcd /var/lib/etcd_bak# è®¾ç½®å˜é‡NODE_IP=172.16.0.105ETCD_IMAGE=registry.cn-hangzhou.aliyuncs.com/rancher/mirrored-coreos-etcd:v3.4.15-rancher1ETCD_NAME=&quot;etcd-rke1-server-1&quot;ETCD_INITIAL_CLUSTER=&quot;etcd-rke1-server-0=https://172.16.0.106:2380,etcd-rke1-server-1=https://172.16.0.105:2380&quot;ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://172.16.0.105:2380&quot;ETCD_INITIAL_CLUSTER_STATE=&quot;existing&quot;# å¯åŠ¨ ETCDdocker run --name=etcd --hostname=`hostname` \\--env=&quot;ETCDCTL_API=3&quot; \\--env=&quot;ETCDCTL_CACERT=/etc/kubernetes/ssl/kube-ca.pem&quot; \\--env=&quot;ETCDCTL_CERT=/etc/kubernetes/ssl/kube-etcd-`echo $NODE_IP|sed 's/\\./-/g'`.pem&quot; \\--env=&quot;ETCDCTL_KEY=/etc/kubernetes/ssl/kube-etcd-`echo $NODE_IP|sed 's/\\./-/g'`-key.pem&quot; \\--env=&quot;ETCDCTL_ENDPOINTS=https://127.0.0.1:2379&quot; \\--env=&quot;ETCD_UNSUPPORTED_ARCH=x86_64&quot; \\--env=&quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot; \\--volume=&quot;/var/lib/etcd:/var/lib/rancher/etcd/:z&quot; \\--volume=&quot;/etc/kubernetes:/etc/kubernetes:z&quot; \\--network=host \\--restart=always \\--label io.rancher.rke.container.name=&quot;etcd&quot; \\--detach=true \\$ETCD_IMAGE \\/usr/local/bin/etcd \\--peer-client-cert-auth \\--client-cert-auth \\--peer-cert-file=/etc/kubernetes/ssl/kube-etcd-`echo $NODE_IP|sed 's/\\./-/g'`.pem \\--peer-key-file=/etc/kubernetes/ssl/kube-etcd-`echo $NODE_IP|sed 's/\\./-/g'`-key.pem \\--cert-file=/etc/kubernetes/ssl/kube-etcd-`echo $NODE_IP|sed 's/\\./-/g'`.pem \\--trusted-ca-file=/etc/kubernetes/ssl/kube-ca.pem \\--initial-cluster-token=etcd-cluster-1 \\--peer-trusted-ca-file=/etc/kubernetes/ssl/kube-ca.pem \\--key-file=/etc/kubernetes/ssl/kube-etcd-`echo $NODE_IP|sed 's/\\./-/g'`-key.pem \\--data-dir=/var/lib/rancher/etcd/ \\--advertise-client-urls=https://$NODE_IP:2379 \\--listen-client-urls=https://0.0.0.0:2379 \\--listen-peer-urls=https://0.0.0.0:2380 \\--initial-advertise-peer-urls=https://$NODE_IP:2380 \\--election-timeout=5000 \\--heartbeat-interval=500 \\--name=$ETCD_NAME \\--initial-cluster=$ETCD_INITIAL_CLUSTER \\--initial-cluster-state=$ETCD_INITIAL_CLUSTER_STATE å¯åŠ¨å®Œåæ£€æŸ¥çŠ¶æ€ï¼Œå¦‚æœæ²¡é—®é¢˜åˆ™å¯ä»¥é‡å¤ä¸Šé¢æ­¥éª¤æ·»åŠ ç¬¬ä¸‰å°èŠ‚ç‚¹ 12docker exec -it -e ETCDCTL_API=3 etcd etcdctl member list -w tabledocker exec -it -e ETCDCTL_API=3 etcd etcdctl endpoint status --cluster -w table é›†ç¾¤çŠ¶æ€æ­£å¸¸åï¼Œæ¢å¤ç¬¬ä¸€å° Control Plane èŠ‚ç‚¹çš„ etcd 1234docker stop etcddocker rename etcd etcd-restoredocker rename etcd-old etcddocker start etcd","link":"/2024/10/24/RKE1-ETCD-%E5%87%BA%E7%8E%B0-request-cluster-id-mismatch-%E9%97%AE%E9%A2%98%E4%BF%AE%E5%A4%8D%E8%AE%B0%E5%BD%95/"},{"title":"NeuVector v5.4 ä¸ºç”¨æˆ·è®¾ç½® Fed è§’è‰²","text":"NeuVector ä» v5.4 ç‰ˆæœ¬èµ·ï¼Œé€šè¿‡ Rancher ç™»å½•åˆ° NeuVector çš„ç”¨æˆ·æ— æ³•åœ¨ NeuVector è¢«è®¾ç½®ä¸º Fed è§’è‰²ï¼Œéœ€è¦åœ¨ Rancher ä¸­è®¾ç½®å¯¹åº”çš„è§’è‰²ï¼Œä»è€Œæ˜ å°„åˆ° NeuVector ä¸­ã€‚ å¯¹äº NV åœ¨ Primary é›†ç¾¤ä¸­çš„ SSO æ˜ å°„ï¼š Global Roleï¼šget/nv-perm.all-permissions æ˜ å°„åˆ° fedReader è§’è‰²ï¼Œ*/nv-perm.all-permissions æ˜ å°„åˆ° fedAdmin è§’è‰²ã€‚ Cluster Roleï¼šget/nv-perm.all-permissions æ˜ å°„åˆ° reader è§’è‰²ï¼Œ*/nv-perm.all-permissions æ˜ å°„åˆ° admin è§’è‰²ï¼Œget/nv-perm.all-permissions,nv-perm.fed æ˜ å°„åˆ° fedReader è§’è‰²ï¼Œ*/nv-perm.all-permissions,nv-perm.fed æ˜ å°„åˆ° fedAdmin è§’è‰²ã€‚ Project Roleï¼šæ²¡æœ‰é¡¹ç›®è§’è‰²ä¼šæ˜ å°„åˆ° fedReader/fedAdmin è§’è‰²ã€‚ å¦‚æœæ˜¯éä¸» NV é›†ç¾¤ï¼Œæ˜ å°„çš„ fedReader è§’è‰²ä¼šè‡ªåŠ¨é™çº§ä¸º reader è§’è‰²ï¼ŒfedAdmin è§’è‰²ä¼šè‡ªåŠ¨é™çº§ä¸º admin è§’è‰²ã€‚ Global Roleå¦‚æœ NV éƒ¨ç½²åœ¨ä¸‹æ¸¸é›†ç¾¤ï¼Œç”±äº Global Role ä¸ä¼šè‡ªåŠ¨åŒæ­¥åˆ°ä¸‹æ¸¸é›†ç¾¤ä¸­ï¼Œæ‰€ä»¥å…ˆè¦åˆ›å»ºä¸€ä¸ª Cluster Roleï¼Œç„¶åå†é€šè¿‡ inheritedClusterRoles å­—æ®µå¼•ç”¨ã€‚ ä»¥ fedAdmin ä¸ºä¾‹ï¼Œåˆ›å»º Cluster Roleï¼š 123456789101112131415161718192021222324252627administrative: falseapiVersion: management.cattle.io/v3builtin: falseclusterCreatorDefault: falsecontext: clusterdisplayName: NeuVector Fed Administrator Cluster Roleexternal: falsehidden: falsekind: RoleTemplatelocked: falsemetadata: name: cluster-role-neuvector-fed-adminprojectCreatorDefault: falseroleTemplateNames: []rules: - apiGroups: - api.neuvector.com resources: - nv-perm.all-permissions verbs: - '*' - apiGroups: - api.neuvector.com resources: - nv-perm.fed verbs: - '*' åˆ›å»º Global Roleï¼š 12345678910apiVersion: management.cattle.io/v3description: NeuVector Fed Administrator Global RoledisplayName: NeuVector Fed Administratorkind: GlobalRolemetadata: name: global-role-neuvector-fed-admininheritedClusterRoles: - cluster-role-neuvector-fed-adminnewUserDefault: falserules: [] ç„¶åç»™ç”¨æˆ·æˆäºˆ Global Role æƒé™ï¼š åœ¨ NV ä¸­å¯ä»¥çœ‹åˆ°è§’è‰²ä¸º fedAdminï¼š Cluster Roleå¦‚æœä¸é€šè¿‡ Global Role ç»™ç”¨æˆ·è¿›è¡Œæˆæƒï¼Œå¯ä»¥ç›´æ¥åœ¨ä¸‹æ¸¸é›†ç¾¤ä½¿ç”¨åˆšåˆšåˆ›å»ºçš„ Cluster Role è¿›è¡Œæˆæƒï¼š","link":"/2025/01/03/NeuVector-v5-4-%E4%B8%BA%E7%94%A8%E6%88%B7%E8%AE%BE%E7%BD%AE-Fed-%E8%A7%92%E8%89%B2/"},{"title":"Cert Manager ä½¿ç”¨éšè®°","text":"åœ¨ Kubernetes ä¸­å¸¸ç”¨ Cert Manager ç”Ÿæˆå¹¶ç®¡ç†è‡ªç­¾åè¯ä¹¦ï¼Œå¸¸è§çš„ CR æœ‰ğŸ‘‡ Issuer: ç”¨äºå®šä¹‰å¦‚ä½•ç”Ÿæˆè¯ä¹¦ ClusterIssuer: ç”¨äºå®šä¹‰å¦‚ä½•ç”Ÿæˆé›†ç¾¤çº§åˆ«çš„è¯ä¹¦ Certificate: ç”¨æ¥è¯·æ±‚å’Œç®¡ç†è¯ä¹¦çš„ä¸»è¦èµ„æº CertificateRequest: æ˜¯ç”¨äºæ‰‹åŠ¨è¯·æ±‚è¯ä¹¦çš„èµ„æº Order: å½“ä½¿ç”¨ ACME åè®®æ—¶ä¼šç”Ÿæˆï¼Œ Challenge: æ˜¯ ACME åè®®ä¸­çš„ä¸€éƒ¨åˆ†ï¼Œç”¨äºè¡¨ç¤º ACME æœåŠ¡å¯¹åŸŸåæ‰€æœ‰æƒçš„éªŒè¯ ä¸€ä¸ªè‡ªç­¾çš„ç®€å•å®ç”¨ä¾‹å­è‡ªç­¾åç”Ÿæˆ CA è¯ä¹¦å’Œç§é’¥ 123456789# ç”Ÿæˆ CA çš„ç§é’¥openssl genrsa -out ca.key 2048# ç”Ÿæˆè‡ªç­¾åçš„ CA è¯ä¹¦openssl req -x509 -new -nodes -key ca.key -subj &quot;/CN=nginx-ca&quot; -days 3650 -out ca.crt -extensions v3_ca -config &lt;(echo &quot;[ v3_ca ]&quot;; echo &quot;basicConstraints=CA:TRUE&quot;)kubectl create secret tls tls-nginx \\ --cert=ca.crt \\ --key=ca.key é€šè¿‡ Issue åˆ›å»ºè‡ªç­¾å 12345678910cat &lt;&lt;EOF | kubectl apply -f -apiVersion: cert-manager.io/v1kind: Issuermetadata: name: nginx-issuer namespace: defaultspec: ca: secretName: tls-nginxEOF é€šè¿‡ Certificate åˆ›å»ºè¯ä¹¦è¯·æ±‚ 1234567891011121314151617cat &lt;&lt;EOF | kubectl apply -f -apiVersion: cert-manager.io/v1kind: Certificatemetadata: name: nginx-certificate namespace: defaultspec: secretName: tls-nginx duration: 24h renewBefore: 12h commonName: nginx.warnerchen.io dnsNames: - nginx.warnerchen.io issuerRef: name: nginx-issuer kind: IssuerEOF ç»™ Ingress æŒ‚è½½åï¼Œå°è¯•è¯·æ±‚","link":"/2024/09/07/Cert-Manager-%E4%BD%BF%E7%94%A8%E9%9A%8F%E8%AE%B0/"},{"title":"RKE2 Calico æŒ‡å®šç½‘å¡","text":"calico-node çš„ IP_AUTODETECTION_METHOD é»˜è®¤ä½¿ç”¨ first-foundï¼Œå¦‚æœèŠ‚ç‚¹å­˜åœ¨å¤šå¼ ç½‘å¡çš„æ—¶å€™ï¼Œå¯èƒ½å¯¼è‡´ calico-node ç»‘å®šåˆ°é”™è¯¯çš„ç½‘å¡ä¸Šï¼Œå¯¼è‡´è·¨èŠ‚ç‚¹ç½‘ç»œä¸é€šã€‚ å¯ä»¥é€šè¿‡ä¿®æ”¹ IP_AUTODETECTION_METHOD ä¸º interface æˆ–è€… cidrs æ¥æŒ‡å®š calico-node ç»‘å®šåˆ°æŒ‡å®šç½‘å¡ä¸Šã€‚ 12345678910111213141516171819cat &lt;&lt;EOF | kubectl apply -f -apiVersion: helm.cattle.io/v1kind: HelmChartConfigmetadata: name: rke2-calico namespace: kube-systemspec: valuesContent: |- global: cattle: clusterId: &quot;xxx&quot; installation: calicoNetwork: nodeAddressAutodetectionV4: interface: &quot;ens34&quot; # ä¹Ÿå¯ä»¥ä½¿ç”¨ cidrsï¼Œinterface å’Œ cidrs ä¸èƒ½åŒæ—¶ä½¿ç”¨ cidrs: - &quot;172.16.16.0/24&quot;EOF","link":"/2024/11/27/RKE2-Calico-%E6%8C%87%E5%AE%9A%E7%BD%91%E5%8D%A1/"},{"title":"Harvester VM OOM é—®é¢˜æ’æŸ¥","text":"Harvester ç‰ˆæœ¬ï¼šv1.3.2 é—®é¢˜ç°è±¡ï¼šç¯å¢ƒä¸­çš„ VM å‘ç”Ÿ OOMï¼Œå¯¹åº”çš„ virt-launcher Pod é‡å¯ã€‚ æ’æŸ¥è¿‡ç¨‹Kernel ä¸­æ•è·åˆ°çš„ OOM æ—¥å¿—ï¼š 1234567...Mar 17 13:06:36 xxx kernel: CPU 1/KVM invoked oom-killer: gfp_mask=0xcc0(GFP_KERNEL), order=0, oom_score_adj=990Mar 17 13:06:36 xxx kernel: Memory cgroup out of memory: Killed process 15621 (qemu-system-x86) total-vm:17962836kB, anon-rss:15698676kB, file-rss:24744kB, shmem-rss:4kB, UID:107 pgtables:31552kB oom_score_adj:990...Mar 20 03:00:55 xxx kernel: virt-launcher invoked oom-killer: gfp_mask=0xcc0(GFP_KERNEL), order=0, oom_score_adj=990Mar 20 03:00:55 xxx kernel: Memory cgroup out of memory: Killed process 37685 (qemu-system-x86) total-vm:19403216kB, anon-rss:16439716kB, file-rss:24368kB, shmem-rss:4kB, UID:107 pgtables:33732kB oom_score_adj:990... CPU 1/KVM æ˜¯ qemu-system-x86 è¿›ç¨‹çš„ä¸€ä¸ªçº¿ç¨‹ï¼Œå®ƒå‘ Guest OS æ¨¡æ‹Ÿ vCPUã€‚è¯¥æ—¥å¿—è¡¨ç¤º CPU 1/KVM çº¿ç¨‹åœ¨æ‰§è¡Œåˆ†é…å†…å­˜æ“ä½œçš„æ—¶å€™è§¦å‘äº† OOMï¼›virt-launcher æ˜¯ä¸€ä¸ªä¸ KubeVirt ç›¸å…³çš„è¿›ç¨‹ï¼Œè¿è¡Œåœ¨è™šæ‹Ÿæœº Pod çš„ç›¸å…³ cgroup ä¸­ã€‚è¯¥æ—¥å¿—è¡¨ç¤º virt-launcher è¿›ç¨‹åœ¨åˆ†é…å†…å­˜æ—¶è§¦å‘äº† OOMã€‚virt-launcher ä¹Ÿåœ¨ qemu-system-x86 è¿›ç¨‹ä¸­è¿è¡Œï¼Œæ‰€ä»¥ Kernel æ—¥å¿—ä¸­è®°å½•çš„è§¦å‘ OOM è¿›ç¨‹ä¹Ÿæ˜¯ qemu-system-x86ã€‚ å†…å­˜èµ„æºä½¿ç”¨æƒ…å†µï¼š 12345678910# Guest OS è§†è§’sles@xxx:~&gt; free -gtotal used free shared buff/cache availableMem: 15 4 3 0 8 11Swap: 0 0 0# Host OS è§†è§’kubectl top podNAME CPU(cores) MEMORY(bytes)virt-launcher-xxx 622m 13138Mi ä» Guest OS çš„å†…å­˜ä½¿ç”¨æƒ…å†µæ¥çœ‹ï¼ŒGuest OS æœ‰ 11GiB å¯ç”¨ï¼Œä½† buff/cache ä»æœ‰ 8GiBï¼›è€Œ virt-launcher Pod å ç”¨å†…å­˜çº¦ä¸º 13GiBã€‚ç”±æ­¤å¯è§ä» Host OS è§’åº¦æ¥çœ‹ï¼Œè¿™äº›ç¼“å­˜ä»ç„¶å ç”¨äº† qemu-system-x86 è¿›ç¨‹çš„ cgroup èµ„æºã€‚ å³ä½¿ Guest OS è®¤ä¸ºå®ƒæœ‰ 11GiB å¯ç”¨ï¼Œä½† Host OS è®¤ä¸º VM ä»ç„¶æŒæœ‰ 13GiB å†…å­˜ï¼Œé‚£ä¹ˆå°±æœ‰å¯èƒ½è§¦å‘ OOMã€‚ Memory Overheadåœ¨ Harvester ä¸­ï¼Œæ¯ä¸ª VM éƒ½è¿è¡Œåœ¨ä¸€ä¸ª Kubernetes Pod å†…ï¼Œä¸»è¦è¿›ç¨‹ä¸º qemu-system-x86ã€‚Pod çš„å†…å­˜åˆ†é…å— Kubernetes çš„ requests å’Œ limits æœºåˆ¶æ§åˆ¶ã€‚é™¤äº† Guest OS æœ¬èº«ä½¿ç”¨çš„å†…å­˜å¤–ï¼ŒHarvester å’Œ KubeVirt è¿˜éœ€è¦é¢å¤–åˆ†é…ä¸€éƒ¨åˆ†å†…å­˜æ¥ç®¡ç† VM çš„ CPUã€å­˜å‚¨ã€ç½‘ç»œç­‰èµ„æºï¼Œè¿™éƒ¨åˆ†ç§°ä¸º Memory Overheadï¼ˆé¢å¤–å†…å­˜ï¼‰ã€‚ OOM å‘ç”Ÿçš„åŸå› å°½ç®¡ Harvester é‡‡ç”¨äº†ä¸€å®šçš„è®¡ç®—å…¬å¼æ¥ä¸º VM é¢„ç•™é¢å¤–å†…å­˜ï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä»å¯èƒ½å‡ºç° OOM é—®é¢˜ï¼Œå¯¼è‡´ qemu-system-x86 è¢« cgroup OOM killer ç»ˆç»“ã€‚ å¯èƒ½å¯¼è‡´ VM OOM çš„åŸå› æœ‰ï¼š VM è¿è¡Œåœ¨ Kubernetes Pod ä¸­ï¼Œå— cgroup æœºåˆ¶é™åˆ¶ï¼Œæ‰€æœ‰è¿›ç¨‹ (å¦‚ virt-launcher, virtlogd, virtqemud) å…±äº« Pod çº§åˆ«çš„å†…å­˜é…é¢ã€‚ Harvester é»˜è®¤ Reserved Memory è¿‡ä½ (100Mi)ï¼Œä¸è¶³ä»¥åº”å¯¹ä¸åŒç±»å‹çš„ VM åŠå…¶æ“ä½œç³»ç»Ÿã€‚ VM åœ¨é•¿æ—¶é—´è¿è¡Œåï¼ŒGuest OS å±‚é¢çœ‹ä»æ˜¯è¾ƒä½çš„å†…å­˜ä½¿ç”¨ç‡ï¼Œä½†ä» Host OS å±‚é¢ä¸Šçœ‹ï¼Œç›¸å…³è¿›ç¨‹å‡ ä¹è€—å°½äº†æ‰€æœ‰èµ„æºï¼Œå¯¼è‡´ Host OS è®¤ä¸º VM å†…å­˜å·²ç»è€—å°½ï¼Œè¿›è€Œè§¦å‘ cgroup OOMã€‚ Reserved Memoryä¸ºäº†é™ä½ OOM å‘ç”Ÿçš„æ¦‚ç‡ï¼ŒHarvester å¼•å…¥ Reserved Memory æœºåˆ¶ï¼Œé»˜è®¤ Reserved Memory ä¸º 100Miã€‚è¯¥æœºåˆ¶ä½¿ç”¨æˆ·å¯ä»¥æ‰‹åŠ¨è°ƒæ•´ Guest OS ä¹‹å¤–çš„ Total Memory Overheadï¼Œä»è€Œé¿å… VM è¿›ç¨‹å›  cgroup OOM è€Œå´©æºƒã€‚ å¦‚ä¸‹ä¸º Total Memory Overhead è®¡ç®—å…¬å¼ï¼šTotal Memory Overhead (æ€»çš„é¢å¤–å†…å­˜) = è‡ªåŠ¨è®¡ç®—çš„ Memory Overhead (æ ¹æ® VM é…ç½®è‡ªåŠ¨è®¡ç®—çš„é¢å¤–å†…å­˜) + Harvester Reserved Memory (é¢„ç•™å†…å­˜) è§£å†³æ–¹æ¡ˆä»¥ä¸‹è§£å†³æ–¹æ¡ˆå‡éœ€è¦é‡å¯ VMï¼š v1.4.x ç‰ˆæœ¬å‰ï¼Œå¯ä»¥é€šè¿‡å¢åŠ  Reserved Memoryï¼Œæé«˜ Total Memory Overhead é¿å… OOM å‘ç”Ÿã€‚ v1.4.x ç‰ˆæœ¬å¼€å§‹ï¼Œåœ¨ Harvester -&gt; Settings ä¸­å¯ä»¥è°ƒæ•´ additional-guest-memory-overhead-ratioï¼Œæé«˜ KubeVirt è®¡ç®—çš„ Memory Overheadï¼Œå‡å°‘ VM è¢« OOM æ€æ­»çš„æ¦‚ç‡ã€‚ v1.4.x ç‰ˆæœ¬å‰å¯ä»¥é€šè¿‡ä¿®æ”¹ CR kubevirts.kubevirt.io æ·»åŠ  spec.configuration.additionalGuestMemoryOverheadRatio é…ç½®ã€‚ä¸”å‡çº§è‡³ v1.4.x åä¼šè‡ªåŠ¨è½¬æ¢ä¸º Harvester -&gt; Settings ä¸­çš„ additional-guest-memory-overhead-ratioã€‚ ç§»é™¤ cgroup å†…å­˜é™åˆ¶ï¼ŒVM å¯èƒ½æ— é™åˆ¶å ç”¨ Host èµ„æºï¼Œå½±å“å…¶ä»– Pod/VMã€‚ ä¸´æ—¶è§£å†³æ–¹æ¡ˆ æ‰‹åŠ¨é‡Šæ”¾ Guest OS å†…çš„ buff/cache å†…å­˜ï¼Œå±äºä¸´æ—¶è§£å†³æ–¹æ¡ˆï¼Œæœªæ¥ä»æœ‰å¯èƒ½å†æ¬¡å‘ç”Ÿ OOMã€‚ 1sync &amp;&amp; echo 3 &gt; /proc/sys/vm/drop_caches","link":"/2025/03/25/Harvester-VM-OOM-%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"},{"title":"RKE2 Cilium without kube-proxy","text":"é›†ç¾¤å¦‚æœä½¿ç”¨ Cilium ä½œä¸º cni çš„è¯ï¼Œå¯ä»¥å®ç° Kubernetes Without kube-proxyã€‚ Cilium çš„ kube-proxy æ›¿ä»£ç¨‹åºä¾èµ–äº socket-LB åŠŸèƒ½ï¼Œéœ€è¦ä½¿ç”¨ v4.19.57ã€v5.1.16ã€v5.2.0 æˆ–æ›´é«˜ç‰ˆæœ¬çš„ Linux å†…æ ¸ã€‚Linux å†…æ ¸ v5.3 å’Œ v5.8 å¢åŠ äº†å…¶ä»–åŠŸèƒ½ï¼ŒCilium å¯åˆ©ç”¨è¿™äº›åŠŸèƒ½è¿›ä¸€æ­¥ä¼˜åŒ– kube-proxy æ›¿ä»£å®ç°ã€‚ å·²æœ‰çš„ RKE2 Cilium é›†ç¾¤ï¼Œå¯ä»¥é€šè¿‡ä¸‹é¢çš„æ­¥éª¤å¼€å¯æ­¤åŠŸèƒ½ã€‚ åœ¨ Rancher é€šè¿‡ Yaml ç¼–è¾‘é›†ç¾¤ï¼š 1234567891011121314spec: kubernetesVersion: v1.27.16+rke2r2 rkeConfig: chartValues: rke2-cilium: # å¦‚æœæœ‰å¤–éƒ¨ LB æŒ‡å‘ kube-apiserverï¼Œå¯ä»¥è®¾ç½®ä¸º VIP åœ°å€ k8sServiceHost: 127.0.0.1 k8sServicePort: 6443 # å…³é”®å‚æ•°ï¼Œå¼€å¯ Cilium kube-proxy æ›¿ä»£åŠŸèƒ½ kubeProxyReplacement: true machineGlobalConfig: cni: cilium # å…³é—­ kube-proxy disable-kube-proxy: true å¾… Provisioning ç»“æŸåï¼Œéœ€è¦é‡å¯æ‰€æœ‰èŠ‚ç‚¹çš„ rke2-server or rke2-agentï¼š 12systemctl restart rke2-serversystemctl restart rke2-agent è¿™ä¸ªæ—¶å€™ agent èŠ‚ç‚¹å°±ä¸ä¼šæœ‰ kube-proxy pod äº†ï¼Œä½† server èŠ‚ç‚¹çš„éœ€è¦æ‰‹åŠ¨ç§»é™¤ kube-proxy Yaml æ–‡ä»¶ï¼š 1mv /var/lib/rancher/rke2/agent/pod-manifests/kube-proxy.yaml ~/kube-proxy.yaml è¿™ä¸ªæ—¶å€™é›†ç¾¤å·²ç»æ²¡æœ‰ kube-proxy podï¼Œç„¶åæ¸…é™¤ä¹‹å‰ç”Ÿæˆçš„ iptables è§„åˆ™ï¼š 1iptables -F &amp;&amp; iptables -X &amp;&amp; iptables -Z &amp;&amp; iptables -F -t nat &amp;&amp; iptables -X -t nat &amp;&amp; iptables -Z -t nat æœ€åï¼Œé‡å¯ Ciliumï¼š 1kubectl -n kube-system rollout restart ds cilium æ£€æŸ¥ KubeProxyReplacement é…ç½®æ˜¯å¦ç”Ÿæ•ˆï¼š 123root@test001:~# kubectl -n kube-system exec ds/cilium -c cilium-agent -- cilium-dbg status | grep KubeProxyReplacementKubeProxyReplacement: True [eth0 172.16.0.2 fe80::216:3eff:fe08:5140 (Direct Routing)]root@test001:~# è·å–æ›´å¤šç»†èŠ‚é…ç½®ï¼š 123456789101112131415161718192021root@test001:~# kubectl -n kube-system exec ds/cilium -c cilium-agent -- cilium-dbg status --verbose...KubeProxyReplacement Details: Status: True Socket LB: Enabled Socket LB Tracing: Enabled Socket LB Coverage: Full Devices: eth0 172.16.0.2 fe80::216:3eff:fe08:5140 (Direct Routing) Mode: SNAT Backend Selection: Random Session Affinity: Enabled Graceful Termination: Enabled NAT46/64 Support: Disabled XDP Acceleration: Disabled Services: - ClusterIP: Enabled - NodePort: Enabled (Range: 30000-32767) - LoadBalancer: Enabled - externalIPs: Enabled - HostPort: Enabled... æŸ¥çœ‹æ˜¯å¦è¿˜æœ‰ kube-proxy çš„ iptables è§„åˆ™ï¼š 1iptables-save | grep KUBE-SVC åˆ›å»ºä¸€ä¸ª Workload å’Œ Service è¿›è¡Œ ClusterIP/NodePort æµ‹è¯•ï¼Œèƒ½æ­£å¸¸é€šä¿¡å³å¯ï¼š 12345678910111213root@test001:~# kubectl get pod -n kube-system | grep kube-proxyroot@test001:~# kubectl get svc nginxNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEnginx NodePort 10.43.38.171 &lt;none&gt; 80:32048/TCP 26hroot@test001:~# curl 10.43.38.171 -IHTTP/1.1 200 OK...root@test001:~# curl 127.0.0.1:32048 -IHTTP/1.1 200 OK...","link":"/2024/10/31/RKE2-Cilium-without-kube-proxy/"},{"title":"RKE1&#x2F;RKE2 Nginx Ingress Controller è‡ªå®šä¹‰é…ç½®","text":"RKE1 é€šè¿‡ cluster.yaml ä¸­é…ç½®ï¼ŒRKE2 é€šè¿‡ HelmChartConfig é…ç½®ã€‚ RKE1å‚è€ƒï¼šhttps://rke.docs.rancher.com/config-options/add-ons/ingress-controllers#configuring-nginx-ingress-controller 1234ingress: provider: nginx options: allow-snippet-annotations: &quot;true&quot; RKE2å‚è€ƒï¼šhttps://github.com/rancher/rke2-charts/tree/main/charts/rke2-ingress-nginx/rke2-ingress-nginx 1234567891011cat &lt;&lt;EOF | kubectl apply -f -apiVersion: helm.cattle.io/v1kind: HelmChartConfigmetadata: name: rke2-ingress-nginx namespace: kube-systemspec: valuesContent: |- controller: allowSnippetAnnotations: &quot;true&quot;EOF","link":"/2025/03/17/RKE1-RKE2-Nginx-Ingress-Controller-%E8%87%AA%E5%AE%9A%E4%B9%89%E9%85%8D%E7%BD%AE/"},{"title":"RKE2 Cilium é…ç½® Cluster Mesh å®ç°è·¨é›†ç¾¤é€šä¿¡","text":"é€šè¿‡ Cilium çš„èƒ½åŠ›å®ç° Kubernetes é›†ç¾¤è¿æ¥åœ¨ä¸€èµ·æ¥æ„å»ºä¸€ä¸ªç½‘çŠ¶é›†ç¾¤ï¼Œåœ¨æ‰€æœ‰é›†ç¾¤ä¹‹é—´å¯ç”¨ pod-to-pod è¿æ¥ï¼Œå®šä¹‰å…¨å±€æœåŠ¡æ¥å¹³è¡¡é›†ç¾¤ä¹‹é—´çš„è´Ÿè½½ï¼Œå¹¶æ‰§è¡Œå®‰å…¨ç­–ç•¥æ¥é™åˆ¶è®¿é—®ã€‚ å®˜æ–¹æ–‡æ¡£ï¼šhttps://docs.cilium.io/en/stable/network/clustermesh/clustermesh/#enable-clustermesh é¦–å…ˆéœ€è¦åˆ›å»ºä¸¤ä¸ª Cilium é›†ç¾¤ï¼Œä¸¤ä¸ªé›†ç¾¤çš„ Cluster CIDR å’Œ Service CIDR ä¸èƒ½å†²çªï¼š åœ¨é™„åŠ é…ç½®ä¸­ï¼Œè®¾ç½®ä¸¤ä¸ªé›†ç¾¤çš„ Cilium Cluster ID å’Œ Nameï¼Œä¹Ÿä¸èƒ½å¤Ÿå†²çªï¼š é›†ç¾¤åˆ›å»ºå¥½åï¼Œåœ¨ä¸¤ä¸ªé›†ç¾¤åˆ›å»ºä¸€ä¸ª SVCï¼Œç”¨äºå°†è¯¥é›†ç¾¤çš„ API server å¯¹å¤–æš´éœ²ï¼š 12345678910111213141516cat &lt;&lt;EOF | kubectl apply -f -apiVersion: v1kind: Servicemetadata: name: apiserver namespace: kube-systemspec: ports: - name: port-6443 port: 6443 protocol: TCP targetPort: 6443 selector: component: kube-apiserver type: NodePortEOF åˆ†åˆ«åœ¨ä¸¤ä¸ªé›†ç¾¤çš„ Control Plane èŠ‚ç‚¹é…ç½® kubeconfigï¼Œæ·»åŠ å¯¹ç«¯é›†ç¾¤çš„é…ç½®ï¼Œserver åœ°å€å¯ä»¥é…ç½®åˆšåˆšåˆ›å»ºå¥½çš„ Service NodePortï¼Œä¾‹å¦‚ï¼š 12345678910111213141516171819202122232425262728293031apiVersion: v1clusters:- cluster: certificate-authority-data: xxx server: https://172.16.16.140:30645 name: rke2-cilium-1- cluster: certificate-authority-data: xxx server: https://172.16.16.141:32460 name: rke2-cilium-2contexts:- context: cluster: rke2-cilium-1 user: rke2-cilium-1 name: rke2-cilium-1- context: cluster: rke2-cilium-2 user: rke2-cilium-2 name: rke2-cilium-2current-context: rke2-cilium-1kind: Configpreferences: {}users:- name: rke2-cilium-1 user: client-certificate-data: xxx client-key-data: xxx- name: rke2-cilium-2 user: client-certificate-data: xxx client-key-data: xxx å®‰è£… Cilium CLIï¼š 1234567CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt)CLI_ARCH=amd64if [ &quot;$(uname -m)&quot; = &quot;aarch64&quot; ]; then CLI_ARCH=arm64; ficurl -L --fail --remote-name-all https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}sha256sum --check cilium-linux-${CLI_ARCH}.tar.gz.sha256sumsudo tar xzvfC cilium-linux-${CLI_ARCH}.tar.gz /usr/local/binrm cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum} åˆ†åˆ«åœ¨ä¸¤ä¸ªé›†ç¾¤å¼€å¯ Cluster Meshï¼š 12345# Cluster 1cilium clustermesh enable --context rke2-cilium-1 --service-type NodePort --helm-release-name rke2-cilium# Cluster 2cilium clustermesh enable --context rke2-cilium-2 --service-type NodePort --helm-release-name rke2-cilium æ‰§è¡Œè¯¥å‘½ä»¤ååœ¨ kube-system ä¸‹ä¼šç”Ÿæˆ Deployment clustermesh-apiserverï¼Œå…¶çŠ¶æ€æ­£å¸¸åˆ™ä»£è¡¨å¼€å¯æˆåŠŸï¼Œä¹Ÿå¯ä»¥é€šè¿‡ä¸‹é¢çš„å‘½ä»¤æ£€æŸ¥ï¼š 12345678910111213141516171819root@test-0:~# cilium status --context rke2-cilium-1 /Â¯Â¯\\ /Â¯Â¯\\__/Â¯Â¯\\ Cilium: OK \\__/Â¯Â¯\\__/ Operator: OK /Â¯Â¯\\__/Â¯Â¯\\ Envoy DaemonSet: disabled (using embedded mode) \\__/Â¯Â¯\\__/ Hubble Relay: disabled \\__/ ClusterMesh: OKDaemonSet cilium Desired: 1, Ready: 1/1, Available: 1/1Deployment cilium-operator Desired: 1, Ready: 1/1, Available: 1/1Deployment clustermesh-apiserver Desired: 1, Ready: 1/1, Available: 1/1Containers: cilium Running: 1 cilium-operator Running: 1 clustermesh-apiserver Running: 1Cluster Pods: 15/15 managed by CiliumHelm chart version:Image versions cilium harbor.warnerchen.com/rancher/mirrored-cilium-cilium:v1.16.2: 1 cilium-operator harbor.warnerchen.com/rancher/mirrored-cilium-operator-generic:v1.16.2: 1 clustermesh-apiserver harbor.warnerchen.com/rancher/mirrored-cilium-clustermesh-apiserver:v1.16.2: 3 å»ºç«‹é›†ç¾¤è¿æ¥ï¼š 12345# Cluster 1cilium clustermesh connect --context rke2-cilium-1 --destination-context rke2-cilium-2 --helm-release-name rke2-cilium# Cluster 2cilium clustermesh connect --context rke2-cilium-2 --destination-context rke2-cilium-1 --helm-release-name rke2-cilium æ—¥å¿—å¦‚ä¸‹åˆ™ä»£è¡¨å¼€å¯æˆåŠŸï¼š ä¹Ÿå¯ä»¥é€šè¿‡ä¸‹é¢çš„å‘½ä»¤æ£€æŸ¥ï¼š 123456789101112131415root@test-0:~# cilium clustermesh status rke2-cilium-1âš ï¸ Service type NodePort detected! Service may fail when nodes are removed from the cluster!âœ… Service &quot;clustermesh-apiserver&quot; of type &quot;NodePort&quot; foundâœ… Cluster access information is available: - 172.16.16.140:32379âœ… Deployment clustermesh-apiserver is readyâ„¹ï¸ KVStoreMesh is enabledâœ… All 1 nodes are connected to all clusters [min:1 / avg:1.0 / max:1]âœ… All 1 KVStoreMesh replicas are connected to all clusters [min:1 / avg:1.0 / max:1]ğŸ”Œ Cluster Connections: - rke2-cilium-2: 1/1 configured, 1/1 connected - KVStoreMesh: 1/1 configured, 1/1 connectedğŸ”€ Global services: [ min:1 / avg:1.0 / max:1 ] å¦‚æœè¿æ¥ Cilium Pod å¤±è´¥å¯ä»¥å°è¯•é‡å¯ Cilium è§£å†³ï¼š 1kubectl -n kube-system rollout restart ds cilium éƒ¨ç½² Demo è¿›è¡Œæµ‹è¯•ï¼š 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798cat &lt;&lt;EOF | kubectl apply -f -apiVersion: v1kind: Servicemetadata: annotations: service.cilium.io/global: 'true' name: global-service-videospec: ports: - name: port-80 port: 80 protocol: TCP targetPort: 80 selector: name: rebel-base---apiVersion: apps/v1kind: Deploymentmetadata: name: rebel-basespec: selector: matchLabels: name: rebel-base replicas: 2 template: metadata: labels: name: rebel-base spec: containers: - name: rebel-base image: harbor.warnerchen.com/library/nginx:mainline volumeMounts: - name: html mountPath: /usr/share/nginx/html/ livenessProbe: httpGet: path: / port: 80 periodSeconds: 1 readinessProbe: httpGet: path: / port: 80 volumes: - name: html configMap: name: rebel-base-response items: - key: message path: index.html---apiVersion: v1kind: ConfigMapmetadata: name: rebel-base-responsedata: # éœ€è¦æ›¿æ¢æ­¤å¤„çš„è¿™é‡Œçš„ Cluster ä¸ºå¯¹åº”çš„é›†ç¾¤åç§° message: &quot;{\\&quot;Name\\&quot;: \\&quot;Warner\\&quot;, \\&quot;Cluster\\&quot;: \\&quot;rke2-cilium-1\\&quot;}\\n&quot;---apiVersion: apps/v1kind: Deploymentmetadata: name: x-wingspec: selector: matchLabels: name: x-wing replicas: 2 template: metadata: labels: name: x-wing spec: containers: - name: x-wing-container image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0 livenessProbe: exec: command: - curl - -sS - -o - /dev/null - localhost readinessProbe: exec: command: - curl - -sS - -o - /dev/null - localhostEOF å¯ä»¥ç›´æ¥é€šè¿‡ Pod IP/Global Service è¿›è¡Œé€šä¿¡ï¼š","link":"/2025/02/13/RKE2-Cilium-%E9%85%8D%E7%BD%AE-Cluster-Mesh-%E5%AE%9E%E7%8E%B0%E8%B7%A8%E9%9B%86%E7%BE%A4%E9%80%9A%E4%BF%A1/"},{"title":"Kubernetes MCP Server ä½¿ç”¨éšè®°","text":"MCP å…¨ç§°ä¸º Model Context Protocolï¼Œä¸­æ–‡è¯‘ä¸ºæ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼Œæ˜¯ä¸€ä¸ªå¼€æ”¾æ ‡å‡†ï¼Œä½¿å¼€å‘äººå‘˜èƒ½å¤Ÿåœ¨æ•°æ®æºå’Œäººå·¥æ™ºèƒ½é©±åŠ¨çš„å·¥å…·ä¹‹é—´å»ºç«‹å®‰å…¨çš„åŒå‘è¿æ¥ã€‚ åœ¨æ²¡æœ‰ MCP ä¹‹å‰ï¼ŒAI è¦è¯»å»åˆ†æèµ„æ–™éœ€è¦å…ˆæ‰‹åŠ¨å°†æ–‡ä»¶è¿›è¡Œä¸Šä¼ ï¼Œæˆ–è€…æ˜¯å°†å†…å®¹å¤åˆ¶åˆ°å¯¹è¯æ¡†å†…ï¼Œä½¿ç”¨è¿‡ç¨‹ç›¸å¯¹ç¹æ‚ï¼›å¦‚æœä½¿ç”¨äº† MCPï¼Œåˆ™å¯ä»¥ç›´æ¥è®© AI å¯¹æœ¬åœ°æ–‡ä»¶è¿›è¡Œåˆ†æã€‚ æ­¤å¤„ä½¿ç”¨å¼€æºé¡¹ç›® Kubernetes MCP Server è¿›è¡Œæµ‹è¯•ã€‚ ç¯å¢ƒä¿¡æ¯ï¼š 12345678910111213node --versionv23.10.0npm --version11.2.0npx --version11.2.0bun --version1.2.5kubectl versionClient Version: v1.31.0Kustomize Version: v5.4.2helm versionversion.BuildInfo{Version:&quot;v3.15.4&quot;, GitCommit:&quot;fa9efb07d9d8debbb4306d72af76a383895aa8c4&quot;, GitTreeState:&quot;clean&quot;, GoVersion:&quot;go1.22.6&quot;} æ„å»º mcp-server-kubernetesï¼š 12345git clone https://github.com/Flux159/mcp-server-kubernetes.gitcd mcp-server-kubernetesgit checkout v0.2.5bun installbun run build å¯åŠ¨ mcp-server-kubernetesï¼š 1npx @modelcontextprotocol/inspector node dist/index.js æµ‹è¯•æ˜¯å¦èƒ½å¤Ÿé€šè¿‡ MCP è¿æ¥åˆ° Kubernetesï¼š é€šè¿‡ä¸‹é¢çš„ claude_desktop_config.json é…ç½®ï¼Œä¸ Claude è¿›è¡Œå¯¹æ¥ï¼š 1234567891011121314{ &quot;mcpServers&quot;: { &quot;kubernetes&quot;: { &quot;command&quot;: &quot;npx&quot;, &quot;args&quot;: [&quot;mcp-server-kubernetes&quot;], &quot;host&quot;: &quot;127.0.0.1&quot;, &quot;port&quot;: 3000, &quot;timeout&quot;: 30000, &quot;env&quot;: { &quot;KUBECONFIG&quot;: &quot;/Users/warchen/Desktop/mcp-server-kubernetes/kubeconfig&quot; } } }} å°è¯•é€šè¿‡ Claude è·å–æŸä¸ª namespace ä¸‹çš„ pod ä¿¡æ¯ï¼Œå¹¶åˆ›å»ºä¸€ä¸ª nginx podï¼š","link":"/2025/03/18/Kubernetes-MCP-Server-%E4%BD%BF%E7%94%A8%E9%9A%8F%E8%AE%B0/"},{"title":"RKE1&#x2F;2 èŠ‚ç‚¹é…ç½® Nvidia Container Toolkit","text":"GPU èŠ‚ç‚¹å®‰è£… Nvidia é©±åŠ¨å®˜æ–¹æ–‡æ¡£ï¼šNVIDIA CUDA Installation Guide for Linux å®‰è£…å‰å‡†å¤‡æŸ¥çœ‹æ˜¯å¦æœ‰å¯ç”¨çš„ GPUï¼š 12root@gpu-0:~# lspci | grep -i nvidia03:00.0 3D controller: NVIDIA Corporation GP104GL [Tesla P4] (rev a1) å®‰è£…ä¾èµ–é¡¹ï¼š 12apt updateapt -y install gcc make Nouveau æ˜¯å¼€æºçš„ NVIDIA é©±åŠ¨ï¼Œä¼šä¸å®˜æ–¹é—­æºé©±åŠ¨å†²çªï¼Œéœ€è¦ç¦ç”¨ï¼š 1234echo -e &quot;blacklist nouveau\\noptions nouveau modeset=0&quot; | sudo tee /etc/modprobe.d/blacklist-nouveau.confupdate-initramfs -urebootlsmod | grep nouveau å…³é—­ Secure Bootï¼š 12mokutil --disable-validationmokutil --sb-state é€šè¿‡ Nvidia å®˜æ–¹ .run ç¨‹åºå®‰è£…é©±åŠ¨ä¸‹è½½å¯¹åº”çš„å®‰è£…ç¨‹åºï¼šNvidia Driver Downloads 1wget -c &quot;https://cn.download.nvidia.com/tesla/570.86.15/NVIDIA-Linux-x86_64-570.86.15.run&quot; æ‰§è¡Œå®‰è£…ï¼š 123chmod +x NVIDIA-Linux-x86_64-570.86.15.run./NVIDIA-Linux-x86_64-570.86.15.runreboot å¦‚æœæ‰§è¡Œ nvidia-smi æ˜¯ No devices were found or NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.ï¼Œå¯ä»¥å°è¯•ç”¨ä¸‹é¢çš„å‘½ä»¤è§£å†³ï¼š 1234apt -y install dkmsVERSION=$(ls /usr/src | awk -F - '/nvidia/{ print $2 }')dkms install -m nvidia -v $VERSIONreboot é‡å¯èŠ‚ç‚¹ä¼šè¿›å…¥ Perform MOK management é¡µé¢ï¼Œé€‰æ‹© EnrollMOK å¹¶è¾“å…¥å¯†ç ï¼Œå®Œæˆåä¼šå†æ¬¡é‡å¯èŠ‚ç‚¹ã€‚ é€šè¿‡ Nvidia å®˜æ–¹ local repo å®‰è£…ä¸‹è½½å¯¹åº”çš„ local repo æ–‡ä»¶ï¼š 1234wget -c &quot;https://cn.download.nvidia.com/tesla/570.86.15/nvidia-driver-local-repo-ubuntu2204-570.86.15_1.0-1_amd64.deb&quot;dpkg -i nvidia-driver-local-repo-ubuntu2204-570.86.15_1.0-1_amd64.debcp /var/nvidia-driver-local-repo-ubuntu2204-570.86.15/nvidia-driver-local-081EF1BD-keyring.gpg /usr/share/keyrings/apt update æŸ¥çœ‹é©±åŠ¨ç‰ˆæœ¬ï¼š 1apt list | grep nvidia-driver å®‰è£…é©±åŠ¨ï¼š 12apt -y install nvidia-driver-570reboot é‡å¯èŠ‚ç‚¹ä¼šè¿›å…¥ Perform MOK management é¡µé¢ï¼Œé€‰æ‹© EnrollMOK å¹¶è¾“å…¥å¯†ç ï¼Œå®Œæˆåä¼šå†æ¬¡é‡å¯èŠ‚ç‚¹ã€‚ é‡å¯å®Œæˆï¼Œå¯ä»¥ç”¨ nvidia-smi å‘½ä»¤æŸ¥çœ‹ GPU ä¿¡æ¯ï¼š é€šè¿‡ Ubuntu PPA å®‰è£…é©±åŠ¨å¯ä»¥é€šè¿‡ Ubuntu PPA è¿›è¡Œå®‰è£…ï¼Œä½†æ¨èå®‰è£…çš„é©±åŠ¨ç‰ˆæœ¬è¾ƒä½ï¼š 1234567891011root@gpu-0:~# ubuntu-drivers devices== /sys/devices/pci0000:03/0000:03:00.0 ==modalias : pci:v000010DEd00001BB3sv000010DEsd000011D8bc03sc02i00vendor : NVIDIA Corporationmodel : GP104GL [Tesla P4]driver : nvidia-driver-470-server - distro non-freedriver : nvidia-driver-470 - distro non-free recommendeddriver : nvidia-driver-418-server - distro non-freedriver : nvidia-driver-390 - distro non-freedriver : nvidia-driver-450-server - distro non-freedriver : xserver-xorg-video-nouveau - distro free builtin æ ¹æ®è¾“å‡ºå†…å®¹ï¼Œå®‰è£…æ¨èçš„ç‰ˆæœ¬ï¼š 12apt -y install nvidia-driver-470reboot é‡å¯èŠ‚ç‚¹ä¼šè¿›å…¥ Perform MOK management é¡µé¢ï¼Œé€‰æ‹© EnrollMOK å¹¶è¾“å…¥å¯†ç ï¼Œå®Œæˆåä¼šå†æ¬¡é‡å¯èŠ‚ç‚¹ã€‚ é‡å¯å®Œæˆï¼Œå¯ä»¥ç”¨ nvidia-smi å‘½ä»¤æŸ¥çœ‹ GPU ä¿¡æ¯ï¼š RKE1 èŠ‚ç‚¹é…ç½® Nvidia Container RuntimeèŠ‚ç‚¹éœ€è¦å…ˆå®‰è£… Dockerï¼š 1curl https://releases.rancher.com/install-docker/20.10.sh | sh å®‰è£… Nvidia Container Toolkitï¼š å®˜æ–¹å®‰è£…æ–‡æ¡£ï¼šInstalling the NVIDIA Container Toolkit 12345678910curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\ &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\ sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\ sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.listsed -i -e '/experimental/ s/^#//g' /etc/apt/sources.list.d/nvidia-container-toolkit.listapt-get updateapt-get install -y nvidia-container-toolkit é…ç½® Nvidia Container Runtimeï¼š 123456789101112cat &lt;&lt;EOF &gt; /etc/docker/daemon.json{ &quot;default-runtime&quot;: &quot;nvidia&quot;, &quot;insecure-registries&quot; : [ &quot;0.0.0.0/0&quot; ], &quot;runtimes&quot;: { &quot;nvidia&quot;: { &quot;path&quot;: &quot;/usr/bin/nvidia-container-runtime&quot;, &quot;runtimeArgs&quot;: [] } }}EOF 1234root@gpu-0:~# systemctl restart dockerroot@gpu-0:~# docker info | grep Runtime Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux nvidia runc Default Runtime: nvidia æµ‹è¯•å®¹å™¨æ˜¯å¦å¯ç”¨ï¼š 123456789101112131415161718192021root@gpu-0:~# docker run --rm --runtime=nvidia --gpus all harbor.warnerchen.com/library/ubuntu:latest nvidia-smiWed Feb 19 09:43:47 2025+-----------------------------------------------------------------------------+| NVIDIA-SMI 470.256.02 Driver Version: 470.256.02 CUDA Version: 11.4 ||-------------------------------+----------------------+----------------------+| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. || | | MIG M. ||===============================+======================+======================|| 0 Tesla P4 Off | 00000000:03:00.0 Off | 0 || N/A 49C P0 23W / 75W | 0MiB / 7611MiB | 2% Default || | | N/A |+-------------------------------+----------------------+----------------------++-----------------------------------------------------------------------------+| Processes: || GPU GI CI PID Type Process name GPU Memory || ID ID Usage ||=============================================================================|| No running processes found |+-----------------------------------------------------------------------------+ RKE2 èŠ‚ç‚¹é…ç½® Nvidia Container Runtimeå®‰è£… Nvidia Container Toolkitï¼š 12345678910curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\ &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\ sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\ sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.listsed -i -e '/experimental/ s/^#//g' /etc/apt/sources.list.d/nvidia-container-toolkit.listapt-get updateapt-get install -y nvidia-container-toolkit æ–°ç‰ˆæœ¬çš„ RKE2 åœ¨å¯åŠ¨æ—¶ä¼šè‡ªåŠ¨æ£€æµ‹èŠ‚ç‚¹ä¸Šæ˜¯å¦å·²å®‰è£… Nvidia Container Toolkitï¼Œè‹¥æ£€æµ‹åˆ°ï¼Œä¼šè‡ªåŠ¨ä¸º containerd è¿›è¡Œç›¸å…³é…ç½®ï¼Œæ— éœ€æ‰‹åŠ¨å¹²é¢„ï¼›å¦‚æœæ˜¯åœ¨èŠ‚ç‚¹æ³¨å†Œè¿› RKE2 é›†ç¾¤ä¹‹åæ‰å®‰è£…çš„ Nvidia Container Toolkitï¼Œåªéœ€é‡å¯è¯¥èŠ‚ç‚¹çš„ RKE2 æœåŠ¡ï¼Œå³å¯å®Œæˆè‡ªåŠ¨é…ç½®ï¼š 12Apr 18 11:45:35 gpu-0 rke2[2226]: time=&quot;2025-04-18T11:45:35+08:00&quot; level=debug msg=&quot;Searching for nvidia container runtime&quot;Apr 18 11:45:35 gpu-0 rke2[2226]: time=&quot;2025-04-18T11:45:35+08:00&quot; level=info msg=&quot;Found nvidia container runtime at /usr/bin/nvidia-container-runtime&quot; 1234root@gpu-0:~# crictl info | grep -i nvidia &quot;nvidia&quot;: { &quot;BinaryName&quot;: &quot;/usr/bin/nvidia-container-runtime&quot;, &quot;name&quot;: &quot;nvidia&quot; å¦‚æœæ˜¯æ—§ç‰ˆæœ¬ RKE2ï¼Œåˆ™éœ€è¦æ‰‹åŠ¨ä¿®æ”¹é…ç½®ï¼š 1234567891011121314cp /var/lib/rancher/rke2/agent/etc/containerd/config.toml .cp /var/lib/rancher/rke2/agent/etc/containerd/config.toml /var/lib/rancher/rke2/agent/etc/containerd/config.toml.tmplvim /var/lib/rancher/rke2/agent/etc/containerd/config.toml.tmpl# åœ¨æœ€åé¢æ·»åŠ ä¸‹é¢çš„å†…å®¹[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.&quot;nvidia&quot;] runtime_type = &quot;io.containerd.runc.v2&quot;[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.&quot;nvidia&quot;.options] BinaryName = &quot;/usr/bin/nvidia-container-runtime&quot;systemctl restart rke2-server or rke2-agentrm /var/lib/rancher/rke2/agent/etc/containerd/config.toml.tmpl é…ç½® defaultRuntimeNameï¼š 123456789101112cp /var/lib/rancher/rke2/agent/etc/containerd/config.toml .cp /var/lib/rancher/rke2/agent/etc/containerd/config.toml /var/lib/rancher/rke2/agent/etc/containerd/config.toml.tmplvim /var/lib/rancher/rke2/agent/etc/containerd/config.toml.tmpl# æ–°å¢ä¸‹é¢çš„å†…å®¹[plugins.&quot;io.containerd.cri.v1.runtime&quot;.containerd] default_runtime_name = &quot;nvidia&quot;systemctl restart rke2-server or rke2-agentrm /var/lib/rancher/rke2/agent/etc/containerd/config.toml.tmpl æ·»åŠ  Nvidia Helm Chart ä»“åº“ï¼š ä»“åº“åœ°å€ï¼šhttps://helm.ngc.nvidia.com/nvidia å®‰è£… GPU Operatorï¼Œåœ¨ values.yaml ä¸­é…ç½® containerd socket å’Œ config.toml æ–‡ä»¶çš„è·¯å¾„ï¼š 1234567toolkit: enabled: true env: - name: CONTAINERD_CONFIG value: /var/lib/rancher/rke2/agent/etc/containerd/config.toml - name: CONTAINERD_SOCKET value: /run/k3s/containerd/containerd.sock å®‰è£…æˆåŠŸï¼š åˆ›å»º Pod éªŒè¯ GPU èµ„æºï¼š 12345678910111213141516171819202122cat &lt;&lt;EOF | kubectl apply -f -apiVersion: v1kind: Podmetadata: name: nbody-gpu-benchmark namespace: defaultspec: restartPolicy: OnFailure runtimeClassName: nvidia containers: - name: cuda-container image: harbor.warnerchen.com/nvidia/k8s/cuda-sample:nbody args: [&quot;nbody&quot;, &quot;-gpu&quot;, &quot;-benchmark&quot;] resources: limits: nvidia.com/gpu: 1 env: - name: NVIDIA_VISIBLE_DEVICES value: all - name: NVIDIA_DRIVER_CAPABILITIES value: allEOF æŸ¥çœ‹æ—¥å¿—ï¼Œè¿è¡ŒæˆåŠŸï¼š 12345678910111213141516171819202122232425root@rke2-cilium-01:~# kubectl logs nbody-gpu-benchmarkRun &quot;nbody -benchmark [-numbodies=&lt;numBodies&gt;]&quot; to measure performance. -fullscreen (run n-body simulation in fullscreen mode) -fp64 (use double precision floating point values for simulation) -hostmem (stores simulation data in host memory) -benchmark (run benchmark to measure performance) -numbodies=&lt;N&gt; (number of bodies (&gt;= 1) to run in simulation) -device=&lt;d&gt; (where d=0,1,2.... for the CUDA device to use) -numdevices=&lt;i&gt; (where i=(number of CUDA devices &gt; 0) to use for simulation) -compare (compares simulation results running once on the default GPU and once on the CPU) -cpu (run n-body simulation on the CPU) -tipsy=&lt;file.bin&gt; (load a tipsy model file for simulation)NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.&gt; Windowed mode&gt; Simulation data stored in video memory&gt; Single precision floating point simulation&gt; 1 Devices used for simulationGPU Device 0: &quot;Pascal&quot; with compute capability 6.1&gt; Compute 6.1 CUDA device: [Tesla P4]20480 bodies, total time for 10 iterations: 27.727 ms= 151.272 billion interactions per second= 3025.446 single-precision GFLOP/s at 20 flops per interaction","link":"/2024/12/17/RKE1-2-%E8%8A%82%E7%82%B9%E9%85%8D%E7%BD%AE-Nvidia-Container-Toolkit/"},{"title":"Rancher Elemental ä½¿ç”¨éšè®°","text":"ç®€ä»‹Rancher Elemental ç”¨äºå¿«é€Ÿéƒ¨ç½²å’Œç®¡ç†åŸºäºå®¹å™¨çš„æ“ä½œç³»ç»Ÿï¼Œå¦‚ SLE Micro å’Œ openSUSE MicroOSã€‚å®ƒä¸“ä¸ºè¾¹ç¼˜è®¡ç®—å’Œäº‘åŸç”Ÿç¯å¢ƒè®¾è®¡ï¼Œå¯ä»¥æä¾›æç®€ã€æ˜“ç»´æŠ¤çš„æ“ä½œç³»ç»Ÿã€‚ ç»„ä»¶ï¼š elementalï¼šè´Ÿè´£æ“ä½œç³»ç»Ÿå®‰è£…ã€æ›´æ–°å’Œç»´æŠ¤çš„å‘½ä»¤è¡Œå·¥å…· elemental-operatorï¼šè¿è¡Œäº kubernetes ä¸­ï¼Œç”¨äºç®¡ç†è®¾å¤‡æ³¨å†Œå’Œç”Ÿå‘½å‘¨æœŸ elemental-registerï¼šè¿è¡Œäºè®¾å¤‡ä¸­ï¼Œç”¨äºå°†è®¾å¤‡ä¸ Rancher Elemental é›†ç¾¤æ³¨å†Œ elemental-system-agentï¼šè´Ÿè´£è®¾å¤‡çš„é…ç½®åº”ç”¨å’Œç”Ÿå‘½å‘¨æœŸç®¡ç† CRDï¼š MachineRegistrationï¼šå®šä¹‰è®¾å¤‡å¦‚ä½•æ³¨å†Œåˆ° Rancher Elemental é›†ç¾¤ï¼Œå¹¶æä¾›åˆå§‹åŒ–é…ç½® MachineInventoryï¼šè®°å½•æ³¨å†Œè®¾å¤‡çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç¡¬ä»¶å±æ€§å’ŒçŠ¶æ€ MachineInventorySelectorï¼šç”¨äºé€‰æ‹©ä¸€ç»„ç¬¦åˆç‰¹å®šæ ‡ç­¾æˆ–æ¡ä»¶çš„è®¾å¤‡ MachineInventorySelectorTemplateï¼šç”¨äºç”Ÿæˆ MachineInventorySelectorï¼Œæ”¯æŒåŠ¨æ€åˆ›å»ºè®¾å¤‡åˆ†ç»„è§„åˆ™ ManagedOSImageï¼šæè¿°å’Œç®¡ç†è®¾å¤‡å¯ç”¨çš„æ“ä½œç³»ç»Ÿé•œåƒä¿¡æ¯ ManagedOSVersionï¼šå®šä¹‰æ“ä½œç³»ç»Ÿç‰ˆæœ¬åŠå…¶æ”¯æŒçš„åŠŸèƒ½å’Œå˜æ›´ç‚¹ ManagedOSVersionChannelï¼šç®¡ç†æ“ä½œç³»ç»Ÿç‰ˆæœ¬æ›´æ–°çš„åˆ†å‘æ¸ é“ SeedImageï¼šç”¨äºåˆ›å»ºå®‰è£…ä»‹è´¨ï¼Œå°† Elemental å®‰è£…åˆ°èŠ‚ç‚¹ä¸Š ä½¿ç”¨éšè®°åœ¨ Rancher Extension å®‰è£… Elemental æ·»åŠ ä¸€ä¸ª OS Channel 1234567891011apiVersion: elemental.cattle.io/v1beta1kind: ManagedOSVersionChannelmetadata: name: sl-micro-6.0-base-channel namespace: fleet-defaultspec: deleteNoLongerInSyncVersions: false options: image: registry.suse.com/rancher/elemental-channel/sl-micro:6.0-base syncInterval: 1h type: custom åˆ›å»ºä¸€ä¸ª MachineRegistrationï¼ŒCloud Configuration å¯ä»¥æ ¹æ®éœ€æ±‚è‡ªå®šä¹‰ï¼Œä¾‹å¦‚è®¾ç½®ä¸»æœºåã€ç½‘ç»œé…ç½®ç­‰ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748apiVersion: elemental.cattle.io/v1beta1kind: MachineRegistrationmetadata: name: elemental-cluster-1 namespace: fleet-defaultspec: config: cloud-config: users: - name: root passwd: password ssh-authorized-keys: - &gt;- ssh-rsa xxx write_files: - content: | [connection] id=eth0 type=ethernet interface-name=eth0 autoconnect=true [ipv4] method=manual address1=172.16.16.141/24,172.16.16.1 dns=172.16.16.12; [ipv6] method=ignore path: /etc/NetworkManager/system-connections/eth0.nmconnection permissions: '0600' elemental: install: debug: true device: /dev/sda reboot: true snapshotter: type: loopdevice reset: reboot: true reset-oem: true reset-persistent: true machineInventoryLabels: author: warner machineUUID: ${System Information/UUID} manufacturer: ${System Information/Manufacturer} productName: ${System Information/Product Name} serialNumber: ${System Information/Serial Number} åˆ›å»ºå®Œåï¼Œé€‰æ‹©å¯¹åº”çš„ OS Version æ„å»ºé•œåƒï¼Œç‚¹å‡»æ„å»ºååœ¨ fleet-default å‘½åç©ºé—´ä¸‹ä¼šç”Ÿæˆä¸€ä¸ª podï¼Œç”¨äº base image æ‹‰å–ã€é•œåƒæ„å»ºã€ç”Ÿæˆé•œåƒä¸‹è½½åœ°å€ åœ¨ç•Œé¢ä¸‹è½½æ„å»ºå¥½çš„ ISOï¼Œä¹Ÿå¯ä»¥é€šè¿‡ SeedImage CRD è·å–ä¸‹è½½åœ°å€ 1kubectl -n fleet-default get seedimages.elemental.cattle.io media-image-reg-xxx -ojsonpath={.status.downloadURL} ä¸‹è½½å¥½åå°±å¯ä»¥é€šè¿‡è¿™ä¸ª ISO åˆ›å»ºè™šæ‹Ÿæœºï¼ŒOS å®‰è£…è¿‡ç¨‹ä¸­éœ€è¦ç”¨åˆ° TPMï¼Œæ‰€ä»¥éœ€è¦åœ¨ vSphere ä¸­å¼€å¯æœ¬æœºç±»å‹çš„ TPM vSphere å¼€å¯æœ¬æœºç±»å‹çš„ TPM æœ‰ä¸¤ä¸ªå‰æï¼š vSphere éœ€è¦é…ç½®åŸŸåï¼Œå¦åˆ™åˆ›å»ºå¥½åä¼šæ— æ³•è¿›è¡Œ TPM å¤‡ä»½ï¼Œæ— æ³•å¤‡ä»½çš„è¯å°±æ— æ³•ç»™è™šæ‹Ÿæœºæ·»åŠ  TPM è®¾å¤‡ åˆ›å»ºè™šæ‹Ÿæœºæ‰€åœ¨çš„ä¸»æœºéœ€è¦åœ¨ä¸€ä¸ªé›†ç¾¤ä¸­ï¼Œå¦åˆ™æ·»åŠ  TPM è®¾å¤‡åä¼šæ— æ³•åˆ›å»º ä»¥ä¸Šæ¡ä»¶å…·å¤‡åï¼Œå³å¯åˆ›å»ºè™šæ‹Ÿæœºï¼Œå¼•å¯¼éœ€è¦é€‰æ‹© EFI æ¨¡å¼ å¼€æœºåå°±ä¼šè‡ªåŠ¨è¿›è¡Œ OS å®‰è£…ï¼Œå¹¶æ³¨å†Œåˆ° Rancher Elemental é›†ç¾¤ä¸­ï¼Œå¯ä»¥åœ¨èŠ‚ç‚¹ä¸Šé€šè¿‡å‘½ä»¤æŸ¥çœ‹æ³¨å†ŒçŠ¶æ€ 1journalctl -f -u elemental-register-install.service æ³¨å†Œæ²¡é—®é¢˜çš„è¯ï¼Œä¼šç”Ÿæˆä¸€ä¸ª MachineInventoryï¼Œè®°å½•è®¾å¤‡çš„è¯¦ç»†ä¿¡æ¯ æ¥ç€å°±å¯ä»¥ç”¨è¿™ä¸ªèŠ‚ç‚¹åˆ›å»ºé›†ç¾¤","link":"/2024/11/20/Rancher-Elemental-%E4%BD%BF%E7%94%A8%E9%9A%8F%E8%AE%B0/"},{"title":"Rancher Pod Metrics éƒ¨åˆ† Panel No data é—®é¢˜æ’æŸ¥","text":"Rancher Pod Metrics æœ‰éƒ¨åˆ† Panel æ˜¾ç¤º No dataï¼Œåªæœ‰ Memory Utilization æ˜¾ç¤ºæ­£å¸¸ï¼š æœ€åˆæ£€æµ‹äº† Prometheusã€Prometheus Targetsã€Grafana ç­‰ï¼Œéƒ½æ²¡æœ‰å¼‚å¸¸ï¼Œç›´æ¥æŸ¥è¯¢ä¹Ÿæ˜¯æœ‰æ•°æ®çš„ã€‚ åæ¥æ£€æŸ¥äº† cattle-dashboards namespace ä¸‹çš„ rancher-default-dashboards-pods ConfigMapï¼Œå‘ç°é™¤äº† Memory Utilization ä¹‹å¤–ï¼Œå…¶ä»– Panel çš„ PromQL éƒ½ä½¿ç”¨äº† __rate_intervalï¼Œè¿™ä¸ªæ˜¯ Grafana 7.2 å¼•å…¥çš„æ–°å˜é‡ï¼Œç”¨äº Prometheus çš„ rate æŸ¥è¯¢ã€‚ æ ¹æ®æ–‡æ¡£çš„è§£é‡Šï¼Œ__rate_interval ä¾èµ–äº Prometheus scrape_interval è€Œè¿›è¡Œè®¡ç®—ï¼Œè¿™ä¸ªå€¼åœ¨ Grafana çš„æ•°æ®æºç•Œé¢å¯ä»¥çœ‹åˆ°ï¼ŒRancher Monitoring Grafana çš„é»˜è®¤æ•°æ®æºé…ç½®æ˜¯åœ¨ cattle-monitoring-system çš„ rancher-monitoring-grafana-datasource ConfigMapï¼Œå¯ä»¥çœ‹åˆ° timeInterval ä¸º 30sï¼š ä¸ Grafana æ•°æ®æºç•Œé¢ä¸­çš„ Scrape Interval ç›¸åŒï¼š å†å»æ£€æŸ¥ Prometheus çš„é…ç½®ï¼Œå‘ç° scrape_interval ä¸º 5mï¼Œä¸é»˜è®¤çš„ 30s ä¸ä¸€è‡´ï¼š æ‰€ä»¥é’ˆå¯¹è¿™ä¸ªé—®é¢˜æœ‰ä¸¤ä¸ªè§£æ³•ï¼š ä¿®æ”¹ cattle-monitoring-system çš„ rancher-monitoring-grafana-datasource ConfigMapï¼Œå°† timeInterval æ”¹ä¸º 5mã€‚ ä¿®æ”¹ Prometheus çš„ scrape_interval å› 30sã€‚ ä¿®æ”¹åé—®é¢˜è§£å†³ï¼š","link":"/2025/02/08/Rancher-Pod-Metrics-%E9%83%A8%E5%88%86-Panel-No-data-%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"},{"title":"RKE2 CoreDNS é…ç½®éšè®°","text":"RKE2 æ˜¯é€šè¿‡ HelmChartConfig CRD è¿›è¡Œé™„åŠ é…ç½®ï¼Œæ‰€ä»¥è¦é…ç½® CoreDNS çš„è¯ï¼Œå»ºè®®ä¹Ÿæ˜¯é€šè¿‡è¿™ç§æ–¹å¼è¿›è¡Œé…ç½®ã€‚ é…ç½® CoreDNS æ‰“å°è§£ææ—¥å¿—123456789101112131415161718192021222324252627282930313233343536cat &lt;&lt;EOF | kubectl apply -f -apiVersion: helm.cattle.io/v1kind: HelmChartConfigmetadata: name: rke2-coredns namespace: kube-systemspec: valuesContent: |- servers: - zones: - zone: . port: 53 plugins: - name: errors - name: health configBlock: |- lameduck 5s - name: ready - name: kubernetes parameters: cluster.local in-addr.arpa ip6.arpa configBlock: |- pods insecure fallthrough in-addr.arpa ip6.arpa ttl 30 - name: prometheus parameters: 0.0.0.0:9153 - name: forward parameters: . /etc/resolv.conf - name: cache parameters: 30 - name: loop - name: reload - name: loadbalance # æ­¤å¤„æ·»åŠ  log æ’ä»¶ - name: logEOF æ•ˆæœå¦‚ä¸‹ï¼š 1234567.:53[INFO] plugin/reload: Running configuration SHA512 = c6665a67f5213bb4bfff40d089abea74c2204a0de6a6081c3756bd4f5702dadc65adc46c9561ea09726560c76b14c7a17ee017d71c40337e40e1e7c3ee8d6580CoreDNS-1.11.1linux/amd64, go1.20.14 X:boringcrypto, ae2bbc29[INFO] 127.0.0.1:44801 - 7331 &quot;HINFO IN 394071549650387858.6622785674508966848. udp 56 false 512&quot; NOTIMP qr,rd,ra 56 0.015719481s[INFO] 172.16.16.140:49138 - 30061 &quot;A IN kubernetes.default.svc.cluster.local. udp 54 false 512&quot; NOERROR qr,aa,rd 106 0.000305994s[INFO] 172.16.16.140:64634 - 7352 &quot;AAAA IN kubernetes.default.svc.cluster.local. udp 54 false 512&quot; NOERROR qr,aa,rd 147 0.000231917s é…ç½® CoreDNS å¯¹ IPv6 ç±»å‹çš„ AAAA è®°å½•æŸ¥è¯¢è¿”å›åŸŸåä¸å­˜åœ¨å½“ä¸šåŠ¡ä¸éœ€è¦åš IPv6 çš„åŸŸåè§£ææ—¶ï¼Œå¯ä»¥é€šè¿‡è¯¥é…ç½®é™ä½é€šä¿¡æˆæœ¬ï¼š 12345678910111213141516171819202122232425262728293031323334353637383940cat &lt;&lt;EOF | kubectl apply -f -apiVersion: helm.cattle.io/v1kind: HelmChartConfigmetadata: name: rke2-coredns namespace: kube-systemspec: valuesContent: |- servers: - zones: - zone: . port: 53 plugins: - name: errors - name: health configBlock: |- lameduck 5s - name: ready - name: kubernetes parameters: cluster.local in-addr.arpa ip6.arpa configBlock: |- pods insecure fallthrough in-addr.arpa ip6.arpa ttl 30 - name: prometheus parameters: 0.0.0.0:9153 - name: forward parameters: . /etc/resolv.conf - name: cache parameters: 30 - name: loop - name: reload - name: loadbalance - name: log # æ­¤å¤„æ·»åŠ  template æ’ä»¶ - name: template parameters: ANY AAAA configBlock: |- rcode NXDOMAINEOF æ•ˆæœå¦‚ä¸‹ï¼š 1234567.:53[INFO] plugin/reload: Running configuration SHA512 = adff475b354490010d53800263b2eaf511bb7e61ee5f84f57447a0302a1d37032e245038e0026c71c91b32c77781b687ed1dc91ce7b82ce9f36ecdcbe5a8589dCoreDNS-1.11.1linux/amd64, go1.20.14 X:boringcrypto, ae2bbc29[INFO] 127.0.0.1:50998 - 41251 &quot;HINFO IN 3159548608793632308.3001229905203107415. udp 57 false 512&quot; NOTIMP qr,rd,ra 57 0.016489023s[INFO] 172.16.16.140:36027 - 14184 &quot;A IN kubernetes.default.svc.cluster.local. udp 54 false 512&quot; NOERROR qr,aa,rd 106 0.00025433s[INFO] 172.16.16.140:61510 - 9818 &quot;AAAA IN kubernetes.default.svc.cluster.local. udp 54 false 512&quot; NXDOMAIN qr,aa,rd 54 0.000246489s","link":"/2025/03/04/RKE2-CoreDNS-%E9%85%8D%E7%BD%AE%E9%9A%8F%E8%AE%B0/"},{"title":"Rancher å¯¹æ¥ Shibboleth + OpenLDAP","text":"å‰æå‰ææ˜¯éœ€è¦éƒ¨ç½²å¥½ Shibboleth å’Œ OpenLDAPã€‚ OpenLDAP éƒ¨ç½²å¯ä»¥å‚è€ƒï¼šOpenLDAP Install Shibboleth éƒ¨ç½²å¯ä»¥å‚è€ƒï¼šShibboleth Install è¿™é‡Œ Shibboleth é€šè¿‡å®¹å™¨éƒ¨ç½²ã€‚ Shibboleth éƒ¨ç½²é€šè¿‡å®¹å™¨å¯åŠ¨ Shibbolethï¼Œå¯ä»¥å…ˆå°†æ‰€éœ€è¦çš„é…ç½®æ–‡ä»¶ä»å®¹å™¨ä¸­æ‹·è´å‡ºæ¥ï¼Œä¿®æ”¹åæŒ‚è½½å¹¶é‡æ–°å¯åŠ¨å®¹å™¨ï¼Œä¸»è¦çš„æ–‡ä»¶æœ‰ï¼š 123456789root@docker-test-0:~/shibboleth-idp# tree.â”œâ”€â”€ access-control.xmlâ”œâ”€â”€ attribute-filter.xmlâ”œâ”€â”€ attribute-resolver.xmlâ”œâ”€â”€ ldap.propertiesâ”œâ”€â”€ metadata-providers.xmlâ”œâ”€â”€ rancher-metadata.xmlâ””â”€â”€ secrets.properties å‡†å¤‡ access-control.xmlï¼Œå‡†å…¥å“ªäº› IP è®¿é—® Shibbolethï¼š 1234&lt;entry key=&quot;AccessByIPAddress&quot;&gt; &lt;bean id=&quot;AccessByIPAddress&quot; parent=&quot;shibboleth.IPRangeAccessControl&quot; p:allowedRanges=&quot;#{ {'127.0.0.1/32', '172.16.16.11/32', '172.16.16.142/32', '172.16.16.140/32', '::1/128'} }&quot; /&gt;&lt;/entry&gt; å‡†å¤‡ attribute-filter.xmlï¼Œé…ç½®è¿”å›å±æ€§çš„æƒé™ï¼š 12345678910111213&lt;!-- å¢åŠ è¿‡æ»¤æ¡ä»¶, attributeID è·Ÿ attribute-resolver ä¸­çš„ friendlyName å€¼å¯¹åº” --&gt;&lt;AttributeFilterPolicy id=&quot;anyone&quot;&gt; &lt;PolicyRequirementRule xsi:type=&quot;ANY&quot;/&gt; &lt;!--&lt;PolicyRequirementRule xsi:type=&quot;Requester&quot; value=&quot;http://test-shibboleth.jacie.work/idp&quot; /&gt;--&gt; &lt;AttributeRule attributeID=&quot;uid&quot;&gt; &lt;PermitValueRule xsi:type=&quot;ANY&quot;/&gt; &lt;/AttributeRule&gt; &lt;AttributeRule attributeID=&quot;displayName&quot; permitAny=&quot;true&quot; /&gt; &lt;AttributeRule attributeID=&quot;givenName&quot; permitAny=&quot;true&quot;/&gt; &lt;AttributeRule attributeID=&quot;entryDN&quot; permitAny=&quot;true&quot;/&gt; &lt;AttributeRule attributeID=&quot;entryUUID&quot; permitAny=&quot;true&quot; /&gt; &lt;AttributeRule attributeID=&quot;memberOf&quot; permitAny=&quot;true&quot; /&gt;&lt;/AttributeFilterPolicy&gt; å‡†å¤‡ attribute-resolver.xmlï¼Œå®šä¹‰ Shibboleth è®¤è¯è¿”å›çš„å±æ€§ä¿¡æ¯ï¼š 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;!-- å¢åŠ  attribute é…ç½®ï¼Œè¿™é‡Œçš„ AttributeEncoder ä¸­çš„ name å±æ€§åœ¨å¤šä¸ª atribute ä¸­ä¸èƒ½é‡å¤ --&gt;&lt;AttributeDefinition xsi:type=&quot;Simple&quot; id=&quot;uid&quot;&gt; &lt;InputDataConnector ref=&quot;myLDAP&quot; attributeNames=&quot;uid&quot;/&gt; &lt;AttributeEncoder xsi:type=&quot;SAML1String&quot; name=&quot;urn:mace:dir:attribute-def:uid&quot; encodeType=&quot;false&quot; /&gt; &lt;AttributeEncoder xsi:type=&quot;SAML2String&quot; name=&quot;urn:oid:0.9.2342.19200300.100.1.1&quot; friendlyName=&quot;uid&quot; encodeType=&quot;false&quot; /&gt;&lt;/AttributeDefinition&gt;&lt;AttributeDefinition xsi:type=&quot;Simple&quot; id=&quot;surname&quot;&gt; &lt;InputDataConnector ref=&quot;myLDAP&quot; attributeNames=&quot;sn&quot;/&gt; &lt;AttributeEncoder xsi:type=&quot;SAML1String&quot; name=&quot;urn:mace:dir:attribute-def:sn&quot; encodeType=&quot;false&quot; /&gt; &lt;AttributeEncoder xsi:type=&quot;SAML2String&quot; name=&quot;urn:oid:2.5.4.4&quot; friendlyName=&quot;sn&quot; encodeType=&quot;false&quot; /&gt;&lt;/AttributeDefinition&gt;&lt;AttributeDefinition xsi:type=&quot;Simple&quot; id=&quot;givenName&quot;&gt; &lt;InputDataConnector ref=&quot;myLDAP&quot; attributeNames=&quot;givenName&quot;/&gt; &lt;AttributeEncoder xsi:type=&quot;SAML1String&quot; name=&quot;urn:mace:dir:attribute-def:givenName&quot; encodeType=&quot;false&quot; /&gt; &lt;AttributeEncoder xsi:type=&quot;SAML2String&quot; name=&quot;urn:oid:2.5.4.42&quot; friendlyName=&quot;givenName&quot; encodeType=&quot;false&quot; /&gt;&lt;/AttributeDefinition&gt;&lt;AttributeDefinition xsi:type=&quot;Simple&quot; id=&quot;displayName&quot;&gt; &lt;InputDataConnector ref=&quot;myLDAP&quot; attributeNames=&quot;displayName&quot;/&gt; &lt;AttributeEncoder xsi:type=&quot;SAML1String&quot; name=&quot;urn:mace:dir:attribute-def:displayName&quot; encodeType=&quot;false&quot; /&gt; &lt;AttributeEncoder xsi:type=&quot;SAML2String&quot; name=&quot;urn:oid:2.16.840.1.113730.3.1.241&quot; friendlyName=&quot;displayName&quot; encodeType=&quot;false&quot; /&gt;&lt;/AttributeDefinition&gt;&lt;!-- è·å–ç”¨æˆ·æ‰€å±è§’è‰²ä¿¡æ¯ï¼Œè¿™é‡Œå¿…é¡»é…ç½®ï¼Œå¦åˆ™å¯¹æ¥ Rancher åæ— æ³•è·å–ç”¨æˆ·ç»„ä¿¡æ¯ --&gt;&lt;AttributeDefinition xsi:type=&quot;Simple&quot; id=&quot;memberOf&quot;&gt; &lt;InputDataConnector ref=&quot;myLDAP&quot; attributeNames=&quot;memberOf&quot;/&gt; &lt;AttributeEncoder xsi:type=&quot;SAML1String&quot; name=&quot;urn:mace:dir:attribute-def:memberOf&quot; encodeType=&quot;false&quot; /&gt; &lt;AttributeEncoder xsi:type=&quot;SAML2String&quot; name=&quot;urn:oid:2.16.840.1.113730.3.1.244&quot; friendlyName=&quot;memberOf&quot; encodeType=&quot;false&quot; /&gt;&lt;/AttributeDefinition&gt;&lt;AttributeDefinition xsi:type=&quot;Simple&quot; id=&quot;entryDN&quot;&gt; &lt;InputDataConnector ref=&quot;myLDAP&quot; attributeNames=&quot;entryDN&quot;/&gt; &lt;AttributeEncoder xsi:type=&quot;SAML1String&quot; name=&quot;urn:mace:dir:attribute-def:entryDN&quot; encodeType=&quot;false&quot; /&gt; &lt;AttributeEncoder xsi:type=&quot;SAML2String&quot; name=&quot;urn:oid:2.5.4.5&quot; friendlyName=&quot;entryDN&quot; encodeType=&quot;false&quot; /&gt;&lt;/AttributeDefinition&gt;&lt;AttributeDefinition xsi:type=&quot;Simple&quot; id=&quot;entryUUID&quot;&gt; &lt;InputDataConnector ref=&quot;myLDAP&quot; attributeNames=&quot;entryUUID&quot;/&gt; &lt;AttributeEncoder xsi:type=&quot;SAML1String&quot; name=&quot;urn:mace:dir:attribute-def:entryUUID&quot; encodeType=&quot;false&quot; /&gt; &lt;AttributeEncoder xsi:type=&quot;SAML2String&quot; name=&quot;urn:oid:2.5.4.6&quot; friendlyName=&quot;entryUUID&quot; encodeType=&quot;false&quot; /&gt;&lt;/AttributeDefinition&gt;&lt;!-- ç¤ºä¾‹ä¸­çš„ myLDAP é…ç½®ä¸­å¢åŠ  ReturnAttributes å±æ€§ --&gt;&lt;DataConnector id=&quot;myLDAP&quot; xsi:type=&quot;LDAPDirectory&quot; ldapURL=&quot;%{idp.attribute.resolver.LDAP.ldapURL}&quot; baseDN=&quot;%{idp.attribute.resolver.LDAP.baseDN}&quot; principal=&quot;%{idp.attribute.resolver.LDAP.bindDN}&quot; principalCredential=&quot;%{idp.attribute.resolver.LDAP.bindDNCredential}&quot; useStartTLS=&quot;%{idp.attribute.resolver.LDAP.useStartTLS:true}&quot; connectTimeout=&quot;%{idp.attribute.resolver.LDAP.connectTimeout}&quot; responseTimeout=&quot;%{idp.attribute.resolver.LDAP.responseTimeout}&quot;&gt; &lt;FilterTemplate&gt; &lt;![CDATA[ %{idp.attribute.resolver.LDAP.searchFilter} ]]&gt; &lt;/FilterTemplate&gt; &lt;ConnectionPool minPoolSize=&quot;%{idp.pool.LDAP.minSize:3}&quot; maxPoolSize=&quot;%{idp.pool.LDAP.maxSize:10}&quot; blockWaitTime=&quot;%{idp.pool.LDAP.blockWaitTime:PT3S}&quot; validatePeriodically=&quot;%{idp.pool.LDAP.validatePeriodically:true}&quot; validateTimerPeriod=&quot;%{idp.pool.LDAP.validatePeriod:PT5M}&quot; expirationTime=&quot;%{idp.pool.LDAP.idleTime:PT10M}&quot; /&gt; &lt;ReturnAttributes&gt;%{idp.attribute.resolver.LDAP.returnAttributes}&lt;/ReturnAttributes&gt;&lt;/DataConnector&gt; å‡†å¤‡ ldap.propertiesï¼Œé…ç½® OpenLDAP ç›¸å…³ä¿¡æ¯è¿›è¡Œå¯¹æ¥ï¼š 1234567891011121314151617181920idp.authn.LDAP.authenticator = bindSearchAuthenticatoridp.authn.LDAP.ldapURL = ldap://172.16.16.142:389idp.authn.LDAP.useStartTLS = falseidp.authn.LDAP.returnAttributes = cn,uid,sn,displayName,givenName,memberOf,entryDN,entryUUIDidp.authn.LDAP.baseDN = ou=shenzhen,dc=rancher,dc=workidp.authn.LDAP.subtreeSearch = trueidp.authn.LDAP.userFilter = (&amp;(objectclass=inetOrgPerson)(uid={user}))idp.authn.LDAP.bindDN = cn=admin,dc=rancher,dc=workidp.authn.LDAP.dnFormat = uid=warner chen,ou=shenzhen,dc=rancher,dc=workidp.attribute.resolver.LDAP.ldapURL = %{idp.authn.LDAP.ldapURL}idp.attribute.resolver.LDAP.connectTimeout = %{idp.authn.LDAP.connectTimeout:PT3S}idp.attribute.resolver.LDAP.responseTimeout = %{idp.authn.LDAP.responseTimeout:PT3S}idp.attribute.resolver.LDAP.connectionStrategy = %{idp.authn.LDAP.connectionStrategy:ACTIVE_PASSIVE}idp.attribute.resolver.LDAP.baseDN = %{idp.authn.LDAP.baseDN:undefined}idp.attribute.resolver.LDAP.bindDN = %{idp.authn.LDAP.bindDN:undefined}idp.attribute.resolver.LDAP.useStartTLS = %{idp.authn.LDAP.useStartTLS:true}idp.attribute.resolver.LDAP.startTLSTimeout = %{idp.authn.LDAP.startTLSTimeout:PT3S}idp.attribute.resolver.LDAP.trustCertificates = %{idp.authn.LDAP.trustCertificates:undefined}idp.attribute.resolver.LDAP.searchFilter = (uid=$resolutionContext.principal)idp.attribute.resolver.LDAP.returnAttributes = %{idp.authn.LDAP.returnAttributes} å‡†å¤‡ secrets.propertiesï¼Œé…ç½®å¯†ç è®¤è¯ä¿¡æ¯ï¼š 1234idp.sealer.storePassword = idpsealerpwdidp.sealer.keyPassword = idpsealerpwdidp.authn.LDAP.bindDNCredential = passwordidp.attribute.resolver.LDAP.bindDNCredential = %{idp.authn.LDAP.bindDNCredential:undefined} å‡†å¤‡ metadata-providers.xmlï¼Œé…ç½®å¯¹æ¥ metadataï¼Œåœ¨åŸæœ‰çš„é…ç½®å¢åŠ ä¸‹é¢çš„å†…å®¹ï¼š 12&lt;MetadataProvider id=&quot;LocalEntityMetadata&quot; xsi:type=&quot;FilesystemMetadataProvider&quot; metadataFile=&quot;/opt/shibboleth-idp/metadata/rancher-metadata.xml&quot;/&gt; å‡†å¤‡ rancher-metadata.xmlï¼Œéœ€è¦ä» Rancher ä¸­ä¸‹è½½ï¼š 1curl --insecure https://&lt;server-url&gt;/v1-saml/shibboleth/saml/metadata -o rancher-metadata.xml å¯åŠ¨ Shibboleth å®¹å™¨ï¼š 123456789docker run -d --name shibboleth-idp -p 8080:8080 \\ -v /root/shibboleth-idp/access-control.xml:/opt/shibboleth-idp/conf/access-control.xml \\ -v /root/shibboleth-idp/attribute-filter.xml:/opt/shibboleth-idp/conf/attribute-filter.xml \\ -v /root/shibboleth-idp/attribute-resolver.xml:/opt/shibboleth-idp/conf/attribute-resolver.xml \\ -v /root/shibboleth-idp/ldap.properties:/opt/shibboleth-idp/conf/ldap.properties \\ -v /root/shibboleth-idp/secrets.properties:/opt/shibboleth-idp/credentials/secrets.properties \\ -v /root/shibboleth-idp/rancher-metadata.xml:/opt/shibboleth-idp/metadata/rancher-metadata.xml \\ -v /root/shibboleth-idp/metadata-providers.xml:/opt/shibboleth-idp/conf/metadata-providers.xml \\ harbor.warnerchen.com/klaalo/shibboleth-idp:4.3.1 è¿™æ—¶å€™éœ€è¦éƒ¨ç½²ä¸€ä¸ª Nginx ä½œä¸ºåå‘ä»£ç†ï¼Œå‡†å¤‡é…ç½®æ–‡ä»¶ï¼š 1234567891011121314151617181920212223242526cat &lt;&lt;EOF &gt; /root/nginx/default.confserver { listen 80; server_name idp.example.org; location / { return 301 https://$host$request_uri; }}server { listen 443 ssl; server_name idp.example.org; ssl_certificate /etc/nginx/ssl/myservice.cert; ssl_certificate_key /etc/nginx/ssl/myservice.key; location / { proxy_pass http://172.16.16.142:8080; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; }}EOF å‡†å¤‡è¯ä¹¦ï¼š 1openssl req -x509 -newkey rsa:2048 -keyout myservice.key -out myservice.cert -days 365 -nodes -subj &quot;/CN=idp.example.org&quot; å¯åŠ¨ Nginxï¼š 1234567docker run -d \\ --name nginx \\ -v /root/nginx/default.conf:/etc/nginx/conf.d/default.conf \\ -v /root/nginx/ssl:/etc/nginx/ssl \\ -p 80:80 \\ -p 443:443 \\ harbor.warnerchen.com/library/nginx:mainline Rancher å¯¹æ¥ Shibbolethå¦‚å›¾ï¼Œè¯ä¹¦å’Œç§é’¥å¯ä»¥ç”¨å‰é¢ç”Ÿæˆçš„ï¼ŒXML å…ƒæ•°æ®éœ€è¦ä» Shibboleth çš„ /opt/shibboleth-idp/metadata/idp-metadata.xml è·å–ï¼š ä¿å­˜åä¼šå¼¹çª—ï¼Œéœ€è¦è¿›è¡Œç™»é™†è®¤è¯ï¼Œç›´æ¥ä½¿ç”¨ OpenLDAP çš„è´¦å·å¯†ç å³å¯ï¼Œç”¨æˆ·ååªéœ€è¦å¡« uidã€‚ äºæ­¤æ­¥éª¤ä¸­è¾“å…¥çš„å‡­æ®ç›¸å…³çš„ IDP ç”¨æˆ·å°†æ˜ å°„åˆ°æœ¬åœ°ä¸»ä½“(admin)å¸æˆ·å¹¶åœ¨ Rancher Prime Manager ä¸­åˆ†é…ç³»ç»Ÿç®¡ç†å‘˜æƒé™ï¼Œæ‰€ä»¥æŸ¥çœ‹ local admin è´¦æˆ·å¯ä»¥çœ‹åˆ°ï¼š 12345678910apiVersion: management.cattle.io/v3description: ''displayName: Default Adminkind: User...principalIds: - local://user-xdvhb - shibboleth_user://warner chen...username: xxx Rancher å¯¹æ¥ Shibboleth + OpenLDAP å®ç°ç”¨æˆ·ç»„æˆæƒåœ¨é…ç½®ä¹‹å‰ OpenLDAP éœ€è¦å¼€å¯ memberOf å±æ€§ï¼Œåˆ›å»ºç”¨æˆ·ç»„å¹¶å°†ç”¨æˆ·æ·»åŠ åˆ°ç»„ä¸­ï¼Œé…ç½®æ–¹æ³•å¯ä»¥å‚è€ƒï¼šé…ç½®ç”¨æˆ·å’Œç”¨æˆ·ç»„ é…ç½®åï¼Œç”¨æˆ·çš„éšè—ä¿¡æ¯èƒ½å¤Ÿçœ‹åˆ°æ‰€å±ç»„ï¼š ç„¶å Rancher éœ€è¦é…ç½®ç”¨æˆ·ç»„æœç´¢åº“ï¼Œè¿™é‡Œçš„ DN æ ¹æ®å®é™…æƒ…å†µå¡«å†™ï¼š OpenLDAP ç›®å½•ç»“æ„ä¸ºï¼š å¯¹æ¥å®Œæˆåï¼Œå³å¯é€šè¿‡ç»„è¿›è¡Œæˆæƒï¼š æˆæƒåï¼Œç»„å†…ç”¨æˆ·ç™»å½• Rancherï¼Œå³å¯ä»¥åˆ°å¯¹åº”çš„èµ„æºï¼š","link":"/2024/12/25/Rancher-%E5%AF%B9%E6%8E%A5-Shibboleth-OpenLDAP/"},{"title":"Rancher Monitoring V2 Prometheus PVC æ‰©å®¹","text":"æ ¹æ® Prometheus Operator å®˜æ–¹æ–‡æ¡£ æè¿°ï¼Œå³ä½¿ StorageClass æ”¯æŒè°ƒæ•´å¤§å°ï¼ŒKubernetesï¼ˆç›®å‰ï¼‰ä¹Ÿä¸æ”¯æŒé€šè¿‡ StatefulSets æ‰©å±•å·ã€‚è¿™æ„å‘³ç€åœ¨æ›´æ–° Prometheus ç­‰è‡ªå®šä¹‰èµ„æºçš„ spec.storage å­—æ®µä¸­çš„å­˜å‚¨è¯·æ±‚æ—¶ï¼ŒOperator å¿…é¡»åˆ é™¤/åˆ›å»ºåº•å±‚çš„ StatefulSetï¼Œè€Œç›¸å…³çš„ PVC ä¸ä¼šæ‰©å±•ã€‚ å¯ä»¥é€šè¿‡ä¸‹é¢çš„æ­¥éª¤è¿›è¡Œæ‰‹åŠ¨æ‰©å®¹ã€‚ é¦–å…ˆéœ€è¦æ£€æŸ¥ StorageClass æ”¯ä¸æ”¯æŒ volume çš„æ‰©å®¹ï¼š 1kubectl get storageclass &lt;storageclass_name&gt; -o custom-columns=NAME:.metadata.name,ALLOWVOLUMEEXPANSION:.allowVolumeExpansion åœ¨ Rancher æ›´æ–° Helm Chart çš„ valuesï¼Œå°†å­˜å‚¨å¤§å°æ”¹æˆéœ€è¦çš„å€¼ï¼Œå†é€šè¿‡ Yaml ç¼–è¾‘å°† Prometheus çš„ paused æ”¹æˆ trueï¼ˆéœ€è¦æ³¨æ„ Yaml ä¸­å¤šå¤„å­˜åœ¨ paused çš„é…ç½®ï¼Œéœ€è¦æ”¹çš„æ˜¯ Prometheus çš„ï¼‰ï¼š ç­‰å¾…æ›´æ–°å®Œæˆåï¼Œé€šè¿‡ä¸‹é¢çš„å‘½ä»¤æ£€æŸ¥æ˜¯å¦æ›´æ–°æˆåŠŸï¼š 1kubectl -n cattle-monitoring-system get prometheus rancher-monitoring-prometheus -oyaml | grep -E &quot;paused|storage&quot; æ‰‹åŠ¨æ›´æ–° PVC çš„å­˜å‚¨å€¼ï¼š 1kubectl -n cattle-monitoring-system patch pvc/prometheus-rancher-monitoring-prometheus-db-prometheus-rancher-monitoring-prometheus-0 --patch '{&quot;spec&quot;: {&quot;resources&quot;: {&quot;requests&quot;: {&quot;storage&quot;:&quot;10Gi&quot;}}}}' åˆ é™¤ StatefulSetï¼š 1kubectl -n cattle-monitoring-system delete statefulset -l operator.prometheus.io/name=rancher-monitoring-prometheus --cascade=orphan åœ¨ Rancher æ›´æ–° Helm Chart çš„ valuesï¼Œé€šè¿‡ Yaml ç¼–è¾‘å°† Prometheus çš„ paused æ”¹å› falseï¼Œæ›´æ–°å®Œæ¯•ä¹‹å Operator å°±ä¼šé‡æ–°ç”Ÿæˆ StatefulSetï¼š æ£€æŸ¥æ˜¯å¦æ‰©å®¹æˆåŠŸï¼Œæ£€æŸ¥ Prometheus å’Œ StatefulSet ä»¥åŠ PVC æ•°æ®æ˜¯å¦ä¸€è‡´ï¼š 1234kubectl -n cattle-monitoring-system get prometheus rancher-monitoring-prometheus -oyaml | grep -E &quot;paused|storage&quot;kubectl -n cattle-monitoring-system get sts prometheus-rancher-monitoring-prometheus -oyaml | grep &quot;storage:&quot;kubectl -n cattle-monitoring-system get pvc prometheus-rancher-monitoring-prometheus-db-prometheus-rancher-monitoring-prometheus-0kubectl -n cattle-monitoring-system exec -it prometheus-rancher-monitoring-prometheus-0 -- df -h /prometheus","link":"/2025/02/10/Rancher-Monitoring-V2-Prometheus-PVC-%E6%89%A9%E5%AE%B9/"},{"title":"Redis Operator ä½¿ç”¨éšè®°","text":"åŸºäº OT-CONTAINER-KIT/redis-operator é¡¹ç›®ï¼Œä½¿ç”¨ Operator åœ¨ Kubernetes ä¸Šéƒ¨ç½² Redisã€‚ å®‰è£… Operator123helm repo add ot-helm https://ot-container-kit.github.io/helm-charts/helm upgrade redis-operator ot-helm/redis-operator \\ --install --create-namespace --namespace ot-operators éƒ¨ç½² Redis Standalone 12345678910111213141516171819202122232425262728cat &lt;&lt;EOF | kubectl apply -f -apiVersion: redis.redis.opstreelabs.in/v1beta1kind: Redismetadata: name: redis-standalonespec: kubernetesConfig: image: quay.io/opstree/redis:v7.0.15 imagePullPolicy: IfNotPresent resources: requests: cpu: 101m memory: 128Mi limits: cpu: 101m memory: 128Mi storage: volumeClaimTemplate: spec: storageClassName: longhorn accessModes: [&quot;ReadWriteOnce&quot;] resources: requests: storage: 1Gi securityContext: runAsUser: 1000 fsGroup: 1000EOF å¦‚æœå‡ºç°æŠ¥é”™ï¼š 1Can't open or create append-only dir appendonlydir: Permission denied éœ€è¦ä¿®æ”¹æ•°æ®ç›®å½•æƒé™è§£å†³ï¼š 1chown -R ubuntu:ubuntu /&lt;path-to-redis-data-dir&gt; éƒ¨ç½²åå°±å¯ä»¥é€šè¿‡ redis-cli å·¥å…·è¿æ¥ï¼š 123456root@rke2-cilium-01:~# kubectl exec -it redis-standalone-0 -- bashredis-standalone-0:/data$ redis-cli127.0.0.1:6379&gt; info# Serverredis_version:7.0.15... éƒ¨ç½² Redis Cluster 12345678910111213141516171819202122232425262728293031cat &lt;&lt;EOF | kubectl apply -f -apiVersion: redis.redis.opstreelabs.in/v1beta1kind: RedisClustermetadata: name: redis-clusterspec: clusterSize: 1 clusterVersion: v7 securityContext: runAsUser: 1000 fsGroup: 1000 persistenceEnabled: true kubernetesConfig: image: quay.io/opstree/redis:v7.0.15 imagePullPolicy: Always resources: requests: cpu: 101m memory: 128Mi limits: cpu: 101m memory: 128Mi storage: volumeClaimTemplate: spec: storageClassName: longhorn accessModes: [&quot;ReadWriteOnce&quot;] resources: requests: storage: 1GiEOF éƒ¨ç½² Redis Sentinel 1234567891011121314151617181920212223cat &lt;&lt;EOF | kubectl apply -f -apiVersion: redis.redis.opstreelabs.in/v1beta1kind: RedisSentinelmetadata: name: redis-sentinelspec: clusterSize: 1 securityContext: runAsUser: 1000 fsGroup: 1000 redisSentinelConfig: redisReplicationName : redis-replication kubernetesConfig: image: quay.io/opstree/redis-sentinel:v7.0.15 imagePullPolicy: IfNotPresent resources: requests: cpu: 101m memory: 128Mi limits: cpu: 101m memory: 128MiEOF é…ç½® Auth1kubectl create secret generic redis-secret --from-literal=password=changeme 12345678910111213141516171819202122232425262728293031cat &lt;&lt;EOF | kubectl apply -f -apiVersion: redis.redis.opstreelabs.in/v1beta1kind: Redismetadata: name: redis-standalonespec: kubernetesConfig: image: quay.io/opstree/redis:v7.0.15 imagePullPolicy: IfNotPresent resources: requests: cpu: 101m memory: 128Mi limits: cpu: 101m memory: 128Mi redisSecret: name: redis-secret key: password storage: volumeClaimTemplate: spec: storageClassName: longhorn accessModes: [&quot;ReadWriteOnce&quot;] resources: requests: storage: 1Gi securityContext: runAsUser: 1000 fsGroup: 1000EOF å¯ä»¥çœ‹åˆ°éœ€è¦å¯†ç è®¤è¯åæ‰èƒ½ä½¿ç”¨ï¼š 12345root@rke2-cilium-01:~# kubectl exec -it redis-standalone-0 -- redis-cli127.0.0.1:6379&gt; infoNOAUTH Authentication required.127.0.0.1:6379&gt; auth changemeOK æ·»åŠ é¢å¤–é…ç½®1234567891011cat &lt;&lt;EOF | kubectl apply -f -apiVersion: v1kind: ConfigMapmetadata: name: redis-external-configdata: redis-additional.conf: | tcp-keepalive 400 slowlog-max-len 158 stream-node-max-bytes 2048EOF 123456789101112131415161718192021222324252627282930313233cat &lt;&lt;EOF | kubectl apply -f -apiVersion: redis.redis.opstreelabs.in/v1beta1kind: Redismetadata: name: redis-standalonespec: redisConfig: additionalRedisConfig: redis-external-config kubernetesConfig: image: quay.io/opstree/redis:v7.0.15 imagePullPolicy: IfNotPresent resources: requests: cpu: 101m memory: 128Mi limits: cpu: 101m memory: 128Mi redisSecret: name: redis-secret key: password storage: volumeClaimTemplate: spec: storageClassName: longhorn accessModes: [&quot;ReadWriteOnce&quot;] resources: requests: storage: 1Gi securityContext: runAsUser: 1000 fsGroup: 1000EOF","link":"/2025/01/13/Redis-Operator-%E4%BD%BF%E7%94%A8%E9%9A%8F%E8%AE%B0/"},{"title":"SUSE AI ä½¿ç”¨éšè®°","text":"SUSE AI æ˜¯ä¸€ä¸ªå¼€æ”¾çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½è§£å†³æ–¹æ¡ˆï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹ç»„ä»¶ï¼š Ollamaï¼šç®€åŒ–æœ¬åœ°è®¾å¤‡ä¸Šå¤§å‹è¯­è¨€æ¨¡å‹ (LLM) å®‰è£…å’Œç®¡ç†çš„å¹³å°ã€‚ Open WebUIï¼šOllama LLM è¿è¡Œç¨‹åºçš„å¯æ‰©å±•ç½‘ç»œç”¨æˆ·ç•Œé¢ã€‚ Milvusï¼šä¸ºç”Ÿæˆå¼äººå·¥æ™ºèƒ½åº”ç”¨æ„å»ºçš„å‘é‡æ•°æ®åº“ï¼Œæ€§èƒ½æŸå¤±æœ€å°ã€‚ å®‰è£…å‰å‡†å¤‡å®‰è£… SUSE AI å‰éœ€è¦å®‰è£… cert-managerï¼š 12345678helm repo add jetstack https://charts.jetstack.iohelm repo updatehelm install \\ cert-manager jetstack/cert-manager \\ --namespace cert-manager \\ --create-namespace \\ --version v1.15.3 \\ --set crds.enabled=true è¿˜éœ€è¦å®‰è£…ä¸­é—´ä»¶ä½¿ç”¨çš„å­˜å‚¨ï¼Œè¿™é‡Œä½¿ç”¨ local-pathï¼š 1$ kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.31/deploy/local-path-storage.yaml å…¶å®ƒå®‰è£…å‰å‡†å¤‡ï¼š 1234567891011kubectl create namespace suse-private-aikubectl create secret docker-registry application-collection \\ --docker-server=dp.apps.rancher.io \\ --docker-username=APPCO_USERNAME \\ --docker-password=APPCO_USER_TOKEN \\ -n suse-private-aihelm registry login dp.apps.rancher.io/charts \\ -u APPCO_USERNAME \\ -p APPCO_USER_TOKEN å®‰è£… Milvuså‡†å¤‡ Milvus é…ç½®ï¼š 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455cat &lt;&lt;EOF &gt; milvus_custom_overrides.yamlglobal: imagePullSecrets: - application-collectioncluster: enabled: Truestandalone: persistence: persistentVolumeClaim: storageClass: local-pathetcd: replicaCount: 1 persistence: storageClassName: local-pathminio: mode: standalone replicas: 1 rootUser: &quot;admin&quot; rootPassword: &quot;adminminio&quot; persistence: storageClass: local-path resources: requests: memory: 1024Mi persistence: enabled: true storageClass: local-path accessMode: ReadWriteOnce size: 10Gikafka: enabled: true name: kafka replicaCount: 3 controller: statefulset: replicas: 1 broker: enabled: true statefulset: replicas: 1 cluster: listeners: client: protocol: 'PLAINTEXT' controller: protocol: 'PLAINTEXT' persistence: enabled: true accessModes: - ReadWriteOnce resources: requests: storage: 5Gi storageClassName: &quot;local-path&quot;EOF å¦‚éœ€è‡ªå®šä¹‰é•œåƒä»“åº“ï¼š 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273cat &lt;&lt;EOF &gt; milvus_custom_overrides.yamlimage: all: registry: harbor.warnerchen.com repository: appco/containers/milvuscluster: enabled: Truestandalone: persistence: persistentVolumeClaim: storageClass: local-pathetcd: images: etcd: registry: harbor.warnerchen.com repository: appco/containers/etcd replicaCount: 1 persistence: storageClassName: local-pathminio: image: registry: harbor.warnerchen.com repository: appco/containers/minio mcImage: registry: harbor.warnerchen.com repository: appco/containers/mc mode: standalone replicas: 1 rootUser: &quot;admin&quot; rootPassword: &quot;adminminio&quot; persistence: storageClass: local-path resources: requests: memory: 1024Mi persistence: enabled: true storageClass: local-path accessMode: ReadWriteOnce size: 10Gikafka: images: controller: registry: harbor.warnerchen.com repository: appco/containers/apache-kafka broker: registry: harbor.warnerchen.com repository: appco/containers/apache-kafka enabled: true name: kafka replicaCount: 3 controller: statefulset: replicas: 1 broker: enabled: true statefulset: replicas: 1 cluster: listeners: client: protocol: 'PLAINTEXT' controller: protocol: 'PLAINTEXT' persistence: enabled: true accessModes: - ReadWriteOnce resources: requests: storage: 5Gi storageClassName: &quot;local-path&quot;EOF å®‰è£… Milvusï¼š 123helm upgrade --install milvus oci://dp.apps.rancher.io/charts/milvus \\ -n suse-private-ai \\ --version 4.2.2 -f milvus_custom_overrides.yaml å®‰è£… Ollamaå‡†å¤‡ Ollama é…ç½®ï¼š 1234567891011121314151617181920cat &lt;&lt;EOF &gt; ollama_custom_overrides.yamlglobal: imagePullSecrets: - application-collectionreplicaCount: 1runtimeClassName: &quot;nvidia&quot;ingress: enabled: falsedefaultModel: &quot;llama2&quot;ollama: models: - &quot;llama2&quot; gpu: enabled: true type: 'nvidia' number: 1persistentVolume: enabled: true storageClass: local-pathEOF å¦‚éœ€è‡ªå®šä¹‰é•œåƒä»“åº“ï¼š 123456789101112131415161718192021cat &lt;&lt;EOF &gt; ollama_custom_overrides.yamlimage: repository: appco/containers/ollama registry: harbor.warnerchen.com pullPolicy: IfNotPresentreplicaCount: 1runtimeClassName: &quot;nvidia&quot;ingress: enabled: falsedefaultModel: &quot;llama2&quot;ollama: models: - &quot;llama2&quot; gpu: enabled: true type: 'nvidia' number: 1persistentVolume: enabled: true storageClass: local-pathEOF å®‰è£… Ollamaï¼š 123helm upgrade --install ollama oci://dp.apps.rancher.io/charts/ollama \\ -n suse-private-ai \\ --version 0.63.0 -f ollama_custom_overrides.yaml å®‰è£… Open WebUIå‡†å¤‡ Open WebUI é…ç½®ï¼š 12345678910111213141516171819202122232425262728293031323334353637383940cat &lt;&lt;EOF &gt; owui_custom_overrides.yamlglobal: imagePullSecrets: - application-collectionollamaUrls:- http://ollama.suse-private-ai.svc.cluster.local:11434persistence: enabled: true storageClass: local-pathollama: enabled: falsepipelines: enabled: Falseingress: enabled: true class: &quot;nginx&quot; annotations: nginx.ingress.kubernetes.io/ssl-redirect: &quot;true&quot; host: suse-ollama-webui.warnerchen.com tls: trueextraEnvVars:- name: DEFAULT_MODELS value: &quot;llama2&quot;- name: DEFAULT_USER_ROLE value: &quot;user&quot;- name: WEBUI_NAME value: &quot;SUSE AI&quot;- name: GLOBAL_LOG_LEVEL value: INFO- name: RAG_EMBEDDING_MODEL value: &quot;sentence-transformers/all-MiniLM-L6-v2&quot;- name: VECTOR_DB value: &quot;milvus&quot;- name: MILVUS_URI value: http://milvus.suse-private-ai.svc.cluster.local:19530- name: INSTALL_NLTK_DATASETS value: &quot;true&quot;cert-manager: enabled: falseEOF å¦‚éœ€è‡ªå®šä¹‰é•œåƒä»“åº“ï¼š 1234567891011121314151617181920212223242526272829303132333435363738394041cat &lt;&lt;EOF &gt; owui_custom_overrides.yamlimage: registry: harbor.warnerchen.com repository: appco/containers/open-webui pullPolicy: IfNotPresentollamaUrls:- http://ollama.suse-private-ai.svc.cluster.local:11434persistence: enabled: true storageClass: local-pathollama: enabled: falsepipelines: enabled: Falseingress: enabled: true class: &quot;nginx&quot; annotations: nginx.ingress.kubernetes.io/ssl-redirect: &quot;true&quot; host: suse-ollama-webui.warnerchen.com tls: trueextraEnvVars:- name: DEFAULT_MODELS value: &quot;llama2&quot;- name: DEFAULT_USER_ROLE value: &quot;user&quot;- name: WEBUI_NAME value: &quot;SUSE AI&quot;- name: GLOBAL_LOG_LEVEL value: INFO- name: RAG_EMBEDDING_MODEL value: &quot;sentence-transformers/all-MiniLM-L6-v2&quot;- name: VECTOR_DB value: &quot;milvus&quot;- name: MILVUS_URI value: http://milvus.suse-private-ai.svc.cluster.local:19530- name: INSTALL_NLTK_DATASETS value: &quot;true&quot;cert-manager: enabled: falseEOF ç­‰å¾…æ‰€æœ‰ Pod æ­£å¸¸è¿è¡Œï¼š è®¿é—® Open WebUIï¼š é€‰æ‹©æ¨¡å‹è¿›è¡Œå¯¹è¯ï¼š å¯ä»¥çœ‹åˆ° Ollama è°ƒç”¨ GPUï¼š å‚è€ƒé“¾æ¥ï¼š https://hackmd.io/@7vxmAdNPTmmlYGSRMuvbmw/HkibY6m8ke https://documentation.suse.com/suse-ai/1.0/html/AI-deployment-intro/index.html","link":"/2025/02/19/SUSE-AI-%E4%BD%BF%E7%94%A8%E9%9A%8F%E8%AE%B0/"},{"title":"Ansible","text":"ä¸€ã€Ansibleç®€ä»‹ansbileæ˜¯ä¸€ä¸ªITè‡ªåŠ¨åŒ–çš„é…ç½®ç®¡ç†å·¥å…·ï¼Œè‡ªåŠ¨åŒ–ä¸»è¦ä½“ç°åœ¨Ansibleé›†æˆäº†ä¸°å¯Œçš„æ¨¡å—ï¼Œå¯ä»¥é€šè¿‡ä¸€ä¸ªå‘½ä»¤å®Œæˆä¸€ç³»åˆ—çš„æ“ä½œï¼Œè¿›è€Œå‡å°‘è¿ç»´é‡å¤æ€§çš„å·¥ä½œå’Œç»´æŠ¤æˆæœ¬ï¼Œæé«˜å·¥ä½œæ•ˆç‡ã€‚ 1.1 ä¸ºä»€ä¹ˆéœ€è¦ansibleæ€è€ƒï¼šå‡è®¾æˆ‘ä»¬è¦åœ¨10å°æœåŠ¡å™¨ä¸Šå®‰è£…å¹¶è¿è¡Œnginxï¼Œè¦å¦‚ä½•æ“ä½œï¼Ÿ sshè¿œç¨‹ç™»å½•åˆ°æœåŠ¡å™¨ æ‰§è¡Œyum -y install nginx æ‰§è¡Œsystemctl start nginx æ‰§è¡Œsystemctl enable nginx é‡å¤åæ¬¡ã€‚ã€‚ã€‚ å¯ä»¥çœ‹åˆ°ç®€å•çš„å·¥ä½œè¦åšåæ¬¡æ˜¯å¾ˆæµªè´¹æ—¶é—´çš„ï¼Œè¿™æ—¶å€™æˆ‘ä»¬å°±éœ€è¦ansibleäº†ã€‚ 1.2 ansibleæœ‰å“ªäº›åŠŸèƒ½ æ‰¹é‡æ‰§è¡Œè¿œç¨‹å‘½ä»¤ï¼Œå¯ä»¥åŒæ—¶å¯¹Nå°ä¸»æœºæ‰§è¡Œå‘½ä»¤ æ‰¹é‡é…ç½®è½¯ä»¶æœåŠ¡ï¼Œå¯ä»¥ç”¨è‡ªåŠ¨åŒ–çš„æ–¹å¼é…ç½®å’Œç®¡ç†æœåŠ¡ å®ç°è½¯ä»¶å¼€å‘åŠŸèƒ½ï¼Œjumpserveråº•å±‚ä½¿ç”¨ansibleæ¥å®ç°è‡ªåŠ¨åŒ–ç®¡ç† ç¼–æ’é«˜çº§çš„ITä»»åŠ¡ï¼Œplaybookæ˜¯ansbileçš„ä¸€é—¨ç¼–ç¨‹è¯­è¨€ï¼Œå¯ä»¥ç”¨æ¥æç»˜ä¸€å¥—ITæ¶æ„ äºŒã€Ansibleå®‰è£…2.1 åœ¨æ§åˆ¶ç«¯ä¸Šå®‰è£…ansibleç›´æ¥åˆ©ç”¨yumæºå®‰è£…å³å¯ï¼Œansibleé…ç½®æ–‡ä»¶ä¸€èˆ¬ä¸éœ€è¦åšå˜åŠ¨ 1yum -y install ansible 2.2 ansibleé…ç½®æ–‡ä»¶çš„ä¼˜å…ˆçº§ å¦‚æœå½“å‰ç›®å½•ä¸å­˜åœ¨ansible.cfgï¼Œä¼šé‡‡ç”¨é»˜è®¤çš„é…ç½®æ–‡ä»¶ 1234ansible --version...config file = /etc/ansible/ansible.cfg... å¦‚æœå½“å‰ç›®å½•å­˜åœ¨ansible.cfgï¼Œåˆ™ä¼šé‡‡ç”¨å½“å‰ç›®å½•çš„é…ç½®æ–‡ä»¶ 1234ansible --version...config file = /root/project1/ansible.cfg... 2.3 ansibleçš„Inventoryåˆ©ç”¨å¯†é’¥æ¥è¿æ¥è¢«æ§ç«¯ åœ¨é¡¹ç›®ç›®å½•ä¸‹åˆ›å»ºhostsæ–‡ä»¶ 12345cd project1vim hosts[cqm]192.168.88.133192.168.88.134 åˆ›å»ºå¯†é’¥ 123ssh-keygenls /root/.ssh/authorized_keys id_rsa id_rsa.pub known_hosts å°†å…¬é’¥ä¼ é€è‡³è¢«æ§ç«¯ä¸»æœº 12ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.88.133ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.88.134 æµ‹è¯•æ˜¯å¦ä¸éœ€è¦å¯†ç å°±å¯ä»¥è¿æ¥ 12ssh root@192.168.88.133ssh root@192.168.88.134 ä¸‰ã€Ansibleçš„ad-hocå’Œå¸¸ç”¨æ¨¡å—3.1 ansibleçš„ad-hocad-hocç®€è€Œè¨€ä¹‹å°±æ˜¯â€œä¸´æ—¶å‘½ä»¤â€ï¼Œæ‰§è¡Œå®Œå°±ç»“æŸï¼Œå¹¶ä¸ä¼šä¿å­˜ ä¸»è¦æ ¼å¼ä¸ºï¼šansible + -i + æŒ‡å®šä¸»æœºæ¸…å• + æŒ‡å®šä¸»æœºç»„åç§° + -m + æŒ‡å®šæ¨¡å— + -a + å…·ä½“å‘½ä»¤ ä½¿ç”¨ad-hocåè¿”å›ç»“æœçš„é¢œè‰²ï¼š ç»¿è‰²ï¼šè¢«æ§ç«¯ä¸»æœºæ²¡æœ‰å‘ç”Ÿå˜åŒ– é»„è‰²ï¼šè¢«æ§ç«¯ä¸»æœºå‘ç”Ÿäº†å˜åŒ– çº¢è‰²ï¼šå‡ºç°æ•…éšœ 3.2 ansibleåŸºæœ¬å‘½ä»¤ ç›´æ¥æ‰§è¡Œå‘½ä»¤ 1ansible -i hosts ä¸»æœºç»„å -m æ¨¡å— -a å‘½ä»¤ åˆ—å‡ºæŸä¸ªä¸»æœºç»„çš„ä¸»æœºæ¸…å• 1ansible -i hosts ä¸»æœºç»„å --list-hosts æŸ¥çœ‹æŸä¸ªæ¨¡å—ä½¿ç”¨æ•™ç¨‹ 12ansible-doc æ¨¡å—åç§°/EX 3.2 shellå’Œcommandæ¨¡å—shellå’Œcommandæœ¬è´¨ä¸Šéƒ½æ˜¯ç”¨æ¥æ‰§è¡Œlinuxçš„åŸºç¡€å‘½ä»¤ï¼Œå¦‚catã€lsç­‰ç­‰ï¼Œä½†commandä¸æ”¯æŒç”¨|è¿™ç§ç®¡é“ç¬¦å‘½ä»¤ ä¾‹å­ï¼ŒåŒæ ·çš„å‘½ä»¤åœ¨commandä¸Šä¼šæŠ¥é”™ 12ansible -i hosts cqm -m shell -a 'ps -ef | grep nginx'ansible -i hosts cqm -m command -a 'ps -ef | grep nginx' 3.3 yumæ¨¡å—1234567ansible -i hosts cqm -m yum -a 'name=httpd state=latest enablerepo=epel'name:æŒ‡å®šå®‰è£…è½¯ä»¶åç§°state: 1.latestä¸ºå®‰è£…æœ€æ–°ç‰ˆæœ¬ 2.absentä¸ºå¸è½½ 3.presentä¸ºå®‰è£…enablerepo:æŒ‡å®šåœ¨å“ªä¸ªyumæºä¸‹å®‰è£… 3.4 copyæ¨¡å—1234567ansible -i hosts cqm -m copy -a 'src=./httpd.conf dest=/etc/httpd/conf/httpd.conf owner=www group=www mode=0755'src:è¡¨ç¤ºè¦å¤åˆ¶çš„æ–‡ä»¶è·¯å¾„dest:è¦å¤åˆ¶åˆ°è¢«æ§ç«¯çš„å“ªä¸ªè·¯å¾„owner:å¤åˆ¶æ–‡ä»¶çš„å±ä¸»group:å¤åˆ¶æ–‡ä»¶çš„å±ç»„mode:æ–‡ä»¶çš„æƒé™ï¼Œ0755ä¸ºrwxr-xr-x(r:4,w:2,x:1)ï¼Œä¹Ÿå¯ä»¥å†™æˆ(u+rwx,g+x,o-rwx)çš„å½¢å¼backup:å¦‚æœè¢«æ§ç«¯æœ‰åŒåæ–‡ä»¶ï¼Œæ˜¯å¦ä¿ç•™ 3.5 fileæ¨¡å—123#æ›´æ”¹æ–‡ä»¶æƒé™ansible -i hosts cqm -m file -a 'path=/etc/nginx/nginx.conf owner=www group=www mode=0644'path:ä»£è¡¨è¦æ”¹å˜æ–‡ä»¶çš„è·¯å¾„(è¢«æ§ç«¯) 12345#åˆ›å»ºç¬¦å·è¿æ¥(è½¯è¿æ¥)ansible -i hosts cqm -m file -a 'src=/root/test1 dest=/root/test2 mode=0755 state=link'src:æºæ–‡ä»¶è·¯å¾„(è¢«æ§ç«¯)dest:è½¯è¿æ¥è·¯å¾„(è¢«æ§ç«¯)state:linkåˆ›å»ºè½¯è¿æ¥ 12345678#åˆ›å»ºæ–‡ä»¶å’Œæ–‡ä»¶å¤¹ansible -i hosts cqm -m file -a 'path=/root/text state=touch/directory mode=0644 recurse=yes'path:è¦åˆ›å»ºåœ¨å“ªstate: 1.touchè¡¨åˆ›å»ºæ–‡ä»¶ 2.directoryè¡¨åˆ›å»ºæ–‡ä»¶å¤¹ 3.absentè¡¨åˆ é™¤recurse: é€’å½’æˆæƒ 3.6 serviceæ¨¡å—12345678ansible -i hosts cqm -m service -a 'name=httpd state=started enabled=yes'name:æœåŠ¡åç§°state: 1.startedå¯åŠ¨ 2.stoppedå…³é—­ 3.restartedé‡å¯ 4.reloadedé‡è½½enabled:æ˜¯å¦å¼€æœºè‡ªå¯ 3.7 groupæ¨¡å—1234567ansible -i hosts cqm -m group -a 'name=cqm state=present gid=1000 system=yes/no'name:åˆ›å»ºç»„åç§°state: 1.presentåˆ›å»ºç»„ 2.absentåˆ é™¤ç»„gid:ç»„idsystem:æ˜¯å¦è®¾ç½®ä¸ºç³»ç»Ÿç»„ 3.8 useræ¨¡å—123456789ansible -i hosts cqm -m user -a 'name=cqm uid=1000 group=cqm shell=/bin/bash state=present create_home=no'name:åˆ›å»ºç”¨æˆ·åç§°uid:ç”¨æˆ·idgroup:æ·»åŠ åˆ°å“ªä¸ªç»„shell:ä½¿ç”¨/bin/bashåˆ›å»ºç”¨æˆ·ï¼Œæˆ–/sbin/nologinstate: 1.presentåˆ›å»ºç”¨æˆ· 2.absentåˆ é™¤ç”¨æˆ·create_home:æ˜¯å¦åˆ›å»ºå®¶ç›®å½•ï¼Œé»˜è®¤ä¸ºyes 1234ansible -i hosts cqm -m user -a 'name=cqm uid=1000 groups=cqm1,cqm2 append=yes state=present system:yes'groups:æ·»åŠ åˆ°å“ªäº›ç»„append:æ·»åŠ åˆ°å¤šä¸ªç»„æ—¶æ·»åŠ è¯¥é¡¹system:æ˜¯å¦è®¾ç½®ä¸ºç³»ç»Ÿç”¨æˆ· 12ansible -i hosts cqm -m user -a 'name=cqm state=absent remove=yes'remove:æ˜¯å¦åˆ é™¤å®¶ç›®å½• 3.9 cronæ¨¡å—1234567891011ansible -i hosts cqm -m cron -a 'name=&quot;check dirs&quot; minute=0 hour=5,2 job=&quot;ls -al &gt; /dev/null&quot;'name:åˆ›å»ºå®šæ—¶ä»»åŠ¡åç§°minute:åˆ†é’Ÿhour:å°æ—¶job:ä»»åŠ¡state:åˆ é™¤å®šæ—¶ä»»åŠ¡ç”¨absent#åœ¨è¢«æ§ç«¯å¯æŸ¥çœ‹crontab -l#Ansible: check dirs0 5,2 * * * ls -al &gt; /dev/null 3.10 mountæ¨¡å—1234567891011121314151617ansible -i hosts cqm -m mount -a 'path=/root/data src=/dev/sr0 fstype=iso9660 opts=&quot;ro&quot; state=present'path:æŒ‚è½½åˆ°å“ªsrc:è¢«æŒ‚è½½çš„ç›®å½•ï¼Œå¯ä»¥æ˜¯ä»¥ä¸‹å½¢å¼ 1.UUIDå½¢å¼:src=&quot;UUID=......&quot; 2.ipå½¢å¼:src=&quot;192.168.88.128:/data&quot;ï¼Œä¸€èˆ¬ç”¨äºæŒ‚è½½nfsæœåŠ¡å™¨çš„ç›®å½•fstype:æŒ‚è½½ç±»å‹ 1.iso9660:æ–‡ä»¶ç³»ç»Ÿæ˜¯ä¸€ä¸ªæ ‡å‡†CD-ROMæ–‡ä»¶ç³»ç»Ÿ 2.ext4:Linuxç³»ç»Ÿä¸‹çš„æ—¥å¿—æ–‡ä»¶ç³»ç»Ÿ 3.xfs:é«˜æ€§èƒ½çš„æ—¥å¿—æ–‡ä»¶ç³»ç»Ÿ 4.nonestate:æŒ‚è½½ç±»å‹ 1.present:å¼€æœºæŒ‚è½½ï¼Œä»…å°†æŒ‚è½½é…ç½®å†™å…¥/etc/fstab 2.mounted:æŒ‚è½½è®¾å¤‡ï¼Œå¹¶å°†é…ç½®å†™å…¥/etc/fstab 3.unmounted:å¸è½½è®¾å¤‡ï¼Œä¸ä¼šæ¸…é™¤/etc/fstabå†™å…¥çš„é…ç½® 4.absent:å¸è½½è®¾å¤‡ï¼Œä¼šæ¸…ç†/etc/fstabå†™å…¥çš„é…ç½®opts:æƒé™ç­‰ï¼Œé»˜è®¤å¡«defaults/etc/fstab:ç£ç›˜è¢«æ‰‹åŠ¨æŒ‚è½½ä¹‹åéƒ½å¿…é¡»æŠŠæŒ‚è½½ä¿¡æ¯å†™å…¥/etc/fstabè¿™ä¸ªæ–‡ä»¶ä¸­ï¼Œå¦åˆ™ä¸‹æ¬¡å¼€æœºå¯åŠ¨æ—¶ä»ç„¶éœ€è¦é‡æ–°æŒ‚è½½ã€‚ 3.11 firewalldæ¨¡å—12345678910111213141516ansible -i hosts cqm -m firewalld -a 'service=https permanent=yes enable=yes immediate=yes state=enabled'service:æ”¾è¡ŒæœåŠ¡port:æ”¾è¡Œç«¯å£ï¼Œå¦‚80/tcpsource:æ”¾è¡ŒæŒ‡å®šipåœ°å€èŒƒå›´ï¼Œå¦‚192.168.88.0/24state:è¡¨é˜²ç«å¢™ç­–ç•¥çŠ¶æ€ 1.enabledç­–ç•¥ç”Ÿæ•ˆ 2.disabledç¦ç”¨ç­–ç•¥ 3.presentæ·»åŠ ç­–ç•¥ 4.absentåˆ é™¤ç­–ç•¥zone:æŒ‡å®šé˜²ç«å¢™ä¿¡ä»»çº§åˆ« 1.drop:ä¸¢å¼ƒæ‰€æœ‰è¿›å…¥çš„åŒ…ï¼Œè€Œä¸ç»™å‡ºä»»ä½•å“åº” 2.block:æ‹’ç»æ‰€æœ‰å¤–éƒ¨å‘èµ·çš„è¿æ¥ï¼Œå…è®¸å†…éƒ¨å‘èµ·çš„è¿æ¥ 3.public:å…è®¸æŒ‡å®šçš„è¿›å…¥è¿æ¥ 4.internal:èŒƒå›´é’ˆå¯¹æ‰€æœ‰äº’è”ç½‘ç”¨æˆ·permanent:yesä¸ºæ°¸ä¹…ç”Ÿæ•ˆimmediate:yesä¸ºç«‹å³ç”Ÿæ•ˆ 3.12 unarchiveæ¨¡å—unarchiveæ¨¡å—èƒ½å¤Ÿå®ç°è§£å‹å†æ‹·è´çš„åŠŸèƒ½ 1234ansible -i hosts cqm -m unarchive -a 'src=./apache.tar.gz dest=/etc/httpd mode=0755 owner=www group=www'src:å‹ç¼©æ–‡ä»¶è·¯å¾„dest:è§£å‹åˆ°å“ªremote_src:è®¾ç½®ä¸ºyesæ—¶è¡¨ç¤ºå‹ç¼©åŒ…å·²ç»åœ¨è¢«æ§ç«¯ä¸»æœºä¸Šï¼Œè€Œä¸æ˜¯ansibleæ§åˆ¶ç«¯æœ¬åœ° 3.13 get_urlæ¨¡å—1234...url:ä¸‹è½½é“¾æ¥dest:ä¿å­˜æ–‡ä»¶åœ°å€mode:è®¾ç½®æƒé™ 3.14 templateæ¨¡å—templateä¸copyç”¨æ³•ç›¸åŒï¼Œä½†templateå¯ä»¥å®åˆ«å˜é‡ï¼Œè€Œcopyä¸è¡Œã€‚ 3.15 yum_repositoryæ¨¡å—yum_repositoryå¯ä»¥ç”¨æ¥é…ç½®yumæº 123456789101112131415- name: Configure Nginx YUM Repo yum_repository: name: nginx description: Nginx YUM Repo file: nginx baseurl: http://nginx.org/packages/centos/7/$basearch/ gpgcheck: no enabled: yes state: presentname:ç›¸å½“äº.repoæ–‡ä»¶ä¸­æ‹¬å·çš„[ä»“åº“å]description:ç›¸å½“äº.repoæ–‡ä»¶ä¸­çš„namefile:ç›¸å½“äº.repoæ–‡ä»¶çš„åç§°baseurl:ç›¸å½“äº.repoæ–‡ä»¶ä¸­baseurlgpgcheck:ç›¸å½“äº.repoæ–‡ä»¶ä¸­gpgcheckenabled:ç›¸å½“äº.repoæ–‡ä»¶ä¸­enabled å››ã€Ansibleçš„Playbookplaybookæ˜¯ansibleçš„å¦ä¸€ç§ä½¿ç”¨æ–¹å¼ï¼Œè¢«ç§°ä¸ºâ€œå‰§æœ¬â€ï¼Œä¸ad-hocä¸åŒçš„æ˜¯ï¼Œplaybookå¯ä»¥å®ç°æŒä¹…ä½¿ç”¨ã€‚ playbookæ˜¯ç”±ä¸€ä¸ªæˆ–å¤šä¸ªplayç»„æˆçš„åˆ—è¡¨ï¼Œplayçš„ä¸»è¦åŠŸèƒ½åœ¨äºå°†äº‹å…ˆå½’å¹¶ä¸ºä¸€ç»„çš„ä¸»æœºè£…æ‰®æˆäº‹å…ˆé€šè¿‡ansibleä¸­çš„taskå®šä¹‰å¥½çš„è§’è‰²ï¼Œä»æ ¹æœ¬ä¸Šæ¥è®²ï¼Œæ‰€è°“çš„taskæ— éå°±æ˜¯è°ƒç”¨ansibleçš„ä¸€ä¸ªmoduleï¼Œå°†å¤šä¸ªplayç»„ç»‡åœ¨ä¸€ä¸ªplaybookä¸­ï¼Œå³å¯å®ç°åŒæ—¶å®Œæˆå¤šé¡¹ä»»åŠ¡ã€‚ playbookçš„æ ¸å¿ƒå…ƒç´  hostsï¼šè¢«æ§ä¸»æœºæ¸…å• tasksï¼šä»»åŠ¡é›† varsï¼šå˜é‡ templatesï¼šæ¨¡æ¿ handlerså’Œnotifyï¼šè§¦å‘å™¨ tagsï¼šæ ‡ç­¾ 4.1 åˆ©ç”¨playbookå®‰è£…apacheplaybooké‡‡ç”¨çš„æ˜¯ymlè¯­æ³•ï¼Œä¸¾ä¸ªæ —å­ 12cd /etc/project1vim httpd.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647- hosts: cqm tasks: #å®‰è£…apacheæœåŠ¡ - name: Install Httpd Service yum: name: httpd state: latest #åˆ›å»ºwwwç»„ - name: Create www Group group: name: www state: present #åˆ›å»ºwwwç”¨æˆ· - name: Create www User user: name: www group: www shell: /sbin/nologin state: present #ä¿®æ”¹apacheé…ç½®æ–‡ä»¶ - name: Configure Httpd Conf copy: src: ./httpd.conf dest: /etc/httpd/conf/httpd.conf owner: www group: www mode: 0644 #å¯åŠ¨æœåŠ¡å¹¶è®¾ä¸ºå¼€æœºè‡ªå¯ - name: Start Httpd Service service: name: httpd state: started enabled: yes #æ”¾è¡Œç«¯å£ - name: Configure Firewall firewalld: zone: public ports: 8080/tcp permanent: yes immediate: yes state: enabled 1234#æ£€æŸ¥è¯­æ³•ansible-playbook --syntax -i hosts httpd.yml#æ‰§è¡Œplaybookansible-playbook -i hosts httpd.yml 4.2 åˆ©ç”¨playbookéƒ¨ç½²nfs å‡†å¤‡å¥½nfsé…ç½®æ–‡ä»¶ 123cd /root/project1cat exports/root/nfs_data 192.168.88.0/24(rw,no_root_squash) ç¼–å†™nfs.ymlæ–‡ä»¶ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#nfsä¸»æœº- hosts: 192.168.88.133 tasks: - name: Create Share Directory file: path: /root/nfs_data mode: 0744 owner: root group: root recurse: yes state: directory - name: Install NFS Service yum: name: nfs-utils state: latest - name: Configure NFS copy: src: ./exports dest: /etc/exports backup: yes - name: Start NFS Service service: name: nfs state: started enabled: yes - name: Stop Firewall Service service: name: firewalld state: stopped#æŒ‚è½½nfsç›®å½•çš„ä¸»æœº- hosts: 192.168.88.134 tasks: - name: Create Share Directory file: path: /root/nfs_data state: directory - name: Install NFS Service yum: name: nfs-utils state: latest - name: Start NFS Service service: name: nfs state: started enabled: yes - name: Mount NFS Share Directory mount: path: /root/nfs_data src: 192.168.88.133:/root/nfs_data fstype: nfs opts: defaults state: mounted æ‰§è¡Œplaybook 1ansible-playbook -i hosts nfs.yml äº”ã€Ansibleçš„å˜é‡5.1 åœ¨playä¸­è®¾ç½®å˜é‡123456789101112- hosts: cqm vars: - web_package: httpd - ftp_package: vsftpd tasks: - name: Install {{ web_package }} and {{ ftp_package }} Service yum: name: - &quot;{{ web_package }}&quot; - &quot;{{ ftp_package }}&quot; state: latest 5.2 åœ¨vars_fileä¸­è®¾ç½®å˜é‡123cat vars.ymlweb_package: httpdftp_package: vsftpd 1234567891011- hosts: cqm vars_files: - ./vars.yml tasks: - name: Install {{ web_package }} and {{ ftp_package }} Service yum: name: - &quot;{{ web_package }}&quot; - &quot;{{ ftp_package }}&quot; state: latest 5.3 é€šè¿‡inventoryä¸»æœºæ¸…å•è®¾ç½®å˜é‡ åˆ›å»ºä¸¤ä¸ªå˜é‡ç›®å½• 12mkdir hosts_varsmkdir groups_vars åœ¨groups_varsç›®å½•ä¸­é’ˆå¯¹æŸä¸ªç»„åˆ›å»ºå˜é‡ 12345cat group_vars/cqmweb_package: httpdftp_package: vsftpd#groups_varsç›®å½•ä¸­ä¹Ÿå¯ä»¥æ–°å»ºallæ¥è®¾ç½®å˜é‡ï¼Œè¿™æ ·æ‰€æœ‰çš„ä¸»æœºç»„éƒ½å¯ä»¥è°ƒç”¨ åœ¨hosts_varsç›®å½•ä¸­é’ˆå¯¹æŸä¸ªä¸»æœºåˆ›å»ºå˜é‡ 123cat hosts_vars/192.168.88.133web_package: httpdftp_package: vsftpd 5.4 åœ¨æ‰§è¡Œplaybookæ—¶é€šè¿‡ -e å‚æ•°è®¾ç½®å˜é‡1234567- hosts: cqm tasks: - name: Install {{ web_package }} Service yum: name: - &quot;{{ web_package }}&quot; state: latest 1ansible-playbook -i hosts -e 'web_package=httpd' test.yml 5.5 ansibleå˜é‡çš„ä¼˜å…ˆçº§ä¼˜å…ˆçº§ç”±ä¸Šè‡³ä¸‹é€’å‡ -eï¼ˆå¤–ç½®ä¼ å‚ï¼‰ vars_files playä¸­çš„vars hosts_vars groups_varsä¸­çš„æŸä¸ªä¸»æœºç»„ groups_varsä¸­çš„all 5.6 registeræ³¨å†Œå˜é‡1234567891011121314151617181920- hosts: cqm tasks: - name: Install Apache Service yum: name: httpd state: latest - name: Start Apache Service service: name: httpd state: started - name: Check Apache Process shell: ps -ef | grep httpd #å°†ç»“æœå‚¨å­˜åˆ°å˜é‡é‡Œ register: check_apache #åˆ©ç”¨debugæ¨¡å—è°ƒç”¨ - name: Output check_apache debug: #è¾“å‡ºmsgä¸­çš„stdout_lines msg: &quot;{{ check_apache.stdout_lines }}&quot; 5.7 factså˜é‡factså˜é‡æ˜¯ansibleæ§åˆ¶ç«¯é‡‡é›†è¢«æ§ç«¯çš„å˜é‡ï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨ ä¸ºäº†æ–¹ä¾¿å¯ä»¥å°†factså˜é‡å†™åˆ°æ–‡æœ¬é‡Œ 1ansible -i hosts cqm -m setup &gt; fasts.txt å…­ã€Ansibleè¯­å¥6.1 æ¡ä»¶åˆ¤æ–­whencentoså®‰è£…apacheæ˜¯httpdï¼Œè€Œubuntuå®‰è£…apacheåˆ™æ˜¯httpd2ï¼Œæ‰€ä»¥è¿™æ—¶å€™å°±éœ€è¦æ¡ä»¶åˆ¤æ–­äº† ä¾‹ä¸€ï¼šä¸åŒç³»ç»Ÿå®‰è£…apache 12345678910111213141516- hosts: cqm tasks - name: Centos Install Apache Service yum: name: httpd state: latest when: - ( ansible_distribution == &quot;CentOS&quot; ) - name: Utunbu Install Apache2 Service yum: name: httpd2 state: latest when: - ( ansible_distribution == &quot;Utunbu&quot; ) ä¾‹äºŒï¼šç»™ä¸»æœºåå¸¦æœ‰webçš„ä¸»æœºé…ç½®yumæº 1234567891011- hosts: cqm tasks: - name: Configure Cqm Yum Repo yum_repository: name: cqm description: cqm yum repo baseurl: http://www.cqmmmmm.com gpgcheck: no enabled: yes when: - ( ansible_fqdn is match (&quot;web*&quot;) ) ä¾‹ä¸‰ï¼šåˆ¤æ–­nfsæœåŠ¡æ˜¯å¦å¯åŠ¨ï¼Œæ²¡æœ‰åˆ™å¯åŠ¨ï¼Œå¦åˆ™é‡å¯ åˆ©ç”¨echo $ï¼Ÿçš„è¿”å›å€¼æ¥æŸ¥çœ‹æ˜¯å¦å¯åŠ¨ 12345678910111213- hosts: cqm tasks: - name: Check NFS Service Status shell: systemctl is-active nfs ignore_errors: yes register: check_nfs - name: Restart NFS Service service: name: nfs state: restarted when: - ( check_nfs.rc == 0 ) 6.2 å¾ªç¯è¯­å¥with_itemswith_itemså¯ä»¥å®ç°å¾ªç¯ï¼Œå¯ä»¥å‡å°‘playbookä¸­åŒæ ·æ¨¡å—çš„ä½¿ç”¨æ¬¡æ•° ä¾‹ä¸€ï¼šåˆ©ç”¨with_itemsé‡å¯nginxå’ŒphpæœåŠ¡ 123456789- hosts: cqm tasks: - name: Restart Nginx and PHP Service service: name: {{ item }} state: restarted with_items: - nginx - php-fpm ä¾‹äºŒï¼šåˆ©ç”¨å˜é‡å¾ªç¯å®‰è£…å¤šä¸ªæœåŠ¡ 12345678910- hosts: cqm tasks: - name: Install Nginx and Mysql Service yum: name: {{ pack }} state: latest vars: pack: - nginx - mysql-server ä¾‹ä¸‰ï¼šåˆ©ç”¨å¾ªç¯åˆ›å»ºå¤šä¸ªç”¨æˆ· 12345678910- hosts: cqm tasks: - name: Create Multiple Users user: name: {{ item.name }} group: {{ item.group }} state: present with_items: - { name: 'aaa', group: 'aaa' } - { name: 'bbb', group: 'bbb' } 6.3 è§¦å‘å™¨handlershandlersæ˜¯ansibleçš„è§¦å‘å™¨ï¼Œé…åˆnotifyä½¿ç”¨ã€‚ handlersåªæœ‰åœ¨playbookæ‰§è¡Œåˆ°æœ€åæ‰ä¼šæ‰§è¡Œï¼Œç®€å•æ¥è¯´å¯ä»¥å°†handlersçœ‹ä½œä¸€ä¸ªç‰¹æ®Šçš„tasksï¼Œåªæœ‰åœ¨notifyæŒ‡å®šçš„æŸä¸ªæ¨¡å—è¿è¡Œäº†æ‰ä¼šè§¦å‘handlersä¸­çš„æ¨¡å—ã€‚ ä¾‹ä¸€ï¼šä¿®æ”¹nginx.confçš„è¯å°±é‡å¯nginxæœåŠ¡ 1234567891011121314151617- hosts: cqm tasks: - name: Configure Nginx File template: src: ./nginx.conf dest: /etc/nginx/nginx.conf mode: 0644 owner: www group: www backup: yes notify: Restart Nginx Service handlers: - name: Restart Nginx Service service: name: nginx state: restarted 6.4 tagsæ ‡ç­¾å¯¹tasksæŒ‡å®šæ ‡ç­¾ï¼Œå¯ä»¥åœ¨æ‰§è¡Œplaybookçš„æ—¶å€™æŒ‡å®šæ‰§è¡Œå“ªä¸ªtagsçš„ä»»åŠ¡ã€‚ ä¾‹ä¸€ï¼šåˆ©ç”¨tagsæ¥æ‰§è¡Œå¼€å¯nginxå’ŒphpæœåŠ¡ 123456789101112- hosts: cqm tasks: - name: Start Nginx and PHP Service service: name: {{ item }} state: started enabled: yes with_items: - nginx - php-fpm tags: start_services...... 1ansible-playbook -i hosts cqm -t 'start_services' test.yml å¦‚æœè¦æŒ‡å®šä¸æ‰§è¡Œå“ªä¸ªæ ‡ç­¾çš„ä»»åŠ¡ï¼Œæ·»åŠ å‚æ•°â€“skip-tags 1ansible-playbook -i hosts cqm --skip-tags 'start_services' test.yml 6.5 åŒ…å«includeå¦‚æœæ¯ä¸ªplaybookéƒ½ä¼šç”¨åˆ°é‡å¯æŸä¸ªæœåŠ¡çš„ä»»åŠ¡ï¼Œé‚£ä¹ˆæ¯ä¸ªplaybookéƒ½è¦å†™ä¸€æ¬¡ï¼Œåˆ©ç”¨includeå°±åªç”¨å†™ä¸€æ¬¡ï¼Œè®©æ¯ä¸ªplaybookè°ƒç”¨å³å¯ã€‚ ä¾‹ä¸€ï¼šå‡†å¤‡ä¸€ä¸ªé‡å¯nginxçš„ymlæ–‡ä»¶æ¥ç»™å„ä¸ªplaybookè°ƒç”¨ 1vim nginx_restart.yml 1234- name: Restart Nginx Service service: name: nginx state: restarted 1234567891011- hosts: cqm tasks: - name: Configure Nginx File template: src: ./nginx.conf dest: /etc/nginx/nginx.conf mode: 0644 owner: www group: www backup: yes include: ./restart_nginx.yml 6.6 é”™è¯¯å¿½ç•¥ignore_errorså°±æ˜¯å­—é¢æ„æ€- -ï¼Œå°½ç®¡æŸä¸ªä»»åŠ¡å‡ºé”™äº†ï¼Œä¹Ÿä¼šç»§ç»­æ‰§è¡Œä¸‹é¢çš„ä»»åŠ¡ã€‚ ä¾‹ä¸€ï¼šå¿½ç•¥æŸä¸ªä»»åŠ¡ 123456- hosts: cqm tasks: - name: ignore errors test command: /bin/false ignore_errors: yes...... 6.7 é”™è¯¯æ¨¡å—failfailæ¨¡å—æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨æ¥â€œæ‰§è¡Œå¤±è´¥â€çš„æ¨¡å—ï¼Œæˆ‘ä»¬éƒ½çŸ¥é“åœ¨shellä¸­åªè¦æ·»åŠ exitå°±å¯ä»¥åœæ­¢æ‰§è¡Œï¼Œè€Œplaybookåªæœ‰åœ¨æŸä¸ªä»»åŠ¡å‡ºé”™äº†æ‰ä¼šåœæ­¢æ‰§è¡Œï¼Œè¿™æ—¶å€™å°±å¯ä»¥åˆ©ç”¨failæ¥åœæ­¢playbookçš„æ‰§è¡Œã€‚ ä¾‹ä¸€ï¼šåˆ©ç”¨failæ¥å®ç°exitçš„åŠŸèƒ½ 1234567891011121314151617181920- hosts: cqm tasks: - name: debug1 debug: msg: &quot;1&quot; - name: debug2 debug: msg: &quot;2&quot; #æ‰§è¡Œè¯¥æ¨¡å—ååé¢çš„debugéƒ½ä¼šæ‰§è¡Œ - name: fail fail: msg: &quot; this is fail module test &quot; - name: debug3 debug: msg: &quot;3&quot; - name: debug4 debug: msg: &quot;4&quot; 6.8 é”™è¯¯æ”¹å˜failed_whenfailed_whençš„ä½œç”¨å°±æ˜¯å°†æ¡ä»¶æˆç«‹çš„ä»»åŠ¡çŠ¶æ€è®¾ç½®ä¸ºå¤±è´¥ã€‚ ä¾‹ä¸€ï¼šåˆ¤æ–­æ˜¯å¦è¾“å‡ºäº†errorï¼Œæ˜¯åˆ™è®¾ç½®ä¸ºä»»åŠ¡å¤±è´¥ 12345678910111213141516- hosts: cqm tasks: - name: debug1 debug: msg: &quot;i am debug1&quot; #å› ä¸ºè¾“å‡ºé‡ŒåŒ…å«äº†errorï¼Œæ‰€ä»¥æ¡ä»¶æˆç«‹å°†è¯¥ä»»åŠ¡è®¾ç½®ä¸ºäº†failï¼Œplaybookä¸­æ­¢ - name: Output Error shell: echo 'this is error' register: output_error failed_when: - ( 'error' in output_error.stdout ) - name: debug2 debug: msg: &quot;i am debug2&quot; 6.9 é”™è¯¯å¤„ç†changed_whenchanged_whençš„ä½œç”¨å°±æ˜¯å°†æ¡ä»¶æˆç«‹çš„ä»»åŠ¡çŠ¶æ€è®¾ç½®ä¸ºchangedã€‚ æˆ‘ä»¬åœ¨è°ƒç”¨handlersçš„æ—¶å€™ï¼Œåªæœ‰ä»»åŠ¡çŠ¶æ€ä¸ºchangedæ‰ä¼šè°ƒç”¨ï¼Œè¿™æ—¶å€™å°±å¯ä»¥ç”¨changed_whenæ”¹å˜ä»»åŠ¡çŠ¶æ€ä¸ºchangedï¼Œå°±å¯ä»¥å®ç°è°ƒç”¨handlersäº†ã€‚ ä¾‹ä¸€ï¼šæ”¹å˜ä»»åŠ¡çŠ¶æ€ä¸ºchangedè€Œè°ƒç”¨è§¦å‘å™¨ 12345678910111213141516171819- hosts: cqm tasks: - name: Configure Nginx File template: src: ./nginx.conf dest: /etc/nginx/nginx.conf mode: 0644 owner: www group: www backup: yes notify: Restart Nginx Service #å°½ç®¡æ–‡ä»¶æ²¡æœ‰æ”¹å˜ï¼Œä»»åŠ¡çŠ¶æ€ä¸ºokä¹Ÿä¼šè¢«æ”¹ä¸ºchangedè€Œè°ƒç”¨handlers changed_when: yes handlers: - name: Restart Nginx Service service: name: nginx state: restarted changed_whenä¹Ÿå¯ä»¥ä½¿ä»»åŠ¡æ°¸è¿œä¸ä¼šæ˜¯changedã€‚ ä¾‹äºŒï¼šä½¿ä»»åŠ¡æ°¸è¿œä¸ºok 12345678910111213141516171819- hosts: cqm tasks: - name: Configure Nginx File template: src: ./nginx.conf dest: /etc/nginx/nginx.conf mode: 0644 owner: www group: www backup: yes notify: Restart Nginx Service #å°½ç®¡æ–‡ä»¶å‘ç”Ÿäº†æ”¹å˜ï¼Œä»»åŠ¡çŠ¶æ€ä¸ºchangedä¹Ÿä¼šè¢«æ”¹ä¸ºok,æ°¸è¿œä¸ä¼šè°ƒç”¨handlers changed_when: false handlers: - name: Restart Nginx Service service: name: nginx state: restarted ä¸ƒã€Ansibleçš„rolesroleså°±æ˜¯é€šè¿‡åˆ†åˆ«å°†å˜é‡ã€æ–‡ä»¶ã€ä»»åŠ¡ã€æ¨¡å—åŠå¤„ç†å™¨æ”¾ç½®äºå•ç‹¬çš„ç›®å½•ä¸­ã€å¹¶å¯ä»¥ä¾¿æ·åœ°includeå®ƒä»¬çš„ä¸€ç§æœºåˆ¶ã€‚ rolesçš„ç›®å½•ç»“æ„ï¼š filesï¼šå­˜æ”¾æ™®é€šæ–‡ä»¶ï¼Œæ¯”å¦‚copyè°ƒç”¨çš„æ–‡ä»¶ handlersï¼šè§¦å‘å™¨ metaï¼šä¾èµ–å…³ç³» tasksï¼šä»»åŠ¡ templatesï¼šå­˜æ”¾å«æœ‰å˜é‡çš„æ–‡ä»¶ varsï¼šå˜é‡ åœ¨æ¯ä¸ªç›®å½•é‡Œçš„ymlæ–‡ä»¶éƒ½å¿…é¡»å‘½åä¸ºmain.yml ä¸€é”®ç”Ÿæˆrolesç›®å½• 1ansible-galaxy role init test å…«ã€åˆ©ç”¨Ansibleæ­å»ºKodcloudé¡¹ç›®æ¶æ„å›¾ 8.1 å‡†å¤‡é¡¹ç›®ç¯å¢ƒ åŸºæœ¬é…ç½® 123mkdir -p /root/project/{host_vars,group_vars}cd /root/projectcp /etc/ansible/ansible.cfg . é…ç½®inventory 12345vim hosts[web]192.168.88.133[db]192.168.88.134 é…ç½®é€šç”¨å˜é‡ 123456vim group_vars/allnfs_server_ip: 192.168.88.134redis_server_ip: 192.168.88.134ip_address_range: 192.168.88.0/24web_user: wwwweb_group: www åˆ›å»ºå„ä¸ªroleæ–‡ä»¶ç›®å½• 1mkdir -p {db_base,redis,mariadb,nfs_server,web_base,nginx,php,nfs_client,kodcloud}/{files,handlers,tasks,templates,vars} 8.2 é…ç½®rolesæ–‡ä»¶1vim kod.yml 1234567891011121314151617181920212223242526272829303132- hosts: db roles: - role: db_base tags: db_base - role: redis tags: redis - role: mariadb tags: mariadb - role: nfs_server tags: nfs_server- hosts: web roles: - role: web_base tags: web_base - role: nginx tags: nginx - role: php tags: php - role: nfs_client tags: nfs_client - role: kodcloud tags: kodcloud 8.3 é…ç½®dbç«¯åŸºæœ¬ç¯å¢ƒ ç¼–å†™tasks 1vim db_base/tasks/main.yml 1234- name: Stop Firewall Service service: name: firewalld state: stopped 8.4 é…ç½®dbç«¯redisæœåŠ¡ ç¼–å†™tasks 1vim redis/tasks/main.yml 1234567891011121314151617- name: Install Redis Service yum: name: redis state: latest- name: Configure Redis Service template: src: redis.conf.j2 dest: /etc/redis.conf backup: yes notify: Restart Redis Service- name: Start Redis Service service: name: redis state: started enabled: yes ç¼–å†™templates 123456vim redis/temlpates/redis.conf.j2egrep -v '^#|^$' redis/templates/redis.conf.j2bind {{ ansible_default_ipv4.address }}protected-mode yesport 6379...... ç¼–å†™handlers 1cat redis/handlers/main.yml 1234- name: Restart Redis Service service: name: redis state: restarted 8.5 é…ç½®dbç«¯mariadbæœåŠ¡ ç¼–å†™tasks 1vim mariadb/tasks/main.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243- name: Install Mariadb Service yum: name: '{{ item }}' state: latest with_items: - mariadb - mariadb-server - MySQL-python- name: Configure Mariadb Service copy: src: my.cnf.j2 dest: /etc/my.cnf backup: yes- name: Start Mariadb Service service: name: mariadb state: started- name: Configure Mariadb Root User mysql_user: user: root password: toortoor- name: Create {{ website }} Databases mysql_db: login_user: root login_password: toortoor name: '{{ website }}' state: present collation: utf8_bin encoding: utf8- name: Create {{ website }} DB User mysql_user: login_user: root login_password: toortoor name: '{{ web_db_user }}' password: '{{ web_db_pass }}' host: '192.168.88.%' priv: '*.*:ALL,GRANT' state: present ç¼–å†™files 1vim mariadb/files/my.cnf.j2 123456789101112131415161718[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sock# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0# Settings user and group are ignored when systemd is used.# If you need to run mysqld under a different user or group,# customize your systemd unit file for mariadb according to the# instructions in http://fedoraproject.org/wiki/Systemd[mysqld_safe]log-error=/var/log/mariadb/mariadb.logpid-file=/var/run/mariadb/mariadb.pid## include all files from the config directory#!includedir /etc/my.cnf.d ç¼–å†™vars 1vim mariadb/vars/main.yml 123website: kodcloudweb_db_user: kodcloudweb_db_pass: toortoor 8.6 é…ç½®dbç«¯nfsæœåŠ¡ ç¼–å†™tasks 1vim nfs_server/tasks/main.yml 123456789101112131415161718192021222324- name: Create NFS Share Directory file: path: '{{ nfs_share_directory }}' mode: 0757 recurse: yes state: directory- name: Install NFS Service yum: name: nfs-utils state: latest- name: Configure NFS template: src: exports.j2 dest: /etc/exports backup: yes notify: Restarted NFS Service- name: Start NFS Service service: name: nfs state: started enabled: yes ç¼–å†™handlers 1vim nfs_server/handlers/main.yml 1234- name: Restarted NFS Service service: name: nfs state: restarted ç¼–å†™vars 1vim nfs_server/vars/main.yml 1nfs_share_directory: /root/nfs_share ç¼–å†™temlpates 12vim nfs_server/templates/exports.j2{{ nfs_share_directory }} {{ ip_address_range }}(rw) 8.7 é…ç½®webç«¯åŸºæœ¬ç¯å¢ƒ ç¼–å†™tasks 1vim web_base/tasks/main.yml 123456789101112- name: Create {{ web_group }} Group group: name: '{{ web_group }}' state: present- name: Create {{ web_user }} User user: name: '{{ web_user }}' group: '{{ web_group }}' state: present create_home: no shell: /sbin/nologin 8.8 é…ç½®webç«¯nginxæœåŠ¡ ç¼–å†™tasks 1vim nginx/tasks/main.yml 1234567891011121314151617181920212223242526272829303132333435363738- name: Configure Firewall firewalld: zone: public port: 80/tcp permanent: yes immediate: yes state: enabled- name: Configure Nginx YUM Repo yum_repository: name: nginx description: Nginx YUM Repo file: nginx baseurl: http://nginx.org/packages/centos/7/$basearch/ gpgcheck: no enabled: yes state: present- name: Install Nginx Service yum: name: nginx state: latest- name: Configure Nginx template: src: '{{ item.src }}' dest: '{{ item.dest }}' backup: yes notify: Restart Nginx Service with_items: - { src: 'nginx.conf.j2', dest: '/etc/nginx/nginx.conf' } - { src: 'default.conf.j2', dest: '/etc/nginx/conf.d/default.conf' }- name: Started Nginx Service service: name: nginx state: started enabled: yes ç¼–å†™handlers 1vim nginx/handlers/main.yml 1234- name: Restart Nginx Service service: name: nginx state: restarted ç¼–å†™templates 1234567891011121314151617181920212223242526272829303132vim nginx/templates/nginx.conf.j2user {{ web_user }};worker_processes {{ ansible_processor_count * 1 }};error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events { worker_connections {{ ansible_processor_count * 1024 }};}http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] &quot;$request&quot; ' '$status $body_bytes_sent &quot;$http_referer&quot; ' '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf;} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546vim nginx/templates/default.conf.j2server { listen {{ nginx_port }}; server_name localhost; #charset koi8-r; #access_log /var/log/nginx/host.access.log main; location / { root /usr/share/nginx/html; index index.php index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # location ~ \\.php$ { root /usr/share/nginx/html; # fastcgi_pass 127.0.0.1:9000; fastcgi_pass unix:/etc/nginx/php-fpm.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\\.ht { # deny all; #}} ç¼–å†™vars 1vim nginx/vars/main.yml 1nginx_port: 80 8.9 é…ç½®webç«¯phpæœåŠ¡ ç¼–å†™tasks 1vim php/tasks/main.yml 123456789101112131415161718192021222324252627282930313233343536373839- name: Configure PHP YUM Repo yum: name: http://rpms.remirepo.net/enterprise/remi-release-7.rpm state: present- name: Install PHP Service yum: name: '{{ item }}' state: present with_items: - '{{ php }}' - &quot;{{ php_version }}-cli&quot; - &quot;{{ php_version }}-common&quot; - &quot;{{ php_version }}-devel&quot; - &quot;{{ php_version }}-embedded&quot; - &quot;{{ php_version }}-gd&quot; - &quot;{{ php_version }}-mcrypt&quot; - &quot;{{ php_version }}-mbstring&quot; - &quot;{{ php_version }}-pdo&quot; - &quot;{{ php_version }}-xml&quot; - &quot;{{ php_version }}-fpm&quot; - &quot;{{ php_version }}-mysqlnd&quot; - &quot;{{ php_version }}-opcache&quot; - &quot;{{ php_version }}-pecl-memcached&quot; - &quot;{{ php_version }}-pecl-redis&quot; - &quot;{{ php_version }}-pecl-mongodb&quot;- name: Configure PHP Service copy: src: www.conf.j2 dest: &quot;{{ php_route }}/php-fpm.d/www.conf&quot; backup: yes notify: Restart Nginx and PHP Service- name: Start PHP Service service: name: &quot;{{ php_version }}-fpm&quot; state: started enabled: yes ç¼–å†™handlers 1vim php/handlers/main.yml 1234567- name: Restart Nginx and PHP Service service: name: '{{ item }}' state: restarted with_items: - &quot;{{ php_version }}-fpm&quot; - nginx ç¼–å†™files 123456789vim php/files/www.conf.j2[www]user = wwwgroup = wwwlisten = /etc/nginx/php-fpm.socklisten.owner = wwwlisten.group = wwwlisten.mode = 0660...... ç¼–å†™vars 1vim php/vars/main.yml 123php: php74php_version: php74-phpphp_route: /etc/opt/remi/php74 8.10 é…ç½®webç«¯nfsæœåŠ¡ ç¼–å†™tasks 1vim nfs_client/tasks/main.yml 1234567891011121314151617181920212223- name: Create NFS Share Directory file: path: '{{ nfs_share_directory }}' state: directory- name: Install NFS Service yum: name: nfs-utils state: latest- name: Start NFS Service service: name: nfs state: started enabled: yes- name: Mount NFS Share Directory mount: path: '{{ nfs_share_directory }}' src: &quot;{{ nfs_server_ip }}:{{ nfs_share_directory }}&quot; fstype: nfs opts: defaults state: mounted ç¼–å†™vars 1vim nfs_client/tasks/main.yml 1nfs_share_directory: /root/nfs_share 8.11 é…ç½®webç«¯kodcloud ç¼–å†™tasks 1vim kodcloud/tasks/main.yml 123456789101112131415161718192021- name: Create Kodcloud Directory file: path: /usr/share/nginx/html/kodcloud owner: www group: www mode: 0777 state: directory- name: Input Kodcloud File unarchive: src: '{{ kod_version }}' dest: /usr/share/nginx/html/kodcloud owner: www group: www mode: 0777- name: Configure Nginx Virtual Host copy: src: kodcloud.conf.j2 dest: /etc/nginx/conf.d/kodcloud.conf notify: Restart Nginx and PHP Service ç¼–å†™handlers 1vim kodcloud/handlers/main.yml 1234567- name: Restart Nginx and PHP Service service: name: '{{ item }}' state: restarted with_items: - nginx - &quot;{{ php_version }}-fpm&quot; ç¼–å†™vars 1vim kodcloud/vars/main.yml 12kod_version: kodbox.1.15.zipphp_version: php74-php ç¼–å†™files 1wget http://static.kodcloud.com/update/download/kodbox.1.15.zip kodcloud/files/kodbox.1.15.zip 12345678910vim kodcloud/files/kodcloud.conf.j2server { listen 80; server_name localhost; location / { root /usr/share/nginx/html/kodcloud; index index.php index.html index.htm; }} 8.12 æ‰§è¡Œplaybook1ansible-playbook -i hosts kod.yml 8.13 æµ‹è¯• ç™»å½•åˆ°webå®‰è£…kodcloud ç™»å½•kodcloud","link":"/2024/02/18/ansible/"},{"title":"RKE2 ä½¿ç”¨ Custom CA éƒ¨ç½²","text":"å‚è€ƒæ–‡æ¡£ï¼šhttps://docs.rke2.io/zh/security/certificates#using-custom-ca-certificates åœ¨æ³¨å†Œé¦–å° RKE2 èŠ‚ç‚¹æ—¶ï¼Œrke2 è¿›ç¨‹ä¼šæ£€æŸ¥ /var/lib/rancher/rke2/server/tls ç›®å½•ä¸­æ˜¯å¦å·²å­˜åœ¨ç›¸å…³è¯ä¹¦æ–‡ä»¶ï¼›è‹¥ä¸å­˜åœ¨ï¼Œå°±ä¼šç”Ÿæˆç›¸å…³è¯ä¹¦ä¾› Kubernetes ä½¿ç”¨ã€‚ å¦‚æœæœ‰è‡ªå®šä¹‰è¯ä¹¦çš„éœ€æ±‚ï¼Œä¹Ÿå¯ä»¥æå‰å°†ç”Ÿæˆå¥½çš„è¯ä¹¦æ”¾ç½®åˆ°è¯¥ç›®å½•ä¸­ã€‚rke2 ä¼šæ£€æµ‹åˆ°è¯ä¹¦å·²å­˜åœ¨ï¼Œä»è€Œè·³è¿‡è¯ä¹¦ç”Ÿæˆæµç¨‹ï¼Œç›´æ¥ä½¿ç”¨è¿™äº›è‡ªå®šä¹‰è¯ä¹¦ã€‚ ç”Ÿæˆè‡ªå®šä¹‰è¯ä¹¦ï¼š 1234567891011121314151617181920cat &lt;&lt;EOF &gt; config[v3_ca]subjectKeyIdentifier = hashauthorityKeyIdentifier = keyid:alwaysbasicConstraints = critical, CA:truekeyUsage = critical, digitalSignature, keyEncipherment, keyCertSignEOFopenssl genrsa -out root-ca.key 4096openssl req -x509 -new -nodes -sha256 -days 7300 \\ -subj &quot;/CN=rke2-root-ca&quot; \\ -key root-ca.key \\ -out root-ca.pem \\ -config config \\ -extensions v3_camkdir -pv /var/lib/rancher/rke2/server/tlscp root-ca.pem root-ca.key /var/lib/rancher/rke2/server/tls é€šè¿‡è„šæœ¬ï¼Œä½¿ç”¨æ ¹ CA è¯ä¹¦ç”Ÿæˆå…¶ä»–è¯ä¹¦ï¼š 12# è¯¥è„šæœ¬ä¼šæ£€æµ‹æ˜¯å¦å­˜åœ¨ root-ca.pem root-ca.keyï¼Œä¸å­˜åœ¨åˆ™ä¼šè‡ªåŠ¨ç”Ÿæˆcurl -sL https://github.com/k3s-io/k3s/raw/master/contrib/util/generate-custom-ca-certs.sh | PRODUCT=rke2 bash - ç”Ÿæˆåçš„è¯ä¹¦æ–‡ä»¶å¦‚ä¸‹ï¼Œå³å¯è¿›è¡ŒèŠ‚ç‚¹æ³¨å†Œï¼š 12345678910111213141516171819root@test-0:/var/lib/rancher/rke2/server/tls# ls -lhtotal 76K-rw-r----- 1 root root 4.9K Apr 15 09:51 client-ca.crt-rw------- 1 root root 227 Apr 15 09:51 client-ca.key-rw-r----- 1 root root 1.3K Apr 15 09:51 client-ca.pemdrwxr-x--- 2 root root 126 Apr 15 09:51 etcd-rw-r----- 1 root root 3.6K Apr 15 09:51 intermediate-ca.crt-rw------- 1 root root 3.2K Apr 15 09:51 intermediate-ca.key-rw-r----- 1 root root 1.9K Apr 15 09:51 intermediate-ca.pem-rw-r----- 1 root root 4.9K Apr 15 09:51 request-header-ca.crt-rw------- 1 root root 227 Apr 15 09:51 request-header-ca.key-rw-r----- 1 root root 1.3K Apr 15 09:51 request-header-ca.pem-rw-r----- 1 root root 1.8K Apr 15 09:51 root-ca.crt-rw------- 1 root root 3.2K Apr 15 09:50 root-ca.key-rw-r--r-- 1 root root 1.8K Apr 15 09:50 root-ca.pem-rw-r----- 1 root root 4.9K Apr 15 09:51 server-ca.crt-rw------- 1 root root 227 Apr 15 09:51 server-ca.key-rw-r----- 1 root root 1.3K Apr 15 09:51 server-ca.pem-rw------- 1 root root 1.7K Apr 15 09:51 service.key å¦‚æœæ˜¯é€šè¿‡ Rancher åˆ›å»ºçš„ RKE2 é›†ç¾¤ï¼Œæ³¨å†Œå®Œæˆåï¼Œcattle-cluster-agent å¯èƒ½ä¼šå­˜åœ¨æŠ¥é”™ï¼š 123...400 Bad Request: Request Header Or Cookie Too Large... è¿™æ˜¯å› ä¸ºè‡ªç­¾åè¯ä¹¦å¯¼è‡´çš„è¯·æ±‚å¤´è¿‡å¤§è€Œè¯·æ±‚å¤±è´¥ï¼Œè°ƒæ•´ Local é›†ç¾¤ Ingress ç›¸å…³å‚æ•°å³å¯ï¼ŒRKE2 å¯ä»¥é€šè¿‡ä¸‹é¢çš„å‘½ä»¤è°ƒæ•´ï¼š 1234567891011121314cat &lt;&lt;EOF | kubectl apply -f -apiVersion: helm.cattle.io/v1kind: HelmChartConfigmetadata: name: rke2-ingress-nginx namespace: kube-systemspec: valuesContent: |- controller: config: large-client-header-buffers: &quot;4 64k&quot; http2-max-field-size: &quot;32k&quot; http2-max-header-size: &quot;64k&quot;EOF","link":"/2025/04/15/RKE2-%E4%BD%BF%E7%94%A8-Custom-CA-%E9%83%A8%E7%BD%B2/"},{"title":"cgroup netns mountnséšè®°","text":"CgroupCgroup å³ Control Groupï¼Œæ˜¯ä¸€ç§ Linux å†…æ ¸æœºåˆ¶ï¼Œå®ƒå…è®¸å¯¹è¿›ç¨‹è¿›è¡Œèµ„æºæ§åˆ¶å’Œç®¡ç†ã€‚Cgroup å¯ä»¥é™åˆ¶è¿›ç¨‹çš„ CPU ä½¿ç”¨ç‡ã€å†…å­˜ä½¿ç”¨é‡ã€ç£ç›˜ I/O ç­‰èµ„æºã€‚ Cgroup ä¸»è¦ä½œç”¨: èµ„æºæ§åˆ¶: å¯ä»¥é™åˆ¶è¿›ç¨‹çš„èµ„æºä½¿ç”¨é‡ï¼Œé˜²æ­¢å•ä¸ªè¿›ç¨‹å ç”¨è¿‡å¤šèµ„æºå¯¼è‡´ç³»ç»Ÿèµ„æºæ¯ç«­ èµ„æºéš”ç¦»: å¯ä»¥å°†ä¸åŒç±»å‹çš„è¿›ç¨‹éš”ç¦»åˆ°ä¸åŒçš„ cgroup ä¸­ï¼Œä»¥ä¾¿æ›´å¥½åœ°ç®¡ç†èµ„æº èµ„æºç»Ÿè®¡: å¯ä»¥æ”¶é›† cgroup ä¸­è¿›ç¨‹çš„èµ„æºä½¿ç”¨æƒ…å†µç»Ÿè®¡æ•°æ®ï¼Œç”¨äºåˆ†æå’Œä¼˜åŒ–èµ„æºåˆ†é… NetnsNetns å³ Network Namespaceï¼Œæ˜¯ä¸€ç§ Linux å†…æ ¸æœºåˆ¶ï¼Œå®ƒå…è®¸åœ¨ä¸åŒçš„è¿›ç¨‹ä¹‹é—´éš”ç¦»ç½‘ç»œèµ„æºã€‚è¿™æ„å‘³ç€æ¯ä¸ª Network Namespace éƒ½æœ‰è‡ªå·±çš„ç‹¬ç«‹ç½‘ç»œé…ç½®ï¼Œä¾‹å¦‚ IP åœ°å€ã€ç«¯å£å·å’Œè·¯ç”±è¡¨ã€‚ Netns ä¸»è¦ä½œç”¨: éš”ç¦»ä¸åŒç”¨æˆ·çš„ç½‘ç»œè¿æ¥ éš”ç¦»ä¸åŒåº”ç”¨ç¨‹åºçš„ç½‘ç»œè¿æ¥ åˆ›å»ºè™šæ‹Ÿç½‘ç»œ MountnsMountns å³ Mount namespaceï¼Œæ˜¯ä¸€ç§ Linux å†…æ ¸æœºåˆ¶ï¼Œå®ƒå…è®¸åœ¨ä¸åŒçš„è¿›ç¨‹ä¹‹é—´éš”ç¦»æŒ‚è½½ç‚¹ã€‚è¿™æ„å‘³ç€æ¯ä¸ª mount namespace éƒ½æœ‰è‡ªå·±çš„ç‹¬ç«‹æŒ‚è½½è§†å›¾ï¼Œå³ä½¿å®ƒä»¬ä½äºåŒä¸€ä¸ªç‰©ç†ä¸»æœºä¸Šã€‚ Mountns ä¸»è¦ä½œç”¨: éš”ç¦»ä¸åŒç”¨æˆ·çš„æŒ‚è½½ç‚¹ éš”ç¦»ä¸åŒåº”ç”¨ç¨‹åºçš„æŒ‚è½½ç‚¹ åˆ›å»ºæ²™ç®±ç¯å¢ƒ æ€»ç»“Cgroupã€Netnsã€Mountns éƒ½æ˜¯ Linux å†…æ ¸æœºåˆ¶ï¼Œç”¨äºå¤„ç†ä¸åŒç±»å‹èµ„æºçš„éš”ç¦»ã€‚ Cgroup å¯ä»¥é™åˆ¶è¿›ç¨‹çš„ CPU/å†…å­˜/ç£ç›˜IO Netns å¯ä»¥éš”ç¦»è¿›ç¨‹çš„ç½‘ç»œè¿æ¥ Mountns å¯ä»¥éš”ç¦»è¿›ç¨‹çš„æŒ‚è½½ç‚¹","link":"/2024/03/31/cgroup-netns-mountns%E9%9A%8F%E8%AE%B0/"},{"title":"Cisco","text":"åœ¨ Cisco ä¸­ï¼Œäº¤æ¢æœºè®¾å¤‡ä¸»è¦åˆ†ä¸ºä»¥ä¸‹å‡ ç§æ¨¡å¼ï¼š ç”¨æˆ·æ¨¡å¼ï¼Œåˆšè¿›å…¥è®¾å¤‡éƒ½æ˜¯ç”¨æˆ·æ¨¡å¼ï¼Œåªèƒ½ç”¨æ¥çœ‹ä¸€äº›ç»Ÿè®¡ä¿¡æ¯ 1Switch&gt; ç‰¹æƒæ¨¡å¼ï¼Œå¯ä»¥æŸ¥çœ‹å¹¶ä¿®æ”¹é…ç½® 12Switch&gt;enableSwitch# å…¨å±€é…ç½®æ¨¡å¼ï¼Œå¯ä»¥ä¿®æ”¹ä¸»æœºåç­‰ 12Switch#config terminalSwitch(config)# æ¥å£æ¨¡å¼ï¼Œå¯ä»¥å¯¹æŒ‡å®šæ¥å£è¿›è¡Œé…ç½® 12Switch(config)#int f0/1Switch(config-if)# 1. Vlanåˆ’åˆ†Vlan å³è™šæ‹Ÿå±€åŸŸç½‘ï¼Œèƒ½å¤Ÿæœ‰æ•ˆé˜²æ­¢å¹¿æ’­é£æš´çš„å‘ç”Ÿã€‚ Vlan çš„åˆ’åˆ†æ˜¯åœ¨äº¤æ¢æœºä¸Šè¿›è¡Œï¼Œå®é™…ä¸Šå°±æ˜¯ç»™æŒ‡å®šç«¯å£è¿›è¡Œåˆ’åˆ†ã€‚ åœ¨åˆ’åˆ† vlan å‰ï¼Œå¯ä»¥çœ‹åˆ°å·¦è¾¹çš„ä¸»æœºä¸å³è¾¹çš„ä¸»æœºéƒ½æ˜¯èƒ½å¤Ÿé€šä¿¡çš„ æ¥ä¸‹æ¥å°†å·¦å³è¾¹çš„ä¸»æœºåˆ†åˆ«åˆ’åˆ†ä¸º vlan10ã€vlan20ï¼Œè¿›å…¥å…¨å±€é…ç½®æ¨¡å¼ 1234567891011121314151617# åˆ›å»ºvlanSwitch(config)#vlan 10Switch(config-vlan)#exitSwitch(config)#vlan 20Switch(config-vlan)#exit# åˆ’åˆ†vlanSwitch(config)#int range f0/1-3Switch(config-if-range)#switchport mode accessSwitch(config-if-range)#switchport access vlan 10Switch(config-if-range)#exitSwitch(config)#int range f0/4-6Switch(config-if-range)#switchport mode accessSwitch(config-if-range)#switchport access vlan 20Switch(config-if-range)#exit# æŸ¥çœ‹é…ç½®Switch#show running-config... å†å»è¿›è¡Œ ping æµ‹è¯•è¿é€šæ€§ï¼Œä¼šå‘ç°åªèƒ½ ping é€šåŒä¸€ vlan ä¸‹çš„ä¸»æœº 2. åˆ†ç±»åœ°å€çš„é€šä¿¡IP åœ°å€åˆ†ä¸ºäº”ç±»ï¼Œå¦‚æœä¸æ˜¯åŒä¸€ç½‘ç»œå·ä¸‹çš„åœ°å€åˆ™ä¸èƒ½å®ç°é€šä¿¡ï¼Œå¦‚ä¸‹å›¾ è¿™æ—¶å€™å¯ä»¥åœ¨ä¸­é—´æ·»åŠ ä¸€å°è·¯ç”±å™¨ï¼Œæ¥ä½œä¸ºå„ä¸»æœºä¹‹é—´çš„é»˜è®¤ç½‘å…³ï¼ˆé»˜è®¤è·¯ç”±ï¼‰ï¼Œå³å¯å®ç°é€šä¿¡ã€‚ è·¯ç”±é…ç½® 123456789Router&gt;enRouter#conf t# è¿›å…¥ç«¯å£è¿›è¡Œé…ç½®Router(config)#int g0/0Router(config-if)#ip add 192.168.88.1 255.255.255.0Router(config-if)#no shutdownRouter(config)#int g0/1Router(config-if)#ip add 172.16.0.1 255.255.0.0Router(config-if)#no shutdown ä¸»æœºé…ç½®é»˜è®¤ç½‘å…³ è¿é€šæ€§æµ‹è¯•ï¼Œç¬¬ä¸€ä¸ª ICMP åŒ…ä¼šä¸¢å¤±æ˜¯å› ä¸ºè·¯ç”±å™¨ä¼šå‘é€ ARP åŒ…å»å¯»æ‰¾ç›®æ ‡ä¸»æœºçš„ Mac åœ°å€ï¼Œæ‰€ä»¥åœ¨è§„å®šæ—¶é—´å†…æ²¡æœ‰æ”¶åˆ°å›é€æŠ¥æ–‡å°±ä¼šè¶…æ—¶ 3. åˆ’åˆ†å­ç½‘å­ç½‘çš„åˆ’åˆ†å®é™…ä¸Šå°±æ˜¯åœ¨åŸæœ‰çš„åŸºç¡€ä¸Šè¿›è¡Œæ›´å°çš„åˆ’åˆ†ï¼Œåˆ’åˆ†å­ç½‘åï¼Œé€šè¿‡ä½¿ç”¨æ©ç ï¼ŒæŠŠå­ç½‘éšè—èµ·æ¥ï¼Œä½¿å¾—ä»å¤–éƒ¨çœ‹ç½‘ç»œæ²¡æœ‰å˜åŒ–ï¼Œè¿™å°±æ˜¯å­ç½‘æ©ç ã€‚ å¦‚ä¸‹å›¾ï¼Œå·¦å³è¾¹ä¸»æœºçœ‹ä¼¼å¥½åƒæ˜¯åœ¨åŒä¸€ç½‘ç»œå·ä¸‹ï¼Œä½†ç”±äºå­ç½‘æ©ç æ˜¯ 255.255.255.192ï¼Œæ‰€ä»¥ä¹‹é—´æ˜¯ä¸èƒ½å¤Ÿé€šä¿¡çš„ï¼Œåªæœ‰ IP åœ°å€ä¸å­ç½‘æ©ç è¿›è¡Œä½ä¸çš„æ“ä½œä¹‹åç½‘ç»œå·ç›¸åŒçš„æ‰èƒ½å¤Ÿè¿›è¡Œé€šä¿¡ï¼Œä¾‹å¦‚å³è¾¹ä¸¤å°ä¸»æœºä¸å­ç½‘æ©ç è¿›è¡Œä½ä¸åç½‘ç»œå·éƒ½æ˜¯ 192.168.88.64ï¼Œå³å¤„äºåŒä¸€ç½‘ç»œå·ä¸‹èƒ½å¤Ÿè¿›è¡Œé€šä¿¡ã€‚ æ¯ä¸ªå­ç½‘å†…å¯ä»¥ä½¿ç”¨çš„ IP ä¸ªæ•°ç”±å­ç½‘å·æ¥åˆ¤æ–­ï¼Œä¾‹å¦‚ 255.255.255.192ï¼Œ192 è½¬åŒ–ä¸ºäºŒè¿›åˆ¶ä¸º 11000000ï¼Œæœ‰ 6 ä¸ª 0ï¼Œå³ IP ä¸ªæ•°ä¸º 2 ** 6 = 64 ä¸ªï¼Œå¸¸è§å­ç½‘æ©ç æœ‰ä»¥ä¸‹å‡ ä¸ªï¼ˆå­ç½‘æ©ç ï¼šå¯ç”¨ä¸»æœº IP ä¸ªæ•°ï¼‰ï¼š 255.255.255.128ï¼š126 255.255.255.192ï¼š62 255.255.255.224ï¼š30 255.255.255.240ï¼š14 255.255.255.248ï¼š6 255.255.255.252ï¼š2 è¦è§£å†³ä¸Šå›¾ç½‘ç»œé€šä¿¡é—®é¢˜ï¼Œåªéœ€è¦åœ¨ä¸­é—´æ·»åŠ ä¸ªè·¯ç”±å™¨å³å¯ã€‚ è·¯ç”±å™¨é…ç½® 12345678Router&gt;enRouter#conf tRouter(config)#int g0/0Router(config-if)#ip add 192.168.88.12 255.255.255.192Router(config-if)#no shutdownRouter(config)#int g0/1Router(config-if)#ip add 192.168.88.102 255.255.255.192Router(config-if)#no shutdown ä¸»æœºæ·»åŠ é»˜è®¤ç½‘å…³ æµ‹è¯•è¿é€šæ€§ 4. æ„é€ è¶…ç½‘ï¼ˆè·¯ç”±èšåˆï¼‰CIDR åœ°å€æ ¼å¼ä¸º xxx.xxx.xxx.xxx/xxï¼Œå¦‚ 192.168.88.10/24ï¼Œ24 ç”¨æ¥åˆ¤æ–­åœ°å€å—ä¿¡æ¯ï¼ŒäºŒè¿›åˆ¶åçš„ IP å‰ 24 ä½ä¸å˜ï¼Œå 8 ä½ä¸º 0ï¼Œå³å¯å¾—å‡ºæœ€å°åœ°å€ï¼Œå 8 ä½ä¸º 1 æ—¶ï¼Œå³å¯å¾—å‡ºæœ€å¤§åœ°å€ï¼Œå³ 192.168.88.0ã€192.168.88.255ã€‚ å¦‚ä¸‹å›¾ï¼Œå†æ²¡æœ‰é…ç½®é™æ€è·¯ç”±æ—¶ï¼Œä¸Šä¸‹ç½‘ç»œçš„ä¸»æœºæ˜¯ä¸èƒ½å¤Ÿä¸å³è¾¹çš„ä¸»æœºé€šä¿¡çš„ï¼Œè¿™æ—¶å€™æ·»åŠ é™æ€è·¯ç”±ï¼Œè®¾ç½®ä¸‹ä¸€è·³åœ°å€å³å¯å®ç°é€šä¿¡ã€‚ å·¦è¾¹è·¯ç”±é…ç½® 1Router(config)#ip route 192.168.88.196 255.255.255.252 192.168.88.194 å³è¾¹è·¯ç”±é…ç½® 12Router(config)#ip route 192.168.88.0 255.255.255.128 192.168.88.193Router(config)#ip route 192.168.88.128 255.255.255.192 192.168.88.193 æµ‹è¯•è¿é€šæ€§ ä»å³è¾¹è·¯ç”±é…ç½®å¯ä»¥çœ‹å‡ºï¼Œä¸¤æ¡é™æ€è·¯ç”±å¯ä»¥è¿›è¡Œè·¯ç”±èšåˆï¼Œå³ 192.168.88 å‰ä¸‰ä¸ªå­—èŠ‚æ˜¯ç›¸åŒçš„ï¼Œé‚£ä¹ˆèšåˆåçš„åœ°å€å—ä¸º 192.168.88.0/24ï¼Œè·¯ç”±é…ç½®ä¸º 1Router(config)#ip route 192.168.88.0 255.255.255.0 192.168.88.193 5. ç‰¹å®šè·¯ç”±å’Œé»˜è®¤è·¯ç”±ç‰¹å®šè·¯ç”±å³å°†æ•°æ®æŠ¥è½¬å‘ç»™ç‰¹å®šçš„ç›®æ ‡åœ°å€ï¼Œè€Œé»˜è®¤è·¯ç”±å³é™¤äº†ç‰¹å®šçš„ç›®æ ‡åœ°å€å¤–éƒ½è½¬å‘ç»™é»˜è®¤çš„è·¯ç”±ï¼Œæµç¨‹å¦‚ä¸‹å›¾ã€‚ åœ¨ä»¥ä¸‹ç½‘ç»œä¸­ï¼Œç›®çš„åœ°å€åªè¦æ˜¯ 192.168.4 ç½‘æ®µï¼Œéƒ½ä¼šä¸‹ä¸€è·³ç»™ R1 è·¯ç”±å™¨ï¼Œå†ç”± R2 è¿›è¡Œè·¯ç”±è½¬å‘ã€‚ R1 è·¯ç”±é…ç½® 12Router(config)#ip route 192.168.4.1 255.255.255.255 10.0.1.1Router(config)#ip route 0.0.0.0 0.0.0.0 10.0.0.1 R2 è·¯ç”±é…ç½® 1Router(config)#ip route 0.0.0.0 0.0.0.0 10.0.1.2 R3 è·¯ç”±é…ç½® 123Router(config)#ip route 192.168.0.0 255.255.255.0 10.0.0.2Router(config)#ip route 192.168.4.0 255.255.255.0 10.0.0.2Router(config)#ip route 0.0.0.0 0.0.0.0 10.0.2.2 R4 è·¯ç”±é…ç½® 1Router(config)#ip route 0.0.0.0 0.0.0.0 10.0.2.1 6. é»‘æ´è·¯ç”±å¦‚æœé™æ€è·¯ç”±é…ç½®äº†ä¸å­˜åœ¨çš„ç½‘æ®µï¼Œé‚£ä¹ˆå°±å¯èƒ½ä¼šå¯¼è‡´è·¯ç”±ç¯è·¯çš„é—®é¢˜ï¼Œè¿™æ—¶å€™å¯ä»¥æ·»åŠ ä¸€ä¸ªé»‘æ´è·¯ç”±è¿›è¡Œè§£å†³ï¼Œå¦‚ä¸‹ï¼Œåªè¦ç›®çš„åœ°å€æ˜¯ 192.168.88.0/24 åœ°å€å¿«çš„æ•°æ®åŒ…éƒ½ä¼šè¢«ä¸¢å¼ƒã€‚ 1Router(config)#ip route 192.168.88.0 255.255.255.0 null0 7. è·¯ç”±ä¿¡æ¯åè®®RIPRIP æ˜¯ä¸€ç§åˆ†å¸ƒå¼çš„åŸºäºè·ç¦»å‘é‡çš„è·¯ç”±é€‰æ‹©åè®®ï¼Œå±äºå†…éƒ¨ç½‘å…³åè®®ï¼Œä¸»è¦é€‚ç”¨äºå°è§„æ¨¡çš„ç½‘ç»œç¯å¢ƒã€‚ åœ¨ RIP åè®®ä¸­ï¼Œæ¯æ¬¡æ•°æ®çš„å‘é€éƒ½ä¼šé€‰æ‹©è·³æ•°æœ€å°‘çš„è·¯ç”±ï¼Œå³ç»è¿‡èŠ‚ç‚¹æœ€å°‘çš„è·¯ç”±çº¿è·¯ã€‚ å¦‚ä¸‹ç½‘ç»œä¸­ï¼Œåœ¨ç»™æ‰€æœ‰ä¸»æœºå’Œè·¯ç”±ç«¯å£é…å¥½ IP åï¼Œè¿˜æ˜¯ä¸èƒ½å¤Ÿé€šä¿¡çš„ï¼Œç»™æ¯ä¸ªè·¯ç”±å™¨è®¾ç½®å®£å‘Šåœ°å€æ®µï¼Œå³é…ç½® RIPï¼Œè·¯ç”±å™¨å°±ä¼šå‘é€ RIP æŠ¥æ–‡æ¥ç®—å‡ºæ¯ä¸ªç½‘æ®µä¹‹é—´çš„æœ€çŸ­è·¯å¾„ï¼Œå¹¶å†™å…¥è·¯ç”±è¡¨ä¸­ï¼Œæœ€ç»ˆè·¯å¾„ä¸º PC1 -&gt; R1 -&gt; R3 -&gt; PC2ã€‚ åœ¨æ¯ä¸ªè·¯ç”±å™¨è®¾ç½® RIP 1234Router(config)#router ripRouter(config-router)#network 10.0.0.0Router(config-router)#network 192.168.2.0Router(config-router)#network 192.168.1.0 è·¯ç”±è¡¨ä¸­ R ä»£è¡¨çš„å°±æ˜¯ RIP åè®®å†™å…¥çš„è·¯ç”± 1Router#show ip route 8. å¼€æ”¾æœ€çŸ­è·¯å¾„ä¼˜å…ˆOSFPOSPF ä¹Ÿå±äºå†…éƒ¨ç½‘å…³åè®®ï¼Œç”¨äºåœ¨å•ä¸€è‡ªæ²»ç³»ç»Ÿ AS å†…å†³ç­–è·¯ç”±ï¼Œæ˜¯åŸºäºé“¾è·¯çŠ¶æ€çš„åŠ¨æ€è·¯ç”±é€‰æ‹©åè®®ã€‚ åœ¨ OSPF ä¸­ï¼Œå½“é“¾è·¯çŠ¶æ€å‘ç”Ÿå˜åŒ–å°±ä¼šé‡‡ç”¨æ´ªæ³›æ³•å»æ›´æ–°ä¿¡æ¯ï¼Œæ¯ä¸ªè·¯ç”±å™¨éƒ½ä¸ç›¸é‚»çš„è·¯ç”±å™¨æˆé‚»å±…å…³ç³»ï¼Œé‚»å±…å†ç›¸äº’å‘é€é“¾è·¯çŠ¶æ€ä¿¡æ¯å½¢æˆé‚»æ¥å…³ç³»ï¼Œä¹‹åå„è‡ªæ ¹æ®æœ€çŸ­è·¯å¾„ç®—æ³•ç®—å‡ºè·¯ç”±ï¼Œæ”¾åœ¨OSPFè·¯ç”±è¡¨ï¼ŒOSPFè·¯ç”±ä¸å…¶ä»–è·¯ç”±æ¯”è¾ƒåä¼˜çš„åŠ å…¥å…¨å±€è·¯ç”±è¡¨ã€‚æ•´ä¸ªè¿‡ç¨‹ä½¿ç”¨äº†äº”ç§æŠ¥æ–‡ã€ä¸‰ä¸ªé˜¶æ®µã€å››å¼ è¡¨ã€‚ åœ¨ä»¥ä¸‹ç½‘ç»œä¸­ï¼Œé€šè¿‡ OSPF é…ç½®è·¯ç”±åçš„è·¯å¾„ä¸º PC1 -&gt; R1 -&gt; R2 -&gt; R3 -&gt; PC2ï¼Œå› ä¸º R1 ä¸ R3 ä¹‹é—´é‡‡ç”¨çš„æ˜¯ä¸²è¡Œæ¥å£ï¼Œæ˜¯ä½é€Ÿé“¾è·¯ã€‚ R1 è·¯ç”±å™¨é…ç½® 123456# 100ä¸ºæŒ‡å®šè¿›ç¨‹ï¼Œå¯åœ¨1-65535ä¹‹é—´é€‰æ‹©Router(config)#route ospf 100# 0.0.0.255ä¸ºåå­ç½‘æ©ç ï¼Œareaä¸ºåœ°åŒºå·Router(config-router)#network 10.0.0.0 0.0.0.255 area 0Router(config-router)#network 192.168.1.0 0.0.0.255 area 0Router(config-router)#network 10.0.1.0 0.0.0.255 area 0 R2 è·¯ç”±å™¨é…ç½® 1234Router(config)#route ospf 100Router(config-router)#network 10.0.0.0 0.0.0.255 area 0Router(config-router)#network 10.0.1.0 0.0.0.255 area 0Router(config-router)#network 10.0.2.0 0.0.0.255 area 0 R3 è·¯ç”±å™¨é…ç½® 1234Router(config)#route ospf 100Router(config-router)#network 10.0.1.0 0.0.0.255 area 0Router(config-router)#network 10.0.2.0 0.0.0.255 area 0Router(config-router)#network 192.168.2.0 0.0.0.255 area 0 é€šè¿‡æµ‹è¯•å¯ä»¥çœ‹åˆ°è·¯ç”±çº¿è·¯çš„é€‰æ‹© å¦‚æœçº¿è·¯æ–­äº†ä¼šè‡ªåŠ¨æ›´æ–°è·¯ç”±è¡¨ï¼Œè¿™æ—¶å€™å†çœ‹çº¿è·¯çš„é€‰æ‹©å°±ä¼šä¸ä¸€æ ·ï¼Œä½†ä¾æ—§å¯ä»¥è”é€š 9. è¾¹ç•Œç½‘å…³åè®®BGPBGP æ˜¯ä¸€ç§å¤–éƒ¨ç½‘å…³åè®®ï¼Œæ˜¯åŸºäºè‡ªæ²»ç³»ç»Ÿ AS ä¹‹é—´çš„è·¯ç”±åè®®ï¼ŒBGPäº¤æ¢çš„ç½‘ç»œå¯è¾¾æ€§ä¿¡æ¯æä¾›äº†è¶³å¤Ÿçš„ä¿¡æ¯æ¥æ£€æµ‹è·¯ç”±å›è·¯å¹¶æ ¹æ®æ€§èƒ½ä¼˜å…ˆå’Œç­–ç•¥çº¦æŸå¯¹è·¯ç”±è¿›è¡Œå†³ç­–ã€‚ æ¯ä¸ª AS ä¼šè®¾ç½®ä¸€ä¸ª BGP å‘è¨€äººï¼Œå³ä¸€ä¸ªè·¯ç”±å™¨ï¼Œç”¨æ¥ä¸ç›¸é‚» AS çš„ BGP å‘è¨€äººäº¤æ¢ç½‘ç»œå¯è¾¾æ€§çš„ä¿¡æ¯ã€‚ å¦‚ä¸‹å›¾ç½‘ç»œï¼Œåˆ†åˆ«æœ‰ä¸‰ä¸ª ASï¼Œè¦å°†ä¸åŒ AS ä¹‹é—´è¿›è¡Œè”é€šï¼Œå°±å¯ä»¥é€šè¿‡ BGP æ¥å®ç°ã€‚ AS 100 ä¸­è·¯ç”±é…ç½® 1234567# 100ä¸ºè‡ªæ²»ç³»ç»Ÿç¼–å·Router(config)#route bgp 100# æŒ‡å®šé‚»å±…ï¼ŒIPå³ä¸ç›¸é‚»è·¯ç”±å™¨çš„è¿æ¥ç«¯å£IPï¼Œ200/300ä¸ºç›¸é‚»ASçš„ç¼–å·Router(config-router)#neighbor 10.0.1.2 remote-as 200Router(config-router)#neighbor 10.0.0.2 remote-as 300# å°†è‡ªèº«ASä¸­çš„ç½‘ç»œä¿¡æ¯é€šæŠ¥å‡ºå»Router(config-router)#network 192.168.10.0 mask 255.255.255.0 AS 200 ä¸­è·¯ç”±é…ç½® 123Router(config)#route bgp 200Router(config-router)#neighbor 10.0.1.1 remote-as 100Router(config-router)#network 192.168.20.0 mask 255.255.255.0 AS 300 ä¸­è·¯ç”±é…ç½® 123Router(config)#route bgp 300Router(config-router)#neighbor 10.0.0.1 remote-as 100Router(config-router)#network 192.168.30.0 mask 255.255.255.0 æŸ¥çœ‹ BGP è·¯ç”±ä¿¡æ¯ï¼Œå¯ä»¥çœ‹åˆ° B ä»£è¡¨çš„ BGP è·¯ç”±ä¿¡æ¯ 12345Router(config-router)#do show ip route...B 192.168.10.0/24 [20/0] via 10.0.1.1, 00:00:00B 192.168.30.0/24 [20/0] via 10.0.1.1, 00:00:00... 10. å¤šè‡‚è·¯ç”±å®ç°vlanä¹‹é—´çš„é€šä¿¡vlan ä¹‹é—´å¦‚æœç½‘æ®µä¸åŒï¼Œå°±æ— æ³•è¿›è¡Œé€šä¿¡ï¼Œå¯ä»¥åœ¨ä¸­é—´æ·»åŠ ä¸€å°è·¯ç”±å™¨æ¥åšåŒæ–¹çš„ç½‘å…³ï¼Œå·²å¤šè‡‚è·¯ç”±çš„æ–¹å¼å®ç°ä¸åŒ vlan ä¸åŒç½‘æ®µä¹‹é—´çš„é€šä¿¡ã€‚ å¤šè‡‚è·¯ç”±å³ä¸€ä¸ªç«¯å£å¯¹åº”ä¸€ä¸ª vlanï¼Œå¦‚ä¸‹å›¾ã€‚ 11. å•è‡‚è·¯ç”±å®ç°vlanä¹‹é—´çš„é€šä¿¡å•è‡‚è·¯ç”±ä¸å¤šè‡‚è·¯ç”±çš„åŸç†æ˜¯ç›¸åŒçš„ï¼ŒåŒºåˆ«åœ¨äºåœ¨å¤šè‡‚è·¯ç”±ä¸­ï¼Œäº¤æ¢æœºåˆ°è·¯ç”±å™¨çš„é“¾è·¯é…ç½®çš„æ˜¯ accessï¼Œåœ¨å•è‡‚è·¯ç”±ä¸­ç”¨ä¸€ä¸ªä¸»å¹² trunk é“¾è·¯æ›¿ä»£ã€‚ åœ¨è¿æ¥äº¤æ¢æœºçš„è·¯ç”±å™¨ä¸Šé…ç½® 12345678910111213# åˆ›å»ºé€»è¾‘å­æ¥å£Router(config)#int g0/0.1# å¯æ¥å—idä¸º10çš„vlanæ•°æ®åŒ…ï¼Œå¹¶å°è£…æˆ802.1qæ¡¢è¿›è¡Œè½¬å‘Router(config-subif)#encapsulation dot1Q 10Router(config-subif)#ip add 192.168.1.254 255.255.255.0Router(config-subif)#exitRouter(config)#int g0/0.2Router(config-subif)#encapsulation dot1Q 20Router(config-subif)#ip add 192.168.2.254 255.255.255.0Router(config-subif)#exit# å¼€å¯æ¥å£Router(config)#int g0/0Router(config-if)#no shutdown åœ¨äº¤æ¢æœºä¸Šå°†ä¸è·¯ç”±å™¨ç›¸æ¥çš„ç«¯å£è®¾ç½®ä¸º trunk å£ 12Switch(config)#int f0/7Switch(config-if)#switchport mode trunk è¿é€šæ€§æµ‹è¯• 12. ä¸‰å±‚äº¤æ¢æœºå®ç°vlanä¹‹é—´çš„é€šä¿¡ä¸‰å±‚äº¤æ¢æœºå°±æ˜¯å…·æœ‰éƒ¨åˆ†è·¯ç”±å™¨åŠŸèƒ½çš„äº¤æ¢æœºã€‚ ä¸‰å±‚äº¤æ¢æœºé…ç½® 1234567891011121314151617181920212223Switch(config)#vlan 10Switch(config-vlan)#exit# è¿›å…¥vlanæ·»åŠ IPSwitch(config)#int vlan10Switch(config-if)#ip add 192.168.1.254 255.255.255.0Switch(config-if)#no shutdownSwitch(config-if)#exitSwitch(config)#vlan 20Switch(config-vlan)#exitSwitch(config)#int vlan20Switch(config-if)#ip add 192.168.2.254 255.255.255.0Switch(config-if)#no shutdownSwitch(config-if)#exit Switch(config)#int range f0/1-3Switch(config-if-range)#switchport mode access Switch(config-if-range)#switchport access vlan 10Switch(config-if-range)#Switch(config-if-range)#exitSwitch(config)#int range f0/4-6Switch(config-if-range)#switchport mode access Switch(config-if-range)#switchport access vlan 20# å¼€å¯è·¯ç”±åŠŸèƒ½Switch(config)#ip routing æµ‹è¯•è¿é€šæ€§","link":"/2024/02/18/cisco/"},{"title":"calicoçš„ä¸‰ç§æ¨¡å¼","text":"Calico çš„è¿è¡Œæ”¯æŒä¸‰ç§æ¨¡å¼: vxlan ipip bgp VXLANå°åŒ…è§£åŒ…: åœ¨ vxlan è®¾å¤‡ä¸Šå°† Pod å‘æ¥çš„æ•°æ®åŒ…æºã€ç›®çš„ mac åœ°å€æ›¿æ¢ä¸ºæœ¬ä¸»æœº vxlan ç½‘å¡å’Œå¯¹ç«¯ vxlan ç½‘å¡çš„ mac åœ°å€ ä¼˜ç¼ºç‚¹: vxlan çš„æ•°æ®åŒ…ä¼šå°è£…åœ¨ udp æ•°æ®åŒ…ä¸­ï¼Œæ‰€ä»¥è¦æ±‚èŠ‚ç‚¹ä¹‹é—´ä¸‰å±‚äº’é€šï¼Œæ”¯æŒè·¨ç½‘æ®µã€‚ä½†å°åŒ…è§£åŒ…çš„è¿‡ç¨‹ä¼šæœ‰ä¸€å®šç½‘ç»œæ€§èƒ½æŸè€— IPIPå°åŒ…è§£åŒ…: åœ¨ tun0 è®¾å¤‡ä¸Šå°† Pod å‘æ¥çš„æ•°æ®åŒ…çš„ mac å±‚å»é™¤ï¼Œç•™ä¸‹ ip å±‚å¹¶ä½¿ç”¨å®¿ä¸»æœºçš„ ip è¿›è¡Œä¸€æ¬¡å°åŒ… ä¼˜ç¼ºç‚¹: è¦æ±‚èŠ‚ç‚¹ä¹‹é—´ä¸‰å±‚äº’é€šï¼Œæ”¯æŒè·¨ç½‘æ®µã€‚ä½†å°åŒ…è§£åŒ…çš„è¿‡ç¨‹ä¼šæœ‰ä¸€å®šç½‘ç»œæ€§èƒ½æŸè€— BGPå°åŒ…è§£åŒ…: ä¸è¿›è¡Œå°åŒ…è§£åŒ… ä¼˜ç¼ºç‚¹: é€šè¿‡ bgp åè®®å°±å¯ä»¥æ”¯æŒèŠ‚ç‚¹ä¹‹é—´çš„ä¸‰å±‚äº’é€šã€‚ CrossSubnetvxlan å’Œ ipip éƒ½æ”¯æŒé…ç½® CrossSubnet æ¨¡å¼ï¼Œè¿™ç§æ¨¡å¼ä¸‹ï¼Œåªæœ‰è·¨ç½‘æ®µèŠ‚ç‚¹çš„ Pod ä¹‹é—´çš„é€šä¿¡æ‰ä¼šè¿›è¡Œå°åŒ…è§£åŒ…ï¼Œè€ŒåŒä¸€ç½‘æ®µèŠ‚ç‚¹çš„ Pod ä¹‹é—´åˆ™ä½¿ç”¨ bgp æ¨¡å¼è¿›è¡Œé€šä¿¡ï¼Œèƒ½å¤Ÿåœ¨ä¸€å®šç¨‹åº¦ä¸Šæé«˜ç½‘ç»œæ€§èƒ½ã€‚","link":"/2024/03/31/calico%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/"},{"title":"Docker","text":"ä¸€. Dockerä»‹ç»1.1 Dockeræ˜¯ä»€ä¹ˆ Docker æ˜¯ä¸€ä¸ªå¼€æºçš„åº”ç”¨å®¹å™¨å¼•æ“ï¼ŒåŸºäº Go è¯­è¨€å¹¶éµä» Apache2.0 åè®®å¼€æºã€‚ Docker å¯ä»¥è®©å¼€å‘è€…æ‰“åŒ…ä»–ä»¬çš„åº”ç”¨ä»¥åŠä¾èµ–åŒ…åˆ°ä¸€ä¸ªè½»é‡çº§ã€å¯ç§»æ¤çš„å®¹å™¨ä¸­ï¼Œç„¶åå‘å¸ƒåˆ°ä»»ä½•æµè¡Œçš„ Linux æœºå™¨ä¸Šï¼Œä¹Ÿå¯ä»¥å®ç°è™šæ‹ŸåŒ–ã€‚ å®¹å™¨æ˜¯å®Œå…¨ä½¿ç”¨æ²™ç®±æœºåˆ¶ï¼Œç›¸äº’ä¹‹é—´ä¸ä¼šæœ‰ä»»ä½•æ¥å£ï¼ˆç±»ä¼¼ iPhone çš„ appï¼‰,æ›´é‡è¦çš„æ˜¯å®¹å™¨æ€§èƒ½å¼€é”€æä½ã€‚ äºŒ. Dockerçš„åŸºæœ¬æ“ä½œ2.1 Dockerçš„å®‰è£…121.å®‰è£…Dockerä¾èµ–ç¯å¢ƒyum -y install yum-utils device-mapper-persistent-data lvm2 122.ä¸‹è½½Dockeré•œåƒæºyum-config-manager --add-repo https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.repo 1233.å®‰è£…Dockeryum makecache fastyum -y install docker-ce 1234.å¯åŠ¨Dockerå¹¶è®¾ä¸ºå¼€æœºè‡ªå¯systemctl start dockersystemctl enable docker 123455.æµ‹è¯•è¿è¡Œhello worlddocker run hello-world...Hello from Docker!... 2.2 Dockerçš„ä¸­å¤®ä»“åº“1ã€Dockerå®˜æ–¹ï¼ˆhub.docker.comï¼‰ï¼šé•œåƒæœ€å…¨ï¼Œä¸‹è½½æœ€æ…¢ 2ã€å›½å†…é•œåƒç½‘ç«™ï¼šç½‘æ˜“èœ‚å·¢ï¼ˆ163yun.comï¼‰ â€‹ daocloudï¼ˆhub.daocloud.ioï¼‰ 3ã€å…¬å¸å†…éƒ¨ç§æœæ‹‰å–é•œåƒï¼š 123456781.é…ç½®/etc/docker/daemon.json{ &quot;registry-mirrors&quot;:[&quot;https://registry.docker-cn.com&quot;], &quot;insecure-registries&quot;:[&quot;ip:port&quot;]}2.é‡å¯ä¸¤ä¸ªæœåŠ¡systemctl daemon-reloadsystemctl restart docker 2.3 Dockeré•œåƒçš„æ“ä½œ12341.æ‹‰å–é•œåƒåˆ°æœ¬åœ°docker pull é•œåƒåç§°[:tag]ä¸¾ä¸ªæ —å­docker pull daocloud.io/library/nginx:1.18.0 122.æŸ¥çœ‹æœ¬åœ°é•œåƒdocker images 123.åˆ é™¤æœ¬åœ°é•œåƒdocker rmi é•œåƒid(image id) 1234.æœ¬åœ°é•œåƒçš„å¯¼å…¥å¯¼å‡ºdocker save -o å¯¼å‡ºè·¯å¾„ é•œåƒiddocker load -i é•œåƒæ–‡ä»¶ 125.ç»™é•œåƒæ·»åŠ æ ‡ç­¾docker tag é•œåƒid repository:tag 2.4 Dockerå®¹å™¨çš„æ“ä½œ1234561.è¿è¡Œå®¹å™¨docker run é•œåƒid/é•œåƒåç§°[:tag]docker run -d -p å®¿ä¸»æœºç«¯å£:å®¹å™¨ç«¯å£ --name å®¹å™¨åç§° é•œåƒid/é•œåƒåç§°[:tag]-d:ä»£è¡¨åå°è¿è¡Œå®¹å™¨-p:ä¸ºäº†æ˜ å°„linuxç«¯å£å’Œå®¹å™¨ç«¯å£--name:æŒ‡å®šå®¹å™¨åç§° 12342.æŸ¥çœ‹å®¹å™¨docker ps -qa-a:æŸ¥çœ‹æ‰€æœ‰å®¹å™¨ï¼ŒåŒ…æ‹¬æ²¡æœ‰è¿è¡Œçš„-q:åªçœ‹å®¹å™¨id 1233.æŸ¥çœ‹å®¹å™¨æ—¥å¿—docker logs -f å®¹å™¨id-f:å¯ä»¥æ»šåŠ¨æŸ¥çœ‹å®¹å™¨æ—¥å¿—çš„æœ€åå‡ è¡Œ 124.è¿›å…¥å®¹å™¨å†…éƒ¨docker exec -it å®¹å™¨id bash 123455.åœæ­¢/åˆ é™¤å®¹å™¨docker stop å®¹å™¨iddocker stop $(docker ps -qa)docker rm å®¹å™¨iddocker rm $(docker ps -qa) 126.å¯åŠ¨å®¹å™¨docker start å®¹å™¨id ä¸‰. Dockeræ•°æ®å·3.1 æ•°æ®å·æ“ä½œæ•°æ®å·å°±æ˜¯å°†å®¿ä¸»æœºçš„ä¸€ä¸ªç›®å½•æ˜ å°„åˆ°å®¹å™¨çš„ä¸€ä¸ªç›®å½•ä¸­ å¯ä»¥åœ¨å®¿ä¸»æœºçš„ç›®å½•ä¸­ç›´æ¥æ“ä½œï¼Œå®¹å™¨çš„ç›®å½•å’Œæ–‡ä»¶ä¹Ÿä¼šè·Ÿç€æ”¹å˜ åˆ›å»ºå¥½çš„æ•°æ®å·ä¼šå­˜æ”¾åœ¨ä¸€ä¸ªé»˜è®¤çš„ç›®å½•ä¸‹ï¼š/var/lib/docker/volumes/ 121.åˆ›å»ºæ•°æ®å·docker volume create æ•°æ®å·åç§° 12342.æŸ¥çœ‹æ•°æ®å·è¯¦ç»†ä¿¡æ¯docker volume inspect æ•°æ®å·åç§°æŸ¥çœ‹å…¨éƒ¨æ•°æ®å·docker volume ls 123.åˆ é™¤æ•°æ®å·docker volume rm æ•°æ®å·åç§° 12345678910114.åº”ç”¨æ•°æ®å·#å¦‚æœæ˜ å°„æ•°æ®å·ä¸å­˜åœ¨ï¼Œdockerä¼šè‡ªåŠ¨åˆ›å»ºï¼Œä¼šå°†å®¹å™¨å†…éƒ¨çš„æ–‡ä»¶å­˜å‚¨åœ¨æ•°æ®å·ä¸­docker run -v æ•°æ®å·åç§°:å®¹å™¨å†…éƒ¨è·¯å¾„ é•œåƒid#ç›´æ¥æŒ‡å®šä¸€ä¸ªè·¯å¾„ä½œä¸ºå­˜æ”¾è·¯å¾„ï¼Œå»ºè®®ä½¿ç”¨è¿™ç§docker run -v æ•°æ®å·è·¯å¾„:å®¹å™¨å†…éƒ¨è·¯å¾„ é•œåƒid-v:æ˜ å°„æ•°æ®å·#å¯ä»¥åœ¨æŒ‡å®šè·¯å¾„åé¢åŠ ä¸Šæƒé™ï¼Œä¸€æ—¦è®¾ç½®æƒé™å°±ä¸å¯ä»¥æ”¹äº†ï¼Œä¸¾ä¸ªæ —å­docker run -v /root/nginx:/etc/nginx:rw nginxro:åªè¯»rw:å¯è¯»å¯å†™ 3.2 å®ç°å®¹å™¨ä¹‹é—´æ•°æ®åŒæ­¥â€“volumes-fromå¯ä»¥å®ç°å®¹å™¨ä¹‹é—´çš„æ•°æ®åŒæ­¥ï¼Œå³ä½¿æœ‰ä¸€å°å®¹å™¨æŒ‚äº†ä¹Ÿä¸ä¼šå½±å“åˆ°æ•°æ®ï¼Œåˆ«çš„å®¹å™¨ä»ç„¶ä¼šæœ‰æ•°æ®åœ¨ã€‚ ä¸¾ä¸ªæ —å­ 12#å¯åŠ¨å®¹å™¨ä¸€ï¼Œå¹¶åˆ›å»ºæµ‹è¯•ç›®å½•docker run -d -v /root/docker/test1:/test1 -v /root/docker/test2:/test2 --name nginx01 é•œåƒid 123#å¯åŠ¨å®¹å™¨äºŒï¼ŒæŒ‚è½½å®¹å™¨ä¸€çš„ç›®å½•docker run -d --name nginx02 --volumes-from nginx01 é•œåƒiddocker exec -it å®¹å™¨äºŒid bash è¿›å…¥å®¹å™¨äºŒå†…éƒ¨åå¯ä»¥çœ‹è§å®¹å™¨ä¸€çš„test1å’Œtest2ï¼Œè¿™æ—¶å€™æ— è®ºåœ¨å®¹å™¨ä¸€è¿˜æ˜¯å®¹å™¨äºŒç”Ÿæˆæˆ–åˆ é™¤æ–‡ä»¶éƒ½ä¼šè¿›è¡ŒåŒæ­¥ ç”¨docker inspect å®¹å™¨idå¯ä»¥çœ‹åˆ°ä¸¤ä¸ªå®¹å™¨æ˜ å°„çš„éƒ½æ˜¯åŒä¸€ä¸ªç›®å½• å››. Dockerfileè‡ªå®šä¹‰é•œåƒDockerfile æ˜¯ä¸€ä¸ªç”¨æ¥æ„å»ºé•œåƒçš„æ–‡æœ¬æ–‡ä»¶ï¼Œæ–‡æœ¬å†…å®¹åŒ…å«äº†ä¸€æ¡æ¡æ„å»ºé•œåƒæ‰€éœ€çš„æŒ‡ä»¤å’Œè¯´æ˜ã€‚ 4.1 åˆ›å»ºè‡ªå®šä¹‰é•œåƒ123456789101112131.åˆ›å»ºä¸€ä¸ªDockerfileæ–‡ä»¶ï¼Œå¹¶æŒ‡å®šè‡ªå®šä¹‰é•œåƒä¿¡æ¯#Dockerfileä¸­å¸¸ç”¨ä¿¡æ¯FROM: è¿™ä¸ªé•œåƒçš„å¦ˆå¦ˆæ˜¯è°?(æŒ‡å®šåŸºç¡€é•œåƒ)MAINTAINER: å‘Šè¯‰åˆ«äººï¼Œè°è´Ÿè´£å…»å®ƒ?(æŒ‡å®šç»´æŠ¤è€…ä¿¡æ¯)CMD: ä½ æƒ³è®©å®ƒå¹²å•¥(æŒ‡å®šå®¹å™¨runå‰è¦åšä»€ä¹ˆï¼Œåªæœ‰æœ€åä¸€ä¸ªä¼šç”Ÿæ•ˆ)ENTRYPOINT: ä½ æƒ³è®©å®ƒå¹²å•¥(æŒ‡å®šå®¹å™¨runå‰è¦åšä»€ä¹ˆï¼Œå¯ä»¥è¿½åŠ å‘½ä»¤)RUN: ä½ æƒ³è®©å®ƒå¹²å•¥(æŒ‡å®šå®¹å™¨runåè¦åšä»€ä¹ˆ)COPY: ç»™å®ƒç‚¹åˆ›ä¸šèµ„é‡‘(æ‹·è´æ–‡ä»¶åˆ°é•œåƒå†…éƒ¨)ADD: ç»™å®ƒç‚¹åˆ›ä¸šèµ„é‡‘(æ‹·è´æ–‡ä»¶åˆ°é•œåƒå†…éƒ¨ï¼Œå¦‚æœæ˜¯å‹ç¼©åŒ…ä¼šè§£å‹äº†å†å°±è¡Œæ‹·è´)WORKDIR: æˆ‘æ˜¯cd(é…ç½®å·¥ä½œç›®å½•ï¼Œæ —å­:å¦‚æœWORKDIRé…ç½®äº†/home,é‚£ä¹ˆCOPYå’ŒADDä½¿ç”¨.ä½œä¸ºæ‹·è´è·¯å¾„çš„è¯éƒ½ä¼šæ‹·è´åˆ°/homeä¸‹)VOLUME: ç»™ä¸€ä¸ªå­˜æ”¾è¡Œæçš„åœ°æ–¹(è®¾ç½®æ•°æ®å·ï¼ŒæŒ‚è½½åˆ°ä¸»æœºç›®å½•)EXPOSE: ç»™ä¸€ä¸ªé—¨(æŒ‡å®šå¯¹å¤–å¼€æ”¾çš„ç«¯å£å·)ENV: è®¾ç½®ç¯å¢ƒå˜é‡(environmentï¼Œä¹Ÿå°±æ˜¯å‚æ•°-e) 122.åœ¨linuxä¸Šé€šè¿‡dockeræŒ‡å®šé•œåƒdocker build -t é•œåƒåç§°:[tag] . 12343.ä¸¾ä¸ªnginxæ —å­cat DockerfileFROM daocloud.io/library/nginx:1.18.0COPY test.html /usr/share/nginx/html/test.html 4.2 CMDå’ŒENTRYPOINTçš„åŒºåˆ«ç”¨CMDå’ŒENTRYPOINTåšåŒä¸€ä¸ªæµ‹è¯• CMD 121.åˆ›å»ºDockerfileæ–‡ä»¶vim /root/docker/Dockerfile 1232.ç¼–å†™FROM daocloud.io/library/centos:latestCMD [&quot;ls&quot;,&quot;-a&quot;] 123.ç”Ÿæˆé•œåƒæ–‡ä»¶docker build -f /root/docker/Dockerfile -t cmd_centos:1.0 . 124.å¯åŠ¨å®¹å™¨ï¼Œä¼šå‘ç°æ‰§è¡Œäº†ls -adocker run cmd_centosé•œåƒid å¦‚æœå¯åŠ¨é•œåƒçš„æ—¶å€™å†åŠ å‚æ•°ä¼šæŠ¥é”™ï¼Œä½†å®Œæ•´çš„å‘½ä»¤å°±å¯ä»¥ ENTRYPOINT 123#é™¤äº†Dockerfileä¸­çš„CMDæ¢æˆäº†ENTRYPOINTå¤–å…¶å®ƒéƒ½ä¸€æ ·FROM daocloud.io/library/centos:latestENTRYPOINT [&quot;ls&quot;,&quot;-a&quot;] è¿™æ—¶å€™æˆ‘ä»¬å†è¿½åŠ å‚æ•°å‘ç°å¯ä»¥äº†ï¼Œè¿™å°±æ˜¯ENTRYPOINTæ¯”èµ·CMDæœ‰å¯ä»¥è¿½åŠ å‚æ•°çš„ä¸åŒ 4.3 åˆ¶ä½œTomcaté•œåƒ å‡†å¤‡tomcatå‹ç¼©åŒ…å’Œjdkå‹ç¼©åŒ… ç¼–å†™Dockerfileæ–‡ä»¶ 12345678910111213141516171819FROM daocloud.io/library/centos:7MAINTAINER cqm's diy tomcat&lt;chenqiming13@qq.com&gt;ADD jdk-8u271-linux-x64.tar.gz /usr/localADD apache-tomcat-9.0.41.tar.gz /usr/localRUN yum -y install vimENV MYPATH /usr/localWORKDIR $MYPATH #è¿›å…¥å®¹å™¨åå°±ä¼šè¿›å…¥MYPATHç›®å½•ENV JAVA_HOME /usr/local/jdk1.8.0_271ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarENV CATALINA_HOME /usr/local/apache-tomcat-9.0.41ENV CATALINA_BASH /usr/local/apache-tomcat-9.0.41ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/binEXPOSE 8080CMD /usr/local/apache-tomcat-9.0.41/bin/startup.sh &amp;&amp; tailf /usr/local/apache-tomcat-9.0.41/bin/logs/catalina.out ç”Ÿæˆtomcaté•œåƒ 1docker build -t cqm_tomcat:1.0 . å¯åŠ¨å®¹å™¨ 1docker run -d -p 8080:8080 --name cqm_tomcat -v /root/tomcat/test:/usr/local/apache-tomcat-9.0.41/webapps/test -v /root/tomcat/logs:/usr/local/apache-tomcat-9.0.41/logs cqm_tomcaté•œåƒid è®¿é—®æµ‹è¯• ä¸Šä¼ é¡¹ç›® 123cd /root/tomcat/testmkdir WEB-INF &amp;&amp; cd WEB-INFvim web.xml 123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xmlns:web=&quot;http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd&quot; id=&quot;WebApp_ID&quot; version=&quot;2.5&quot;&gt;&lt;display-name&gt;db&lt;/display-name&gt;&lt;welcome-file-list&gt;&lt;welcome-file&gt;index.html&lt;/welcome-file&gt;&lt;welcome-file&gt;index.htm&lt;/welcome-file&gt;&lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt;&lt;welcome-file&gt;default.html&lt;/welcome-file&gt;&lt;welcome-file&gt;default.htm&lt;/welcome-file&gt;&lt;welcome-file&gt;default.jsp&lt;/welcome-file&gt;&lt;/welcome-file-list&gt;&lt;/web-app&gt; 1vim ../index.hsp 123456789101112131415&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;title&gt;cqm's tomcat&lt;/title&gt;&lt;/head&gt;&lt;body&gt;this is cqm's tomcat web!!!&lt;br/&gt;&lt;%System.out.println(&quot;-----this is cqm's tomcat web logs-----&quot;);%&gt;&lt;/body&gt;&lt;/html&gt; æŸ¥çœ‹é¡¹ç›®æ˜¯å¦éƒ¨ç½²æˆåŠŸ 4.4 ä¸Šä¼ è‡ªå®šä¹‰é•œåƒåˆ°Docker Hub12345671.ç™»å½•dockerè´¦å·docker login -u dockerç”¨æˆ·å...Login Succeeded#é€€å‡ºè´¦å·docker logout 12345671.ç™»å½•dockerè´¦å·docker login -u dockerç”¨æˆ·å...Login Succeeded#é€€å‡ºè´¦å·docker logout 122.ç»™è¦ä¸Šä¼ çš„é•œåƒæ·»åŠ æ ‡ç­¾docker tag é•œåƒid dockerç”¨æˆ·å/é•œåƒåç§°:ç‰ˆæœ¬å· 123.ä¸Šä¼ é•œåƒåˆ°Docker Hubdocker push é•œåƒid dockerç”¨æˆ·å/é•œåƒåç§°:ç‰ˆæœ¬å· äº”. Dockerç½‘ç»œDockerä½¿ç”¨æ¡¥æ¥æ¨¡å¼åœ¨Linuxä¸»æœºä¸Šæ·»åŠ ä¸€ä¸ªdocker0çš„ç½‘å¡ï¼Œè€ŒDockeræ¯å¯åŠ¨ä¸€ä¸ªå®¹å™¨å°±ä¼šæ·»åŠ ä¸€ä¸ªæ–°çš„ç½‘å¡ï¼Œä½¿ç”¨çš„æ˜¯evth-pairæŠ€æœ¯ã€‚evth-pairå°±æ˜¯ä¸€å¯¹è™šæ‹Ÿè®¾å¤‡æ¥å£ï¼Œæ·»åŠ çš„ç½‘å¡éƒ½æ˜¯æˆå¯¹å‡ºç°çš„ï¼Œä¸€æ®µè¿æ¥é•œåƒï¼Œä¸€æ®µè¿æ¥docker0ï¼Œæ‰€ä»¥evth-pairå°±æ˜¯ä¸€åº§æ¡¥æ¢ï¼Œç”¨æ¥è¿æ¥å„ç§è™šæ‹Ÿç½‘ç»œè®¾å¤‡ã€‚ åˆ©ç”¨ip addræ¥æŸ¥çœ‹Linuxä¸»æœºçš„ç½‘å¡æƒ…å†µï¼Œå¯ä»¥çœ‹åˆ°docker0ç½‘å¡ æˆ‘ä»¬æ‹‰å–ä¸€ä¸ªé•œåƒï¼Œå¹¶å¯åŠ¨ æˆ‘ä»¬åœ¨ä½¿ç”¨ip addrå¯ä»¥çœ‹åˆ°å‡ºç°äº†å¯¹æ–°çš„ç½‘å¡ è¿›å…¥å®¹å™¨å†…éƒ¨æŸ¥çœ‹ç½‘å¡å¯ä»¥çœ‹åˆ°æ˜¯å¯¹åº”çš„ ç”±æ­¤å¯çŸ¥dockerç½‘ç»œçš„æ¶æ„ 5.1åˆ›å»ºè‡ªå®šä¹‰ç½‘ç»œ åˆ›å»ºè‡ªå®šä¹‰ç½‘ç»œ 1234docker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 cqmnet--driver:ç½‘ç»œç±»å‹ï¼Œbridgeä¸ºæ¡¥æ¥--subnet:é…ç½®å­ç½‘--gateway:é…ç½®ç½‘å…³åœ°å€ å¯åŠ¨ä¸¤ä¸ªtomcatå®¹å™¨å¹¶æŒ‡å®šè‡ªå®šä¹‰ç½‘ç»œ 12docker run -d -p 8081:8080 --net cqmnet --name tomcat01 é•œåƒiddocker run -d -p 8082:8080 --net cqmnet --name tomcat02 é•œåƒid æµ‹è¯•ä¸¤ä¸ªå®¹å™¨ä¹‹é—´æ˜¯å¦è¿é€š 5.2 å®ç°docker0å’Œè‡ªå®šä¹‰ç½‘ç»œä¹‹é—´çš„è¿é€š åˆ›å»ºä¸¤ä¸ªdocker0ç½‘æ®µçš„å®¹å™¨ 12docker run -d -p 8083:8080 --name tomcat03 é•œåƒiddocker run -d -p 8084:8080 --name tomcat04 é•œåƒid åˆ©ç”¨coonnectè¿›è¡Œè¿é€š 1docker network connect cqmnet tomcat03 è¿™æ—¶å€™å†çœ‹è‡ªå®šä¹‰ç½‘ç»œçš„ä¿¡æ¯ï¼Œå¯ä»¥çœ‹åˆ°tomcat03è¢«æ·»åŠ è¿›æ¥äº† æµ‹è¯• ç»“è®ºï¼Œç”±æ­¤å¯çŸ¥ï¼Œconnectæ˜¯å°†ä¸€ä¸ªç½‘ç»œä¸­çš„å®¹å™¨æ·»åŠ åˆ°å¦ä¸€ä¸ªç½‘ç»œä¸­ï¼Œé€šä¿—æ¥è®²å°±æ˜¯è¯¥å®¹å™¨åŒæ—¶æ‹¥æœ‰ä¸¤ä¸ªç½‘ç»œçš„åœ°å€ï¼Œå°±å®ç°äº†ä¸¤ä¸ªç½‘ç»œä¹‹é—´çš„äº’é€šã€‚ 5.3 ä¸åŒä¸»æœºä¹‹é—´å®¹å™¨çš„äº’è”æ–¹æ³•ä¸€ï¼šé™æ€è·¯ç”± é™æ€è·¯ç”±æ–¹æ³•åŸç†å°±æ˜¯å°†å®¹å™¨çš„è¯·æ±‚è½¬å‘åˆ°æŒ‡å®šçš„ä¸»æœºä¸Šï¼Œå†ç”±ä¸»æœºè½¬å‘ç»™å®¹å™¨ã€‚ ä¿®æ”¹ daemon.json æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼Œä½¿ä¹‹æ¯ä¸ªä¸»æœºçš„ docker é»˜è®¤ç½‘æ®µä¸åŒ 1234# ä¸»æœºä¸€&quot;bip&quot;: &quot;172.17.1.10/24&quot;# ä¸»æœºäºŒ&quot;bip&quot;: &quot;172.17.2.10/24&quot; æ·»åŠ è·¯ç”±è§„åˆ™ 1234# ä¸»æœºä¸€ï¼Œç½‘å…³ä¸ºä¸»æœºäºŒçš„IPåœ°å€ï¼Œå³è®¿é—®172.17.2.0ç½‘æ®µçš„æ•°æ®åŒ…éƒ½ä¼šè¢«è½¬å‘åˆ°ä¸»æœºäºŒä¸Šroute add -net 172.17.2.0 netmask 255.255.255.0 gw 192.168.88.130# ä¸»æœºäºŒroute add -net 172.17.1.0 netmask 255.255.255.0 gw 192.168.88.135 æ–¹æ³•äºŒï¼šMacvlan Macvlan åŸç†æ˜¯å°†ä¸€å¼ ç‰©ç†ç½‘å¡è™šæ‹Ÿæˆå¤šå—è™šæ‹Ÿç½‘å¡çš„æŠ€æœ¯ï¼Œä½¿å¾—è™šæ‹Ÿç½‘å¡ä¸ç‰©ç†ç½‘å¡çš„å‚æ•°ç­‰éƒ½ç›¸åŒã€‚ å¼€å¯ç½‘å¡çš„æ··æ‚æ¨¡å¼ 1ip link set ens33 promisc [on/off] / ifconfig ens33 [-]promisc åˆ›å»º Macvlan ç½‘ç»œ 12# å­ç½‘å’Œç½‘å…³å‡å’Œä¸»æœºä¸€è‡´docker network create --driver macvlan --subnet 192.168.88.0/24 --gateway 192.168.88.1 -o parent=ens33 [network_name] åˆ›å»ºå®¹å™¨éœ€è¦æŒ‡å®šç½‘ç»œ 1docker run -d -it --name centos --net [network_name] --ip 192.168.88.10 centos:7 5.4 Overlayoverlay æ˜¯ä¸€ç§åœ¨ç½‘ç»œæ¶æ„ä¸Šè¿›è¡Œå åŠ çš„è™šæ‹ŸåŒ–æŠ€æœ¯ï¼Œå³åœ¨åŸæœ‰çš„ç½‘ç»œæ¡†æ¶ä¸Šå åŠ ä¸€å±‚è™šæ‹Ÿç½‘ç»œï¼Œä»è€Œå®ç°åº”ç”¨åœ¨è™šæ‹Ÿç½‘ç»œä¸Šæ‰¿è½½ï¼Œä»¥åŠä¸å…¶å®ƒç½‘ç»œä¸šåŠ¡åˆ†ç¦»ã€‚ åœ¨è¿™ä¸ªoverlayç½‘ç»œæ¨¡å¼é‡Œé¢ï¼Œæœ‰ä¸€ä¸ªç±»ä¼¼äºæœåŠ¡ç½‘å…³çš„åœ°å€ï¼Œç„¶åæŠŠè¿™ä¸ªåŒ…è½¬å‘åˆ°ç‰©ç†æœåŠ¡å™¨è¿™ä¸ªåœ°å€ï¼Œæœ€ç»ˆé€šè¿‡è·¯ç”±å’Œäº¤æ¢ï¼Œåˆ°è¾¾å¦ä¸€ä¸ªæœåŠ¡å™¨çš„ipåœ°å€ã€‚ å®ç° overlay ç½‘ç»œéœ€è¦æœ‰æ³¨å†Œå‘ç°ä¸­å¿ƒçš„é”®å€¼æ•°æ®åº“æ”¯æŒï¼Œå¯ä»¥ç”¨ consulã€etcdã€zookeeper ç­‰ã€‚ åŒºåˆ«ï¼š consulï¼šæœåŠ¡å‘ç°/å…¨å±€çš„åˆ†å¸ƒå¼ key-value å­˜å‚¨ã€‚è‡ªå¸¦ DNS æŸ¥è¯¢æœåŠ¡ï¼Œå¯ä»¥è·¨æ•°æ®ä¸­å¿ƒã€‚æä¾›èŠ‚ç‚¹çš„å¥åº·æ£€æŸ¥ï¼Œå¯ä»¥å®ç°åŠ¨æ€çš„ consul èŠ‚ç‚¹å¢å‡ï¼Œdocker å®˜æ–¹çš„ç”¨ä¾‹æ¨èã€‚ etcdï¼šæœåŠ¡å‘ç°/å…¨å±€çš„åˆ†å¸ƒå¼ key-value å­˜å‚¨ã€‚é™æ€çš„æœåŠ¡å‘ç°ï¼Œå¦‚æœå®ç°åŠ¨æ€çš„æ–°å¢etcdèŠ‚ç‚¹ï¼Œéœ€è¦ä¾èµ–ç¬¬ä¸‰æ–¹ç»„ä»¶ã€‚ 5.4.1 consulconsul ç”¨äºå¾®æœåŠ¡ä¸‹çš„æœåŠ¡æ²»ç†ï¼Œä¸»è¦ç‰¹ç‚¹æœ‰ï¼šæœåŠ¡å‘ç°ã€æœåŠ¡é…ç½®ã€å¥åº·æ£€æŸ¥ã€é”®å€¼å­˜å‚¨ã€å®‰å…¨æœåŠ¡é€šä¿¡ã€å¤šæ•°æ®ä¸­å¿ƒç­‰ã€‚ æ³¨æ„ï¼šoverlay æ‰€éœ€å†…æ ¸ç‰ˆæœ¬ä¸º 3.18+ å®‰è£… consul 12curl -O https://releases.hashicorp.com/consul/1.10.3/consul_1.10.3_linux_amd64.zipunzip consul_1.10.3_linux_amd64.zip å‡†å¤‡ config.json æ–‡ä»¶ 123456789101112131415{ &quot;advertise_addr&quot;: &quot;192.168.88.130&quot;, # æ›´æ”¹æˆ‘ä»¬å‘ç¾¤é›†ä¸­å…¶ä»–èŠ‚ç‚¹é€šå‘Šçš„åœ°å€ &quot;bind_addr&quot;: &quot;192.168.88.130&quot;, # å†…éƒ¨ç¾¤é›†é€šä¿¡ç»‘å®šçš„åœ°å€ï¼Œè¿™æ˜¯ç¾¤é›†ä¸­æ‰€æœ‰å…¶ä»–èŠ‚ç‚¹éƒ½åº”è¯¥å¯ä»¥è®¿é—®çš„IPåœ°å€ &quot;data_dir&quot;: &quot;/opt/consul&quot;, # æ•°æ®å­˜æ”¾ç›®å½• &quot;server&quot;: true, # æ˜¯å¦æ˜¯server agentèŠ‚ç‚¹ &quot;node_name&quot;: &quot;server1&quot;, # èŠ‚ç‚¹åç§° &quot;enable_syslog&quot;: true, &quot;enable_debug&quot;: true, &quot;log_level&quot;: &quot;info&quot;, # æ—¥å¿—çº§åˆ« &quot;bootstrap_expect&quot;: 3, # æä¾›æ•°æ®ä¸­å¿ƒä¸­é¢„æœŸæœåŠ¡å™¨çš„æ•°é‡ï¼Œå³éœ€è¦3å°consul server agent &quot;start_join&quot;: [&quot;192.168.88.130&quot;, &quot;192.168.88.135&quot;, &quot;192.168.88.100&quot;], # å¯åŠ¨æ—¶æŒ‡å®šèŠ‚ç‚¹åœ°å€çš„å­—ç¬¦ä¸²æ•°ç»„ï¼ŒæŒ‡å®šæ˜¯å…¶ä»–çš„consul server agentçš„åœ°å€ &quot;retry_join&quot;: [&quot;192.168.88.130&quot;, &quot;192.168.88.135&quot;, &quot;192.168.88.100&quot;], # å…è®¸start_joinæ—¶å¤±è´¥æ—¶ï¼Œç»§ç»­é‡æ–°è¿æ¥ &quot;ui&quot;: true, # å¯åŠ¨uiç•Œé¢ &quot;client_addr&quot;: &quot;0.0.0.0&quot; # Consulå°†ç»‘å®šå®¢æˆ·ç«¯æ¥å£çš„åœ°å€ï¼ŒåŒ…æ‹¬HTTPå’ŒDNSæœåŠ¡å™¨} å¯åŠ¨ consul æŸ¥çœ‹çŠ¶æ€ 12345./consul agent -config-dir ./config.json# æŸ¥çœ‹é›†ç¾¤çŠ¶æ€./consul members# æŸ¥çœ‹leader./consul operator raft list-peers è®¿é—® consul ui é…ç½® docker/daemon.json 123# è™½ç„¶æ˜¯consulé›†ç¾¤ï¼Œä½†åªèƒ½å¡«å†™ä¸€ä¸ªconsulèŠ‚ç‚¹çš„ä¿¡æ¯&quot;cluster-store&quot;: &quot;consul://192.168.88.130:8500&quot;,&quot;cluster-advertise&quot;: &quot;192.168.88.130:2376&quot; åˆ›å»º docker ç½‘ç»œï¼Œå»åˆ°å…¶å®ƒä¸»æœºæŸ¥çœ‹ docker ç½‘ç»œå¯ä»¥çœ‹åˆ°æ˜¯å·²ç»åŒæ­¥çš„ 1docker network create --driver overlay consulnet åœ¨ä¸åŒçš„ä¸»æœºåˆ›å»ºå®¹å™¨æµ‹è¯•æ˜¯å¦èƒ½å¤Ÿäº’è” 1docker run -d --name centos1 --network consulnet centos:7 åœ¨å®¹å™¨å†…éƒ¨å¯ä»¥çœ‹åˆ°æœ‰ä¸¤å¼ ç½‘å¡ï¼Œeth0 æ˜¯ overlay åˆ›å»ºçš„ï¼Œå³ä¸€ä¸ª vxlanï¼›eth1 åˆ™æ˜¯æœåŠ¡ç½‘å…³çš„ç½‘å¡ 5.4.2 etcdetcd æ˜¯ä¸€ä¸ªé«˜å¯ä»¥çš„é”®å€¼å­˜å‚¨ç³»ç»Ÿï¼Œä¸»è¦ç”¨äºåˆ†äº«é…ç½®å’ŒæœåŠ¡å‘ç°ã€‚ å®‰è£… etcd 1234567891011ETCD_VER=v3.5.1GITHUB_URL=https://github.com/etcd-io/etcd/releases/downloadDOWNLOAD_URL=${GOOGLE_URL}curl -L ${DOWNLOAD_URL}/${ETCD_VER}/etcd-${ETCD_VER}-linux-amd64.tar.gz -o /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gztar -zvxf /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz -C /tmp/etcd-download-test --strip-components=1rm -f /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz/tmp/etcd-download-test/etcd --version/tmp/etcd-download-test/etcdctl version/tmp/etcd-download-test/etcdutl version å¯åŠ¨ etcd 12345678910111213141516HOST=192.168.88.130CLUSTER_IPS=(192.168.88.130 192.168.88.135 192.168.88.136)ETCD_DATADIR=/root/etcd/datanohup ./etcd -name node1 \\ -initial-advertise-peer-urls http://$HOST:2380 \\ -listen-peer-urls http://$HOST:2380 \\ -listen-client-urls http://$HOST:2379,http://127.0.0.1:2379 \\ -advertise-client-urls http://$HOST:2379 \\ -initial-cluster-token etcd-cluster \\ -initial-cluster node1=http://${CLUSTER_IPS[0]}:2380,node2=http://${CLUSTER_IPS[1]}:2380,node3=http://${CLUSTER_IPS[2]}:2380 \\ -initial-cluster-state new \\ -data-dir $ETCD_DATADIR &amp;# listen-peer-urls:èŠ‚ç‚¹ä¸èŠ‚ç‚¹ä¹‹é—´æ•°æ®äº¤æ¢, å› æ­¤éœ€è¦ç›‘å¬åœ¨å…¶ä»–èŠ‚ç‚¹å¯ä»¥è®¿é—®çš„IPåœ°å€ä¸Šï¼Œé»˜è®¤ç«¯å£2380# listen-client-urls:ç”¨æˆ·å®¢æˆ·æœºè®¿é—®etcdæ•°æ®, ä¸€èˆ¬ç›‘å¬åœ¨æœ¬åœ°, å¦‚æœéœ€è¦é›†ä¸­ç®¡ç†, å¯ä»¥ç›‘å¬åœ¨ç®¡ç†æœåŠ¡å™¨å¯ä»¥è®¿é—®çš„IPåœ°å€ä¸Šï¼Œé»˜è®¤ç«¯å£2379# initial-advertise-peer-urls:è¡¨ç¤ºèŠ‚ç‚¹ç›‘å¬å…¶ä»–èŠ‚ç‚¹åŒæ­¥ä¿¡å·çš„åœ°å€ï¼Œé»˜è®¤ç«¯å£2380# advertise-client-urls:åœ¨åŠ å…¥proxyèŠ‚ç‚¹å, ä¼šä½¿ç”¨è¯¥å¹¿æ’­åœ°å€, å› æ­¤éœ€è¦ç›‘å¬åœ¨ä¸€ä¸ªproxyèŠ‚ç‚¹å¯ä»¥è®¿é—®çš„IPåœ°å€ä¸Šï¼Œé»˜è®¤ç«¯å£2379 æŸ¥çœ‹ etcd é›†ç¾¤ä¿¡æ¯å’Œå¥åº·çŠ¶æ€ 12./etcdctl member list./etcdctl cluster-health ä¿®æ”¹ docker/daemon.json 12&quot;cluster-store&quot;: &quot;etcd://192.168.88.130:2379&quot;,&quot;cluster-advertise&quot;: &quot;192.168.88.130:2376&quot; æŸ¥çœ‹æ˜¯å¦æ³¨å†Œåˆ° etcd 12./etcdctl ls //docker åˆ›å»º docker ç½‘ç»œ 1docker network create --driver overlay etcdnet åˆ›å»ºå®¹å™¨æµ‹è¯•æ˜¯å¦äº’é€š 1docker run -d -it --name centos1 --network etcdnet centos:7 5.5 Flannelä¸Calicoåœ¨ Kubernetes ä¸­ï¼Œä½¿ç”¨çš„ç½‘ç»œç»„ä»¶ä¸»è¦ä¸º Flannel å’Œ Calico ä¸¤ç§ï¼Œéƒ½å¯ä»¥å®ç°ä¸åŒä¸»æœºä¹‹é—´å®¹å™¨çš„é€šä¿¡ï¼Œä½¿ç”¨å‰ææ˜¯è¦æœ‰ etcdã€‚ 5.5.1 FlannelFlannel ç½‘ç»œæ¶æ„å¦‚ä¸‹ æ·»åŠ ç½‘ç»œé…ç½®åˆ° etcd 123# Network:flannelç½‘æ®µ# Type:ç½‘ç»œç±»å‹./etcdctl set /coreos.com/network/config '{ &quot;Network&quot;: &quot;10.0.0.0/24&quot;, &quot;Backend&quot;: {&quot;Type&quot;: &quot;vxlan&quot;} }' å®‰è£… Flannel 1curl -O https://github.com/flannel-io/flannel/releases/download/v0.15.0/flannel-v0.15.0-linux-amd64.tar.gz å¯åŠ¨ Flannelï¼Œä¼šç”Ÿæˆ /run/flannel/subnet.envï¼Œè·¯ç”±è¡¨ä¹Ÿä¼šåŠ ä¸Šæ–°è§„åˆ™ 12# -etcd-endpoints:etcdåœ°å€./flanneld -etcd-endpoints &quot;http://192.168.88.30:2379&quot; ç”Ÿæˆ docker å‚æ•°ä¿¡æ¯ 1./mk-docker-opts.sh -d /root/etcd/docker -c ä¿®æ”¹ /usr/lib/systemd/system/docker.service 12345vim /usr/lib/systemd/system/docker.service# æ·»åŠ EnvironmentFile=/root/etcd/docker# åœ¨ExecStartååŠ ä¸ŠExecStart=/usr/bin/dockerd $DOCKER_OPTS é‡å¯ docker åæµ‹è¯•å®¹å™¨æ˜¯å¦èƒ½å¤Ÿäº’è” 5.5.2 CalicoCalico æ˜¯ç›®å‰ä¼ä¸šåœ¨ k8s é›†ç¾¤ä¸Šä½¿ç”¨çš„æœ€å¤šçš„å®¹å™¨äº’é€šç½‘ç»œæ–¹æ¡ˆï¼Œæ¯”èµ· Flannel èƒ½å¤Ÿå®ç°æ›´è¿‡å¤æ‚çš„éœ€æ±‚ã€‚ Calico æ˜¯ä¸€ç§çº¯ä¸‰å±‚çš„è§£å†³æ–¹æ¡ˆï¼Œå› æ­¤é¿å…äº†ä¸äºŒå±‚æ–¹æ¡ˆç›¸å…³çš„æ•°æ®åŒ…å°è£…æ“ä½œï¼Œä¸­é—´æ²¡æœ‰ä»»ä½• NAT å’Œ overlayï¼Œç›´æ¥èµ° TCP/IP åè®®æ ˆï¼Œé€šè¿‡ iptables å®ç°å¤æ‚çš„ç½‘ç»œè§„åˆ™ã€‚ Calico ç»„ä»¶å¦‚ä¸‹ï¼š Felixï¼šè¿è¡Œåœ¨æ¯ä¸€å°ä¸»æœºä¸­ï¼Œä¸»è¦è´Ÿè´£ç½‘ç»œæ¥å£ç®¡ç†å’Œç›‘å¬ã€è·¯ç”±ã€ARP ç®¡ç†ã€ACL ç®¡ç†å’ŒåŒæ­¥ã€çŠ¶æ€ä¸ŠæŠ¥ç­‰ã€‚ etcdï¼šåˆ†å¸ƒå¼é”®å€¼å­˜å‚¨ï¼Œä¿è¯ç½‘ç»œæ•°æ®çš„ä¸€è‡´æ€§ã€‚ BIDRï¼ˆBGP Clientï¼‰ï¼šæ¯ä¸€ä¸ªä¸»æœºéƒ½ä¼šæœ‰ä¸ª BIDRï¼Œç”¨æ¥å®ç°ä¸åŒçš„è·¯ç”±åè®®ï¼ŒCalico ç›‘å¬ä¸»æœºä¸Š Felix æ³¨å…¥çš„ä¿¡æ¯ï¼Œç„¶åé€šè¿‡ BGP åè®®å‘Šè¯‰å…¶å®ƒèŠ‚ç‚¹ï¼Œä»è€Œå®ç°äº’è”ã€‚ BGP Route Reflectorï¼šç”¨äºè§£å†³ç½‘ç»œè§„æ¨¡è¿‡å¤§çš„ç»„ä»¶ã€‚ Calico å·¥ä½œæ¨¡å¼ï¼š IPIPï¼šå°† IP æ•°æ®åŒ…å†æ¬¡å°è£…åˆ°ä¸€ä¸ª IP åŒ…é‡Œï¼Œç›¸å½“äºä¸€ä¸ªåŸºäºç½‘ç»œå±‚çš„ç½‘æ¡¥ï¼Œæ™®é€šçš„ç½‘æ¡¥æ˜¯åŸºäº Mac åœ°å€çš„ï¼Œè€Œ IPIP èƒ½å°†ä¸¤ç«¯çš„è·¯ç”±åšæˆä¸€ä¸ª tunnelï¼Œå°†å…¶è¿æ¥ã€‚ BGPï¼šå³è¾¹ç•Œç½‘å…³åè®®ã€‚ åœ¨æ‰€æœ‰ä¸»æœºä¸Šä¸‹è½½ Calico Controller 1curl -o calicoctl -O -L &quot;https://github.com/projectcalico/calicoctl/releases/download/v3.21.0/calicoctl&quot; é…ç½® calicoctl.cfg 12345apiVersion: projectcalico.org/v3kind: CalicoAPIConfigmetadata:spec: etcdEndpoints: http://192.168.88.30:2379 åˆå§‹åŒ– Calico 12# ip:å®¿ä¸»æœºip./calicoctl node run --ip=192.168.88.30 -c ./calicoctl.cfg æŸ¥çœ‹ Calico çŠ¶æ€ 1./calicoctl node status ç”±äºæ–°ç‰ˆæœ¬çš„ Calico ä¸å†æ”¯æŒ docker å•ç‹¬ä½¿ç”¨ï¼Œä½†é€šè¿‡æ’ä»¶å¯ä»¥å®ç° 1234git clone https://github.com/projectcalico/libnetwork-plugin.gitcd libnetwork-plugin# ä¸‹è½½æ’ä»¶é•œåƒmake image è¿è¡Œ libnetwork å®¹å™¨ 1docker run -d --privileged --name calico-docker-network-plugin --net host --restart always -v /run/docker/plugins:/run/docker/plugins -e ETCD_ENDPOINTS=http://192.168.88.30:2379 calico/libnetwork-plugin åˆ›å»º ippool 123456789101112131415# æŸ¥çœ‹calicoç›®å‰åœ°å€æ± ./calicoctl get ippools# åˆ›å»ºåœ°å€æ± yamlæ–‡ä»¶cat ip.yamlapiVersion: projectcalico.org/v3kind: IPPoolmetadata: name: ippool-testspec: cidr: 10.0.0.0/24 ipipMode: Nerver natOutgoing: true disabled: false nodeSelector: all()./calicoctl apply -f ip.yaml åˆ›å»º GlobalNetworkPolicy 12345678910apiVersion: projectcalico.org/v3kind: GlobalNetworkPolicymetadata: name: gnp-testspec: selector: all ingress: - action: Allow egress: - action: Allow åˆ›å»º docker ç½‘ç»œ 1docker create network -d calico --ipam-driver calico-ipam --subnet 10.0.0.0/24 caliconet å…³é—­ ipv6 å†…æ ¸ 1echo 1 &gt; /proc/sys/net/ipv6/conf/default/disable_ipv6 åˆ›å»ºå®¹å™¨æµ‹è¯• 1docker run -d -it --name centos1 --network caliconet centos:7 å…­. Docker-ComposeCompose æ˜¯ç”¨äºå®šä¹‰å’Œè¿è¡Œå¤šå®¹å™¨ Docker åº”ç”¨ç¨‹åºçš„å·¥å…·ã€‚é€šè¿‡ Composeï¼Œå¯ä»¥ä½¿ç”¨ YML æ–‡ä»¶æ¥é…ç½®åº”ç”¨ç¨‹åºéœ€è¦çš„æ‰€æœ‰æœåŠ¡ã€‚ç„¶åï¼Œä½¿ç”¨ä¸€ä¸ªå‘½ä»¤ï¼Œå°±å¯ä»¥ä» YML æ–‡ä»¶é…ç½®ä¸­åˆ›å»ºå¹¶å¯åŠ¨æ‰€æœ‰æœåŠ¡ã€‚ 6.1 Docker-Composeä½¿ç”¨æ­¥éª¤1231.ä½¿ç”¨ Dockerfile å®šä¹‰åº”ç”¨ç¨‹åºçš„ç¯å¢ƒ2.ä½¿ç”¨ docker-compose.yml å®šä¹‰æ„æˆåº”ç”¨ç¨‹åºçš„æœåŠ¡ï¼Œè¿™æ ·å®ƒä»¬å¯ä»¥åœ¨éš”ç¦»ç¯å¢ƒä¸­ä¸€èµ·è¿è¡Œ3.æ‰§è¡Œ docker-compose up å‘½ä»¤æ¥å¯åŠ¨å¹¶è¿è¡Œæ•´ä¸ªåº”ç”¨ç¨‹åº 6.2 å®‰è£…Docker-Compose121.ä¸‹è½½curl -L https://get.daocloud.io/docker/compose/releases/download/1.27.4/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose 122.èµ‹æƒchmod +x /usr/local/bin/docker-compose 6.3 ç¼–å†™Docker-Composeç®¡ç†MySQLå’ŒNginxå®¹å™¨123456789101112131415161718192021222324252627282930313233341.åˆ›å»ºæ•°æ®å·ç›®å½•mkdir /root/docker_mysql_nginx/docker_mysql/mysql_datamkdir /root/docker_mysql_nginx/docker_nginx/nginx_confmkdir /root/docker_mysql_nginx/docker_nginx/nginx_html2.ç¼–å†™vim /root/docker_mysql_nginx/docker-compose.ymlversion: '3.8' #æŒ‡å®šæœ¬ yml ä¾ä»çš„ compose å“ªä¸ªç‰ˆæœ¬åˆ¶å®šçš„ #å¯å‚è€ƒhttps://docs.docker.com/compose/compose-file/services: mysql: #æŒ‡å®šæœåŠ¡çš„åç§° restart: always #åªè¦dockerå¯åŠ¨ï¼Œè¿™ä¸ªå®¹å™¨å°±ä¸€èµ·å¯åŠ¨ image: daocloud.io/library/mysql:5.7.4 #æŒ‡å®šé•œåƒè·¯å¾„ container_name: mysql #æŒ‡å®šå®¹å™¨åç§° ports: - 3306:3306 #æŒ‡å®šç«¯å£å·çš„æ˜ å°„ environment: MYSQL_ROOT_PASSWORD: toortoor #æŒ‡å®šmysqlçš„rootç”¨æˆ·ç™»å½•å¯†ç  TZ: Asia/Shanghai #æŒ‡å®šæ—¶åŒº volumes: - /root/docker_mysql_nginx/docker_mysql/mysql_data:/var/lib/mysql #æ˜ å°„æ•°æ®å· nginx: restart: always image: daocloud.io/library/nginx:1.18.0 container_name: nginx ports: - 80:80 environment: TZ: Asia/Shanghai volumes: - /root/docker_mysql_nginx/docker_nginx/nginx_conf:/etc/nginx - /root/docker_mysql_nginx/docker_nginx/nginx_html:/usr/share/nginx/html 6.4 ä½¿ç”¨Docker-Composeå‘½ä»¤åœ¨ä½¿ç”¨Docker-Composeå‘½ä»¤æ—¶ï¼Œç³»ç»Ÿä¼šåœ¨å½“å‰ç›®å½•ä¸‹å¯»æ‰¾ymlæ–‡ä»¶ 1231.åº”ç”¨Docker-Composeå¯åŠ¨å®¹å™¨docker-compose up -d-d:åœ¨åå°è¿è¡Œå®¹å™¨ 122.å…³é—­å¹¶åˆ é™¤å®¹å™¨docker-compose down 123.å¼€å¯|å…³é—­|é‡å¯å·²ç”±docker-composeç®¡ç†çš„å®¹å™¨docker-compose start | stop | restart 124.æŸ¥çœ‹ç”±docker-composeç®¡ç†çš„å®¹å™¨docker-compose ps 1235.æŸ¥çœ‹docker-composeæ—¥å¿—docker-compose logs -f-f:å¯ä»¥æ»šåŠ¨æŸ¥çœ‹ 6.5 Docker-Composeé…åˆDockerfileä½¿ç”¨docker-compose.yml 123456789101112version: '3.8'services: nginx: build: context: ./ #æŒ‡å®šåœ¨å½“å‰ç›®å½•ä¸‹å¯»æ‰¾dockerfile dockerfile: Dockerfile #æŒ‡å®šdockerfileæ–‡ä»¶å image: nginx:1.18.0 #ä½¿ç”¨ä¸Šè¾¹åˆ¶ä½œå¥½çš„é•œåƒ container_name: nginx ports: - 8080:80 environment: TZ: Asia/Shanghai Dockerfile 12from daocloud.io/library/nginx:1.18.0copy test.html /usr/share/nginx/html/test.html é‡åˆ°çš„é”™è¯¯ 12345678910111.ERROR: yaml.scanner.ScannerError: while scanning for the next tokenfound character '\\t' that cannot start any token#æ˜¯å› ä¸ºymlæ–‡ä»¶é‡Œä½¿ç”¨äº†tabï¼Œymlæ–‡ä»¶æ ¼å¼ä¸å…è®¸ä½¿ç”¨ï¼Œå…¨éƒ¨æ¢æˆç©ºæ ¼2.WARNING: Image for service nginx was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.#æ˜¯å› ä¸ºè¿è¡Œdocker-composeæ—¶è‡ªå®šä¹‰é•œåƒä¸å­˜åœ¨ï¼Œä¼šå¸®åŠ©ç”Ÿæˆè‡ªå®šä¹‰é•œåƒ#æä¾›ä¸¤ç§æ„å»ºæ–¹æ³•ï¼š#docker-compose build#docker-compose up --build 6.6 Docker-Composeéƒ¨ç½²wordpress ç¼–å†™docker-compose.yml 1234567891011121314151617181920212223242526272829version: '3.8'services: db: container_name: mysql image: daocloud.io/library/mysql:latest volumes: - db_data:/var/lib/mysql restart: always ports: - 3306:3306 environment: MYSQL_ROOT_PASSWORD: toortoor MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: toortoor wordpress: container_name: wordpress image: wordpress:latest ports: - 80:80 restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: toortoor WORDPRESS_DB_NAME: wordpressvolumes: db_data: {} å¯åŠ¨ 1docker-compose up -d","link":"/2024/02/18/docker/"},{"title":"RKE1 éƒ¨ç½²éšè®°","text":"éƒ¨ç½² RKE1 å‰æœŸå‡†å¤‡ 1234567# RKE1 äºŒè¿›åˆ¶curl -LO &quot;https://github.com/rancher/rke/releases/download/v1.5.12/rke_linux-amd64&quot;mv rke_linux-amd64 /usr/local/bin/rke &amp;&amp; chmod +x /usr/local/bin/rke# å„èŠ‚ç‚¹å®‰è£… Dockercurl https://releases.rancher.com/install-docker/20.10.sh | sh ç”Ÿæˆé…ç½® 1234567891011121314151617181920212223242526272829303132333435cat &lt;&lt;EOF &gt; cluster.yml# æ—§ç‰ˆæœ¬ rke1 ç§é’¥ç±»å‹ä¸æ”¯æŒ rsaï¼Œéœ€è¦é€‰æ‹© ed25519ssh_key_path: /root/.ssh/id_ed25519nodes: - address: 172.16.0.106 hostname_override: rke1-server-0 internal_address: 172.16.0.106 user: root role: - controlplane - etcd - worker - address: 172.16.0.105 hostname_override: rke1-server-1 internal_address: 172.16.0.105 user: root role: - controlplane - etcd - worker - address: 172.16.0.104 hostname_override: rke1-server-2 internal_address: 172.16.0.104 user: root role: - controlplane - etcd - workerprivate_registries: - url: registry.cn-hangzhou.aliyuncs.com is_default: truekubernetes_version: &quot;v1.20.15-rancher2-2&quot;network: plugin: calicoEOF å®‰è£… RKE1 1rke up --config cluster.yml æ–¹ä¾¿åç»­è¿ç»´é…ç½® 123456789101112131415161718192021222324docker cp kube-apiserver:usr/local/bin/kubectl /usr/local/bin/kubectlecho &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrcmkdir ~/.kubemv kube_config_cluster.yml ~/.kube/config# https://www.suse.com/support/kb/doc/?id=000020018# Rancher 2.7.14+/Rancher 2.8.5+, RKE 1.4.19+/RKE 1.5.10+kubectl --kubeconfig $(docker inspect kubelet --format '{{ range .Mounts }}{{ if eq .Destination &quot;/etc/kubernetes&quot; }}{{ .Source }}{{ end }}{{ end }}')/ssl/kubecfg-kube-node.yaml get secrets -n kube-system full-cluster-state -o json | jq -r .data.\\&quot;full-cluster-state\\&quot; | base64 -d | jq -r .currentState.certificatesBundle.\\&quot;kube-admin\\&quot;.config | sed -e &quot;/^[[:space:]]*server:/ s_:.*_: \\&quot;https://127.0.0.1:6443\\&quot;_&quot; &gt; ~/.kube/config# Without jq commanddocker run --rm --net=host -v $(docker inspect kubelet --format '{{ range .Mounts }}{{ if eq .Destination &quot;/etc/kubernetes&quot; }}{{ .Source }}{{ end }}{{ end }}')/ssl:/etc/kubernetes/ssl:ro --entrypoint bash $(docker inspect $(docker images -q --filter=label=org.opencontainers.image.source=https://github.com/rancher/hyperkube) --format='{{index .RepoTags 0}}' | tail -1) -c 'kubectl --kubeconfig /etc/kubernetes/ssl/kubecfg-kube-node.yaml get secret -n kube-system full-cluster-state -o json | jq -r .data.\\&quot;full-cluster-state\\&quot; | base64 -d | jq -r .currentState.certificatesBundle.\\&quot;kube-admin\\&quot;.config | sed -e &quot;/^[[:space:]]*server:/ s_:.*_: \\&quot;https://127.0.0.1:6443\\&quot;_&quot;' &gt; ~/.kube/config# Earlier versions of Rancher and RKEkubectl --kubeconfig $(docker inspect kubelet --format '{{ range .Mounts }}{{ if eq .Destination &quot;/etc/kubernetes&quot; }}{{ .Source }}{{ end }}{{ end }}')/ssl/kubecfg-kube-node.yaml get configmap -n kube-system full-cluster-state -o json | jq -r .data.\\&quot;full-cluster-state\\&quot; | jq -r .currentState.certificatesBundle.\\&quot;kube-admin\\&quot;.config | sed -e &quot;/^[[:space:]]*server:/ s_:.*_: \\&quot;https://127.0.0.1:6443\\&quot;_&quot; &gt; ~/.kube/config# Without jq commanddocker run --rm --net=host -v $(docker inspect kubelet --format '{{ range .Mounts }}{{ if eq .Destination &quot;/etc/kubernetes&quot; }}{{ .Source }}{{ end }}{{ end }}')/ssl:/etc/kubernetes/ssl:ro --entrypoint bash $(docker inspect $(docker images -q --filter=label=org.opencontainers.image.source=https://github.com/rancher/hyperkube.git) --format='{{index .RepoTags 0}}' | tail -1) -c 'kubectl --kubeconfig /etc/kubernetes/ssl/kubecfg-kube-node.yaml get configmap -n kube-system full-cluster-state -o json | jq -r .data.\\&quot;full-cluster-state\\&quot; | jq -r .currentState.certificatesBundle.\\&quot;kube-admin\\&quot;.config | sed -e &quot;/^[[:space:]]*server:/ s_:.*_: \\&quot;https://127.0.0.1:6443\\&quot;_&quot;' &gt; ~/.kube/configcurl https://rancher-mirror.rancher.cn/helm/get-helm-3.sh | INSTALL_HELM_MIRROR=cn bash -s -- --version v3.17.1echo &quot;source &lt;(helm completion bash)&quot; &gt;&gt; ~/.bashrc å¸¸è§é—®é¢˜å¦‚æœæ˜¯ CentOS å’Œ RHEL ç³»ç»Ÿï¼Œé»˜è®¤ä¸å…è®¸ä½¿ç”¨ root ç”¨æˆ·è¿›è¡Œå®‰è£…ï¼ŒæŠ¥é”™ä¿¡æ¯å¦‚ä¸‹ï¼š 1WARN[0000] Failed to set up SSH tunneling for host [x.x.x.x]: Canâ€™t retrieve Docker Info ï¼ŒFailed to dial to /var/run/docker.sock: ssh: rejected: administratively prohibited (open failed) éœ€è¦å‡†å¤‡å…¶ä»–ç”¨æˆ·ï¼š 1groupadd rancher &amp;&amp; useradd rancher -g rancher &amp;&amp; usermod -aG docker rancher å¦‚æœå‡ºç°ä¸‹é¢é”™è¯¯ï¼Œæ˜¯ç”±äºæŒ‡å®šçš„ ssh_key_path æ–‡ä»¶å¯¹åº”çš„ä¸»æœºä¸æ­£ç¡®æˆ–å¯¹åº”çš„ç”¨æˆ·åä¸æ­£ç¡®ï¼Œå¯ä»¥æ£€æŸ¥ä¸‹èŠ‚ç‚¹å¯¹åº”ç”¨æˆ·çš„ ~/.ssh/authorized_keys æ–‡ä»¶æ˜¯å¦æ­£ç¡®ï¼š 1WARN[0000] Failed to set up SSH tunneling for host [x.x.x.x]: Can't retrieve Docker Info: error during connect: Get &quot;http://%2Fvar%2Frun%2Fdocker.sock/v1.24/info&quot;: Unable to access node with address [x.x.x.x:22] using SSH. Please check if you are able to SSH to the node using the specified SSH Private Key and if you have configured the correct SSH username. Error: ssh: handshake failed: ssh: unable to authenticate, attempted methods [none publickey], no supported methods remain å¦‚æœå‡ºç°ä¸‹é¢é”™è¯¯ï¼š 1WARN[0000] Failed to set up SSH tunneling for host [x.x.x.x]: Can't retrieve Docker Info: error during connect: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.24/info: Unable to access the service on /var/run/docker.sock. The service might be still starting up. Error: ssh: rejected: connect failed (open failed) éœ€è¦åœ¨ /etc/ssh/sshd_config æ–‡ä»¶ä¸­æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š 1AllowTcpForwarding yes æ¸…ç† iptables è§„åˆ™1234567iptables -F \\ &amp;&amp; iptables -X \\ &amp;&amp; iptables -Z \\ &amp;&amp; iptables -F -t nat \\ &amp;&amp; iptables -X -t nat \\ &amp;&amp; iptables -Z -t nat \\ &amp;&amp; docker restart kube-proxy æ¸…ç†èŠ‚ç‚¹123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116#!/bin/bashKUBE_SVC='kubeletkube-schedulerkube-proxykube-controller-managerkube-apiserver'for kube_svc in ${KUBE_SVC};do # åœæ­¢æœåŠ¡ if [[ `systemctl is-active ${kube_svc}` == 'active' ]]; then systemctl stop ${kube_svc} fi # ç¦æ­¢æœåŠ¡å¼€æœºå¯åŠ¨ if [[ `systemctl is-enabled ${kube_svc}` == 'enabled' ]]; then systemctl disable ${kube_svc} fidone# åœæ­¢æ‰€æœ‰å®¹å™¨docker stop $(docker ps -aq)# åˆ é™¤æ‰€æœ‰å®¹å™¨docker rm -f $(docker ps -qa)# åˆ é™¤æ‰€æœ‰å®¹å™¨å·docker volume rm $(docker volume ls -q)# å¸è½½mountç›®å½•for mount in $(mount | grep tmpfs | grep '/var/lib/kubelet' | awk '{ print $3 }') /var/lib/kubelet /var/lib/rancher;do umount $mount;done# å¤‡ä»½ç›®å½•mv /etc/kubernetes /etc/kubernetes-bak-$(date +&quot;%Y%m%d%H%M&quot;)mv /var/lib/etcd /var/lib/etcd-bak-$(date +&quot;%Y%m%d%H%M&quot;)mv /var/lib/rancher /var/lib/rancher-bak-$(date +&quot;%Y%m%d%H%M&quot;)mv /opt/rke /opt/rke-bak-$(date +&quot;%Y%m%d%H%M&quot;)# åˆ é™¤æ®‹ç•™è·¯å¾„rm -rf /etc/ceph \\ /etc/cni \\ /opt/cni \\ /run/secrets/kubernetes.io \\ /run/calico \\ /run/flannel \\ /var/lib/calico \\ /var/lib/cni \\ /var/lib/kubelet \\ /var/log/containers \\ /var/log/kube-audit \\ /var/log/pods \\ /var/run/calico \\ /usr/libexec/kubernetes# æ¸…ç†ç½‘ç»œæ¥å£no_del_net_inter='lodocker0ethensbond'network_interface=`ls /sys/class/net`for net_inter in $network_interface;do if ! echo &quot;${no_del_net_inter}&quot; | grep -qE ${net_inter:0:3}; then ip link delete $net_inter fidone# æ¸…ç†æ®‹ç•™è¿›ç¨‹port_list='804436443237623792380847290991025010254'for port in $port_list;do pid=`netstat -atlnup | grep $port | awk '{print $7}' | awk -F '/' '{print $1}' | grep -v - | sort -rnk2 | uniq` if [[ -n $pid ]]; then kill -9 $pid fidonekube_pid=`ps -ef | grep -v grep | grep kube | awk '{print $2}'`if [[ -n $kube_pid ]]; then kill -9 $kube_pidfi# æ¸…ç†Iptablesè¡¨## æ³¨æ„ï¼šå¦‚æœèŠ‚ç‚¹Iptablesæœ‰ç‰¹æ®Šé…ç½®ï¼Œä»¥ä¸‹å‘½ä»¤è¯·è°¨æ…æ“ä½œsudo iptables --flushsudo iptables --flush --table natsudo iptables --flush --table filtersudo iptables --table nat --delete-chainsudo iptables --table filter --delete-chainsystemctl restart docker# é‡å¯èŠ‚ç‚¹reboot","link":"/2024/09/05/RKE1-%E9%83%A8%E7%BD%B2%E9%9A%8F%E8%AE%B0/"},{"title":"CKA","text":"è®°å½•åˆ·é¢˜- - Jobï¼šåˆ›å»ºä¸€ä¸ªå›ºå®šç»“æŸæ¬¡æ•°çš„å¹¶è¡Œ Jobï¼Œå…± 2 ä¸ª podï¼Œè¿è¡Œ 45 completionï¼ŒJob pod æ‰“å°â€œBeijingâ€ï¼Œé•œåƒè‡ªé€‰ã€‚ 12345678910111213141516171819apiVersion: batch/v1kind: Jobmetadata: name: jobspec: parallelism: 2 completions: 45 restartPolicy: Never template: metadata: name: job spec: containers: - name: job image: busybox:latest command: - 'sh' - '-c' - 'echo Beijing' initContainerï¼špod çš„ container åœ¨å¯åŠ¨æ—¶ä¼šæ£€æŸ¥ volume ä¸­æŸä¸ªç›®å½•æ˜¯å¦å­˜åœ¨æŸä¸ªæ–‡ä»¶ï¼Œè‹¥ä¸å­˜åœ¨åˆ™é€€å‡ºï¼Œè‹¥å­˜åœ¨ï¼Œåˆ™è¿è¡Œã€‚è¦æ±‚ä¿®æ”¹ pod çš„ yamlï¼Œé€šè¿‡ initContainer åˆ›å»ºè¯¥æ–‡ä»¶ï¼Œä½¿podè¿è¡Œã€‚ 1 å°†åä¸º ek8s-node-1 çš„ node è®¾ç½®ä¸ºä¸å¯ç”¨ï¼Œå¹¶é‡æ–°è°ƒåº¦è¯¥ node ä¸Šæ‰€æœ‰è¿è¡Œçš„ podsã€‚ 1234# cordon:å°†nodeè®¾ç½®ä¸ºä¸å¯ç”¨ï¼Œå°†é˜»æ­¢æ–°podè°ƒåº¦åˆ°è¯¥èŠ‚ç‚¹ä¹‹ä¸Šï¼Œä½†ä¸ä¼šå½±å“ä»»ä½•å·²ç»åœ¨å…¶ä¸Šçš„ podï¼Œè¿™æ˜¯é‡å¯èŠ‚ç‚¹æˆ–è€…æ‰§è¡Œå…¶ä»–ç»´æŠ¤æ“ä½œä¹‹å‰çš„ä¸€ä¸ªæœ‰ç”¨çš„å‡†å¤‡æ­¥éª¤ï¼ŒDaemonSetåˆ›å»ºçš„podèƒ½å¤Ÿå®¹å¿èŠ‚ç‚¹çš„ä¸å¯è°ƒåº¦å±æ€§ã€‚kubectl cordon ek8s-node-1# drain:ä»èŠ‚ç‚¹å®‰å…¨çš„é©±é€æ‰€æœ‰podsã€‚kubectl drain ek8s-node-1 --delete-local-data --ignore-daemonsets --force åœ¨ç°æœ‰çš„ namespace app-team1 ä¸­åˆ›å»ºä¸€ä¸ªåä¸º cicd-token çš„æ–° ServiceAccountï¼Œåˆ›å»ºä¸€ä¸ª deployment-clusterrole ä¸”åªèƒ½å¤Ÿåˆ›å»º Deploymentã€DaemonSetã€StatefulSet èµ„æºçš„ Cluster Roleï¼Œå¹¶å°†æ–°çš„ deployment-clusterrole ç»‘å®šåˆ° cicd-tokenã€‚ 12345kubectl create sa cicd-token -n app-team1kubectl create clusterrole deployment-clusterrole --verb=create --resource=Deployment,StatefulSet,DaemonSetkubectl create rolebinding cicd-rolebinding --clusterrole=deployment-clusterrolr --serviceaccount=app-team1:cicd-token k8s master 1.20.0 å‡çº§åˆ° 1.20.1ï¼Œå¹¶å‡çº§ kubeletã€kubectlã€‚ 12345678910# å°†èŠ‚ç‚¹è®¾ä¸ºä¸å¯è°ƒåº¦æ€§kubectl cordon mk8s-master-0kubectl drain mk8s-master-0 --igonre-daemonsets# å‡çº§apt-get updateapt-get -y install kubeadm=1.20.1-00kubeadm update apply v1.20.1 --etcd-upgrade=falseapt-get -y install kubelet=1.20.1-00 kubectl=1.20.1-00# å°†ä¸å¯è°ƒåº¦æ€§å»é™¤kubectl uncordon mk8s-master-0 etcd å¤‡ä»½/æ¢å¤ã€‚ 1234# å¤‡ä»½ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 --cacert=&lt;trusted-ca-file&gt; --cert=&lt;cert-file&gt; --key=&lt;key-file&gt; snapshot save &lt;backup-file-location&gt;# æ¢å¤ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 --cacert=&lt;trusted-ca-file&gt; --cert=&lt;cert-file&gt; --key=&lt;key-file&gt; snapshot restore &lt;backup-file-location&gt; åœ¨ internal çš„å‘½åç©ºé—´ä¸‹åˆ›å»ºä¸€ä¸ªåä¸º allow-port-from-namespace çš„ NetworkPolicyï¼Œæ­¤ NetworkPolicy å…è®¸ internal ä¸­çš„ pod è®¿é—® echo å‘½åç©ºé—´ä¸­ 9000 çš„ç«¯å£ã€‚ 123# å…ˆè·å–echoç§Ÿæˆ·çš„labelskubectl get ns echo --show-labelsecho-key: echo-value 1234567891011121314151617apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: allow-port-from-namespace namespace: internalspec: podSelector: {} policyTypes: - Ingress ingress: - from: - namespaceSelector: matchLabels: echo-key: echo-value ports: - protocol: TCP port: 9000 åœ¨ ing-internal ä¸‹åˆ›å»ºä¸€ä¸ª ingress åä¸º pingï¼Œé€šè¿‡ 5678 ç«¯å£æš´éœ² hello svc ä¸‹çš„ /helloã€‚ 123456789101112131415apiVersion: extensions/v1beta1kind: Ingressmetadata: name: ping namespace: ing-internalspec: rules: - http: paths: - path: /hello backend: service: name: hello port: number: 5678 å°† deployment webserver æ‰©å±•è‡³ 6 podsã€‚ 1kubectl scale deployment webserver --replicas 6 åˆ›å»ºä¸€ä¸ªåä¸º nginx-kusc00401 çš„ podï¼Œé•œåƒä¸º nginxï¼Œè°ƒåº¦åˆ° disk=ssd çš„èŠ‚ç‚¹ä¸Šã€‚ 1234567891011121314apiVersion: v1kind: Podmetadata: name: nginx-kusc00401spec: containers: - name: nginx image: nginx:1.20.1 imagePullPolicy: Always ports: - name: http containerPort: 80 NodeSelector: disk=ssd å°†ä¸€ä¸ªç°æœ‰çš„ pod é›†æˆåˆ° k8s å†…ç½®æ—¥å¿—è®°å½•ä½“ç³»ç»“æ„ä¸­ï¼ˆkubectl logsï¼‰ï¼Œä½¿ç”¨ busybox æ¥å°†åä¸º sidecar å®¹å™¨æ·»åŠ åˆ°åä¸º 11-factor-app çš„ pod ä¸­ï¼Œsidecar éœ€è¿è¡Œ /bin/sh -c tail -n+1 -f /var/log/11-factor-app.log ï¼Œä½¿ç”¨å®‰è£…åœ¨ /var/log çš„ volumeï¼Œä½¿æ—¥å¿—æ–‡ä»¶ 11-factor-app.log å¯ç”¨äº sidecar å®¹å™¨ã€‚ 12345678910111213141516171819202122232425262728293031323334apiVersion: v1kind: Podmetadata: name: 11-factor-appspec: volumes: - name: log emptyDir: {} containers: - name: count image: busybox command: - /bin/sh - -c - &gt; i=0; while true; do echo &quot;$i: $(date)&quot; &gt;&gt; /var/log/11-factor-app.log; i=$((i+1)); sleep 1; done volumeMounts: - name: log mountPath: /var/log - name: sidecar image: busybox command: - /bin/sh - -c - 'tail -n+1 -f /var/log/11-factor-app.log' volumeMounts: - name: log mountPath: /var/log é€šè¿‡ pod label name=cpu-utilizer å¯»æ‰¾ cpu å ç”¨æœ€å¤šçš„ podï¼Œå¹¶å†™å…¥ /opt/tmp/tmp.txtã€‚ 1kubectl top pod -A -l name=cpu-utilizer --sort-by=cpu &gt;&gt; /opt/tmp/tmp.txt","link":"/2024/02/18/cka/"},{"title":"Jenkins","text":"Jenkinsæ˜¯ä¸€ä¸ªå¼€æºçš„æŒç»­é›†æˆçš„æœåŠ¡å™¨ï¼ŒJenkinså¼€æºå¸®åŠ©æˆ‘ä»¬è‡ªåŠ¨æ„å»ºå„ç±»é¡¹ç›®ã€‚Jenkinså¼ºå¤§çš„æ’ä»¶å¼ï¼Œä½¿å¾—Jenkinså¯ä»¥é›†æˆå¾ˆå¤šè½¯ä»¶ï¼Œå¯èƒ½å¸®åŠ©æˆ‘ä»¬æŒç»­é›†æˆæˆ‘ä»¬çš„å·¥ç¨‹é¡¹ç›®ã€‚ ä¸€ã€ä»€ä¹ˆæ˜¯CIã€CD Devopsä¹Ÿå°±æ˜¯å¼€å‘è¿ç»´ä¸€ä½“åŒ–ï¼Œè€Œéšç€Devopsçš„å…´èµ·ï¼Œå‡ºç°äº†æŒç»­é›†æˆã€æŒç»­äº¤ä»˜ä»¥åŠæŒç»­éƒ¨ç½²çš„æ–°æ–¹æ³•ï¼Œä¼ ç»Ÿçš„è½¯ä»¶å¼€å‘å’Œäº¤ä»˜æ–¹æ³•æ­£åœ¨è¿…é€Ÿå˜å¾—è¿‡æ—¶ã€‚ä»å†å²ä¸Šçœ‹ï¼Œåœ¨æ•æ·æ—¶ä»£ï¼Œå¤§å¤šæ•°å…¬å¸ä¼šæ¯æœˆã€æ¯å­£åº¦ã€æ¯ä¸¤å¹´ç”šè‡³æ¯å¹´å‘å¸ƒéƒ¨ç½²æˆ–å‘å¸ƒè½¯ä»¶ã€‚ç„¶è€Œï¼Œåœ¨DevOpsæ—¶ä»£ï¼Œæ¯å‘¨ã€æ¯å¤©ã€ç”šè‡³æ¯å¤©å¤šæ¬¡ã€‚å½“SaaSæ­£åœ¨å é¢†ä¸–ç•Œæ—¶ï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾åœ°åŠ¨æ€æ›´æ–°åº”ç”¨ç¨‹åºï¼Œè€Œæ— éœ€å¼ºè¿«å®¢æˆ·ä¸‹è½½æ–°ç»„ä»¶ã€‚å¾ˆå¤šæ—¶å€™ï¼Œä»–ä»¬ç”šè‡³éƒ½ä¸ä¼šæ„è¯†åˆ°æ­£åœ¨å‘ç”Ÿå˜åŒ–ã€‚å¼€å‘å›¢é˜Ÿé€šè¿‡è½¯ä»¶äº¤ä»˜æµæ°´çº¿ï¼ˆPipelineï¼‰å®ç°è‡ªåŠ¨åŒ–ï¼Œä»¥ç¼©çŸ­äº¤ä»˜å‘¨æœŸï¼Œå¤§å¤šæ•°å›¢é˜Ÿéƒ½æœ‰è‡ªåŠ¨åŒ–æµç¨‹æ¥æ£€æŸ¥ä»£ç å¹¶éƒ¨ç½²åˆ°æ–°ç¯å¢ƒã€‚ æŒç»­é›†æˆçš„é‡ç‚¹æ˜¯å°†å„ä¸ªå¼€å‘äººå‘˜çš„å·¥ä½œé›†åˆåˆ°ä¸€ä¸ªä»£ç ä»“åº“ä¸­ã€‚é€šå¸¸ï¼Œæ¯å¤©éƒ½è¦è¿›è¡Œå‡ æ¬¡ï¼Œä¸»è¦ç›®çš„æ˜¯å°½æ—©å‘ç°é›†æˆé”™è¯¯ï¼Œä½¿å›¢é˜Ÿæ›´åŠ ç´§å¯†ç»“åˆï¼Œæ›´å¥½åœ°åä½œã€‚ æŒç»­äº¤ä»˜çš„ç›®çš„æ˜¯æœ€å°åŒ–éƒ¨ç½²æˆ–é‡Šæ”¾è¿‡ç¨‹ä¸­å›ºæœ‰çš„æ‘©æ“¦ã€‚å®ƒçš„å®ç°é€šå¸¸èƒ½å¤Ÿå°†æ„å»ºéƒ¨ç½²çš„æ¯ä¸ªæ­¥éª¤è‡ªåŠ¨åŒ–ï¼Œä»¥ä¾¿ä»»ä½•æ—¶åˆ»èƒ½å¤Ÿå®‰å…¨åœ°å®Œæˆä»£ç å‘å¸ƒï¼ˆç†æƒ³æƒ…å†µä¸‹ï¼‰ã€‚ æŒç»­éƒ¨ç½²æ˜¯ä¸€ç§æ›´é«˜ç¨‹åº¦çš„è‡ªåŠ¨åŒ–ï¼Œæ— è®ºä½•æ—¶å¯¹ä»£ç è¿›è¡Œé‡å¤§æ›´æ”¹ï¼Œéƒ½ä¼šè‡ªåŠ¨è¿›è¡Œæ„å»º/éƒ¨ç½²ã€‚ è€ŒJenkinså°±æ˜¯æ¥å®ç°ä»¥ä¸ŠæŒç»­é›†æˆå·¥ä½œçš„æœåŠ¡å™¨ã€‚ äºŒã€æŒç»­é›†æˆç¯å¢ƒæ­å»ºJenkinsæµç¨‹å›¾ï¼š 2.1 Gitlabä»£ç æ‰˜ç®¡æœåŠ¡å™¨å®‰è£…Gitlab æ˜¯ä¸€ä¸ªç”¨äºä»“åº“ç®¡ç†ç³»ç»Ÿçš„å¼€æºé¡¹ç›®ï¼Œä½¿ç”¨Gitä½œä¸ºä»£ç ç®¡ç†å·¥å…·ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šæ­å»ºèµ·æ¥çš„WebæœåŠ¡ã€‚ å¼€å¯postfixæœåŠ¡ï¼ˆæ”¯æŒgitlabå‘ä¿¡åŠŸèƒ½ï¼‰ 12systemctl start postfixsystemctl enable postfix é…ç½®gitlabçš„yumæº 123456789vim /etc/yum.repos.d/gitlab-cd.repo[gitlab-ce]name=Gitlab CE Repositorybaseurl=https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el$releasever/gpgcheck=0enabled=1yum clean allyum makecache å®‰è£…gitlab 1yum -y install gitlab-ce ä¿®æ”¹gitlabé…ç½®æ–‡ä»¶ 123456789vim /etc/gitlab/gitlab.rb#ç”¨æˆ·è®¿é—®æ‰€ä½¿ç”¨çš„URLï¼ŒåŸŸåæˆ–è€…IPåœ°å€external_url 'http://192.168.88.133'#æ—¶åŒºgitlab_rails['time_zone'] = 'Asia/Shanghai'#å¯ç”¨SMTPé‚®ç®±åŠŸèƒ½gitlab_rails['smtp_enable'] = 'ture'#ä½¿ç”¨SSHåè®®æ‹‰å–ä»£ç æ‰€ä½¿ç”¨çš„è¿æ¥ç«¯å£gitlab_rails['gitlab_shell_ssh_port'] = '22' åˆ·æ–°é…ç½® 1gitlab-ctl reconfigure å¯åŠ¨æœåŠ¡ 123gitlab-ctl restartgitlab-ctl status...... docker-compose.yaml 123456789101112131415161718version: '3.8'services: gitlab: container_name: gitlab image: gitlab/gitlab-ce:latest restart: always environment: GITLAB_OMNIBUS_CONFIG: | external_url 'http://192.168.88.30' gitlab_rails['time_zone'] = 'Asia/Shanghai' gitlab_rails['gitlab_shell_ssh_port'] = '22' ports: - '80:80' - '23:22' volumes: - '/root/cicd/gitlab/config:/etc/gitlab' - '/root/cicd/gitlab/logs:/var/log/gitlab' - '/root/cicd/gitlab/data:/var/opt/gitlab' è¿›å…¥å®¹å™¨æŸ¥çœ‹é»˜è®¤ç”¨æˆ·åå’Œä¿®æ”¹å¯†ç  123456789gitlab-rails console# æŸ¥æ‰¾rootç”¨æˆ·u=User.where(id:1).first# ä¿®æ”¹å¯†ç u.password='toortoor'# ç¡®è®¤ä¿®æ”¹å¯†ç u.password_confirmation='toortoor'# ä¿å­˜ä¿®æ”¹u.save 2.2 Gitlabåˆ›å»ºç»„ã€ç”¨æˆ·ã€é¡¹ç›®Gitlabåˆ›å»ºç»„ï¼š æ·»åŠ ç»„ è®¾ç½®ç»„åå’Œæƒé™ Gitlabåˆ›å»ºç”¨æˆ·ï¼š æ·»åŠ ç”¨æˆ· é…ç½®é€‰é¡¹ å°†ç”¨æˆ·æ·»åŠ åˆ°é¡¹ç›®ç»„ Gitlabåˆ›å»ºé¡¹ç›®ï¼š åœ¨æŒ‡å®šç»„ä¸­æ·»åŠ é¡¹ç›® è®¾ç½®é¡¹ç›®åç§° 2.5 é¡¹ç›®ä¸Šä¼ åˆ°Gitlab 2.4 Jenkinså®‰è£… å®‰è£…JDK 1yum -y install java-1.8.0-openjdk* æ”¾è¡Œç«¯å£ 12firewall-cmd --zone=public --add-port=8888/tcp --permanentfirewall-cmd --reload æ·»åŠ Jenkinså®˜æ–¹æºå¹¶å®‰è£… 123wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.reporpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.keyyum -y install jenkins ä¿®æ”¹é…ç½®æ–‡ä»¶ 123vim /etc/sysconfig/jenkinsJENKINS_USER=&quot;root&quot;JENKINS_PORT=&quot;8888&quot; æŸ¥çœ‹åˆå§‹å¯†ç  12cat /var/lib/jenkins/secrets/initialAdminPassword...... docker-compose.yaml 1234567891011version: '3.8'services: jenkins: container_name: jenkins image: jenkins:2.60.3 restart: always ports: - '8080:8080' - '50000:50000' volumes: - '/root/cicd/jenkins/home:/var/jenkins_home' 2.5 Jenkinsä¸­æ–‡æ’ä»¶å®‰è£… ç”±äºJenkinså®˜æ–¹ä¸‹è½½æ’ä»¶å¾ˆæ…¢ï¼Œæˆ‘ä»¬ä¿®æ”¹ä¸ºå›½å†…Jenkinsæ’ä»¶åœ°å€ï¼Œjenkins -&gt; Manage jenkins -&gt; Manage Plugins æ›´æ¢é…ç½®æ–‡ä»¶ä¸­çš„åœ°å€ 12345cp /var/lib/jenkins/updates/default.json /var/lib/jenkins/updates/default.json.backupsed -i 's/https:\\/\\/updates.jenkins.io\\/download/https:\\/\\/mirrors.tuna.tsinghua.edu.cn\\/jenkins/g' /var/lib/jenkins/updates/default.json &amp;&amp; sed -i 's/http:\\/\\/www.google.com/https:\\/\\/www.baidu.com/g' /var/lib/jenkins/updates/default.jsonsystemctl restart jenkins å®‰è£…ä¸­æ–‡æ’ä»¶ 2.6 Jenkinsç”¨æˆ·æƒé™ç®¡ç† ç”±äºJenkinsåŠŸèƒ½è¾ƒä¸ºç®€ä»‹ï¼Œéƒ½è¦é å®‰è£…æ’ä»¶æ¥ä¸°å¯Œä½“éªŒï¼Œæ‰€ä»¥ç”¨æˆ·ç®¡ç†éœ€è¦å®‰è£…role-basedæ’ä»¶ åœ¨Configure Global Securityå¼€å¯åˆšåˆšå®‰è£…çš„æ’ä»¶ åœ¨Manage and Assign Rolesä¸­åˆ›å»ºè§’è‰²baseroleå¹¶åˆ†é…å…·ä½“æƒé™ ç”¨æˆ·æ²¡åŠ å…¥è§’è‰²å‰æ˜¯æ²¡æœ‰è®¿é—®æƒé™çš„ï¼Œå°†ç”¨æˆ·åŠ å…¥åˆ°è§’è‰²baseroleå³å¯ï¼Œä½†åªæœ‰éƒ¨åˆ†æƒé™ 2.7 Jenkinså®‰è£…å‡­è¯ç®¡ç†æ’ä»¶ å®‰è£…Credential Bindingæ’ä»¶ï¼Œå®‰è£…å®Œå°±å¯ä»¥çœ‹åˆ°å¤šäº†å‡­æ®çš„åŠŸèƒ½ 2.8 Jenkinsæ™®é€šç”¨æˆ·å¯†ç è®¤è¯ ä¸ºäº†Jenkinsèƒ½å¤Ÿæ‹‰å–gitlabçš„ä»£ç ï¼Œéœ€è¦å®‰è£…gitæ’ä»¶ 1yum -y install git åˆ›å»ºæ™®é€šç”¨æˆ·å‡­è¯ï¼Œæ³¨æ„è¿™é‡Œçš„ç”¨æˆ·æ˜¯gitlabåˆ›å»ºå¥½çš„ç”¨æˆ· åˆ›å»ºé¡¹ç›®æ·»åŠ æ™®é€šç”¨æˆ·å‡­è¯ build nowæ„å»º Jenkinsä¸»æœºä¸ŠæŸ¥çœ‹æ˜¯å¦æ„å»ºæˆåŠŸ 2.9 Jenkinsä½¿ç”¨sshå…å¯†è®¤è¯ åœ¨Jenkinsä¸»æœºä¸Šç”Ÿäº§å…¬é’¥ç§é’¥ 1ssh-keygen -t rsa åœ¨gitlabä¸Šæ·»åŠ å…¬é’¥ åœ¨Jenkinsä¸Šæ·»åŠ sshå‡­è¯ åˆ›å»ºé¡¹ç›®æ·»åŠ sshå‡­è¯ build nowæ„å»ºé¡¹ç›®å 2.10 Jenkinså®‰è£…Maven ä¸‹è½½maven 1234wget https://mirrors.bfsu.edu.cn/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gzmkdir maventar -xf apache-maven-3.6.3-bin.tar.gzcp apache-maven-3.6.3-bin.tar.gz/* maven/ é…ç½®ç¯å¢ƒå˜é‡ 123456vim /etc/profileexport JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdkexport MAVEN_HOME=/root/mavenexport PATH=$PATH:$JAVA_HOME/bin:/$MAVEN_HOME/binsource /etc/profilemvn -v å…¨å±€å·¥å…·é…ç½®é‡Œæ–°å¢jdkå’Œmaven åœ¨ç³»ç»Ÿé…ç½®é‡Œæ·»åŠ ä¸‰ä¸ªå˜é‡ ä¿®æ”¹mavené…ç½®æ–‡ä»¶ 123456789mkdir /root/repovim /root/maven/conf/settings.xml&lt;localRepository&gt;/root/repo&lt;/localRepository&gt;&lt;mirror&gt; &lt;id&gt;aliyunmaven&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;é˜¿é‡Œäº‘å…¬å…±ä»“åº“&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/public&lt;/url&gt;&lt;/mirror&gt; æµ‹è¯•mavenæ„å»ºé¡¹ç›® 2.11 Tomcatå®‰è£…å’Œé…ç½® å®‰è£…jdkå’Œtomcat 123456yum -y install java-1.8.0-openjdk*wget https://downloads.apache.org/tomcat/tomcat-9/v9.0.43/bin/apache-tomcat-9.0.43.tar.gztar -xf apache-tomcat-9.0.43.tar.gzmkdir /root/tomcatmv apache-tomcat-9.0.43.tar.gz/* /root/tomcat./root/tomcat/bin/startup.sh æ·»åŠ tomcatç®¡ç†ç”¨æˆ· 123456789vim /root/tomcat/conf/tomcat-users.xml &lt;role rolename=&quot;tomcat&quot;/&gt; &lt;role rolename=&quot;role1&quot;/&gt; &lt;role rolename=&quot;manager-gui&quot;/&gt; &lt;role rolename=&quot;manager-script&quot;/&gt; &lt;role rolename=&quot;admin-gui&quot;/&gt; &lt;role rolename=&quot;admin-script&quot;/&gt; &lt;role rolename=&quot;manager-status&quot;/&gt; &lt;user username=&quot;tomcat&quot; password=&quot;toortoor&quot; roles=&quot;manager-gui,manager-script,tomcat,admin-gui,admin-script&quot;/&gt; 12345vim /root/tomcat/webapps/manager/META-INF/context.xml&lt;!-- &lt;Valve className=&quot;org.apache.catalina.valves.RemoteAddrValve&quot; allow=&quot;127\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1&quot; /&gt;--&gt; æµ‹è¯• ä¸‰ã€Jenkinsæ„å»ºé¡¹ç›®Jenkinsæ„å»ºçš„é¡¹ç›®ç±»å‹ä¸»è¦ä¸ºä»¥ä¸‹ä¸‰ç§ï¼š è‡ªç”±é£æ ¼è½¯ä»¶é¡¹ç›®ï¼ˆfreestyle projectï¼‰ Mavené¡¹ç›®ï¼ˆmaven projectï¼‰ æµæ°´çº¿é¡¹ç›®ï¼ˆpipeline projectï¼‰ 3.1 è‡ªç”±é£æ ¼è½¯ä»¶é¡¹ç›®æ„å»º è¦å°†é¡¹ç›®éƒ¨ç½²åˆ°tomcatæœåŠ¡å™¨ä¸Šï¼Œéœ€è¦å®‰è£…deploy to containeræ’ä»¶ Jenkins -&gt; æ–°å»ºitems ä½¿ç”¨sshå…å¯†ç™»å½•æ¥æ‹‰å–ä»£ç  ä½¿ç”¨mavenç¼–è¯‘æ‰“åŒ… éƒ¨ç½² å†æ¬¡æ„å»ºåå¯ä»¥å›åˆ°tomcatæŸ¥çœ‹æ˜¯å¦éƒ¨ç½²æˆåŠŸ 3.2 Mavené¡¹ç›®æ„å»º å®‰è£…Maven Integrationæ’ä»¶ åˆ›å»ºmavené¡¹ç›® æ„å»ºè®¾ç½®ï¼Œå…¶ä½™è®¾ç½®éƒ½ç›¸åŒ æ„å»ºåæŸ¥çœ‹æ˜¯å¦éƒ¨ç½²æˆåŠŸ 3.3 Pipeline projectç®€ä»‹pipelineå°±æ˜¯ä¸€å¥—è¿è¡Œåœ¨Jenkinsä¸Šçš„å·¥ä½œæµæ¡†æ¶ï¼Œå°†ç‹¬ç«‹è¿è¡Œçš„å•ä¸ªæˆ–å¤šä¸ªèŠ‚ç‚¹çš„ä»»åŠ¡è¿æ¥èµ·æ¥ï¼Œå®ç°å¤æ‚æµç¨‹çš„ç¼–æ’å’Œå¯è§†åŒ–çš„å·¥ä½œã€‚ ä¼˜ç‚¹æœ‰ï¼š è‡ªåŠ¨åœ°ä¸ºæ‰€æœ‰åˆ†æ”¯åˆ›å»ºæµæ°´çº¿æ„å»ºè¿‡ç¨‹å¹¶æ‹‰å–è¯·æ±‚ã€‚ åœ¨æµæ°´çº¿ä¸Šä»£ç å¤æŸ¥/è¿­ä»£ (ä»¥åŠå‰©ä½™çš„æºä»£ç )ã€‚ å¯¹æµæ°´çº¿è¿›è¡Œå®¡è®¡è·Ÿè¸ªã€‚ è¯¥æµæ°´çº¿çš„çœŸæ­£çš„æºä»£ç ï¼Œå¯ä»¥è¢«é¡¹ç›®çš„å¤šä¸ªæˆå‘˜æŸ¥çœ‹å’Œç¼–è¾‘ã€‚ 3.4 Pipelineæµæ°´çº¿é¡¹ç›®æ„å»º å®‰è£…pipelineæ’ä»¶ æ–°å»ºæµæ°´çº¿é¡¹ç›® å£°æ˜å¼æµæ°´çº¿ 3.5 Jenkinsfileè„šæœ¬æ–‡ä»¶pipelineè„šæœ¬å†…å®¹æ”¾åœ¨JenkinsæœåŠ¡å™¨ä¸å¥½ç®¡ç†ï¼Œæ‰€ä»¥å°±åœ¨é¡¹ç›®æ·»åŠ ä¸€ä¸ªJenkinsfileæ–‡ä»¶å¹¶æ¨é€åˆ°gitlabä¸Šï¼Œå®ç°ç›´æ¥æ‹‰å–æ‰§è¡Œã€‚ åœ¨é¡¹ç›®ä¸‹æ·»åŠ ä¸€ä¸ªJenkinsfileï¼Œå°†pipelineå†…å®¹å¤åˆ¶è¿›å»å¹¶æ¨é€åˆ°gitlabä¸Š åœ¨pipelineé¡¹ç›®ä¸­ä¿®æ”¹ä¸ºåœ¨gitlabæ‹‰å–Jenkinsfileæ–‡ä»¶ å››ã€Jenkinsæ„å»ºç»†èŠ‚4.1 Jenkinså¸¸ç”¨çš„æ„å»ºè§¦å‘å™¨Jenkinså†…ç½®4ç§æ„å»ºè§¦å‘å™¨ï¼š è§¦å‘è¿œç¨‹æ„å»º å…¶å®ƒå·¥ç¨‹æ„å»ºåè§¦å‘ å®šæ—¶æ„å»º è½®è¯¢SCM 4.2 è§¦å‘è¿œç¨‹æ„å»º åœ¨é¡¹ç›®ä¸­è®¾ç½®è§¦å‘å™¨ åœ¨æµè§ˆå™¨è¾“å…¥JENKINS_URL/job/pipeline-project/build?token=TOKEN_NAMEå³å¯è§¦å‘ 4.3 å…¶å®ƒå·¥ç¨‹æ„å»ºåè§¦å‘æ˜¯æŒ‡æŸä¸€å·¥ç¨‹æ„å»ºåæ‰ä¼šè§¦å‘æ„å»ºï¼Œè¿™é‡Œæµ‹è¯•freestyleå·¥ç¨‹æ„å»ºåè§¦å‘pipelineæ„å»º åœ¨pipelineé…ç½®æ„å»ºåè§¦å‘ freestyleå·¥ç¨‹æ„å»ºåå°±ä¼šè§¦å‘pipelineæ„å»º 4.4 å®šæ—¶æ„å»ºäº”ä¸ª*åˆ†åˆ«ä»£è¡¨åˆ†æ—¶æ—¥æœˆå‘¨ï¼ŒH/2åˆ™ä»£è¡¨æ¯åˆ†æ—¶æ—¥æœˆå‘¨ 4.5 è½®è¯¢SCMå’Œå®šæ—¶æ„å»ºä¸€æ ·æ˜¯è®¾ç½®æ—¶é—´æ¥è¿›è¡Œæ„å»ºï¼Œä¸è¿‡è½®è¯¢åªæœ‰åœ¨ä»£ç ä»“åº“å‘ç”Ÿå˜åŒ–åæ‰ä¼šè§¦å‘ï¼Œç›¸å½“äºå®šæ—¶æ£€æŸ¥ æ³¨æ„ï¼šè½®è¯¢ä¼šå®šæ—¶æ‰«æä»“åº“çš„ä»£ç ï¼Œå¢å¤§ç³»ç»Ÿçš„å¼€é”€ï¼Œä¸å»ºè®®ä½¿ç”¨ 4.6 Gitlab Hookè‡ªåŠ¨è§¦å‘æ„å»ºSCMè½®è¯¢æ˜¯JenkinsæœåŠ¡å™¨ä¸»åŠ¨æ£€æµ‹gitlabä¸­çš„ä»£ç æœ‰æ²¡æœ‰å‘ç”Ÿå˜åŒ–ï¼Œè€Œgitlabçš„webhookå¯ä»¥å®ç°ä»£ç å˜æ›´åå‘JenkinsæœåŠ¡å™¨ä¸»åŠ¨å‘é€æ„å»ºè¯·æ±‚ï¼Œå®ç°è‡ªåŠ¨æ„å»ºã€‚ åœ¨Jenkinså®‰è£…gitlabå’Œgitlab hookæ’ä»¶ åœ¨gitlabé…ç½®ä¸­å…è®¸å‘å‡ºè¯·æ±‚ åœ¨é¡¹ç›®ä¸­æ·»åŠ ç¬¬ä¸€æ­¥ä¸­çš„åœ°å€ é…ç½®Jenkinså…è®¸æ¥å—gitlabå‘é€è¿‡æ¥çš„è¯·æ±‚ 4.7 Jenkinså‚æ•°åŒ–æ„å»ºå‰è¾¹å®æ“æ¼”ç¤ºçš„éƒ½æ˜¯é»˜è®¤ä»masterä¸‹æ‹‰å–ä»£ç ï¼Œå¦‚æœè¦å®ç°åœ¨å…¶ä»–åˆ†æ”¯æ‹‰å–ä»£ç ï¼Œå°±éœ€è¦è®¾ç½®å‚æ•°åŒ–æ„å»ºã€‚ åœ¨Jenkinsçš„é¡¹ç›®ä¸­æ·»åŠ å‚æ•°ï¼Œè¿™é‡Œé€‰æ‹©å­—ç¬¦ä¸²å‚æ•° ä¿®æ”¹Jenkinsfileæ–‡ä»¶ä¸­æ‹‰å–ä»£ç éƒ¨åˆ†çš„masterä¸ºå˜é‡ï¼Œå¹¶æ¨é€åˆ°gitlab åœ¨é¡¹ç›®ä¸­æ·»åŠ ä¸€ä¸ªv1åˆ†æ”¯ åœ¨Jenkinsä¸­æ‹‰å–v1ä»£ç æ„å»º 4.8 é…ç½®é‚®ä»¶æœåŠ¡å™¨å‘é€æ„å»ºç»“æœ å®‰è£…Email Extensionæ’ä»¶ åœ¨Jenkinsä¸­é…ç½® åœ¨é¡¹ç›®ä¸­åˆ›å»ºä¸€ä¸ªemail.htmlæ–‡ä»¶ï¼Œæ·»åŠ ä»¥ä¸‹å†…å®¹å¹¶æ¨é€åˆ°gitlabä¸­ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;${PROJECT_NAME}-ç¬¬${BUILD_NUMBER}æ¬¡æ„å»ºæ—¥å¿—&lt;/title&gt;&lt;/head&gt; &lt;body leftmargin=&quot;8&quot; marginwidth=&quot;0&quot; topmargin=&quot;8&quot; marginheight=&quot;4&quot;&gt; &lt;table width=&quot;95%&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; style=&quot;font-size: 11pt; font-family: Tahoma, Arial, Helvetica, sans-serif&quot;&gt; &lt;tr&gt; &lt;td&gt;(æœ¬é‚®ä»¶æ˜¯ç¨‹åºè‡ªåŠ¨ä¸‹å‘çš„ï¼Œè¯·å‹¿å›å¤ï¼)&lt;br/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;h2&gt; &lt;font color=&quot;#0000FF&quot;&gt;æ„å»ºç»“æœ - ${BUILD_STATUS}&lt;/font&gt; &lt;/h2&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;br /&gt; &lt;b&gt;&lt;font color=&quot;#0B610B&quot;&gt;æ„å»ºä¿¡æ¯&lt;/font&gt;&lt;/b&gt; &lt;hr size=&quot;2&quot; width=&quot;100%&quot; align=&quot;center&quot; /&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;ul&gt; &lt;li&gt;é¡¹ç›®åç§° ï¼š ${PROJECT_NAME}&lt;/li&gt; &lt;li&gt;æ„å»ºç¼–å· ï¼š ç¬¬${BUILD_NUMBER}æ¬¡æ„å»º&lt;/li&gt; &lt;li&gt;è§¦å‘åŸå› ï¼š ${CAUSE}&lt;/li&gt; &lt;li&gt;æ„å»ºæ—¥å¿—ï¼š &lt;a href=&quot;${BUILD_URL}console&quot;&gt;${BUILD_URL}console&lt;/a&gt;&lt;/li&gt; &lt;li&gt;æ„å»º Url ï¼š &lt;a href=&quot;${BUILD_URL}&quot;&gt;${BUILD_URL}&lt;/a&gt;&lt;/li&gt; &lt;li&gt;å·¥ä½œç›®å½• ï¼š &lt;a href=&quot;${PROJECT_URL}ws&quot;&gt;${PROJECT_URL}ws&lt;/a&gt;&lt;/li&gt; &lt;li&gt;é¡¹ç›® Url ï¼š &lt;a href=&quot;${PROJECT_URL}&quot;&gt;${PROJECT_URL}&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;b&gt;&lt;font color=&quot;#0B610B&quot;&gt;Changes Since Last Successful Build:&lt;/font&gt;&lt;/b&gt; &lt;hr size=&quot;2&quot; width=&quot;100%&quot; align=&quot;center&quot; /&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;ul&gt; &lt;li&gt;å†å²å˜æ›´è®°å½• : &lt;a href=&quot;${PROJECT_URL}changes&quot;&gt;${PROJECT_URL}changes&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; ${CHANGES_SINCE_LAST_SUCCESS,reverse=true, format=&quot;Changes for Build #%n:&lt;br /&gt;%c&lt;br /&gt;&quot;,showPaths=true,changesFormat=&quot;&lt;pre&gt;[%a]&lt;br /&gt;%m&lt;/pre&gt;&quot;,pathFormat=&quot; %p&quot;} &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;hr size=&quot;2&quot; width=&quot;100%&quot; align=&quot;center&quot; /&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;b&gt;&lt;font color=&quot;#0B610B&quot;&gt;æ„å»ºæƒ…å†µæ€»è§ˆ:&lt;/font&gt;&lt;/b&gt;${TEST_COUNTS,var=&quot;fail&quot;}&lt;br/&gt; &lt;hr size=&quot;2&quot; width=&quot;100%&quot; align=&quot;center&quot; /&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;textarea cols=&quot;80&quot; rows=&quot;30&quot; readonly=&quot;readonly&quot; style=&quot;font-family: Courier New&quot;&gt;${BUILD_LOG,maxLines=23}&lt;/textarea&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/body&gt;&lt;/html&gt; åœ¨Jenkinsfileä¸­æ·»åŠ å‘é€emailåŠŸèƒ½ï¼Œpostå³æŒ‡æ„å»ºåæ“ä½œ 123456789post { always { emailext( subject: 'æ„å»ºé€šçŸ¥ï¼š${PROJECT_NAME} - Build # ${BUILD_NUMBER} - ${BUILD_STATUS}!', body: '${FILE,path=&quot;email.html&quot;}', to: 'chenqiming13@qq.com' ) }} æ„å»ºæµ‹è¯•æ˜¯å¦æ”¶åˆ°é‚®ä»¶ äº”ã€Jenkins+SonarQubeä»£ç å®¡æŸ¥ sonarqubeæ˜¯ä¸€ä¸ªç”¨äºç®¡ç†ä»£ç è´¨é‡çš„å¼€æ”¾å¹³å°ï¼Œå¯ä»¥å¿«é€Ÿå®šä½ä»£ç ä¸­æ½œåœ¨çš„é”™è¯¯ã€‚ ç¯å¢ƒè¦æ±‚ï¼š JDK11 PostgreSQL 5.1 å®‰è£…PostgreSQL æ–°ç‰ˆæœ¬çš„sonarqubeä¸å†æ”¯æŒMySQLï¼Œæ‰€ä»¥åœ¨JenkinsæœåŠ¡å™¨ä¸Šå®‰è£…PostgreSQLå¹¶åˆ›å»ºä¸€ä¸ªsonaræ•°æ®åº“ 1234567891011121314151617181920212223#å®‰è£…postgresqlyum -y install https://download.postgresql.org/pub/repos/yum/9.6/redhat/rhel-7-x86_64/pgdg-redhat-repo-latest.noarch.rpmyum -y install postgresql96-server postgresql96-contrib#åˆå§‹åŒ–postgresqlpostgresql-9.6-setup initdbsystemctl enable postgresql-9.6.servicesystemctl start postgresql-9.6.service#åˆå§‹åŒ–ä¹‹åä¼šè‡ªåŠ¨åˆ›å»ºpostgresç”¨æˆ·ï¼Œåˆ‡æ¢ç”¨æˆ·su - postgres#psqlè¿›å…¥å‘½ä»¤è¡Œæ¨¡å¼é…ï¼Œ\\qé€€å‡ºpsqlalter user postgres with password 'toortoor';create database sonar;create user sonar;alter user sonar with password 'toortoor';alter role sonar createdb;alter role sonar superuser;alter role sonar createrole;alter database sonar owner to sonar;\\q å¼€å¯è¿œç¨‹è®¿é—®å’Œè¿œç¨‹è¿æ¥ 12345vim /var/lib/pgsql/9.6/data/postgresql.conflisten_addresses = '*'vim /var/lib/pgsql/9.6/data/pg_hba.confhost all all 127.0.0.1/32 trusthost all all 192.168.88.1/32 trust é‡å¯æœåŠ¡ 5.2 å®‰è£…SonarQube å®‰è£…sonarqube 123456wget https://binaries.sonarsource.com/Distribution/sonarqube/sonarqube-8.7.1.42226.zipunzip sonarqube-8.7.1.42226.zipmv sonarqube-8.7.1.42226 sonarqubeuseradd sonarchown -R sonar:sonar sonarqube/*mv sonarqube /opt/sonarqube ä¿®æ”¹sonaré…ç½®æ–‡ä»¶ 123456vim sonarqube/conf/sonar.propertiessonar.jdbc.username=sonarsonar.jdbc.password=toortoorsonar.jdbc.url=jdbc:postgresql://localhost/sonarqube?currentSchema=my_schemasonar.jdbc.url=jdbc:postgresql://localhost/sonar?currentSchema=publicsonar.web.port=9000 å¯åŠ¨sonarqube 123#åªèƒ½ç”¨sonarç”¨æˆ·å¯åŠ¨su sonar./opt/sonarqube/bin/linux-x86-64/sonar.sh start é‡åˆ°çš„é—®é¢˜ 123456#sonarç”¨æˆ·çº¿ç¨‹æ•°ä¸å¤Ÿï¼Œ*ä»£è¡¨æ‰€æœ‰ç”¨æˆ·cat /etc/security/limits.conf* soft nofile 65536* hard nofile 65536* soft noproc 65535* hard noproc 65535 deploy.yaml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374apiVersion: apps/v1kind: Deploymentmetadata: name: sonarqube labels: app: sonarqubespec: replicas: 1 selector: matchLabels: app: sonarqube template: metadata: name: sonarqube labels: app: sonarqube spec: initContainers: - name: init-sysctl image: busybox imagePullPolicy: IfNotPresent command: [&quot;sysctl&quot;, &quot;-w&quot;, &quot;vm.max_map_count=262144&quot;] securityContext: privileged: true containers: - name: sonarqube image: sonarqube:lts-community imagePullPolicy: IfNotPresent ports: - containerPort: 9000 env: # æ­¤å¤„ç”¨åˆ°äº†é›†ç¾¤ç°æœ‰çš„pg # æ•°æ®åº“ç”¨æˆ·sonarqube # æ•°æ®åº“åsonarqube - name: SONARQUBE_JDBC_USERNAME value: &quot;sonarqube&quot; - name: SONARQUBE_JDBC_PASSWORD value: &quot;dangerous&quot; - name: SONARQUBE_JDBC_URL value: &quot;jdbc:postgresql://dcs-installer-gitlab-postgresql.dcs-system:5432/sonarqube&quot; livenessProbe: httpGet: path: /sessions/new port: 9000 initialDelaySeconds: 60 periodSeconds: 30 readinessProbe: httpGet: path: /sessions/new port: 9000 initialDelaySeconds: 60 periodSeconds: 30 failureThreshold: 6 resources: limits: cpu: 2000m memory: 2048Mi requests: cpu: 1000m memory: 1024Mi ---apiVersion: v1kind: Servicemetadata: name: sonarqubespec: type: NodePort selector: app: sonarqube ports: - port: 9000 targetPort: 9000 protocol: TCP 5.3 Jenkinsæ•´åˆSonarQube å®‰è£…sonarqube scanneræ’ä»¶ åœ¨Jenkinså®‰è£…sonarqube scanner åœ¨sonarqubeä¸­ç”Ÿæˆå¯†é’¥ åœ¨ç³»ç»Ÿé…ç½®ä¸­é…ç½®sonarqube serverï¼Œåˆ©ç”¨åˆšåˆšç”Ÿæˆçš„å¯†é’¥ 5.4 å®ç°ä»£ç å®¡æŸ¥éæµæ°´çº¿é¡¹ç›®æ·»åŠ ä»£ç å®¡æŸ¥ åœ¨é¡¹ç›®ä¸­æ·»åŠ æ„å»ºæ­¥éª¤ 123456789101112131415161718192021#Must be unique in a given SonarQube instance# SonarQubeåˆ›å»ºé¡¹ç›®æ—¶çš„keysonar.projectKey=freestyle_project#This is the name and version displayed in the SonarQube UI.# é¡¹ç›®åç§°sonar.projectName=freestyle_project# é¡¹ç›®ç‰ˆæœ¬sonar.projectVersion=1.0#Path is relative to the sonar-project.properties file.#This property is optional if sonar.modules is set.sonar.sources=.# å¿½ç•¥æ‰«æçš„ç›®å½•sonar.exclusions=**/test/**,**/target/**sonar.java.source=11sonar.java.target=11#Encoding of the source code.Default is default system encoding.sonar.sourceEncoding=UTF-8 æ„å»ºé¡¹ç›® å›åˆ°sonarqubeå°±å¯ä»¥çœ‹åˆ°æäº¤çš„ä»£ç å®¡æŸ¥äº† æµæ°´çº¿é¡¹ç›®æ·»åŠ ä»£ç å®¡æŸ¥ åœ¨é¡¹ç›®ä¸­åˆ›å»ºsonar-project.properties 1234567891011121314151617#Must be unique in a given SonarQube instancesonar.projectKey=pipeline_project#This is the name and version displayed in the SonarQube UI.sonar.projectName=pipeline_projectsonar.projectVersion=1.0#Path is relative to the sonar-project.properties file.#This property is optional if sonar.modules is set.sonar.sources=.sonar.exclusions=**/test/**,**/target/**sonar.java.source=11sonar.java.target=11#Encoding of the source code.Default is default system encoding.sonar.sourceEncoding=UTF-8 ä¿®æ”¹Jenkinsfileæ–‡ä»¶ 123456789101112stage('code checking'){ steps { script { //å¼•å…¥scannerå·¥å…· scannerHome = tool 'sonar-scanner' } //å¼•å…¥sonarqubeæœåŠ¡å™¨ç¯å¢ƒ withSonarQubeEnv('sonarqube') { sh &quot;${scannerHome}/bin/sonar-scanner&quot; } }} å°†Jenkinsfileå’Œsonar-project.propertiesæ¨é€åˆ°gitlab æ„å»ºé¡¹ç›®ååœ¨sonarqubeå°±å¯ä»¥çœ‹åˆ°ä»£ç å®¡æŸ¥äº† å…­ã€Jenkins+Docker+SpringCloudå¾®æœåŠ¡æŒç»­é›†æˆ å¤§è‡´æµç¨‹ï¼š å¼€å‘äººå‘˜pushä»£ç åˆ°gitlabã€‚ JenkinsæœåŠ¡å™¨è¿›è¡Œç¼–è¯‘æ‰“åŒ…å¹¶æ„å»ºé•œåƒæ¨é€åˆ°harboré•œåƒä»“åº“ï¼ˆæœåŠ¡å™¨çš„JAVAç¯å¢ƒè¦ä¸é¡¹ç›®å¯¹åº”ï¼‰ã€‚ JenkinsæœåŠ¡å™¨è§¦å‘è¿œç¨‹å‘½ä»¤ä½¿ç”Ÿäº§æœåŠ¡å™¨ï¼ˆtomcatï¼‰ä»ç§æœ‰ä»“åº“æ‹‰å–é•œåƒã€‚ ç”Ÿäº§æœåŠ¡å™¨ï¼ˆtomcatï¼‰ç”Ÿæˆå®¹å™¨ï¼Œé¡¹ç›®ä¸Šçº¿ã€‚ ç”¨æˆ·è®¿é—®ã€‚ 6.1 Harboréƒ¨ç½² ä¸‹è½½ 1curl -O https://github.com/goharbor/harbor/releases/download/v2.3.4/harbor-offline-installer-v2.3.4.tgz ä¿®æ”¹ harbor.yml 123456789101112131415161718192021222324252627282930313233343536cp harbor.yml.tmpl harbor.ymlegrep -v '^#|^$|*#' harbor.ymlhostname: 192.168.88.30http: port: 81harbor_admin_password: toortoordatabase: password: toortoor max_idle_conns: 100 max_open_conns: 900data_volume: /root/cicd/harbor/datatrivy: ignore_unfixed: false skip_update: false insecure: falsejobservice: max_job_workers: 10notification: webhook_job_max_retry: 10chart: absolute_url: disabledlog: level: info local: rotate_count: 50 rotate_size: 200M location: /root/cicd/harbor/var_version: 2.3.0proxy: http_proxy: https_proxy: no_proxy: components: - core - jobservice - trivy docker-compose.yaml æ–‡ä»¶ä¸­æŒ‡å®š harbor è®¿é—®ç«¯å£ä¸º 80ï¼Œé¿å…ä¸ gitlab å†²çªï¼Œ ä¿®æ”¹ä¸º 81 é€šè¿‡è„šæœ¬éƒ¨ç½² 12./prepare./install.sh åˆ›å»ºç§æœ‰ä»“åº“ ä¿®æ”¹ daemon.jsonï¼Œè®© docker ä¿¡ä»»æ­¤ä»“åº“ 1234{ &quot;registry-mirrors&quot;: [&quot;https://5v5rh037.mirror.aliyuncs.com&quot;], &quot;insecure-registries&quot;: [&quot;192.168.88.30:81&quot;]} ç™»å½•è¿œç¨‹é•œåƒä»“åº“ 1docker login -u admin -p toortoor 192.168.88.30:81 6.2 æäº¤ä»£ç åˆ°Gitlab 6.3 Jenkinsåˆ›å»ºæµæ°´çº¿å·¥ç¨‹ åˆ›å»ºå·¥ç¨‹ åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹åˆ›å»º Jenkinsfileï¼Œé€šè¿‡è¯­æ³•ç”Ÿæˆå™¨è¿›è¡Œç¼–å†™ Jenkinsfile æ‹‰å–ä»£ç éƒ¨åˆ† åœ¨æµæ°´çº¿å·¥ç¨‹ä¸­åˆ›å»ºå‚æ•°ï¼Œå¦‚æœæœ‰å¤šä¸ªæœåŠ¡å°±å¯ä»¥æ ¹æ®å‚æ•°é€‰æ‹©è¿›è¡Œæ„å»º Jenkinsfile æ·»åŠ ç¼–è¯‘æ‰“åŒ…å¾®æœåŠ¡å·¥ç¨‹éƒ¨åˆ†ï¼Œä»¥åŠé€šè¿‡ Dockerfile æ„å»ºé•œåƒéƒ¨åˆ† åœ¨ pom.xml ä¸­æ·»åŠ  Dockerfile ä¾èµ– 12345678910&lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.4.10&lt;/version&gt; &lt;configuration&gt; &lt;repository&gt;${project.artifactId}&lt;/repository&gt; &lt;buildArgs&gt; &lt;JAR_NAME&gt;target/${project.build.finalname}.jar&lt;/JAR_NAME&gt; &lt;/buildArgs&gt; &lt;/plugin&gt; åœ¨é¡¹ç›®æ ¹ç›®å½•æ·»åŠ  Dockerfile 123456FROM openjdk:11ARG JAR_NAMEWORKDIR /usr/src/myappEXPOSE 8080COPY ./${JAR_NAME} /usr/src/myapp/ENTRYPOINT [&quot;java&quot;, &quot;-jar&quot;, &quot;/usr/src/myapp/${JAR_NAME}&quot;] Jenkinsfile æ·»åŠ ä¸Šä¼ é•œåƒè‡³ Harbor éƒ¨åˆ† åœ¨ Jenkins ä¸­æ·»åŠ  Harbor è´¦æˆ·å‡­è¯ï¼Œä»¥ä¾¿äºä¸Šä¼ ä»£ç ï¼Œè¿™é‡Œç”¨åˆ°çš„æ˜¯ Harbor çš„ç”¨æˆ·åå’Œå¯†ç  ä¿ç•™å¥½å‡­è¯ID åœ¨è¯­æ³•ç”Ÿæˆå™¨ä¸­ç”Ÿæˆæ–°è¯­æ³•ç”¨äºç™»å½• Harbor ä»“åº“ Jenkins å®‰è£… Publish Over SSH æ’ä»¶ï¼Œèƒ½å¤Ÿå¯¹è¿œç¨‹ä¸»æœºå‘é€ shell å‘½ä»¤ï¼Œå®‰è£…å®Œåå…ˆç»™è¿œç¨‹ä¸»æœºå‘é€å…¬é’¥ 1ssh-copy-id root@192.168.88.30 å‘é€å®Œååœ¨ç³»ç»Ÿé…ç½®è¿›è¡Œé…ç½® æ¥ç€ç”Ÿæˆæµæ°´çº¿è¯­æ³•ï¼Œå»è¿œç¨‹æ‰§è¡Œè„šæœ¬æ–‡ä»¶ test.sh test.sh 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#!/bin/bashharbor_url=$1project_name=$2image_name=$3service_port=$4# åˆ é™¤noneå®¹å™¨echo &quot;docker rmi none...&quot;docker images | grep none | awk '{ print &quot;docker rmi &quot;$3 }' | sh &amp;&gt;/dev/null# æ£€æŸ¥æ˜¯å¦æœ‰å·²è¿è¡Œå®¹å™¨num=`docker ps | grep $project_name | wc -l`if [ $num -gt 0 ]then docker stop $project_name &amp;&amp; docker rm $project_name &amp;&gt;/dev/null if [ `echo $?` -eq 0 ] then echo &quot;docker stop $project_name &amp;&amp; docker rm $project_name [OK]&quot; else echo &quot;ERROR: docker stop $project_name &amp;&amp; docker rm $project_name&quot; fifi# æ£€æŸ¥æ˜¯å¦æœ‰é‡å‘½åé•œåƒtemp=`docker images | grep $image_name | awk '{ print $1&quot;:&quot;$2 }' | wc -l`if [ $temp -eq 1 ]then docker rmi $image_name &amp;&gt;/dev/null if [ `echo $?` -eq 0 ] then echo &quot;docker rmi $image_name [OK]&quot; else echo &quot;ERROR: docker rmi $image_name&quot; fifi# ç™»å½•é•œåƒä»“åº“echo &quot;docker login repository...&quot;docker login -u admin -p toortoor $harbor_url &amp;&gt;/dev/nullif [ `echo $?` -ne 0 ]then echo &quot;ERROR: failed to login repository&quot;else echo &quot;docker login repository [OK]&quot;fi# æ‹‰å–é•œåƒecho &quot;docker pull image...&quot;docker pull $image_name &amp;&gt;/dev/nullif [ `echo $?` -ne 0 ]then echo &quot;ERROR: failed to pull image&quot;else echo &quot;docker pull image [OK]&quot;fi# è¿è¡Œå®¹å™¨echo &quot;docker run container...&quot;docker run -d --name $project_name -p $service_port:8080 $image_name &amp;&gt;/dev/nullif [ `echo $?` -ne 0 ]then echo &quot;ERROR: failed to run container&quot;else echo &quot;docker run container [OK]&quot;fi æœ€ç»ˆçš„ Jenkinsfile 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// gitå‡­è¯iddef git_auth = &quot;bad37d0d-7260-43a2-a350-9abf6e99753a&quot;// gitå‡­è¯urldef git_url = &quot;http://192.168.88.30/test_group/test_project.git&quot;// Harboråœ°å€def harbor_url = &quot;192.168.88.30:81&quot;// é•œåƒä»“åº“åç§°def harbor_repository = &quot;test&quot;// Harborç”¨æˆ·å‡­è¯IDdef harbor_auth = &quot;c147d241-a254-48d6-be1c-0d5f0964ce9a&quot;// é•œåƒç‰ˆæœ¬å·def image_version = &quot;1.0&quot;// æ‹‰å–çš„å¾®æœåŠ¡åç§°def project_name = &quot;test&quot;// å¾®æœåŠ¡æ‰€éœ€ç«¯å£å·def service_port = &quot;8081&quot;node { // æ‹‰å–ä»£ç  stage('Pull Code') { git branch: &quot;${branch}&quot;, credentialsId: &quot;${git_auth}&quot;, url: &quot;${git_url}&quot; } // ç¼–è¯‘ï¼Œæ‰“åŒ…å¾®æœåŠ¡å·¥ç¨‹ï¼Œæ„å»ºé•œåƒ stage('Mvn clean package and Docker build') { sh &quot;mvn clean package dockerfile:build&quot; } // ä¸Šä¼ é•œåƒè‡³Harbor stage('Push image to Harbor') { // é•œåƒå‘½åï¼Œæ‰“æ ‡ç­¾ def image_name = &quot;${project_name}:${image_version}&quot; sh &quot;docker tag ${project_name}:latest ${harbor_url}/${harbor_repository}/${image_name} &amp;&amp; docker rmi ${project_name}:latest&quot; // ç™»å½•Harborä»“åº“ withCredentials([usernamePassword(credentialsId: &quot;${harbor_auth}&quot;, passwordVariable: 'harbor_password', usernameVariable: 'harbor_user')]) { sh &quot;docker login -u ${harbor_user} -p ${harbor_password} ${harbor_url}&quot; } // é•œåƒä¸Šä¼  sh &quot;docker push ${harbor_url}/${harbor_repository}/${project_name}:${image_version}&quot; } // è¿œç¨‹è¿æ¥æœåŠ¡å™¨æ‹‰å–é•œåƒè¿è¡Œ stage('Pull image and Running container') { // è·å–é•œåƒå‘½å def image_name = &quot;${project_name}:${image_version}&quot; sshPublisher(publishers: [sshPublisherDesc(configName: '192.168.88.30', transfers: [sshTransfer(cleanRemote: false, excludes: '', execCommand: './root/test.sh $harbor_url $project_name $harbor_url/$harbor_repository/image_name $service_port', execTimeout: 120000, flatten: false, makeEmptyDirs: false, noDefaultExcludes: false, patternSeparator: '[, ]+', remoteDirectory: '', remoteDirectorySDF: false, removePrefix: '', sourceFiles: '')], usePromotionTimestamp: false, useWorkspaceInPromotion: false, verbose: false)]) }} 6.4 å¾®æœåŠ¡æ¶æ„CICDä¼˜åŒ–ä»ä»¥ä¸Šé…ç½®ä¸­å¯ä»¥çœ‹åˆ°ï¼Œæ¯æ¬¡æ„å»ºéƒ½åªèƒ½é€‰æ‹©ä¸€ä¸ªæœåŠ¡ï¼Œä¸”éƒ¨ç½²çš„æœåŠ¡å™¨ä¹Ÿåªæœ‰ä¸€å°ï¼Œæ˜¯ä¸ç¬¦åˆç”Ÿäº§ç¯å¢ƒçš„ï¼Œä¸»è¦éœ€æ±‚æœ‰ä»¥ä¸‹ä¸‰ä¸ªï¼š å¤šä¸ªå¾®æœåŠ¡åŒæ—¶æ„å»ºæµæ°´çº¿å·¥ç¨‹ æ‰¹é‡å¤„ç†é•œåƒ å°†å¾®æœåŠ¡éƒ¨ç½²æœåŠ¡å™¨é›†ç¾¤ å®‰è£… Extended Choice Parameter æ’ä»¶ï¼Œå®ç°å¤šä¸ªå¾®æœåŠ¡åŒæ—¶æ„å»º åœ¨åˆ›å»ºæµæ°´çº¿æ—¶è®¾ç½®é€‰é¡¹ å°†å…¬é’¥ä¸‹å‘ï¼Œå¹¶åœ¨ç³»ç»Ÿè®¾ç½®çš„ Publish over SSH ä¸­æ·»åŠ å¤šå°ä¸»æœº åœ¨æµæ°´çº¿å·¥ç¨‹ä¸­æ·»åŠ å¤šä¸€ä¸ªå¤šé€‰é¡¹é…ç½®ï¼Œç”¨äºé€‰æ‹©è¦éƒ¨ç½²çš„æœåŠ¡å™¨ ä¿®æ”¹æµæ°´çº¿è¯­æ³• 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475// gitå‡­è¯iddef git_auth = &quot;bad37d0d-7260-43a2-a350-9abf6e99753a&quot;// gitå‡­è¯urldef git_url = &quot;http://192.168.88.30/test_group/test_project.git&quot;// Harboråœ°å€def harbor_url = &quot;192.168.88.30:81&quot;// é•œåƒä»“åº“åç§°def harbor_repository = &quot;test&quot;// Harborç”¨æˆ·å‡­è¯IDdef harbor_auth = &quot;c147d241-a254-48d6-be1c-0d5f0964ce9a&quot;// é•œåƒç‰ˆæœ¬å·def image_version = &quot;1.0&quot;node { // è·å–æœåŠ¡å def selectedProjectNames = &quot;${project_name}&quot;.split(&quot;,&quot;) // è·å–é›†ç¾¤åœ°å€ def selectedServices = &quot;${publish_server}&quot;.split(&quot;,&quot;) // æ‹‰å–ä»£ç  stage('Pull Code') { git branch: &quot;${branch}&quot;, credentialsId: &quot;${git_auth}&quot;, url: &quot;${git_url}&quot; } // ç¼–è¯‘ï¼Œæ‰“åŒ…å¾®æœåŠ¡å·¥ç¨‹ï¼Œæ„å»ºé•œåƒ stage('Mvn clean package and Docker build') { sh &quot;mvn clean package dockerfile:build&quot; } // ä¸Šä¼ é•œåƒè‡³Harbor stage('Push image to Harbor') { for(int i=0; i&lt;selectedProjectNames.length; i++) { // è·å–æ¯ä¸ªé€‰é¡¹ def project_info = selectedProjectNames[i] // è·å–é€‰é¡¹ä¸­çš„å¾®æœåŠ¡åç§° def current_project_name = &quot;${project_info}&quot;.split(&quot;@&quot;)[0] // é•œåƒå‘½åï¼Œæ‰“æ ‡ç­¾ def image_name = &quot;${current_project_name}:${image_version}&quot; sh &quot;docker tag ${current_project_name}:latest ${harbor_url}/${harbor_repository}/${image_name} &amp;&amp; docker rmi ${current_project_name}:latest&quot; // ç™»å½•Harborä»“åº“ withCredentials([usernamePassword(credentialsId: &quot;${harbor_auth}&quot;, passwordVariable: 'harbor_password', usernameVariable: 'harbor_user')]) { sh &quot;docker login -u ${harbor_user} -p ${harbor_password} ${harbor_url}&quot; } // é•œåƒä¸Šä¼  sh &quot;docker push ${harbor_url}/${harbor_repository}/${current_project_name}:${image_version}&quot; } } // è¿œç¨‹è¿æ¥æœåŠ¡å™¨æ‹‰å–é•œåƒè¿è¡Œ stage('Pull image and Running container') { for(int i=0; i&lt;selectedProjectNames.length; i++) { // è·å–æ¯ä¸ªé€‰é¡¹ def project_info = selectedProjectNames[i] // è·å–é€‰é¡¹ä¸­çš„å¾®æœåŠ¡åç§° def current_project_name = &quot;${project_info}&quot;.split(&quot;@&quot;)[0] // è·å–é€‰é¡¹ä¸­çš„å¾®æœåŠ¡æ‰€éœ€ç«¯å£ def current_project_port = &quot;${project_info}&quot;.split(&quot;@&quot;)[1] // éœ€è¦æ‹‰å–çš„é•œåƒ def image_name = &quot;${current_project_name}:${image_version}&quot; // éå†æ‰€æœ‰æœåŠ¡å™¨ï¼Œåˆ†åˆ«éƒ¨ç½² for(int j=0; j&lt;selectedServices.length; j++) { // è·å–å½“å‰æœåŠ¡å™¨ def current_server = selectedServices[j] // åŠ ä¸Šå‚æ•°é…ç½®ï¼Œæ ¹æ®é…ç½®æ–‡ä»¶çš„ä¸åŒé€‰æ‹©ä¸åŒçš„æœåŠ¡å™¨éƒ¨ç½² if(current_server == &quot;192.168.88.31&quot;) { activeProfile = activeProfile+&quot;serviceName-server1&quot; }else if(current_server == &quot;192.168.88.32&quot;) { activeProfile = activeProfile+&quot;serviceName-server2&quot; } // è¿œç¨‹æ‰§è¡Œè„šæœ¬ sshPublisher(publishers: [sshPublisherDesc(configName: &quot;${current_server}&quot;, transfers: [sshTransfer(cleanRemote: false, excludes: '', execCommand: './root/test.sh $harbor_url $current_project_name $harbor_url/$harbor_repository/$image_name $current_project_port $activeProfile', execTimeout: 120000, flatten: false, makeEmptyDirs: false, noDefaultExcludes: false, patternSeparator: '[, ]+', remoteDirectory: '', remoteDirectorySDF: false, removePrefix: '', sourceFiles: '')], usePromotionTimestamp: false, useWorkspaceInPromotion: false, verbose: false)]) } } }} ä¿®æ”¹ test.sh 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#!/bin/bashharbor_url=$1project_name=$2image_name=$3service_port=$4profile=$6# åˆ é™¤noneå®¹å™¨echo &quot;docker rmi none...&quot;docker images | grep none | awk '{ print &quot;docker rmi &quot;$3 }' | sh &amp;&gt;/dev/null# æ£€æŸ¥æ˜¯å¦æœ‰å·²è¿è¡Œå®¹å™¨num=`docker ps | grep $project_name | wc -l`if [ $num -gt 0 ]then docker stop $project_name &amp;&amp; docker rm $project_name &amp;&gt;/dev/null if [ `echo $?` -eq 0 ] then echo &quot;docker stop $project_name &amp;&amp; docker rm $project_name [OK]&quot; else echo &quot;ERROR: docker stop $project_name &amp;&amp; docker rm $project_name&quot; fifi# æ£€æŸ¥æ˜¯å¦æœ‰é‡å‘½åé•œåƒtemp=`docker images | grep $image_name | awk '{ print $1&quot;:&quot;$2 }' | wc -l`if [ $temp -eq 1 ]then docker rmi $image_name &amp;&gt;/dev/null if [ `echo $?` -eq 0 ] then echo &quot;docker rmi $image_name [OK]&quot; else echo &quot;ERROR: docker rmi $image_name&quot; fifi# ç™»å½•é•œåƒä»“åº“echo &quot;docker login repository...&quot;docker login -u admin -p toortoor $harbor_url &amp;&gt;/dev/nullif [ `echo $?` -ne 0 ]then echo &quot;ERROR: failed to login repository&quot;else echo &quot;docker login repository [OK]&quot;fi# æ‹‰å–é•œåƒecho &quot;docker pull image...&quot;docker pull $image_name &amp;&gt;/dev/nullif [ `echo $?` -ne 0 ]then echo &quot;ERROR: failed to pull image&quot;else echo &quot;docker pull image [OK]&quot;fi# è¿è¡Œå®¹å™¨echo &quot;docker run container...&quot;docker run -d --name $project_name -p $service_port:8080 $image_name $profile &amp;&gt;/dev/nullif [ `echo $?` -ne 0 ]then echo &quot;ERROR: failed to run container&quot;else echo &quot;docker run container [OK]&quot;fi ä¸ƒã€åŸºäºK8Sçš„CICDåŸºäº Kubernetes å¹³å°æ¥å®ç° CICD åŠŸèƒ½ã€‚ 7.1 Jenkinså¯¹æ¥K8S é¦–å…ˆé€šè¿‡ bitnami helm éƒ¨ç½² Jenkinsï¼ˆMasterï¼‰ï¼Œéœ€å¼€æ”¾ jnlp 50000 ç«¯å£ 1234567# æ·»åŠ repoæºhelm repo add bitnami https://charts.bitnami.com/bitnami# ä¸‹è½½chartåˆ°æœ¬åœ°helm pull bitnami/jenkins# æ ¹æ®éœ€æ±‚ä¿®æ”¹values.yaml# éƒ¨ç½²helm install jenkins jeknins/ RBAC æˆæƒï¼ŒSA åä¸º jenkinsï¼Œåç»­ä¼šç”¨åˆ° 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647apiVersion: v1kind: ServiceAccountmetadata: name: jenkins namespace: nextcloud---kind: RoleapiVersion: rbac.authorization.k8s.io/v1beta1metadata: name: jenkins namespace: nextcloudrules: - apiGroups: [&quot;&quot;] resources: [&quot;pods&quot;] verbs: [&quot;create&quot;,&quot;delete&quot;,&quot;get&quot;,&quot;list&quot;,&quot;patch&quot;,&quot;update&quot;,&quot;watch&quot;] - apiGroups: [&quot;&quot;] resources: [&quot;pods/exec&quot;] verbs: [&quot;create&quot;,&quot;delete&quot;,&quot;get&quot;,&quot;list&quot;,&quot;patch&quot;,&quot;update&quot;,&quot;watch&quot;] - apiGroups: [&quot;&quot;] resources: [&quot;pods/log&quot;] verbs: [&quot;get&quot;,&quot;list&quot;,&quot;watch&quot;] - apiGroups: [&quot;&quot;] resources: [&quot;secrets&quot;] verbs: [&quot;get&quot;] - apiGroups: [&quot;extensions&quot;, &quot;apps&quot;] resources: [&quot;deployments&quot;] verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;] - apiGroups: [&quot;&quot;] resources: [&quot;services&quot;] verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;]---apiVersion: rbac.authorization.k8s.io/v1beta1kind: RoleBindingmetadata: name: jenkins namespace: nextcloudroleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: jenkinssubjects: - kind: ServiceAccount name: jenkins namespace: nextcloud è·å–åˆšåˆšåˆ›å»ºçš„ ca.crt ä¿¡æ¯ 1kubectl get secret jenkins-token-xxx -oyaml | awk '/ca.crt/{ print $2 }' | base64 -d åœ¨ Jenkins åˆ›å»ºå‡­æ® æ·»åŠ äº‘ï¼Œè¿™é‡Œç”¨åˆ°åˆšåˆšåˆ›å»ºçš„å‡­æ® è®¾ç½® Pod Templateï¼Œå³ Jenkins Slaveï¼Œå°†åŒ…å« jnlp ä¸€ä¸ªå®¹å™¨ï¼Œæ¥å®ç°ç¼–è¯‘æ‰“åŒ…ç­‰åŠŸèƒ½ã€‚ è¿™é‡Œéœ€æŒ‚è½½å®¿ä¸»æœºçš„ docker.sockã€docker å’Œ kubectl çš„äºŒè¿›åˆ¶æ–‡ä»¶ã€‚ ç„¶åä½¿ç”¨åˆ°åˆšåˆšåˆ›å»ºçš„ SAã€‚ æµ‹è¯•é“¾æ¥ã€‚ 7.2 æ„å»ºå‰å‡†å¤‡éœ€è¦åœ¨é¡¹ç›®çš„æ ¹ç›®å½•ä¸‹å‡†å¤‡å¥½ Dockerfileã€Jenkinsfileã€deploy.yamlã€‚ Jenkinsfile 123456789101112131415161718192021222324252627282930313233343536373839404142// gitlabåŠharburå‡­æ®è®¤è¯ç­‰ä¿¡æ¯def git_auth = &quot;764f29f3-8955-4551-a23a-659aa4c8deaa&quot;def git_url = &quot;http://192.168.159.12:30098/root/nextcloud.git&quot;def harbor_url = &quot;192.168.159.101&quot;def harbor_repository = &quot;nextcloud&quot;def harbor_auth = &quot;7ebc36f8-73a3-417f-864f-24856490b1a2&quot;def project_name = &quot;nextcloud&quot;// jenkins-slaveä¸ºpod templateä¸­çš„namenode('jenkins-slave') { // jnlpä¸ºpod templateä¸­çš„å®¹å™¨åç§° container('jnlp') { // pipelineæ­¥éª¤ stage('Git Clone') { git branch: &quot;${branch}&quot;, credentialsId: &quot;${git_auth}&quot;, url: &quot;${git_url}&quot; } stage('Docker Build') { sh &quot;docker build -t ${harbor_url}/${harbor_repository}/${project_name}:${branch}-${version} .&quot; } stage('Docker Push') { withCredentials([usernamePassword(credentialsId: &quot;${harbor_auth}&quot;, passwordVariable: 'harbor_password', usernameVariable: 'harbor_user')]) { sh &quot;docker login -u ${harbor_user} -p ${harbor_password} ${harbor_url}&quot; } sh &quot;docker push ${harbor_url}/${harbor_repository}/${project_name}:${branch}-${version}&quot; sh &quot;docker rmi ${harbor_url}/${harbor_repository}/${project_name}:${branch}-${version}&quot; } } // åœ¨deploy.yamlä¸­å°†é•œåƒtagè®¾ä¸ºäº†build-tag,æ–¹ä¾¿é€šè¿‡sedä¿®æ”¹ stage('Sed YAML') { sh &quot;sed -i 's#build-tag#${branch}-${version}#g' deploy.yaml&quot; } stage('Deploy to K8s') { sh &quot;kubectl apply -f deploy.yaml&quot; }} 7.3 åˆ›å»ºæµæ°´çº¿é¡¹ç›®è¿™é‡Œæ·»åŠ äº†ä¸¤ä¸ªå­—ç¬¦å‚æ•°ï¼Œç”¨äºæ„å»ºå‰é€‰æ‹©åˆ†æ”¯å’Œ tag çš„æ ‡ç­¾å®šä¹‰ã€‚ æ„å»ºæµ‹è¯•ï¼Œä¼šå‘ç°é›†ç¾¤ä¸­åˆ›å»ºäº†ä¸€ä¸ª jenkins-slave-xxx çš„ podï¼Œpod ä¸­åŒ…å« jnlp ä¸€ä¸ªå®¹å™¨ï¼Œé€šè¿‡è§‚å¯Ÿæ—¥å¿—å¯å‘ç°ä¸ Jenkins Master è¿›è¡Œäº†è¿æ¥ã€‚ Jenkins ä¸­æŸ¥çœ‹æµæ°´çº¿è¿›åº¦ã€‚ æµæ°´çº¿ç»“æŸåï¼Œé€šè¿‡ kubectl å¯çœ‹åˆ°é¡¹ç›®å·²éƒ¨ç½²ï¼Œä¸”ä½¿ç”¨çš„é•œåƒæ˜¯åˆšåˆšæ„å»ºå¥½çš„ã€‚","link":"/2024/02/18/jenkins/"},{"title":"etcd leaderé€‰ä¸¾","text":"etcd æ˜¯åŸºäº raft ç®—æ³•è¿›è¡Œé€‰ä¸¾ï¼Œè€Œ raft æ˜¯ä¸€ç§ç®¡ç†æ—¥å¿—ä¸€è‡´æ€§çš„åè®®ï¼Œå°†ç³»ç»Ÿä¸­çš„è§’è‰²åˆ†ä¸ºä¸‰ä¸ª leader: æ¥å—å®¢æˆ·ç«¯çš„è¯·æ±‚ï¼Œå¹¶å‘ follower å‘é€åŒæ­¥è¯·æ±‚æ—¥å¿— follower: æ¥æ”¶ leader åŒæ­¥çš„æ—¥å¿— candidate: å€™é€‰è€…è§’è‰²ï¼Œåœ¨é€‰ä¸¾è¿‡ç¨‹ä¸­å‘æŒ¥ä½œç”¨ leader é€‰ä¸¾ raft æ˜¯é€šè¿‡å¿ƒè·³æœºåˆ¶æ¥è§¦å‘ leader çš„é€‰ä¸¾ï¼Œæ¯ä¸€ä¸ªå®ä¾‹(ä¾‹å¦‚ etcd pod)å¯åŠ¨åéƒ½ä¼šåˆå§‹åŒ–ä¸ºä¸€ä¸ª followerï¼Œleader åˆ™ä¼šå‘¨æœŸæ€§çš„å‘æ‰€æœ‰ follower å‘é€å¿ƒè·³åŒ…ï¼Œåœ¨ etcd çš„ç¼–æ’ä¸­å°±èƒ½çœ‹åˆ°ç›¸å…³çš„å‚æ•° å¦‚æœ follower å¦‚æœåœ¨é€‰ä¸¾è¶…æ—¶æ—¶é—´å†…æ²¡æœ‰æ”¶åˆ° leader çš„å¿ƒè·³åŒ…ï¼Œå°±ä¼šç­‰å¾…ä¸€ä¸ªéšæœºçš„æ—¶é—´ï¼Œç„¶åå‘èµ· leader é€‰ä¸¾ã€‚æ¯ä¸ª follower éƒ½æœ‰ä¸€ä¸ªæ—¶é’Ÿï¼Œè¿™ä¸ªæ—¶é’Ÿæ˜¯ä¸€ä¸ªéšæœºçš„å€¼ï¼Œé›†ç¾¤ä¸­è°çš„æ—¶é’Ÿå…ˆè·‘å®Œï¼Œé‚£ä¹ˆå°±ç”±è°æ¥å‘èµ· leader é€‰ä¸¾ è¯¥ follower ä¼šå°†å½“å‰çš„ä»»æœŸ(term) + 1 ç„¶åè½¬åŒ–ä¸º candidateï¼Œå…ˆç»™è‡ªå·±æŠ•ç¥¨ç„¶åå‘é›†ç¾¤ä¸­çš„å…¶ä»– follower å‘é€ RequestVote RPC é‚£ä¹ˆæœ€ç»ˆçš„ç»“æœä¼šæœ‰ä¸‰ç§: è‡ªå·±èµ¢å¾—äº†æœ€å¤šçš„ç¥¨æ•°ï¼Œæˆä¸º leader æ”¶åˆ°äº† leader çš„æ¶ˆæ¯ï¼Œè¡¨ç¤ºå·²ç»æœ‰å…¶ä»–æœåŠ¡æŠ¢å…ˆæˆä¸ºäº† leader æ²¡æœ‰æœåŠ¡è·å¾—æœ€é«˜ç¥¨æ•°ï¼Œå³é€‰ä¸¾å¤±è´¥ï¼Œä¼šç­‰å¾…é€‰ä¸¾æ—¶é—´è¶…æ—¶åè¿›è¡Œä¸‹ä¸€æ¬¡é€‰ä¸¾ åœ¨ raft åè®®ä¸­ï¼Œæ‰€æœ‰çš„æ—¥å¿—æ¡ç›®éƒ½åªä¼šæ˜¯ leader å¾€ follower å†™å…¥ï¼Œä¸” leader çš„æ—¥å¿—åªå¢ä¸å‡ï¼Œæ‰€ä»¥èƒ½è¢«é€‰ä¸¾æˆä¸º leader çš„èŠ‚ç‚¹ï¼Œä¸€å®šåŒ…å«äº†æ‰€æœ‰å·²ç»æäº¤çš„æ—¥å¿—æ¡ç›®","link":"/2024/03/19/etcd-leader%E9%80%89%E4%B8%BE/"},{"title":"kube-proxyå·¥ä½œåŸç†","text":"kube-proxy ä»¥ DaemonSet çš„å½¢å¼è¿è¡Œåœ¨é›†ç¾¤çš„æ‰€æœ‰èŠ‚ç‚¹ä¸­ï¼Œè´Ÿè´£ç®¡ç†é›†ç¾¤å¤–åˆ° Serviceï¼Œä»¥åŠ Service åˆ° Pod çš„æµé‡è½¬å‘ã€‚ kube-proxy æœ‰ä¸‰ç§æ¨¡å¼: userspace iptables ipvs åœ¨è¿è¡Œäº† kube-proxy çš„èŠ‚ç‚¹ä¸Šï¼Œå¯ä»¥é€šè¿‡ä¸‹é¢çš„å‘½ä»¤æŸ¥çœ‹ kube-proxy çš„è¿è¡Œæ¨¡å¼: 1curl localhost:10249/proxyMode iptablesé€šè¿‡ kube-proxy çš„ cm å¯ä»¥æŸ¥çœ‹ mode æˆ‘ä»¬éƒ½çŸ¥é“ SVC æœ‰å¤šç§ç±»å‹ï¼Œå¸¸ç”¨çš„æœ‰ ClusterIPã€NodePortã€Headlessã€LoadBalancer ç­‰ç­‰ï¼Œè¿™é‡Œæˆ‘ä»¬é€šè¿‡åˆ›å»ºç±»å‹çš„ SVCï¼ŒæŸ¥çœ‹ kube-proxy ä¸‹å‘çš„iptables è§„åˆ™ ClusterIP é€šè¿‡ iptables-save å‘½ä»¤æ‰“å°è¿™ä¸ª SVC çš„è§„åˆ™ PodIP: 10.233.74.106ClusterIP: 10.233.54.175 1234567891011121314# å°†æ¥è‡ª Pod IP 10.233.74.106 çš„æµé‡æ ‡è®°ä¸ºæœåŠ¡ default/nginxï¼Œå¹¶è½¬å‘åˆ° KUBE-MARK-MASQ é“¾ä¸­-A KUBE-SEP-EUB75IW55XDW6EHN -s 10.233.74.106/32 -m comment --comment &quot;default/nginx:tcp-80&quot; -j KUBE-MARK-MASQ# å°†åŒ¹é…çš„ TCP æµé‡è¿›è¡Œ DNATï¼Œè½¬å‘åˆ°åç«¯ Pod 10.233.74.106:80-A KUBE-SEP-EUB75IW55XDW6EHN -p tcp -m comment --comment &quot;default/nginx:tcp-80&quot; -m tcp -j DNAT --to-destination 10.233.74.106:80# åŒ¹é…ç›®æ ‡åœ°å€ä¸ºæœåŠ¡ default/nginx çš„ cluster IP 10.233.54.175 çš„ TCP 80 ç«¯å£æµé‡-A KUBE-SERVICES -d 10.233.54.175/32 -p tcp -m comment --comment &quot;default/nginx:tcp-80 cluster IP&quot; -m tcp --dport 80 -j KUBE-SVC-XX3NNXKPRC7N6OJH# æ ‡è®°æ¥è‡ªå¤–éƒ¨ç½‘ç»œï¼ˆé™¤äº† PodCIDR 10.233.64.0/18ï¼‰çš„ã€ç›®æ ‡åœ°å€ä¸ºæœåŠ¡ default/nginx çš„ cluster IP 10.233.54.175 çš„ TCP 80 ç«¯å£çš„æµé‡-A KUBE-SVC-XX3NNXKPRC7N6OJH ! -s 10.233.64.0/18 -d 10.233.54.175/32 -p tcp -m comment --comment &quot;default/nginx:tcp-80 cluster IP&quot; -m tcp --dport 80 -j KUBE-MARK-MASQ# å°†åŒ¹é…çš„æµé‡è½¬å‘åˆ° KUBE-SEP-EUB75IW55XDW6EHN é“¾ä¸­ï¼Œè¿›è¡Œ DNAT åœ°å€è½¬æ¢-A KUBE-SVC-XX3NNXKPRC7N6OJH -m comment --comment &quot;default/nginx:tcp-80 -&gt; 10.233.74.106:80&quot; -j KUBE-SEP-EUB75IW55XDW6EHN NodePort æŠŠè¿™ä¸ª SVC ç±»å‹æ”¹æˆ NodePort é€šè¿‡ iptables-save å‘½ä»¤æ‰“å°è¿™ä¸ª SVC çš„è§„åˆ™ï¼Œå¤šäº†ä¸¤æ¡è§„åˆ™ 12345# ç”¨äºæ ‡è®°æ¥è‡ªå¤–éƒ¨çš„ã€ç›®æ ‡åœ°å€ä¸ºæœåŠ¡ default/nginx çš„ NodePort æµé‡-A KUBE-EXT-XX3NNXKPRC7N6OJH -m comment --comment &quot;masquerade traffic for default/nginx:tcp-80 external destinations&quot; -j KUBE-MARK-MASQ# ç”¨äºåŒ¹é…ç›®æ ‡ç«¯å£ä¸º 32594 çš„ TCP æµé‡ï¼Œå¹¶å°†è¯¥æµé‡è½¬å‘åˆ°ä¸Šé¢çš„è§„åˆ™è¿›è¡Œ MASQ æ ‡è®°-A KUBE-NODEPORTS -p tcp -m comment --comment &quot;default/nginx:tcp-80&quot; -m tcp --dport 32594 -j KUBE-EXT-XX3NNXKPRC7N6OJH IPVSé€šè¿‡ kube-proxy çš„ cm å¯ä»¥æŸ¥çœ‹ mode æ¥è‡ª GPT çš„å›ç­”: IPVS æ˜¯ Linux å†…æ ¸ä¸­å®ç°çš„è™šæ‹ŸæœåŠ¡å™¨æŠ€æœ¯ï¼Œå®ƒå¯ä»¥å°†ç½‘ç»œæµé‡è´Ÿè½½å‡è¡¡åˆ°å¤šå°æœåŠ¡å™¨ä¸Šï¼Œä»è€Œæé«˜æœåŠ¡æ€§èƒ½å’Œå¯é æ€§ã€‚ ClusterIP PodIP: 10.233.76.138ClusterIP: 10.233.27.36 é€šè¿‡ ipvsadm å‘½ä»¤æŸ¥çœ‹è¿™ä¸ªè™šæ‹ŸæœåŠ¡å™¨ 12345678910Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConn# å°†ç›®æ ‡åœ°å€ä¸º nginx.default.svc.cluster.lo:80 çš„ TCP æµé‡è½¬å‘åˆ°åç«¯ Pod 10.233.76.138:80TCP nginx.default.svc.cluster.lo rr -&gt; 10-233-76-138.nginx.default. Masq 1 0 0# å°†ç›®æ ‡åœ°å€ä¸º 10.233.27.36:80 çš„ TCP æµé‡è½¬å‘åˆ°åç«¯ Pod 10.233.76.138:80TCP 10.233.27.36:80 rr -&gt; 10.233.76.138:80 Masq 1 0 0 NodePort é€šè¿‡ ipvsadm å‘½ä»¤æŸ¥çœ‹è¿™ä¸ªè™šæ‹ŸæœåŠ¡å™¨ï¼Œå¤šäº†ä¸‰æ¡è§„åˆ™ 1234567891011# 10.233.74.64 ä¸º nodelocaldns ç½‘å¡çš„ IPï¼Œç”±äº NodePort æ˜¯å…¨ç›‘å¬ï¼Œæ‰€ä»¥ä¹Ÿæœ‰å¯¹åº”çš„è§„åˆ™TCP 169.254.25.10:30229 rr -&gt; 10.233.76.138:80 Masq 1 0 0# èŠ‚ç‚¹IPTCP 192.168.159.11:30229 rr -&gt; 10.233.76.138:80 Masq 1 0 0# 10.233.74.64 ä¸º tun0 ç½‘å¡çš„ IPï¼Œç”±äº NodePort æ˜¯å…¨ç›‘å¬ï¼Œæ‰€ä»¥ä¹Ÿæœ‰å¯¹åº”çš„è§„åˆ™TCP 10.233.74.64:30229 rr -&gt; 10.233.76.138:80 Masq 1 0","link":"/2024/03/30/kube-proxy%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/"},{"title":"Kubernetes","text":"ä¸€ã€æ¦‚å¿µ1.1 k8sæ¦‚è¿°Kubernetes æ˜¯ä¸€ä¸ªå¯ç§»æ¤çš„ã€å¯æ‰©å±•çš„å¼€æºå¹³å°ï¼Œç”¨äºç®¡ç†å®¹å™¨åŒ–çš„å·¥ä½œè´Ÿè½½å’ŒæœåŠ¡ï¼Œå¯ä¿ƒè¿›å£°æ˜å¼é…ç½®å’Œè‡ªåŠ¨åŒ–ã€‚ Kubernetes æ‹¥æœ‰ä¸€ä¸ªåºå¤§ä¸”å¿«é€Ÿå¢é•¿çš„ç”Ÿæ€ç³»ç»Ÿã€‚Kubernetes çš„æœåŠ¡ã€æ”¯æŒå’Œå·¥å…·å¹¿æ³›å¯ç”¨ã€‚ å®¹å™¨æ˜¯æ‰“åŒ…å’Œè¿è¡Œåº”ç”¨ç¨‹åºçš„å¥½æ–¹å¼ã€‚åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œä½ éœ€è¦ç®¡ç†è¿è¡Œåº”ç”¨ç¨‹åºçš„å®¹å™¨ï¼Œå¹¶ç¡®ä¿ä¸ä¼šåœæœºã€‚ ä¾‹å¦‚ï¼Œå¦‚æœä¸€ä¸ªå®¹å™¨å‘ç”Ÿæ•…éšœï¼Œåˆ™éœ€è¦å¯åŠ¨å¦ä¸€ä¸ªå®¹å™¨ã€‚å¦‚æœç³»ç»Ÿå¤„ç†æ­¤è¡Œä¸ºï¼Œä¼šä¸ä¼šæ›´å®¹æ˜“ï¼Ÿ è¿™å°±æ˜¯ Kubernetes æ¥è§£å†³è¿™äº›é—®é¢˜çš„æ–¹æ³•ï¼ Kubernetes ä¸ºä½ æä¾›äº†ä¸€ä¸ªå¯å¼¹æ€§è¿è¡Œåˆ†å¸ƒå¼ç³»ç»Ÿçš„æ¡†æ¶ã€‚ Kubernetes ä¼šæ»¡è¶³ä½ çš„æ‰©å±•è¦æ±‚ã€æ•…éšœè½¬ç§»ã€éƒ¨ç½²æ¨¡å¼ç­‰ã€‚ ä¾‹å¦‚ï¼ŒKubernetes å¯ä»¥è½»æ¾ç®¡ç†ç³»ç»Ÿçš„ Canary éƒ¨ç½²ã€‚ Kubernetes ç®€ç§° k8sï¼Œä¸»è¦åŠŸèƒ½æœ‰ï¼š æœåŠ¡å‘ç°å’Œè´Ÿè½½å‡è¡¡ å­˜å‚¨ç¼–æ’ è‡ªåŠ¨éƒ¨ç½²å’Œå›æ»š è‡ªåŠ¨å®Œæˆè£…ç®±è®¡ç®— è‡ªæˆ‘ä¿®å¤ å¯†é’¥ä¸é…ç½®ç®¡ç† 1.2 k8sç»„ä»¶ä¸€ä¸ª Kubernetes é›†ç¾¤ç”±ä¸€ç»„è¢«ç§°ä½œèŠ‚ç‚¹çš„æœºå™¨ç»„æˆã€‚è¿™äº›èŠ‚ç‚¹ä¸Šè¿è¡Œ Kubernetes æ‰€ç®¡ç†çš„å®¹å™¨åŒ–åº”ç”¨ã€‚é›†ç¾¤å…·æœ‰è‡³å°‘ä¸€ä¸ªå·¥ä½œèŠ‚ç‚¹ã€‚ å·¥ä½œèŠ‚ç‚¹æ‰˜ç®¡ä½œä¸ºåº”ç”¨è´Ÿè½½çš„ç»„ä»¶çš„ Pod ã€‚æ§åˆ¶å¹³é¢ç®¡ç†é›†ç¾¤ä¸­çš„å·¥ä½œèŠ‚ç‚¹å’Œ Pod ã€‚ ä¸ºé›†ç¾¤æä¾›æ•…éšœè½¬ç§»å’Œé«˜å¯ç”¨æ€§ï¼Œè¿™äº›æ§åˆ¶å¹³é¢ä¸€èˆ¬è·¨å¤šä¸»æœºè¿è¡Œï¼Œé›†ç¾¤è·¨å¤šä¸ªèŠ‚ç‚¹è¿è¡Œã€‚ 1.2.1 æ§åˆ¶å¹³é¢ç»„ä»¶kube-apiserverï¼š API æœåŠ¡å™¨æ˜¯ Kubernetes æ§åˆ¶é¢çš„ç»„ä»¶ï¼Œè¯¥ç»„ä»¶å…¬å¼€äº† Kubernetes APIã€‚API æœåŠ¡å™¨æ˜¯ Kubernetes æ§åˆ¶é¢çš„å‰ç«¯ã€‚ etcdï¼š etcd æ˜¯å…¼å…·ä¸€è‡´æ€§å’Œé«˜å¯ç”¨æ€§çš„é”®å€¼æ•°æ®åº“ï¼Œå¯ä»¥ä½œä¸ºä¿å­˜ Kubernetes æ‰€æœ‰é›†ç¾¤æ•°æ®çš„åå°æ•°æ®åº“ã€‚ kube-schedulerï¼š æ§åˆ¶å¹³é¢ç»„ä»¶ï¼Œè´Ÿè´£ç›‘è§†æ–°åˆ›å»ºçš„ã€æœªæŒ‡å®šè¿è¡ŒèŠ‚ç‚¹ï¼ˆnodeï¼‰çš„ Podsï¼Œé€‰æ‹©èŠ‚ç‚¹è®© Pod åœ¨ä¸Šé¢è¿è¡Œã€‚ è°ƒåº¦å†³ç­–è€ƒè™‘çš„å› ç´ åŒ…æ‹¬å•ä¸ª Pod å’Œ Pod é›†åˆçš„èµ„æºéœ€æ±‚ã€ç¡¬ä»¶/è½¯ä»¶/ç­–ç•¥çº¦æŸã€äº²å’Œæ€§å’Œåäº²å’Œæ€§è§„èŒƒã€æ•°æ®ä½ç½®ã€å·¥ä½œè´Ÿè½½é—´çš„å¹²æ‰°å’Œæœ€åæ—¶é™ã€‚ kube-controller-managerï¼š åœ¨ä¸»èŠ‚ç‚¹ä¸Šè¿è¡Œæ§åˆ¶å™¨çš„ç»„ä»¶ã€‚ æ§åˆ¶å™¨åŒ…æ‹¬ï¼š èŠ‚ç‚¹æ§åˆ¶å™¨ï¼ˆNode Controllerï¼‰: è´Ÿè´£åœ¨èŠ‚ç‚¹å‡ºç°æ•…éšœæ—¶è¿›è¡Œé€šçŸ¥å’Œå“åº” ä»»åŠ¡æ§åˆ¶å™¨ï¼ˆJob controllerï¼‰: ç›‘æµ‹ä»£è¡¨ä¸€æ¬¡æ€§ä»»åŠ¡çš„ Job å¯¹è±¡ï¼Œç„¶ååˆ›å»º Pods æ¥è¿è¡Œè¿™äº›ä»»åŠ¡ç›´è‡³å®Œæˆ ç«¯ç‚¹æ§åˆ¶å™¨ï¼ˆEndpoints Controllerï¼‰: å¡«å……ç«¯ç‚¹(Endpoints)å¯¹è±¡(å³åŠ å…¥ Service ä¸ Pod) æœåŠ¡å¸æˆ·å’Œä»¤ç‰Œæ§åˆ¶å™¨ï¼ˆService Account &amp; Token Controllersï¼‰: ä¸ºæ–°çš„å‘½åç©ºé—´åˆ›å»ºé»˜è®¤å¸æˆ·å’Œ API è®¿é—®ä»¤ç‰Œ cloud-controller-managerï¼š äº‘æ§åˆ¶å™¨ç®¡ç†å™¨æ˜¯æŒ‡åµŒå…¥ç‰¹å®šäº‘çš„æ§åˆ¶é€»è¾‘çš„æ§åˆ¶å¹³é¢ç»„ä»¶ã€‚äº‘æ§åˆ¶å™¨ç®¡ç†å™¨å…è®¸æ‚¨é“¾æ¥èšåˆåˆ°äº‘æä¾›å•†çš„åº”ç”¨ç¼–ç¨‹æ¥å£ä¸­ï¼Œå¹¶åˆ†ç¦»å‡ºç›¸äº’ä½œç”¨çš„ç»„ä»¶ä¸æ‚¨çš„é›†ç¾¤äº¤äº’çš„ç»„ä»¶ã€‚ ä¸‹é¢çš„æ§åˆ¶å™¨éƒ½åŒ…å«å¯¹äº‘å¹³å°é©±åŠ¨çš„ä¾èµ–ï¼š èŠ‚ç‚¹æ§åˆ¶å™¨ï¼ˆNode Controllerï¼‰: ç”¨äºåœ¨èŠ‚ç‚¹ç»ˆæ­¢å“åº”åæ£€æŸ¥äº‘æä¾›å•†ä»¥ç¡®å®šèŠ‚ç‚¹æ˜¯å¦å·²è¢«åˆ é™¤ è·¯ç”±æ§åˆ¶å™¨ï¼ˆRoute Controllerï¼‰: ç”¨äºåœ¨åº•å±‚äº‘åŸºç¡€æ¶æ„ä¸­è®¾ç½®è·¯ç”± æœåŠ¡æ§åˆ¶å™¨ï¼ˆService Controllerï¼‰: ç”¨äºåˆ›å»ºã€æ›´æ–°å’Œåˆ é™¤äº‘æä¾›å•†è´Ÿè½½å‡è¡¡å™¨ 1.2.2 Nodeç»„ä»¶èŠ‚ç‚¹ç»„ä»¶åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šè¿è¡Œï¼Œç»´æŠ¤è¿è¡Œçš„ Pod å¹¶æä¾› Kubernetes è¿è¡Œç¯å¢ƒã€‚ kubeletï¼š ä¸€ä¸ªåœ¨é›†ç¾¤ä¸­æ¯ä¸ªèŠ‚ç‚¹ï¼ˆnodeï¼‰ä¸Šè¿è¡Œçš„ä»£ç†ã€‚å®ƒä¿è¯å®¹å™¨ï¼ˆcontainersï¼‰éƒ½è¿è¡Œåœ¨ Pod ä¸­ã€‚ kubelet æ¥æ”¶ä¸€ç»„é€šè¿‡å„ç±»æœºåˆ¶æä¾›ç»™å®ƒçš„ PodSpecsï¼Œç¡®ä¿è¿™äº› PodSpecs ä¸­æè¿°çš„å®¹å™¨å¤„äºè¿è¡ŒçŠ¶æ€ä¸”å¥åº·ã€‚ kubelet ä¸ä¼šç®¡ç†ä¸æ˜¯ç”± Kubernetes åˆ›å»ºçš„å®¹å™¨ã€‚ å®¹å™¨è¿è¡Œæ—¶ï¼ˆContainer Runtimeï¼‰ï¼š å®¹å™¨è¿è¡Œç¯å¢ƒæ˜¯è´Ÿè´£è¿è¡Œå®¹å™¨çš„è½¯ä»¶ï¼Œä¾‹å¦‚ Docker ã€‚ 1.2.3 æ’ä»¶ï¼ˆAddonsï¼‰æ’ä»¶ä½¿ç”¨ Kubernetes èµ„æºï¼ˆDaemonSetã€Deploymentç­‰ï¼‰å®ç°é›†ç¾¤åŠŸèƒ½ã€‚ å› ä¸ºè¿™äº›æ’ä»¶æä¾›é›†ç¾¤çº§åˆ«çš„åŠŸèƒ½ï¼Œæ’ä»¶ä¸­å‘½åç©ºé—´åŸŸçš„èµ„æºå±äº kube-system å‘½åç©ºé—´ã€‚ DNSï¼š å°½ç®¡å…¶ä»–æ’ä»¶éƒ½å¹¶éä¸¥æ ¼æ„ä¹‰ä¸Šçš„å¿…éœ€ç»„ä»¶ï¼Œä½†å‡ ä¹æ‰€æœ‰ Kubernetes é›†ç¾¤éƒ½åº”è¯¥ æœ‰é›†ç¾¤ DNSï¼Œ å› ä¸ºå¾ˆå¤šç¤ºä¾‹éƒ½éœ€è¦ DNS æœåŠ¡ã€‚ Web ç•Œé¢ï¼ˆä»ªè¡¨ç›˜ï¼‰ï¼š Dashboard æ˜¯Kubernetes é›†ç¾¤çš„é€šç”¨çš„ã€åŸºäº Web çš„ç”¨æˆ·ç•Œé¢ã€‚ å®ƒä½¿ç”¨æˆ·å¯ä»¥ç®¡ç†é›†ç¾¤ä¸­è¿è¡Œçš„åº”ç”¨ç¨‹åºä»¥åŠé›†ç¾¤æœ¬èº«å¹¶è¿›è¡Œæ•…éšœæ’é™¤ã€‚ å®¹å™¨èµ„æºç›‘æ§ï¼š å®¹å™¨èµ„æºç›‘æ§å°†å…³äºå®¹å™¨çš„ä¸€äº›å¸¸è§çš„æ—¶é—´åºåˆ—åº¦é‡å€¼ä¿å­˜åˆ°ä¸€ä¸ªé›†ä¸­çš„æ•°æ®åº“ä¸­ï¼Œå¹¶æä¾›ç”¨äºæµè§ˆè¿™äº›æ•°æ®çš„ç•Œé¢ã€‚ é›†ç¾¤å±‚é¢æ—¥å¿—ï¼š é›†ç¾¤å±‚é¢æ—¥å¿—æœºåˆ¶è´Ÿè´£å°†å®¹å™¨çš„æ—¥å¿—æ•°æ® ä¿å­˜åˆ°ä¸€ä¸ªé›†ä¸­çš„æ—¥å¿—å­˜å‚¨ä¸­ï¼Œè¯¥å­˜å‚¨èƒ½å¤Ÿæä¾›æœç´¢å’Œæµè§ˆæ¥å£ã€‚ 1.3 Pod1.3.1 Podæ¦‚å¿µPod æ˜¯ k8s ä¸­çš„æœ€å°å•å…ƒï¼Œä¸€ä¸ª Pod åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªå®¹å™¨ï¼Œä¸€ä¸ª Pod ä¸ä¼šè·¨è¶Šå¤šä¸ªèŠ‚ç‚¹ï¼ˆNodeï¼‰ã€‚ è€Œæ¯ä¸ª Pod é‡Œéƒ½ä¼šæœ‰ä¸€ä¸ªæ ¹å®¹å™¨ pauseï¼ŒPod ä¸­çš„å…¶ä»–å®¹å™¨éƒ½å…±äº« pause æ ¹å®¹å™¨çš„ç½‘ç»œæ ˆå’ŒvolumeæŒ‚è½½å·ï¼Œå› æ­¤å®¹å™¨ä¹‹é—´çš„é€šä¿¡å’Œæ•°æ®äº¤æ¢ä¼šæ›´ä¸ºé«˜æ•ˆã€‚ 1.3.2 RCã€RSã€Deploymentk8s ç®¡ç† Pod ä¸»è¦ç”¨åˆ°ä»¥ä¸‹ä¸‰ä¸ªç»„ä»¶ï¼š Replication Controllerï¼ˆRCï¼‰ï¼šç”¨æ¥ç¡®ä¿å®¹å™¨åº”ç”¨çš„å‰¯æœ¬æ•°å§‹ç»ˆä¿æŒåœ¨ç”¨æˆ·å®šä¹‰çš„å‰¯æœ¬æ•°ï¼Œå¦‚æœæœ‰å®¹å™¨å¼‚å¸¸é€€å‡ºï¼Œä¼šè‡ªåŠ¨åˆ›å»ºæ–°çš„ Pod æ¥ä»£æ›¿ï¼Œå¦‚æœæœ‰å¼‚å¸¸å¤šå‡ºçš„å®¹å™¨ä¹Ÿä¼šè‡ªåŠ¨å›æ”¶ã€‚ ReplicaSetï¼ˆRSï¼‰ï¼šç›¸æ¯” RC å¤šäº†æ”¯æŒ selectorï¼Œæ¨èä½¿ç”¨ RSã€‚ Deploymentï¼šç”¨æ¥ç®¡ç† RSã€‚ æ¥çœ‹çœ‹ Deployment å’Œ RS æ˜¯å¦‚ä½•å®ç°æ›´æ–°çš„ï¼š Deployment åˆ›å»ºæ–°çš„ RS RS1åˆ é™¤ä¸€ä¸ªå®¹å™¨ï¼Œæ¥ç€ RS2 æ–°å»ºä¸€ä¸ªæ–°ç‰ˆæœ¬çš„ Pod å…¨éƒ¨æ›´æ–°å®Œä¹‹åï¼ŒRS1 å¹¶ä¸ä¼šåˆ é™¤ï¼Œè€Œæ˜¯ä¿ç•™ç€å¤„äºåœç”¨çŠ¶æ€ï¼Œå¦‚æœæ–°ç‰ˆæœ¬å‡ºäº†é—®é¢˜éœ€è¦å›æ»šï¼Œå°±å¯ä»¥åè¿‡æ¥æ“ä½œå®ç°å›æ»š 1.3.3 Horizontal Pod AutoscalerHorizontal Pod Autoscalerï¼ˆHPAï¼‰åœ¨k8sé›†ç¾¤ä¸­ç”¨äº Pod æ°´å¹³è‡ªåŠ¨å¼¹æ€§ä¼¸ç¼©ï¼Œå®ƒæ˜¯åŸºäº CPU å’Œå†…å­˜åˆ©ç”¨ç‡å¯¹ Deployment å’Œ RS ä¸­çš„ Pod æ•°é‡è¿›è¡Œè‡ªåŠ¨æ‰©ç¼©å®¹ï¼ˆé™¤äº† CPU å’Œå†…å­˜åˆ©ç”¨ç‡ä¹‹å¤–ï¼Œä¹Ÿå¯ä»¥åŸºäºå…¶ä»–åº”ç¨‹åºæä¾›çš„åº¦é‡æŒ‡æ ‡ custom metrics è¿›è¡Œè‡ªåŠ¨æ‰©ç¼©å®¹ï¼‰ã€‚ å‡å¦‚ HPA æ£€æµ‹åˆ°å½“å‰ Deployment å’Œ RS æ‰€ç®¡ç†çš„ Pod çš„ CPU æˆ–å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡äº†è®¾å®šä¹‹åï¼Œå°±ä¼šåˆ›å»ºæ–°çš„ Pod æ¥å®ç°é™å‹ï¼Œæ–°å»º Pod çš„æ•°é‡é™åˆ¶ç”± Max å’Œ Min è®¾å®šã€‚ 1.3.4 StatefulSetRS å’Œ Deployment éƒ½æ˜¯é¢å‘æ— çŠ¶æ€çš„æœåŠ¡ï¼Œå®ƒä»¬æ‰€ç®¡ç†çš„ Pod çš„ IPã€åå­—ï¼Œå¯åœé¡ºåºç­‰éƒ½æ˜¯éšæœºçš„ï¼Œè€Œ StatefulSet æ˜¯æœ‰çŠ¶æ€çš„é›†åˆï¼Œç®¡ç†æ‰€æœ‰æœ‰çŠ¶æ€çš„æœåŠ¡ï¼Œæ¯”å¦‚ MySQLã€MongoDB é›†ç¾¤ç­‰ã€‚ StatefulSet çš„ç‰¹ç‚¹æœ‰ï¼š Pod çš„ä¸€è‡´æ€§ï¼šåŒ…å«æ¬¡åºï¼ˆå¯åœé¡ºåºï¼Œä¾‹å¦‚ mysql -&gt; php-fpm -&gt; nginx çš„å¯åŠ¨é¡ºåºï¼‰ã€ç½‘ç»œä¸€è‡´æ€§ï¼ˆä¸ Pod ç›¸å…³ï¼Œä¸è¢«è°ƒåº¦çš„ Node èŠ‚ç‚¹æ— å…³ï¼‰ã€‚ ç¨³å®šçš„å­˜å‚¨ï¼šå³ Pod é‡æ–°è°ƒåº¦ä¹‹åè¿˜æ˜¯è®¿é—®åˆ°ç›¸åŒçš„æŒä¹…åŒ–æ•°æ®ï¼ŒåŸºäº PVCï¼ˆPV æ˜¯é›†ç¾¤ä¸­ç”±ç®¡ç†å‘˜æä¾›æˆ–ä½¿ç”¨å­˜å‚¨ç±»åŠ¨æ€æä¾›çš„ä¸€å—å­˜å‚¨ã€‚å®ƒæ˜¯é›†ç¾¤ä¸­çš„èµ„æºï¼Œå°±åƒèŠ‚ç‚¹æ˜¯é›†ç¾¤èµ„æºä¸€æ ·ã€‚è€Œ PVC æ˜¯ç”¨æˆ·å¯¹å­˜å‚¨çš„è¯·æ±‚ã€‚å®ƒç±»ä¼¼äº Podï¼ŒPod æ¶ˆè€— Node èµ„æºï¼Œè€Œ PVC æ¶ˆè€— PV èµ„æºã€‚ï¼‰ æ¥å®ç°ã€‚ ç¨³å®šçš„æ¬¡åºï¼šå¯¹äºNä¸ªå‰¯æœ¬çš„ StatefulSetï¼Œæ¯ä¸ª Pod éƒ½åœ¨ [0ï¼ŒN) çš„èŒƒå›´å†…åˆ†é…ä¸€ä¸ªæ•°å­—åºå·ï¼Œä¸”æ˜¯å”¯ä¸€çš„ã€‚ ç¨³å®šçš„ç½‘ç»œï¼šPod çš„ hostname æ¨¡å¼ä¸ºï¼š( StatefulSet åç§° ) - ( åºå· )ã€‚ 1.3.5 DaemonSetDaemonSet ç¡®ä¿å…¨éƒ¨æˆ–è€…ä¸€éƒ¨åˆ† Node ä¸Šè¿è¡Œä¸€ä¸ª Pod çš„å‰¯æœ¬ï¼Œå½“æœ‰ Node åŠ å…¥é›†ç¾¤æ—¶ï¼Œä¹Ÿä¼šä¸ºä»–ä»¬æ–°å¢ä¸€ä¸ª Podï¼Œå½“è¿™äº› Node é€€å‡ºé›†ç¾¤æ—¶ï¼Œè¿™äº› Pod ä¹Ÿä¼šè¢«å›æ”¶ã€‚ DaemonSet çš„ä¸€äº›å…¸å‹ç”¨æ³•ï¼š è¿è¡Œé›†ç¾¤å­˜å‚¨ daemonï¼Œä¾‹å¦‚åœ¨æ¯ä¸ª Node ä¸Šè¿è¡Œ glusterdã€cephç­‰ã€‚ è¿è¡Œæ—¥å¿—æ”¶é›†daemonï¼Œä¾‹å¦‚fluentdã€logstashç­‰ã€‚ è¿è¡Œç›‘æ§daemonï¼Œä¾‹å¦‚ Prometheus çš„ Node exporterã€zabbixç­‰ã€‚ 1.3.6 Jobå’ŒCron JobJob è´Ÿè´£æ‰¹å¤„ç†ä»»åŠ¡ï¼Œå³ä»…æ‰§è¡Œä¸€æ¬¡çš„ä»»åŠ¡ï¼Œå®ƒä¿è¯æ‰¹å¤„ç†ä»»åŠ¡çš„ä¸€ä¸ªæˆ–å¤šä¸ª Pod æˆåŠŸç»“æŸã€‚ è¿™é‡Œå¯èƒ½æœ‰äººä¼šæƒ³ï¼Œé‚£åœ¨ linux ä¸Šç›´æ¥æ‰§è¡Œè„šæœ¬ä¸å°±è¡Œäº†å—ï¼Ÿå…¶å®è¿™å°±ä¼šæœ‰ä¸ªé—®é¢˜ï¼Œå¦‚æœè„šæœ¬æ‰§è¡Œå¤±è´¥é‚£ä¹ˆä¹…é€€å‡ºä¸”ä¸ä¼šå†æ‰§è¡Œäº†ï¼Œéœ€è¦æ‰§è¡Œå°±å¿…é¡»æ‰‹åŠ¨ï¼Œä½† Job è®¾ç½®çš„ä»»åŠ¡åªæœ‰åœ¨æ­£å¸¸æ‰§è¡Œç»“æŸåæ‰ä¼šç»“æŸï¼Œå¦åˆ™ä¸€ç›´æ‰§è¡Œåˆ°æˆåŠŸä¸ºæ­¢ã€‚Job ä¹Ÿå¯ä»¥è®¾ç½®æˆåŠŸçš„æ¬¡æ•°è¦è¾¾åˆ°å‡ æ¬¡æ‰å…è®¸é€€å‡ºã€‚ Cron Job æ˜¯åŸºäºæ—¶é—´ç®¡ç†æ§åˆ¶ Jobï¼Œå³åœ¨ç»™å®šçš„æ—¶é—´åªè¿è¡Œä¸€æ¬¡ã€å‘¨æœŸæ€§çš„åœ¨æŒ‡å®šæ—¶é—´è¿è¡Œã€‚ 1.3.7 ServicePod çš„ç”Ÿå‘½æ˜¯æœ‰é™çš„ï¼Œå¦‚æœ Pod é‡å¯ IP ä¹Ÿå¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–ã€‚å¦‚æœæˆ‘ä»¬å°† Pod çš„ IP å†™æ­»ï¼ŒPod å¦‚æœæŒ‚äº†æˆ–é‡å¯ï¼Œå…¶å®ƒçš„æœåŠ¡ä¹Ÿä¼šä¸å¯ç”¨ã€‚æˆ‘ä»¬å¯ä»¥æŠŠæˆ‘ä»¬çš„æœåŠ¡ï¼ˆå„ç§ Podï¼‰æ³¨å†Œåˆ°æœåŠ¡å‘ç°ä¸­å¿ƒå»ï¼Œè®©æœåŠ¡å‘ç°ä¸­å¿ƒå»åŠ¨æ€æ›´æ–°å…¶å®ƒæœåŠ¡çš„é…ç½®å°±å¯ä»¥äº†ï¼Œk8s å°±ç»™æˆ‘ä»¬æä¾›äº†è¿™ä¹ˆä¸€ä¸ªæœåŠ¡ï¼Œå³ Serviceã€‚ æˆ‘ä»¬è¿™æ ·å°±å¯ä»¥ä¸ç”¨å»ç®¡åç«¯çš„ Pod å¦‚ä½•å˜åŒ–ï¼Œåªéœ€è¦æŒ‡å®š Service çš„åœ°å€å°±å¯ä»¥äº†ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨ä¸­é—´æ·»åŠ äº†ä¸€å±‚æœåŠ¡å‘ç°çš„ä¸­é—´ä»¶ï¼ŒPod é”€æ¯æˆ–è€…é‡å¯åï¼ŒæŠŠè¿™ä¸ª Pod çš„åœ°å€æ³¨å†Œåˆ°è¿™ä¸ªæœåŠ¡å‘ç°ä¸­å¿ƒå»ã€‚ 1.4 k8sçš„ç½‘ç»œé€šè®¯æ–¹å¼k8s çš„ç½‘ç»œæ¨¡å‹å‡å®šäº†æ‰€æœ‰çš„ Pod éƒ½åœ¨ä¸€ä¸ªå¯ä»¥ç›´æ¥è¿é€šçš„æ‰å¹³åŒ–ç½‘ç»œç©ºé—´ä¸­ï¼Œåœ¨è¿™ GCEï¼ˆGoogle Compute Engineï¼‰é‡Œé¢æ˜¯ç°æˆçš„ç½‘ç»œæ¨¡å‹ã€‚ Flannel æ˜¯ CoreOS å›¢é˜Ÿé’ˆå¯¹ Kubernetes è®¾è®¡ä¸€ä¸ªç½‘ç»œè§„åˆ’æœåŠ¡ï¼Œç®€å•æ¥è¯´ï¼Œå®ƒçš„åŠŸèƒ½æ˜¯è®©é›†ç¾¤ä¸­çš„ä¸åŒèŠ‚ç‚¹ä¸»æœºåˆ›å»º Docker å®¹å™¨éƒ½å…·æœ‰å…¨é›†ç¾¤å”¯ä¸€çš„è™šæ‹Ÿ IP åœ°å€ã€‚è€Œä¸”å®ƒè¿˜èƒ½åœ¨è¿™äº› IP åœ°å€ä¹‹é—´å»ºç«‹ä¸€ä¸ªè¦†ç›–ç½‘ç»œï¼ˆOverlay Networkï¼‰ï¼Œé€šè¿‡è¦†ç›–ç½‘ç»œå°†æ•°æ®åŒ…åŸå°ä¸åŠ¨çš„ä¼ é€’åˆ°ç›®æ ‡å®¹å™¨å†…ã€‚ é€šè¿‡ä¸€ä¸ªæ¶æ„å›¾æ¥çœ‹çœ‹ä¸åŒæƒ…å†µä¸‹çš„é€šè®¯æ˜¯æ€ä¹ˆæ ·çš„ï¼š é€šè®¯æƒ…å†µä¸»è¦åˆ†ä¸ºä»¥ä¸‹å‡ ç§ï¼š åŒä¸€ Pod ä¸åŒå®¹å™¨ä¹‹é—´çš„é€šä¿¡ï¼šé‡‡ç”¨ pause ç½‘ç»œæ ˆã€‚ åŒä¸€ Node ä¸åŒ Pod ä¹‹é—´çš„é€šä¿¡ï¼šé€šè¿‡ docker0 ç½‘æ¡¥è¿›è¡Œé€šä¿¡ã€‚ ä¸åŒ Node çš„ Pod ä¹‹é—´çš„é€šä¿¡ï¼šä¸åŒ Node çš„ Pod ä¹‹é—´çš„é€šä¿¡æ˜¯ k8s ç½‘ç»œé€šä¿¡çš„éš¾ç‚¹ï¼Œæ˜¯é€šè¿‡ Flannel ç½‘ç»œé€šè®¯æ–¹å¼æ¥å®ç°çš„ï¼Œé€šè®¯çš„è¿‡ç¨‹åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š æ•°æ®åŒ…ä» Node1 çš„ Pod åˆ°è¾¾ docker0 ç½‘æ¡¥ Flanneld ä¼šå¼€å¯ä¸€ä¸ª Flannel0 çš„ç½‘æ¡¥ï¼Œç”¨æ¥æŠ“å–åˆ°è¾¾ docker0 çš„æ•°æ®ï¼Œå¯ä»¥ç†è§£ä¸ºä¸€ä¸ªé’©å­å‡½æ•° Flanneld ä¼šæœ‰å¾ˆå¤šè·¯ç”±è¡¨ä¿¡æ¯ï¼Œæ˜¯å­˜å‚¨åœ¨ etcd ä¸­ç”± Flanneld è‡ªåŠ¨è·å–çš„ï¼Œé€šè¿‡è·¯ç”±è¡¨çŸ¥é“äº†è½¬å‘ä¿¡æ¯åå°±é€šè¿‡ç‰©ç†ç½‘å¡è¿›è¡Œè½¬å‘ å‘é€åˆ°ç›®æ ‡ä¸»æœºçš„ç‰©ç†ç½‘å¡åï¼Œå°±ä¼šå†é€šè¿‡ Flanneld -&gt; Flannel0ç½‘æ¡¥ -&gt; docker0ç½‘æ¡¥ï¼Œæœ€ç»ˆåˆ°è¾¾ç›®çš„ Pod Pod ä¸ service ä¹‹é—´çš„é€šä¿¡ï¼šé‡‡ç”¨å„èŠ‚ç‚¹çš„ iptables è§„åˆ™æ¥å®ç°ã€‚ Pod åˆ°å¤–ç½‘ï¼šé€šè¿‡ Flanneld åˆ°è¾¾ç‰©ç†ç½‘å¡ï¼Œç»è¿‡è·¯ç”±é€‰æ‹©åï¼Œiptables æ‰§è¡Œ Masqueradeï¼ŒæŠŠPod çš„è™šæ‹Ÿ IP æ”¹ä¸º ç‰©ç†ç½‘å¡çš„ IPï¼Œåœ¨å‘å¤–ç½‘æœåŠ¡å™¨å‘å‡ºè¯·æ±‚ã€‚ å¤–ç½‘åˆ° Podï¼šé€šè¿‡ service è¿›è¡Œè®¿é—®ï¼Œä¸€èˆ¬ä½¿ç”¨ NodePortã€‚ äºŒã€k8séƒ¨ç½²æœ¬æ¬¡ k8s éƒ¨ç½²ä¸ºä»¥ä¸‹ç¯å¢ƒ 2.1 åŸºæœ¬ç¯å¢ƒé…ç½®ï¼ˆæ‰€æœ‰èŠ‚ç‚¹ï¼‰ åœ¨å„ä¸»æœºè®¾ç½®ä¸»æœºåä»¥åŠhostæ–‡ä»¶è§£æ 1234567hostnamectl set-hostname k8s-master01hostnamectl set-hostname k8s-node01hostnamectl set-hostname k8s-node02vim /etc/hosts192.168.88.10 k8s-master01192.168.88.20 k8s-node01192.168.88.21 k8s-node02 å®‰è£…ä¾èµ– 1yum -y install conntrack ntpdate ntp ipvsadm ipset jp iptables curl stsstat libseccomp wget vim net-tools git è®¾ç½®é˜²ç«å¢™ä¸ºiptableså¹¶è®¾ç½®ç©ºè§„åˆ™ 12345systemctl stop firewalld &amp;&amp; systemctl disable firewalldyum -y install iptables-servicessystemctl start iptablessystemctl enable iptablesiptables -F &amp;&amp; service iptables save å…³é—­è™šæ‹Ÿå†…å­˜å’Œselinux 12swapoff -a &amp;&amp; sed -i '/ swap / s/^\\(.*\\)$/#/g' /etc/fstabsetenforce 0 &amp;&amp; sed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config è°ƒæ•´å†…æ ¸å‚æ•° 1234567891011121314151617cat &gt; kubernetes.conf &lt;&lt;EOFnet.bridge.bridge-nf-call-iptables=1net.bridge.bridge-nf-call-ipv6tables=1net.ipv4.ip_forward=1net.ipv4.tcp_tw_recycle=0vm.swappiness=0 # ç¦ç”¨swapï¼Œåªæœ‰ç³»ç»ŸOOMæ—¶æ‰å…è®¸ä½¿ç”¨vm.overcommit_memory=1 # ä¸æ£€æŸ¥ç‰©ç†å†…å­˜æ˜¯å¦å¤Ÿç”¨vm.panic_on_oom=0 # å¼€å¯OOMfs.inotify.max_user_instances=8192fs.inotify.max_user_watches=1048576fs.file-max=52706963fs.nr_open=52706963net.ipv6.conf.all.disable_ipv6=1net.netfilter.nf_conntrack_max=2310720EOFcp kubernetes.conf /etc/sysctl.d/kubernetes.confsysctl -p /etc/sysctl.d/kubernetes.conf è°ƒæ•´ç³»ç»Ÿæ—¶åŒº 1234567# è®¾ä¸ºä¸­å›½/ä¸Šæµ·timedatectl set-timezone Asia/Shanghai# å°†å½“å‰UTCæ—¶é—´å†™å…¥ç¡¬ä»¶æ—¶é’Ÿtimedatectl set-local-rtc 0# é‡å¯ä¾èµ–äºæ—¶é—´çš„æœåŠ¡systemctl restart rsyslogsystemctl restart crond å…³é—­ä¸éœ€è¦çš„æœåŠ¡ 12# å…³é—­é‚®ä»¶æœåŠ¡systemctl stop postfix &amp;&amp; systemctl disable postfix è®¾ç½®rsyslogå’Œsystemd journald 1234567891011121314151617181920212223242526272829# æŒä¹…åŒ–ä¿å­˜æ—¥å¿—ç›®å½•mkdir /var/log/journalmkdir /etc/systemd/journald.conf.dcat &gt; /etc/systemd/journald.conf.d/99-prophet.conf &lt;&lt;EOF[Journal]#æŒä¹…åŒ–ä¿å­˜åˆ°ç£ç›˜Storage=persistent#å‹ç¼©å†å²æ—¥å¿—Compress=yes SyncIntervalSec=5mRateLimitInterval=30sRateLimitBurst=1000#æœ€å¤§å ç”¨ç©ºé—´ 10GSystemMaxUse=10G#å•æ—¥å¿—æ–‡ä»¶æœ€å¤§ 200MSystemMaxFileSize=200M#æ—¥å¿—ä¿å­˜æ—¶é—´ 2 å‘¨MaxRetentionSec=2week#ä¸å°†æ—¥å¿—è½¬å‘åˆ° syslogForwardToSyslog=noEOFsystemctl restart systemd-journald å‡çº§å†…æ ¸ 12345678910# å¯¼å…¥å…¬é’¥rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org# å®‰è£…elrepoæºyum -y install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm# å‡çº§å†…æ ¸yum --enablerepo=elrepo-kernel install -y kernel-lt# è®¾ç½®å¼€æœºä»æ–°å†…æ ¸å¯åŠ¨grub2-set-default &quot;CentOS Linux (5.4.116-1.e17.elrepo.x86_64) 7 (Core)&quot;# æŸ¥çœ‹å†…æ ¸å¯åŠ¨é¡¹grub2-editenv list 2.2 kubeadméƒ¨ç½²ï¼ˆæ‰€æœ‰èŠ‚ç‚¹ï¼‰ kube-proxyå¼€å¯ipvså‰ç½®æ¡ä»¶ 123456789101112131415modprobe br_netfiltervim /etc/sysconfig/modules/ipvs.modules#!/bin/bashipvs_modules=&quot;ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo ip_vs_nq ip_vs_sed ip_vs_ftp nf_conntrack&quot;for kernel_module in ${ipvs_modules};do /sbin/modinfo -F filename ${kernel_module} &gt; /dev/null 2&gt;&amp;1 if [ $? -eq 0 ]; then /sbin/modprobe ${kernel_module} fidonechmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack å®‰è£…docker 123456789101112131415161718192021yum -y install yum-utils device-mapper-persistent-data lvm2yum-config-manager --add-repo https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.repoyum makecache fastyum -y install docker-ce docker-ce-climkdir /etc/dockercat &gt; /etc/docker/daemon.json &lt;&lt;EOF{ &quot;registry-mirrors&quot;: [&quot;http://f1361db2.m.daocloud.io&quot;], &quot;exec-opts&quot;:[&quot;native.cgroupdriver=systemd&quot;], &quot;log-driver&quot;:&quot;json-file&quot;, &quot;log-opts&quot;:{ &quot;max-size&quot;:&quot;100m&quot; }}EOFmkdir -p /etc/systemd/system/docker.service.dsystemctl daemon-reload &amp;&amp; systemctl start docker &amp;&amp; systemctl enable docker 2.3 å®‰è£…kubeadmï¼ˆæ‰€æœ‰èŠ‚ç‚¹ï¼‰ å®‰è£… kubeadm kubectl kubelet 123456789101112cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOFyum -y install kubeadm kubectl kubeletsystemctl enable kubelet é€šè¿‡kubeadmæŸ¥çœ‹ç›®å‰å„é•œåƒç‰ˆæœ¬ 12345678kubeadm config images listk8s.gcr.io/kube-apiserver:v1.21.0k8s.gcr.io/kube-controller-manager:v1.21.0k8s.gcr.io/kube-scheduler:v1.21.0k8s.gcr.io/kube-proxy:v1.21.0k8s.gcr.io/pause:3.4.1k8s.gcr.io/etcd:3.4.13-0k8s.gcr.io/coredns/coredns:v1.8.0 ç¼–å†™è„šæœ¬ï¼Œé€šè¿‡é˜¿é‡Œé•œåƒå®‰è£… 1234567891011121314151617181920212223242526vim k8s_images.sh#!/bin/bashapiserver_var=v1.21.0controller_manager_var=v1.21.0scheduler_var=v1.21.0proxy_var=v1.21.0pause_var=3.4.1etcd_var=3.4.13-0coredns_var=v1.8.0image_aliyun=(kube-apiserver:$apiserver_var kube-controller-manager:$controller_manager_var kube-scheduler:$scheduler_var kube-proxy:$proxy_var pause:$pause_var etcd:$etcd_var coredns/coredns:$coredns_var)for image in ${image_aliyun[@]}do docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$image docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$image k8s.gcr.io/${image} docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/$imagedone./k8s_images.sh# é—®é¢˜# ç”±äºæ­å·é˜¿é‡Œæºé‡Œç›®å‰æ²¡æœ‰coredns:v1.8.0ç‰ˆæœ¬ï¼Œæ‰€ä»¥åœ¨åŒ—äº¬é˜¿é‡Œæºä¸‹è½½docker pull registry.cn-beijing.aliyuncs.com/dotbalo/coredns:1.8.0docker tag registry.cn-beijing.aliyuncs.com/dotbalo/coredns:1.8.0 k8s.gcr.io/coredns/coredns:v1.8.0docker rmi registry.cn-beijing.aliyuncs.com/dotbalo/coredns:1.8.0 2.4 åˆå§‹åŒ–MasterèŠ‚ç‚¹1kubeadm config print init-defaults &gt; kubeadm.config.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546vim kubeadm.config.ymlapiVersion: kubeadm.k8s.io/v1beta2bootstrapTokens:- groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authenticationkind: InitConfigurationlocalAPIEndpoint: # æ”¹æˆmasterèŠ‚ç‚¹IPåœ°å€ advertiseAddress: 192.168.88.10 bindPort: 6443nodeRegistration: criSocket: /var/run/dockershim.sock name: node taints: null---apiServer: timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta2certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrollerManager: {}dns: type: CoreDNSetcd: local: dataDir: /var/lib/etcdimageRepository: k8s.gcr.iokind: ClusterConfigurationkubernetesVersion: 1.21.0networking: dnsDomain: cluster.local podSubnet: 10.244.0.0/16 serviceSubnet: 10.96.0.0/12scheduler: {}# æ·»åŠ è¿™ä¸€æ®µ---apiVersion: kubeproxy.config.k8s.io/v1alpha1kind: KubeProxyConfigurationkubeproxy: config: mode: ipvs 123456kubeadm init --config=kubeadm.config.yml --upload-certs | tee kubeadm-init.log...# åˆå§‹åŒ–åæ“ä½œmkdir -p $HOME/.kubecp -i /etc/kubernetes/admin.conf $HOME/.kube/configchown $(id -u):$(id -g) $HOME/.kube/config 2.5 éƒ¨ç½²ç½‘ç»œ123mkdir -p k8s/plugin/flannel &amp;&amp; cd k8s/plugin/flannelwget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.ymlkubectl create -f kube-flannel.yml kube-flannel.ymlæ–‡ä»¶å†…å®¹ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223---apiVersion: policy/v1beta1kind: PodSecurityPolicymetadata: name: psp.flannel.unprivileged annotations: seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/defaultspec: privileged: false volumes: - configMap - secret - emptyDir - hostPath allowedHostPaths: - pathPrefix: &quot;/etc/cni/net.d&quot; - pathPrefix: &quot;/etc/kube-flannel&quot; - pathPrefix: &quot;/run/flannel&quot; readOnlyRootFilesystem: false # Users and groups runAsUser: rule: RunAsAny supplementalGroups: rule: RunAsAny fsGroup: rule: RunAsAny # Privilege Escalation allowPrivilegeEscalation: false defaultAllowPrivilegeEscalation: false # Capabilities allowedCapabilities: ['NET_ADMIN', 'NET_RAW'] defaultAddCapabilities: [] requiredDropCapabilities: [] # Host namespaces hostPID: false hostIPC: false hostNetwork: true hostPorts: - min: 0 max: 65535 # SELinux seLinux: # SELinux is unused in CaaSP rule: 'RunAsAny'---kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: flannelrules:- apiGroups: ['extensions'] resources: ['podsecuritypolicies'] verbs: ['use'] resourceNames: ['psp.flannel.unprivileged']- apiGroups: - &quot;&quot; resources: - pods verbs: - get- apiGroups: - &quot;&quot; resources: - nodes verbs: - list - watch- apiGroups: - &quot;&quot; resources: - nodes/status verbs: - patch---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: flannelroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: flannelsubjects:- kind: ServiceAccount name: flannel namespace: kube-system---apiVersion: v1kind: ServiceAccountmetadata: name: flannel namespace: kube-system---kind: ConfigMapapiVersion: v1metadata: name: kube-flannel-cfg namespace: kube-system labels: tier: node app: flanneldata: cni-conf.json: | { &quot;name&quot;: &quot;cbr0&quot;, &quot;cniVersion&quot;: &quot;0.3.1&quot;, &quot;plugins&quot;: [ { &quot;type&quot;: &quot;flannel&quot;, &quot;delegate&quot;: { &quot;hairpinMode&quot;: true, &quot;isDefaultGateway&quot;: true } }, { &quot;type&quot;: &quot;portmap&quot;, &quot;capabilities&quot;: { &quot;portMappings&quot;: true } } ] } net-conf.json: | { &quot;Network&quot;: &quot;10.244.0.0/16&quot;, &quot;Backend&quot;: { &quot;Type&quot;: &quot;vxlan&quot; } }---apiVersion: apps/v1kind: DaemonSetmetadata: name: kube-flannel-ds namespace: kube-system labels: tier: node app: flannelspec: selector: matchLabels: app: flannel template: metadata: labels: tier: node app: flannel spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/os operator: In values: - linux hostNetwork: true priorityClassName: system-node-critical tolerations: - operator: Exists effect: NoSchedule serviceAccountName: flannel initContainers: - name: install-cni image: quay.io/coreos/flannel:v0.14.0-rc1 command: - cp args: - -f - /etc/kube-flannel/cni-conf.json - /etc/cni/net.d/10-flannel.conflist volumeMounts: - name: cni mountPath: /etc/cni/net.d - name: flannel-cfg mountPath: /etc/kube-flannel/ containers: - name: kube-flannel image: quay.io/coreos/flannel:v0.14.0-rc1 command: - /opt/bin/flanneld args: - --ip-masq - --kube-subnet-mgr resources: requests: cpu: &quot;100m&quot; memory: &quot;50Mi&quot; limits: cpu: &quot;100m&quot; memory: &quot;50Mi&quot; securityContext: privileged: false capabilities: add: [&quot;NET_ADMIN&quot;, &quot;NET_RAW&quot;] env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace volumeMounts: - name: run mountPath: /run/flannel - name: flannel-cfg mountPath: /etc/kube-flannel/ volumes: - name: run hostPath: path: /run/flannel - name: cni hostPath: path: /etc/cni/net.d - name: flannel-cfg configMap: name: kube-flannel-cfg éƒ¨ç½²å®Œåå¯ä»¥çœ‹åˆ° flannel ç½‘å¡ é€šè¿‡å‘½ä»¤æŸ¥çœ‹å„æ¨¡å—è¿è¡Œæƒ…å†µ 1kubectl get pod -n kube-system 2.6 æ·»åŠ NodeèŠ‚ç‚¹ æŸ¥çœ‹kubeadm-init.log 123...kubeadm join 192.168.88.10:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:37c9645a7a2ee75301f132537240157ecd4f464494022cc442f77489c1978989 åœ¨nodeä¸»æœºä¸Šæ‰§è¡Œ 12kubeadm join 192.168.88.10:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:37c9645a7a2ee75301f132537240157ecd4f464494022cc442f77489c1978989 åœ¨masterä¸»æœºæŸ¥çœ‹æ˜¯å¦åŠ å…¥æˆåŠŸ 1234kubectl get node...kubectl get pod -n kube-system -o wide... ä¸‰ã€k8sèµ„æºæ¸…å•åœ¨ k8s ä¸­ï¼Œä¸€èˆ¬ä½¿ç”¨ yaml æ ¼å¼çš„æ–‡ä»¶æ¥åˆ›å»ºç¬¦åˆæˆ‘ä»¬é¢„æœŸæœŸæœ›çš„ podï¼Œè¿™æ ·çš„ yaml æ–‡ä»¶æˆ‘ä»¬ä¸€èˆ¬ç§°ä¸ºèµ„æºæ¸…å•ã€‚ 3.1 èµ„æºç±»å‹åç§°ç©ºé—´çº§åˆ« å·¥ä½œè´Ÿè½½å‹èµ„æºï¼šPodã€RSã€Deploymentã€StatefulSetã€DaemonSetã€Jobã€CronJob æœåŠ¡å‘ç°åŠè´Ÿè½½å‡è¡¡å‹èµ„æºï¼šService é…ç½®ä¸å­˜å‚¨å‹èµ„æºï¼šVolumeã€CSI ç‰¹æ®Šç±»å‹çš„å­˜å‚¨å·ï¼šConfigMap(å½“é…ç½®ä¸­å¿ƒæ¥ä½¿ç”¨çš„èµ„æºç±»å‹)ã€Secret(ä¿å­˜æ•æ„Ÿæ•°æ®)ã€DownwarAPI(æŠŠå¤–éƒ¨ç¯å¢ƒä¸­çš„ä¿¡æ¯è¾“å‡ºç»™å®¹å™¨) é›†ç¾¤çº§èµ„æºï¼šNamespaceã€Nodeã€Roleã€ClusterRoleã€RoleBindingã€ClusterRoleBinding å…ƒæ•°æ®å‹èµ„æºï¼šHPAã€PodTemplateã€LimitRange 3.2 å¸¸ç”¨å­—æ®µå¿…è¦å±æ€§ å‚æ•°å å­—æ®µç±»å‹ è¯´æ˜ apiVersion String K8S API çš„ç‰ˆæœ¬ï¼Œç›®å‰åŸºæœ¬æ˜¯v1ï¼Œå¯ä»¥ç”¨ kubectl api-versions å‘½ä»¤æŸ¥è¯¢ kind String è¿™é‡ŒæŒ‡çš„æ˜¯ yaml æ–‡ä»¶å®šä¹‰çš„èµ„æºç±»å‹å’Œè§’è‰²ï¼Œæ¯”å¦‚: Pod metadata Object å…ƒæ•°æ®å¯¹è±¡ï¼Œå›ºå®šå€¼å†™ metadata metadata.name String å…ƒæ•°æ®å¯¹è±¡çš„åå­—ï¼Œè¿™é‡Œç”±æˆ‘ä»¬ç¼–å†™ï¼Œæ¯”å¦‚å‘½åPodçš„åå­— metadata.namespace String å…ƒæ•°æ®å¯¹è±¡çš„å‘½åç©ºé—´ï¼Œç”±æˆ‘ä»¬è‡ªèº«å®šä¹‰ spec Object è¯¦ç»†å®šä¹‰å¯¹è±¡ï¼Œå›ºå®šå€¼å†™Spec spec.containers[] list è¿™é‡Œæ˜¯Specå¯¹è±¡çš„å®¹å™¨åˆ—è¡¨å®šä¹‰ï¼Œæ˜¯ä¸ªåˆ—è¡¨ spec.containers[].name String è¿™é‡Œå®šä¹‰å®¹å™¨çš„åå­— spec.containers[].image String è¿™é‡Œå®šä¹‰è¦ç”¨åˆ°çš„é•œåƒåç§° spec ä¸»è¦å¯¹è±¡ å‚æ•°å å­—æ®µç±»å‹ è¯´æ˜ spec.containers[].name String å®šä¹‰å®¹å™¨çš„åå­— spec.containers[].image String å®šä¹‰è¦ç”¨åˆ°çš„é•œåƒçš„åç§° spec.containers[].imagePullPolicy String å®šä¹‰é•œåƒæ‹‰å–ç­–ç•¥ï¼Œæœ‰ Alwaysï¼ŒNeverï¼ŒIfNotPresent ä¸‰ä¸ªå€¼è¯¾é€‰ ï¼ˆ1ï¼‰Alwaysï¼šæ„æ€æ˜¯æ¯æ¬¡å°è¯•é‡æ–°æ‹‰å–é•œåƒ ï¼ˆ2ï¼‰Neverï¼šè¡¨ç¤ºä»…ä½¿ç”¨æœ¬åœ°é•œåƒ ï¼ˆ3ï¼‰IfNotPresentï¼šå¦‚æœæœ¬åœ°æœ‰é•œåƒå°±æ˜¯ç”¨æœ¬åœ°é•œåƒï¼Œæ²¡æœ‰å°±æ‹‰å–åœ¨çº¿é•œåƒã€‚ä¸Šé¢ä¸‰ä¸ªå€¼éƒ½æ²¡è®¾ç½®çš„è¯ï¼Œé»˜è®¤æ˜¯ Always spec.containers[].command[] List æŒ‡å®šå®¹å™¨å¯åŠ¨å‘½ä»¤ï¼Œå› ä¸ºæ˜¯æ•°ç»„å¯ä»¥æŒ‡å®šå¤šä¸ªï¼Œä¸æŒ‡å®šåˆ™ä½¿ç”¨é•œåƒæ‰“åŒ…æ—¶ä½¿ç”¨çš„å¯åŠ¨å‘½ä»¤ spec.containers[].args[] List æŒ‡å®šå®¹å™¨å¯åŠ¨å‘½ä»¤å‚æ•°ï¼Œå› ä¸ºæ˜¯æ•°ç»„å¯ä»¥æŒ‡å®šå¤šä¸ª spec.containers[].workingDir String æŒ‡å®šå®¹å™¨çš„å·¥ä½œç›®å½• spec.containers[].volumeMounts[] List æŒ‡å®šå®¹å™¨å†…éƒ¨çš„å­˜å‚¨å·é…ç½® spec.containers[].volumeMounts[].name String æŒ‡å®šå¯ä»¥è¢«å®¹å™¨æŒ‚è½½çš„å­˜å‚¨å·çš„åç§° spec.containers[].volumeMounts[].mountPath String æŒ‡å®šå¯ä»¥è¢«å®¹å™¨æŒ‚è½½çš„å®¹å™¨å·çš„è·¯å¾„ spec.containers[].volumeMounts[].readOnly String è®¾ç½®å­˜å‚¨å·è·¯å¾„çš„è¯»å†™æ¨¡å¼ï¼Œtrue æˆ–è€… falseï¼Œé»˜è®¤ä¸ºè¯»å†™æ¨¡å¼ spec.containers[].ports[] List æŒ‡å®šå®¹å™¨éœ€è¦ç”¨åˆ°çš„ç«¯å£åˆ—è¡¨ spec.containers[].ports[].name String æŒ‡å®šç«¯å£åç§° spec.containers[].ports[].containerPort String æŒ‡å®šå®¹å™¨éœ€è¦ç›‘å¬çš„ç«¯å£å· spec.containers[].ports.hostPort String æŒ‡å®šå®¹å™¨æ‰€åœ¨ä¸»æœºéœ€è¦ç›‘å¬çš„ç«¯å£å·ï¼Œé»˜è®¤è·Ÿä¸Šé¢ containerPort ç›¸åŒï¼Œæ³¨æ„è®¾ç½®äº† hostPort åŒä¸€å°ä¸»æœºæ— æ³•å¯åŠ¨è¯¥å®¹å™¨çš„ç›¸åŒå‰¯æœ¬ï¼ˆå› ä¸ºä¸»æœºçš„ç«¯å£å·ä¸èƒ½ç›¸åŒï¼Œè¿™æ ·ä¼šå†²çªï¼‰ spec.containers[].ports[].protocol String æŒ‡å®šç«¯å£åè®®ï¼Œæ”¯æŒTCPå’ŒUDPï¼Œé»˜è®¤å€¼ä¸ºTCP spec.containers[].env[] List æŒ‡å®šå®¹å™¨è¿è¡Œåƒéœ€è®¾ç½®çš„ç¯å¢ƒå˜é‡åˆ—è¡¨ spec.containers[].env[].name String æŒ‡å®šç¯å¢ƒå˜é‡åç§° spec.containers[].env[].value String æŒ‡å®šç¯å¢ƒå˜é‡å€¼ spec.containers[].resources Object æŒ‡å®šèµ„æºé™åˆ¶å’Œèµ„æºè¯·æ±‚çš„å€¼ï¼ˆè¿™é‡Œå¼€å§‹å°±æ˜¯è®¾ç½®å®¹å™¨çš„èµ„æºä¸Šé™ï¼‰ spec.containers[].resources.limits Object æŒ‡å®šè®¾ç½®å®¹å™¨è¿è¡Œæ—¶èµ„æºçš„è¿è¡Œä¸Šé™ spec.containers[].resources.limits.cpu String æŒ‡å®šCPUçš„é™åˆ¶ï¼Œå•ä½ä¸º core æ•°ï¼Œå°†ç”¨äº docker run â€“cpu-shares å‚æ•° spec.containers[].resources.limits.memory String æŒ‡å®š MEM å†…å­˜çš„é™åˆ¶ï¼Œå•ä½ä¸º MIBï¼ŒGIB spec.containers[].resources.requests Object æŒ‡å®šå®¹å™¨å¯åŠ¨å’Œè°ƒåº¦å®¤çš„é™åˆ¶è®¾ç½® spec.containers[].resources.requests.cpu String CPUè¯·æ±‚ï¼Œå•ä½ä¸º core æ•°ï¼Œå®¹å™¨å¯åŠ¨æ—¶åˆå§‹åŒ–å¯ç”¨æ•°é‡ spec.containers[].resources.requests.memory String å†…å­˜è¯·æ±‚ï¼Œå•ä½ä¸º MIBï¼ŒGIB å®¹å™¨å¯åŠ¨çš„åˆå§‹åŒ–å¯ç”¨æ•°é‡ é¢å¤–çš„å‚æ•°é¡¹ å‚æ•°å å­—æ®µç±»å‹ è¯´æ˜ spec.restartPolicy String å®šä¹‰Podé‡å¯ç­–ç•¥ï¼Œå¯ä»¥é€‰æ‹©å€¼ä¸º Alwaysã€OnFailureã€Neverï¼Œé»˜è®¤å€¼ä¸º Alwaysã€‚1. Alwaysï¼šPodä¸€æ—¦ç»ˆæ­¢è¿è¡Œï¼Œåˆ™æ— è®ºå®¹å™¨æ˜¯å¦‚ä½•ç»ˆæ­¢çš„ï¼Œkubelet æœåŠ¡éƒ½å°†é‡å¯å®ƒã€‚2. OnFailureï¼šåªæœ‰ Pod ä»¥éé›¶é€€å‡ºç ç»ˆæ­¢æ—¶ï¼Œkubelet æ‰ä¼šé‡å¯è¯¥å®¹å™¨ã€‚å¦‚æœå®¹å™¨æ­£å¸¸ç»“æŸï¼ˆé€€å‡ºç ä¸º0ï¼‰ï¼Œåˆ™ kubelet å°†ä¸ä¼šé‡å¯å®ƒã€‚3. Neverï¼šPod ç»ˆæ­¢åï¼Œkubelet å°†é€€å‡ºç æŠ¥å‘Šç»™ Masterï¼Œä¸ä¼šé‡å¯è¯¥ Podã€‚ spec.nodeSelector Object å®šä¹‰ Node çš„ Label è¿‡æ»¤æ ‡ç­¾ï¼Œä»¥ key:value æ ¼å¼æŒ‡å®š spec.imagePullSecrets Object å®šä¹‰pull é•œåƒæ˜¯ä½¿ç”¨ secret åç§°ï¼Œä»¥ name:secretkey æ ¼å¼æŒ‡å®š spec.hostNetwork Boolean å®šä¹‰æ˜¯å¦ä½¿ç”¨ä¸»æœºç½‘ç»œæ¨¡å¼ï¼Œé»˜è®¤å€¼ä¸º falseã€‚è®¾ç½® true è¡¨ç¤ºä½¿ç”¨å®¿ä¸»æœºç½‘ç»œï¼Œä¸ä½¿ç”¨ docker ç½‘æ¡¥ï¼ŒåŒæ—¶è®¾ç½®äº† true å°†æ— æ³•åœ¨åŒä¸€å°å®¿ä¸»æœºä¸Šå¯åŠ¨ç¬¬äºŒä¸ªå‰¯æœ¬ã€‚ è¾…åŠ©å‘½ä»¤ 12# æŸ¥çœ‹èµ„æºå¯¹è±¡ç”¨æ³•kubectl explain &lt;èµ„æºå¯¹è±¡&gt; ä¾‹å­ï¼š åˆ›å»º yaml æ–‡ä»¶ 123456789101112vim nginx.yaml# æ­¤å¤„åªæœ‰å¿…è¦å­—æ®µapiVersion: v1kind: Podmetadata: name: nginx-pod labels: app: nginxspec: containers: - name: nginx image: daocloud.io/library/nginx:latest åˆ›å»ºpod 1kubectl apply -f nginx.yaml æŸ¥çœ‹çŠ¶æ€ 123456789# æŸ¥çœ‹æ˜¯å¦ç”Ÿæˆpodkubectl get pod...# æŸ¥çœ‹podè¯¦ç»†ä¿¡æ¯kubectl describe pod nginx-pod...# æµ‹è¯•èƒ½å¦è®¿é—®curl 10.244.1.2 # æ­¤å¤„ä¸ºflannelåˆ†é…çš„åœ°å€... 3.3 å®¹å™¨ç”Ÿå‘½å‘¨æœŸæ¯ä¸€ä¸ª Pod è¢«æˆåŠŸåˆ›ç«‹ä¹‹å‰ï¼Œéƒ½ä¼šè¿›è¡Œåˆå§‹åŒ–ï¼Œä¼šè¿è¡Œé›¶ä¸ªæˆ–è‹¥å¹²ä¸ª init å®¹å™¨ï¼Œinit å®¹å™¨è¿è¡Œå®Œå°±é‡Šæ”¾ï¼Œæ¥ç€æ‰ä¼šè¿è¡Œ main ä¸»å®¹å™¨ï¼Œå½“ç„¶åœ¨ init å®¹å™¨è¿è¡Œä¹‹å‰ä¼šå…ˆè¿è¡Œ pause å®¹å™¨ï¼Œä»¥ä¿è¯å­˜å‚¨å’Œç½‘ç»œçš„å¯ç”¨ã€‚ init å®¹å™¨ä¸æ™®é€šçš„å®¹å™¨éå¸¸ç›¸ä¼¼ï¼Œé™¤äº†ä»¥ä¸‹ä¸¤ç‚¹ï¼š init å®¹å™¨æ€»æ˜¯è¿è¡Œåˆ°å®Œæˆã€‚ æ¯ä¸ª init å®¹å™¨éƒ½è¦åœ¨ä¸‹ä¸€ä¸ªå®¹å™¨å¯åŠ¨ä¹‹å‰å®Œæˆã€‚ å¦‚æœ Pod çš„ Init å®¹å™¨å¤±è´¥ï¼Œkubelet ä¼šä¸æ–­åœ°é‡å¯è¯¥ Init å®¹å™¨ç›´åˆ°è¯¥å®¹å™¨æˆåŠŸä¸ºæ­¢ã€‚ ç„¶è€Œï¼Œå¦‚æœ Pod å¯¹åº”çš„ restartPolicy å€¼ä¸º â€œNeverâ€ï¼ŒKubernetes ä¸ä¼šé‡æ–°å¯åŠ¨ Podã€‚ å¦‚æœä¸ºä¸€ä¸ª Pod æŒ‡å®šäº†å¤šä¸ª Init å®¹å™¨ï¼Œè¿™äº›å®¹å™¨ä¼šæŒ‰é¡ºåºé€ä¸ªè¿è¡Œã€‚ æ¯ä¸ª Init å®¹å™¨å¿…é¡»è¿è¡ŒæˆåŠŸï¼Œä¸‹ä¸€ä¸ªæ‰èƒ½å¤Ÿè¿è¡Œã€‚å½“æ‰€æœ‰çš„ Init å®¹å™¨è¿è¡Œå®Œæˆæ—¶ï¼Œ Kubernetes æ‰ä¼šä¸º Pod åˆå§‹åŒ–åº”ç”¨å®¹å™¨å¹¶åƒå¹³å¸¸ä¸€æ ·è¿è¡Œã€‚ init å®¹å™¨çš„ä½¿ç”¨ å› ä¸º Init å®¹å™¨å…·æœ‰ä¸åº”ç”¨å®¹å™¨åˆ†ç¦»çš„å•ç‹¬é•œåƒï¼Œå…¶å¯åŠ¨ç›¸å…³ä»£ç å…·æœ‰å¦‚ä¸‹ä¼˜åŠ¿ï¼š Init å®¹å™¨å¯ä»¥åŒ…å«ä¸€äº›å®‰è£…è¿‡ç¨‹ä¸­åº”ç”¨å®¹å™¨ä¸­ä¸å­˜åœ¨çš„å®ç”¨å·¥å…·æˆ–ä¸ªæ€§åŒ–ä»£ç ã€‚ ä¾‹å¦‚ï¼Œæ²¡æœ‰å¿…è¦ä»…ä¸ºäº†åœ¨å®‰è£…è¿‡ç¨‹ä¸­ä½¿ç”¨ç±»ä¼¼ sedã€awkã€python æˆ– dig è¿™æ ·çš„å·¥å…·è€Œå» FROM ä¸€ä¸ªé•œåƒæ¥ç”Ÿæˆä¸€ä¸ªæ–°çš„é•œåƒã€‚ Init å®¹å™¨å¯ä»¥å®‰å…¨åœ°è¿è¡Œè¿™äº›å·¥å…·ï¼Œé¿å…è¿™äº›å·¥å…·å¯¼è‡´åº”ç”¨é•œåƒçš„å®‰å…¨æ€§é™ä½ã€‚ åº”ç”¨é•œåƒçš„åˆ›å»ºè€…å’Œéƒ¨ç½²è€…å¯ä»¥å„è‡ªç‹¬ç«‹å·¥ä½œï¼Œè€Œæ²¡æœ‰å¿…è¦è”åˆæ„å»ºä¸€ä¸ªå•ç‹¬çš„åº”ç”¨é•œåƒã€‚ Init å®¹å™¨èƒ½ä»¥ä¸åŒäº Pod å†…åº”ç”¨å®¹å™¨çš„æ–‡ä»¶ç³»ç»Ÿè§†å›¾è¿è¡Œã€‚å› æ­¤ï¼ŒInit å®¹å™¨å¯ä»¥è®¿é—®åº”ç”¨å®¹å™¨ä¸èƒ½è®¿é—®çš„ Secret çš„æƒé™ã€‚ ç”±äº Init å®¹å™¨å¿…é¡»åœ¨åº”ç”¨å®¹å™¨å¯åŠ¨ä¹‹å‰è¿è¡Œå®Œæˆï¼Œå› æ­¤ Init å®¹å™¨æä¾›äº†ä¸€ç§æœºåˆ¶æ¥é˜»å¡æˆ–å»¶è¿Ÿåº”ç”¨å®¹å™¨çš„å¯åŠ¨ï¼Œç›´åˆ°æ»¡è¶³äº†ä¸€ç»„å…ˆå†³æ¡ä»¶ã€‚ ä¸€æ—¦å‰ç½®æ¡ä»¶æ»¡è¶³ï¼ŒPod å†…çš„æ‰€æœ‰çš„åº”ç”¨å®¹å™¨ä¼šå¹¶è¡Œå¯åŠ¨ã€‚ init å®¹å™¨ä½¿ç”¨ä¾‹å­ ç¼–å†™ yaml æ–‡ä»¶ 12345678910111213141516171819202122232425vim busybox.yamlapiVersion: v1kind: Pod# å®šä¹‰äº†ä¸€ä¸ª Pod å« busybox-podï¼Œbusybox å°è£…äº† linux çš„å¤§é‡å‘½ä»¤metadata: name: busybox-pod labels: app: busybox# å®šä¹‰è¯¥ Pod ä¸‹çš„èµ„æºï¼Œä¹Ÿå°±æ˜¯å®¹å™¨spec: # å®šä¹‰äº†ä¸€ä¸ª busybox å®¹å™¨ containers: - name: busybox image: busybox:latest command: ['sh','-c','echo The busybox app is running! &amp;&amp; sleep 3600'] # å®šä¹‰ init å®¹å™¨ï¼Œinit å®¹å™¨å…¨éƒ¨æ‰§è¡Œå®Œå‰ä¸ä¼šæ‰§è¡Œ busybox å®¹å™¨ initContainers: # ç¬¬ä¸€ä¸ª init å®¹å™¨ï¼Œå¦‚æœæ£€æŸ¥ service ä¸­æ²¡æœ‰æ³¨å†Œ myserviceï¼Œåˆ™ä¼‘çœ 2ç§’ç»§ç»­æ‰§è¡Œï¼Œç›´åˆ°æˆåŠŸ - name: init-myservice image: busybox command: ['sh','-c','until nslookup myservice; do echo waiting for myservice; sleep 2; done'] # ç¬¬ä¸€ä¸ª init å®¹å™¨è¿è¡Œå®Œå°±è¿è¡Œè¯¥ init å®¹å™¨ï¼Œæ£€æŸ¥ service ä¸­æœ‰æ²¡æœ‰æ³¨å†Œ mydb - name: init-mydb image: busybox command: ['sh','-c','until nslookup mydb; do echo waiting for mydb; sleep 2; done'] è¿è¡Œ 1kubectl create -f busybox.yaml å¯ä»¥çœ‹åˆ°ä¸€ç›´å¤„äº Init:0/2 çŠ¶æ€ï¼Œå› ä¸ºç¬¬ä¸€ä¸ª init å®¹å™¨ä¸€ç›´æ²¡å®Œæˆ ç¼–å†™ yaml æ–‡ä»¶æ·»åŠ  service 1234567891011121314151617181920vim service.yamlapiVersion: v1kind: Servicemetadata: name: myservicespec: ports: - protocol: TCP port: 80 targetPort: 9376---apiVersion: v1kind: Servicemetadata: name: mydbspec: ports: - protocol: TCP port: 80 targetPort: 9377 è¿è¡Œ 1kubectl create -f service.yaml å¯ä»¥çœ‹åˆ°ä¸¤ä¸ª init å®¹å™¨éƒ½æ‰§è¡Œå®Œï¼Œmain ä¸»å®¹å™¨ä¹Ÿå°±è¿è¡Œäº† 3.4 æ¢é’ˆæ¢é’ˆï¼ˆprobeï¼‰æ˜¯ç”± kubelet å¯¹å®¹å™¨æ‰§è¡Œçš„å®šæœŸè¯Šæ–­ã€‚ è¦æ‰§è¡Œè¯Šæ–­ï¼Œkubelet è°ƒç”¨ç”±å®¹å™¨å®ç°çš„ Handler ï¼ˆå¤„ç†ç¨‹åºï¼‰ã€‚æœ‰ä¸‰ç§ç±»å‹çš„å¤„ç†ç¨‹åºï¼š ExecActionï¼š åœ¨å®¹å™¨å†…æ‰§è¡ŒæŒ‡å®šå‘½ä»¤ã€‚å¦‚æœå‘½ä»¤é€€å‡ºæ—¶è¿”å›ç ä¸º 0 åˆ™è®¤ä¸ºè¯Šæ–­æˆåŠŸã€‚ TCPSocketActionï¼š å¯¹å®¹å™¨çš„ IP åœ°å€ä¸Šçš„æŒ‡å®šç«¯å£æ‰§è¡Œ TCP æ£€æŸ¥ã€‚å¦‚æœç«¯å£æ‰“å¼€ï¼Œåˆ™è¯Šæ–­è¢«è®¤ä¸ºæ˜¯æˆåŠŸçš„ã€‚ HTTPGetActionï¼š å¯¹å®¹å™¨çš„ IP åœ°å€ä¸ŠæŒ‡å®šç«¯å£å’Œè·¯å¾„æ‰§è¡Œ HTTP Get è¯·æ±‚ã€‚å¦‚æœå“åº”çš„çŠ¶æ€ç å¤§äºç­‰äº 200 ä¸”å°äº 400ï¼Œåˆ™è¯Šæ–­è¢«è®¤ä¸ºæ˜¯æˆåŠŸçš„ã€‚ æ¯æ¬¡æ¢æµ‹éƒ½å°†è·å¾—ä»¥ä¸‹ä¸‰ç§ç»“æœä¹‹ä¸€ï¼š Successï¼ˆæˆåŠŸï¼‰ï¼šå®¹å™¨é€šè¿‡äº†è¯Šæ–­ã€‚ Failureï¼ˆå¤±è´¥ï¼‰ï¼šå®¹å™¨æœªé€šè¿‡è¯Šæ–­ã€‚ Unknownï¼ˆæœªçŸ¥ï¼‰ï¼šè¯Šæ–­å¤±è´¥ï¼Œå› æ­¤ä¸ä¼šé‡‡å–ä»»ä½•è¡ŒåŠ¨ã€‚ æ¢é’ˆå¯ä»¥åˆ†ä¸ºä»¥ä¸‹ä¸‰ç§ï¼š livenessProbeï¼šæŒ‡ç¤ºå®¹å™¨æ˜¯å¦æ­£åœ¨è¿è¡Œã€‚å¦‚æœå­˜æ´»æ€æ¢æµ‹å¤±è´¥ï¼Œåˆ™ kubelet ä¼šæ€æ­»å®¹å™¨ï¼Œ å¹¶ä¸”å®¹å™¨å°†æ ¹æ®å…¶é‡å¯ç­–ç•¥å†³å®šæœªæ¥ã€‚å¦‚æœå®¹å™¨ä¸æä¾›å­˜æ´»æ¢é’ˆï¼Œ åˆ™é»˜è®¤çŠ¶æ€ä¸º Successã€‚ readinessProbeï¼šæŒ‡ç¤ºå®¹å™¨æ˜¯å¦å‡†å¤‡å¥½ä¸ºè¯·æ±‚æä¾›æœåŠ¡ã€‚å¦‚æœå°±ç»ªæ€æ¢æµ‹å¤±è´¥ï¼Œ ç«¯ç‚¹æ§åˆ¶å™¨å°†ä»ä¸ Pod åŒ¹é…çš„æ‰€æœ‰æœåŠ¡çš„ç«¯ç‚¹åˆ—è¡¨ä¸­åˆ é™¤è¯¥ Pod çš„ IP åœ°å€ã€‚ åˆå§‹å»¶è¿Ÿä¹‹å‰çš„å°±ç»ªæ€çš„çŠ¶æ€å€¼é»˜è®¤ä¸º Failureã€‚ å¦‚æœå®¹å™¨ä¸æä¾›å°±ç»ªæ€æ¢é’ˆï¼Œåˆ™é»˜è®¤çŠ¶æ€ä¸º Successã€‚ startupProbe: æŒ‡ç¤ºå®¹å™¨ä¸­çš„åº”ç”¨æ˜¯å¦å·²ç»å¯åŠ¨ã€‚å¦‚æœæä¾›äº†å¯åŠ¨æ¢é’ˆï¼Œåˆ™æ‰€æœ‰å…¶ä»–æ¢é’ˆéƒ½ä¼šè¢«ç¦ç”¨ï¼Œç›´åˆ°æ­¤æ¢é’ˆæˆåŠŸä¸ºæ­¢ã€‚å¦‚æœå¯åŠ¨æ¢æµ‹å¤±è´¥ï¼Œkubelet å°†æ€æ­»å®¹å™¨ï¼Œè€Œå®¹å™¨ä¾å…¶é‡å¯ç­–ç•¥è¿›è¡Œé‡å¯ã€‚ å¦‚æœå®¹å™¨æ²¡æœ‰æä¾›å¯åŠ¨æ¢æµ‹ï¼Œåˆ™é»˜è®¤çŠ¶æ€ä¸º Successã€‚ 3.4.1 readinessProbeå°±ç»ªæ£€æµ‹ ç¼–å†™ yaml æ–‡ä»¶ 123456789101112131415161718192021vim readinessProbe.yamlapiVersion: v1kind: Podmetadata: name: readiness-httpget-pod namespace: defaultspec: containers: - name: readiness-httpget-container image: daocloud.io/library/nginx:latest # è°ƒç”¨readinessProbeæ¢é’ˆ readinessProbe: httpGet: # æ£€æŸ¥80ç«¯å£ port: 80 # æ£€æŸ¥è¯¥ç›®å½•ä¸‹çš„ç½‘é¡µ path: /test.html # å®¹å™¨å¯åŠ¨1ç§’åæ‰è¿›è¡Œæ£€æµ‹ initialDelaySeconds: 1 # æ¯3ç§’æ£€æµ‹ä¸€æ¬¡ periodSeconds: 3 ç”Ÿæˆ Pod 1kubectl create -f readinessProbe.yaml å¯ä»¥çœ‹åˆ°è™½ç„¶ Pod è¿è¡Œäº†ï¼Œä½† ready çŠ¶æ€æ˜¯ä¸å¯¹çš„ è¿›å…¥å®¹å™¨åˆ›å»ºæ–‡ä»¶ï¼Œé—®é¢˜å³å¯è§£å†³ 12kubectl exec -it readiness-httpget-pod -- /bin/shecho 'this is test' &gt; /usr/share/nginx/html/test.html 3.4.2 livenessProbeå­˜æ´»æ£€æµ‹livenessProbe-exec ç¼–å†™ yaml æ–‡ä»¶ 123456789101112131415161718vim livenessProbe_exec.yamlapiVersion: v1kind: Podmetadata: name: liveness-exec-pod namespace: defaultspec: containers: - name: liveness-exec-container image: busybox command: ['sh','-c','touch /tmp/test; sleep 60; rm -rf /tmp/test; sleep 3600'] # æŸ¥çœ‹æœ¬åœ°æ˜¯å¦æœ‰é•œåƒï¼Œæœ‰åˆ™ä½¿ç”¨ï¼Œæ²¡æœ‰åˆ™ä¸‹è½½ imagePullPolicy: IfNotPresent livenessProbe: exec: command: ['test','-e','/tmp/test'] initialDelaySeconds: 1 periodSeconds: 3 ç”Ÿæˆ Pod 1kubectl create -f livenessProbe.yaml å¯ä»¥çœ‹åˆ°å½“ test æ–‡ä»¶ç»™åˆ é™¤çš„æ—¶å€™ï¼ŒPod å°±ä¼šé‡å¯ï¼Œé‡å¯ååˆä¼šæœ‰ test æ–‡ä»¶ï¼Œä¸€ç›´å¾ªç¯ä¸‹å» livenessProbe-httpget ç¼–å†™ yaml æ–‡ä»¶ 12345678910111213141516171819202122vim livenessProbe_httpget.yamlapiVersion: v1kind: Podmetadata: name: liveness-httpget-pod namespace: defaultspec: containers: - name: liveness-httpget-container image: daocloud.io/library/nginx:latest ports: - name: http containerPort: 80 # Podç”Ÿæˆ1ç§’ä¹‹åä¼šæ¯3ç§’æ£€æµ‹ä¸€æ¬¡æ˜¯å¦å­˜åœ¨index.htmlæ–‡ä»¶ï¼Œå¦‚æœè¶…è¿‡10ç§’æ²¡æœ‰åˆ™é‡å¯Pod livenessProbe: httpGet: port: http path: /index.html initialDelaySeconds: 1 periodSeconds: 3 # å…è®¸è¶…æ—¶æ—¶é—´ timeoutSeconds: 10 åˆ›å»ºå®¹å™¨ï¼Œå¯ä»¥çœ‹åˆ°æ˜¯åœ¨æ­£å¸¸è¿è¡Œçš„ 1kubectl create -f livenessProbe_httpget.yaml åˆ é™¤ index.html æ–‡ä»¶ï¼Œå¯ä»¥çœ‹åˆ°ä¼šæ‰§è¡Œé‡å¯ 12kubectl exec -it liveness-httpget-pod -- /bin/shrm -rf /usr/share/nginx/html/index.html livenessProbe-tcp ç¼–å†™ yaml æ–‡ä»¶ 12345678910111213141516vim livenessProbe_tcp.yamlapiVersion: v1kind: Podmetadata: name: liveness-tcp-pod namespace: defaultspec: containers: - name: liveness-tcp-container image: daocloud.io/library/nginx:latest livenessProbe: initialDelaySeconds: 5 timeoutSeconds: 1 tcpSocket: port: 8080 periodSeconds: 3 ç”Ÿæˆ Podï¼Œä¼šå‘ç°ä¸€ç›´å¤„äºé‡å¯çŠ¶æ€ 1kubectl create -f livenessProbe_tcp.yaml 3.4.3 Start å’Œ StopStart å’Œ Stop æ˜¯æŒ‡ Pod åœ¨ç”Ÿæˆåæ‰§è¡Œå’Œç»“æŸå‰æ‰§è¡Œçš„å‘½ä»¤ ç¼–å†™ yaml æ–‡ä»¶ 1234567891011121314151617vim start_stop.ymlapiVersion: v1kind: Podmetadata: name: start-stop-pod namespace: defaultspec: containers: - name: start-stop-container image: daocloud.io/library/nginx:latest lifecycle: postStart: exec: command: ['/bin/sh','-c','echo this is postStart test &gt; /usr/share/message'] preStop: exec: command: ['/bin/sh','-c','echo this is preStop test &gt; /usr/share/message'] ç”Ÿæˆ Podï¼Œè¿›å…¥ Pod å¯ä»¥çœ‹åˆ° Start æ‰§è¡Œçš„å‘½ä»¤ï¼Œç”±äº Pod åœæ­¢åå°±æ²¡æœ‰äº†ï¼Œæ‰€ä»¥çœ‹ä¸åˆ° Stop æ‰§è¡Œçš„å‘½ä»¤ 1kubectl exec -it start-stop-pod -- /bin/sh å››ã€k8sæ§åˆ¶å™¨4.1 ä»€ä¹ˆæ˜¯æ§åˆ¶å™¨k8s ä¸­å†…ç½®äº†å¾ˆå¤š controllerï¼Œç”¨æ¥æ§åˆ¶ Pod çš„å…·ä½“çŠ¶æ€å’Œè¡Œä¸ºã€‚ æ§åˆ¶å™¨çš„ç±»å‹æœ‰ï¼š ReplicationControllerï¼ˆå·²å¼ƒç”¨ï¼‰ å’Œ ReplicaSet Deployment DaemonSet StateFulSet Job å’Œ CronJob Horizontal Pod Autoscaling 4.2 RS ä¸ Deploymentk8s ç®¡ç† Pod ä¸»è¦ç”¨åˆ°ä»¥ä¸‹ä¸‰ä¸ªç»„ä»¶ï¼š Replication Controllerï¼ˆRCï¼‰ï¼šç”¨æ¥ç¡®ä¿å®¹å™¨åº”ç”¨çš„å‰¯æœ¬æ•°å§‹ç»ˆä¿æŒåœ¨ç”¨æˆ·å®šä¹‰çš„å‰¯æœ¬æ•°ï¼Œå¦‚æœæœ‰å®¹å™¨å¼‚å¸¸é€€å‡ºï¼Œä¼šè‡ªåŠ¨åˆ›å»ºæ–°çš„ Pod æ¥ä»£æ›¿ï¼Œå¦‚æœæœ‰å¼‚å¸¸å¤šå‡ºçš„å®¹å™¨ä¹Ÿä¼šè‡ªåŠ¨å›æ”¶ã€‚ ReplicaSetï¼ˆRSï¼‰ï¼šç›¸æ¯” RC å¤šäº†æ”¯æŒ selectorï¼Œæ¨èä½¿ç”¨ RSã€‚ Deploymentï¼šç”¨æ¥ç®¡ç† RSã€‚ RS å•ç‹¬ä½¿ç”¨ ç¼–å†™ yaml æ–‡ä»¶ 1234567891011121314151617181920212223vim rs_test.yamlapiVersion: apps/v1kind: ReplicaSetmetadata: # RSåç§° name: rs-testspec: # è®¾ç½®å‰¯æœ¬æ•° replicas: 3 selector: # è®¾ç½®æ ‡ç­¾ matchLabels: tier: rs-test # è®¾ç½®æ¨¡æ¿ï¼Œä¼šæ ¹æ®æ­¤æ¨¡æ¿ç”ŸæˆPod template: metadata: # ä¸ä¸Šè¾¹RSè®¾ç½®çš„æ ‡ç­¾ç›¸å¯¹åº”ï¼Œè¯´æ˜æ ¹æ®è¯¥æ¨¡æ¿åˆ›å»ºçš„Podéƒ½ç”±æ ‡ç­¾ç›¸å¯¹RSç®¡ç† labels: tier: rs-test spec: containers: - name: rs-nginx-container image: daocloud.io/library/nginx:latest ç”Ÿæˆ RSï¼Œå¯ä»¥çœ‹åˆ°ä¼šæ ¹æ® replicasè®¾ç½®çš„æ•°é‡åˆ›å»º Pod 1kubectl create -f rs_test.yaml åˆ é™¤è¿™äº› Podï¼ŒRS ä¹Ÿä¼šæŒ‰ç…§å‰¯æœ¬æ•°é‡æ–°å»ºç«‹æ–°çš„ Pod 1kubectl delete pod --all RS ä¸ Deployment ç¼–å†™ yaml æ–‡ä»¶ 1234567891011121314151617181920212223242526vim nginx_deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment# Deploymentè¯¦ç»†ä¿¡æ¯spec: # å‰¯æœ¬æ•° replicas: 3 # é€‰æ‹©æ ‡ç­¾ selector: # æ ‡ç­¾åŒ¹é…ï¼Œä¸Deploymentå¯¹åº” matchLabels: app: nginx-deployment # Podæ¨¡æ¿ template: metadata: # å®šä¹‰æ ‡ç­¾ labels: app: nginx-deployment spec: containers: - name: nginx-deployment-container image: daocloud.io/library/nginx:latest ports: - containerPort: 80 ç”Ÿæˆ Deployment 12kubectl create -f nginx_deployment.yaml --recordrecord:è®°å½•å‘½ä»¤ï¼Œæ–¹ä¾¿æ¯æ¬¡ reversion çš„å˜åŒ– å¯ä»¥çœ‹åˆ°ä¼šç”Ÿæˆå¯¹åº”çš„ RS å’Œ Pod æ‰©å®¹ 1kubectl scale deployment nginx-deployment --replicas 5 æ›´æ–°é•œåƒ 1kubectl set image deployment/nginx-deployment nginx-deployment-container=daocloud.io/library/nginx:1.19.1 å¯ä»¥çœ‹åˆ°ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„ RSï¼Œä»¥å®ç°ç°åº¦æ›´æ–° å›æ»š 1kubectl rollout undo deployment/nginx-deployment æŸ¥çœ‹å›æ»šçŠ¶æ€ 1kubectl rollout status deployment/nginx-deployment æŸ¥çœ‹å†å²ç‰ˆæœ¬ 1kubectl rollout history deployment/nginx-deployment å›åˆ°å†å²æŒ‡å®šç‰ˆæœ¬ 1kubectl rollout undo deployment/nginx-deployment --to-revision=1 æš‚åœæ›´æ–° 1kubectl rollout pause deployment/nginx-deployment 4.3 DaemonSetDaemonSet ç¡®ä¿å…¨éƒ¨æˆ–è€…ä¸€éƒ¨åˆ† Node ä¸Šè¿è¡Œä¸€ä¸ª Pod çš„å‰¯æœ¬ï¼Œå½“æœ‰ Node åŠ å…¥é›†ç¾¤æ—¶ï¼Œä¹Ÿä¼šä¸ºä»–ä»¬æ–°å¢ä¸€ä¸ª Podï¼Œå½“è¿™äº› Node é€€å‡ºé›†ç¾¤æ—¶ï¼Œè¿™äº› Pod ä¹Ÿä¼šè¢«å›æ”¶ã€‚ DaemonSet çš„ä¸€äº›å…¸å‹ç”¨æ³•ï¼š è¿è¡Œé›†ç¾¤å­˜å‚¨ daemonï¼Œä¾‹å¦‚åœ¨æ¯ä¸ª Node ä¸Šè¿è¡Œ glusterdã€cephç­‰ã€‚ è¿è¡Œæ—¥å¿—æ”¶é›†daemonï¼Œä¾‹å¦‚fluentdã€logstashç­‰ã€‚ è¿è¡Œç›‘æ§daemonï¼Œä¾‹å¦‚ Prometheus çš„ Node exporterã€zabbixç­‰ã€‚ ç¼–å†™ yaml æ–‡ä»¶ 12345678910111213141516171819202122vim daemonset_test.yamlapiVersion: apps/v1kind: DaemonSetmetadata: # DaemonSetåç§° name: daemonset-test # è®¾ç½®æ ‡ç­¾ labels: app: daemonset-nginxspec: selector: # è¯¥æ ‡ç­¾è¦ä¸ä¸Šè¾¹æ ‡ç­¾ä¸€è‡´ matchLabels: name: daemonset-nginx template: metadata: labels: name: daemonset-nginx-pod spec: containers: - name: daemonset-nginx-container image: daocloud.io/library/nginx:latest ç”Ÿæˆ DaemonSet 1kubectl create -f daemonset_test.yaml åˆ é™¤ä¸€ä¸ª Pod ä¹‹å DaemonSet ä¸ºä¿è¯æ¯ä¸ªèŠ‚ç‚¹éƒ½è‡³å°‘æœ‰ä¸€ä¸ªå‰¯æœ¬ï¼Œå°±ä¼šé‡æ–°åˆ›å»ºæ–°çš„ Pod 4.4 Job å’Œ CronJob4.4.1 JobJob è´Ÿè´£æ‰¹å¤„ç†ä»»åŠ¡ï¼Œå³ä»…æ‰§è¡Œä¸€æ¬¡çš„ä»»åŠ¡ï¼Œå®ƒä¿è¯æ‰¹å¤„ç†ä»»åŠ¡çš„ä¸€ä¸ªæˆ–å¤šä¸ª Pod æˆåŠŸç»“æŸã€‚ Job spec spec.templateæ ¼å¼åŒ Pod ç›¸åŒ RestartPolicyä»…æ”¯æŒNeverå’ŒOnFailure å•ä¸ª Pod æ—¶ï¼Œé»˜è®¤ Pod æˆåŠŸè¿è¡Œå Job å³ç»“æŸ spec.completionsæ ‡å¿— Job ç»“æŸæ—¶éœ€è¦æˆåŠŸè¿è¡Œçš„ Pod ä¸ªæ•°ï¼Œé»˜è®¤ä¸º1 spec.parallelismæ ‡å¿—å¹¶è¡Œè¿è¡Œçš„ Pod ä¸ªæ•°ï¼Œé»˜è®¤ä¸º1 spec.activeDeadlineSecondsæ ‡å¿—å¤±è´¥ Pod çš„é‡è¯•æœ€å¤§æ—¶é—´ï¼Œè¶…è¿‡è¯¥æ—¶é—´å°±ä¸ä¼šå†é‡è¯• ç¼–å†™ yaml æ–‡ä»¶ 1234567891011121314151617vim job.yamlapiVersion: batch/v1kind: Jobmetadata: name: jobspec: template: metadata: name: job-pod spec: containers: - name: job-pod-container image: perl imagePullPolicy: IfNotPresent # é€šè¿‡perlè¯­è¨€è¿›è¡Œåœ†å‘¨ç‡è®¡ç®—ï¼Œè®¡ç®—å°æ•°ç‚¹å2000ä½ command: ['perl','-Mbignum=bpi','-wle','print bpi(2000)'] restartPolicy: Never ç”Ÿæˆ Jobï¼Œå¯ä»¥çœ‹åˆ°å¼€å§‹æ˜¯ Runningï¼Œæ¥ç€å°±æ˜¯ Completedï¼Œä»£è¡¨ Job å·²ç»å®Œæˆ 1kubectl create -f job.yaml æŸ¥çœ‹æ—¥å¿—å¯ä»¥çœ‹åˆ°è®¡ç®—å¥½çš„åœ†å‘¨ç‡ 4.4.2 CronJobCron Job æ˜¯åŸºäºæ—¶é—´ç®¡ç†æ§åˆ¶ Jobï¼Œå³åœ¨ç»™å®šçš„æ—¶é—´åªè¿è¡Œä¸€æ¬¡ã€å‘¨æœŸæ€§çš„åœ¨æŒ‡å®šæ—¶é—´è¿è¡Œã€‚ CronJob spec æ‰€æœ‰ CronJob çš„ schedule: æ—¶é—´éƒ½æ˜¯åŸºäº kube-controller-manager çš„æ—¶åŒºã€‚ .spec.schedule æ˜¯ .spec éœ€è¦çš„åŸŸã€‚å®ƒä½¿ç”¨äº† Cron æ ¼å¼ä¸²ï¼Œä¾‹å¦‚ 0 * * * * or @hourly ï¼Œåšä¸ºå®ƒçš„ä»»åŠ¡è¢«åˆ›å»ºå’Œæ‰§è¡Œçš„è°ƒåº¦æ—¶é—´ã€‚ .spec.jobTemplateæ˜¯ä»»åŠ¡çš„æ¨¡ç‰ˆï¼Œæ˜¯å¿…é¡»é¡¹ã€‚ .spec.startingDeadlineSeconds åŸŸæ˜¯å¯é€‰é¡¹ã€‚å®ƒè¡¨ç¤ºä»»åŠ¡å¦‚æœç”±äºæŸç§åŸå› é”™è¿‡äº†è°ƒåº¦æ—¶é—´ï¼Œå¼€å§‹è¯¥ä»»åŠ¡çš„æˆªæ­¢æ—¶é—´çš„ç§’æ•°ã€‚è¿‡äº†æˆªæ­¢æ—¶é—´ï¼ŒCronJob å°±ä¸ä¼šå¼€å§‹ä»»åŠ¡ã€‚ ä¸æ»¡è¶³è¿™ç§æœ€åæœŸé™çš„ä»»åŠ¡ä¼šè¢«ç»Ÿè®¡ä¸ºå¤±è´¥ä»»åŠ¡ã€‚å¦‚æœè¯¥åŸŸæ²¡æœ‰å£°æ˜ï¼Œé‚£ä»»åŠ¡å°±æ²¡æœ‰æœ€åæœŸé™ã€‚ .spec.suspendåŸŸä¹Ÿæ˜¯å¯é€‰çš„ã€‚å¦‚æœè®¾ç½®ä¸º true ï¼Œåç»­å‘ç”Ÿçš„æ‰§è¡Œéƒ½ä¼šæŒ‚èµ·ã€‚ è¿™ä¸ªè®¾ç½®å¯¹å·²ç»å¼€å§‹çš„æ‰§è¡Œä¸èµ·ä½œç”¨ã€‚é»˜è®¤æ˜¯å…³é—­çš„ã€‚ .spec.successfulJobsHistoryLimit å’Œ .spec.failedJobsHistoryLimitæ˜¯å¯é€‰çš„ã€‚ è¿™ä¸¤ä¸ªå­—æ®µæŒ‡å®šåº”ä¿ç•™å¤šå°‘å·²å®Œæˆå’Œå¤±è´¥çš„ä»»åŠ¡ã€‚ é»˜è®¤è®¾ç½®ä¸º3å’Œ1ã€‚é™åˆ¶è®¾ç½®ä¸º0ä»£è¡¨ç›¸åº”ç±»å‹çš„ä»»åŠ¡å®Œæˆåä¸ä¼šä¿ç•™ã€‚ å¹¶å‘æ€§è§„åˆ™ .spec.concurrencyPolicyå£°æ˜äº† CronJob åˆ›å»ºçš„ä»»åŠ¡æ‰§è¡Œæ—¶å‘ç”Ÿé‡å å¦‚ä½•å¤„ç†ã€‚ spec ä»…èƒ½å£°æ˜ä¸‹åˆ—è§„åˆ™ä¸­çš„ä¸€ç§ï¼š Allow (é»˜è®¤)ï¼šCronJob å…è®¸å¹¶å‘ä»»åŠ¡æ‰§è¡Œã€‚ Forbidï¼š CronJob ä¸å…è®¸å¹¶å‘ä»»åŠ¡æ‰§è¡Œï¼›å¦‚æœæ–°ä»»åŠ¡çš„æ‰§è¡Œæ—¶é—´åˆ°äº†è€Œè€ä»»åŠ¡æ²¡æœ‰æ‰§è¡Œå®Œï¼ŒCronJob ä¼šå¿½ç•¥æ–°ä»»åŠ¡çš„æ‰§è¡Œã€‚ Replaceï¼šå¦‚æœæ–°ä»»åŠ¡çš„æ‰§è¡Œæ—¶é—´åˆ°äº†è€Œè€ä»»åŠ¡æ²¡æœ‰æ‰§è¡Œå®Œï¼ŒCronJob ä¼šç”¨æ–°ä»»åŠ¡æ›¿æ¢å½“å‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡ã€‚ å¹¶å‘æ€§è§„åˆ™ä»…é€‚ç”¨äºç›¸åŒ CronJob åˆ›å»ºçš„ä»»åŠ¡ã€‚å¦‚æœæœ‰å¤šä¸ª CronJobï¼Œå®ƒä»¬ç›¸åº”çš„ä»»åŠ¡æ€»æ˜¯å…è®¸å¹¶å‘æ‰§è¡Œçš„ã€‚ ç¼–å†™ yaml æ–‡ä»¶ 12345678910111213141516171819202122vim crontjob.yamlapiVersion: batch/v1kind: CronJobmetadata: name: cronjobspec: # CronJobå¿…è¦å­—æ®µï¼Œæ ¼å¼ä¸ºåˆ†æ—¶æ—¥æœˆå‘¨ schedule: &quot;*/1 * * * *&quot; # jobæ¨¡æ¿ jobTemplate: spec: template: spec: containers: - name: crontab-pod image: busybox imagePullPolicy: IfNotPresent command: - /bin/sh - -c - date; echo 'Welcome My K8s' restartPolicy: OnFailure ç”Ÿæˆ CronJobï¼Œå¯ä»¥çœ‹åˆ°æ¯åˆ†é’Ÿéƒ½ä¼šåˆ›å»ºä¸€ä¸ª Job å’Œ Pod 1kubectl create -f cronjob.yaml äº”ã€Service5.1 ä»€ä¹ˆæ˜¯Service åˆ°è¿™é‡Œæˆ‘ä»¬éƒ½çŸ¥é“ï¼ŒDeployment ä¼šæ ¹æ® replicasä¿è¯ Pod çš„æ•°é‡ï¼Œå½“ä¸Šå›¾çš„å…¶ä¸­ä¸€ä¸ª php-fpm Pod å‡ºç°é—®é¢˜æ—¶ï¼Œå°±ä¼šæ–°å»ºä¸€ä¸ªæ¥ä»£æ›¿ã€‚ä½†è¿™æ—¶å€™ä¼šä¼šå‡ºç°ä¸€ä¸ªé—®é¢˜ï¼Œæ–°çš„ Pod çš„åœ°å€ä¸æ—§çš„å¾ˆå¯èƒ½ä¸ä¸€æ ·ï¼Œé‚£ nginx ä¹Ÿæ— æ³•è¿æ¥åˆ°æ–°çš„ Podï¼Œé™¤éä¿®æ”¹ nginx çš„é…ç½®ï¼Œè¿™æ ·çš„ k8s é›†ç¾¤æ•ˆç‡æ˜¯éå¸¸ä½çš„ã€‚ Service å°±èƒ½è§£å†³è¯¥é—®é¢˜ï¼Œåœ¨ nginx å’Œ php-fpm ä¸­é—´æ·»åŠ ä¸€ä¸ª Serviceï¼Œç”±è¯¥ Service æ¥ç®¡ç†å„ php-fpm Pod çš„ä¿¡æ¯ï¼Œæ¯ä¸ª Pod ä¼šè®¾ç½®ä¸€ä¸ªæ ‡ç­¾ï¼Œåªè¦ä¸ SVC ä¸­è®¾ç½®çš„æ ‡ç­¾ç›¸åŒ¹é…ï¼Œå°±å¯ä»¥è¿›è¡Œç®¡ç†ï¼Œå…¶å®ƒ Podï¼ˆä¾‹å¦‚ä¸‹å›¾çš„ nginxï¼‰æƒ³è¦è®¿é—®è¯¥ SVC ç®¡ç†çš„ Podï¼Œåªè¦é€šè¿‡ SVC çš„åœ°å€å°±å¯ä»¥è®¿é—®åˆ°ã€‚ Service å®šä¹‰äº†è¿™æ ·ä¸€ç§æŠ½è±¡ï¼šé€»è¾‘ä¸Šçš„ä¸€ç»„ Podï¼Œä¸€ç§å¯ä»¥è®¿é—®å®ƒä»¬çš„ç­–ç•¥ â€”â€” é€šå¸¸ç§°ä¸ºå¾®æœåŠ¡ã€‚ 5.2 Serviceå‘å¸ƒæœåŠ¡ï¼ˆæœåŠ¡ç±»å‹)å¯¹ä¸€äº›åº”ç”¨çš„æŸäº›éƒ¨åˆ†ï¼ˆå¦‚å‰ç«¯ï¼‰ï¼Œå¯èƒ½å¸Œæœ›å°†å…¶æš´éœ²ç»™ Kubernetes é›†ç¾¤å¤–éƒ¨ çš„ IP åœ°å€ã€‚ Kubernetes ServiceTypes å…è®¸æŒ‡å®šä½ æ‰€éœ€è¦çš„ Service ç±»å‹ï¼Œé»˜è®¤æ˜¯ ClusterIPã€‚ Type çš„å–å€¼ä»¥åŠè¡Œä¸ºå¦‚ä¸‹ï¼š ClusterIPï¼šé€šè¿‡é›†ç¾¤çš„å†…éƒ¨ IP æš´éœ²æœåŠ¡ï¼Œé€‰æ‹©è¯¥å€¼æ—¶æœåŠ¡åªèƒ½å¤Ÿåœ¨é›†ç¾¤å†…éƒ¨è®¿é—®ã€‚ è¿™ä¹Ÿæ˜¯é»˜è®¤çš„ ServiceTypeã€‚ NodePortï¼šé€šè¿‡æ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„ IP å’Œé™æ€ç«¯å£ï¼ˆNodePortï¼‰æš´éœ²æœåŠ¡ã€‚ NodePort æœåŠ¡ä¼šè·¯ç”±åˆ°è‡ªåŠ¨åˆ›å»ºçš„ ClusterIP æœåŠ¡ã€‚ é€šè¿‡è¯·æ±‚ &lt;èŠ‚ç‚¹ IP&gt;:&lt;èŠ‚ç‚¹ç«¯å£&gt;ï¼Œä½ å¯ä»¥ä»é›†ç¾¤çš„å¤–éƒ¨è®¿é—®ä¸€ä¸ª NodePort æœåŠ¡ã€‚ LoadBalancerï¼šä½¿ç”¨äº‘æä¾›å•†çš„è´Ÿè½½å‡è¡¡å™¨å‘å¤–éƒ¨æš´éœ²æœåŠ¡ã€‚ å¤–éƒ¨è´Ÿè½½å‡è¡¡å™¨å¯ä»¥å°†æµé‡è·¯ç”±åˆ°è‡ªåŠ¨åˆ›å»ºçš„ NodePort æœåŠ¡å’Œ ClusterIP æœåŠ¡ä¸Šã€‚ ExternalNameï¼šé€šè¿‡è¿”å› CNAME å’Œå¯¹åº”å€¼ï¼Œå¯ä»¥å°†æœåŠ¡æ˜ å°„åˆ° externalName å­—æ®µçš„å†…å®¹ï¼ˆä¾‹å¦‚ï¼Œfoo.bar.example.comï¼‰ã€‚ æ— éœ€åˆ›å»ºä»»ä½•ç±»å‹ä»£ç†ã€‚ ClusterIP NodePort LoadBalancer ExternalName 5.3 è™šæ‹Ÿ IP å’Œ Service ä»£ç†åœ¨ Kubernetes é›†ç¾¤ä¸­ï¼Œæ¯ä¸ª Node è¿è¡Œä¸€ä¸ª kube-proxy è¿›ç¨‹ã€‚ kube-proxy è´Ÿè´£ä¸º Service å®ç°äº†ä¸€ç§ VIPï¼ˆè™šæ‹Ÿ IPï¼‰çš„å½¢å¼ï¼Œè€Œä¸æ˜¯ ExternalName çš„å½¢å¼ã€‚ ä»£ç†æ¨¡å¼åˆ†ç±»ï¼š userspace ä»£ç†æ¨¡å¼ åœ¨è¯¥æ¨¡å¼ä¸‹ï¼Œæ‰€æœ‰æ“ä½œéƒ½è¦é€šè¿‡ kube-proxy è¿›è¡Œä¸€ä¸ªä»£ç†çš„æ“ä½œï¼Œkube-proxy çš„å‹åŠ›ç›¸å¯¹ä¼šè¾ƒå¤§ã€‚ iptables ä»£ç†æ¨¡å¼ åœ¨è¯¥æ¨¡å¼ä¸‹ï¼Œæ‰€æœ‰çš„è®¿é—®éƒ½é€šè¿‡ iptables æ¥å¤„ç†ï¼Œkube-proxy çš„å‹åŠ›å°±ä¼šå‡å°å¾ˆå¤šã€‚ IPVS ä»£ç†æ¨¡å¼ åœ¨è¯¥æ¨¡å¼ä¸‹ï¼Œiptables æ¢æˆäº† IPVSï¼Œé€šè¿‡å†…æ ¸æ¨¡å—æ¥å®ç°è´Ÿè½½å‡è¡¡ã€‚ åœ¨ ipvs æ¨¡å¼ä¸‹ï¼Œkube-proxy ç›‘è§† Kubernetes æœåŠ¡å’Œç«¯ç‚¹ï¼Œè°ƒç”¨ netlink æ¥å£ç›¸åº”åœ°åˆ›å»º IPVS è§„åˆ™ï¼Œ å¹¶å®šæœŸå°† IPVS è§„åˆ™ä¸ Kubernetes æœåŠ¡å’Œç«¯ç‚¹åŒæ­¥ã€‚ è¯¥æ§åˆ¶å¾ªç¯å¯ç¡®ä¿ IPVS çŠ¶æ€ä¸æ‰€éœ€çŠ¶æ€åŒ¹é…ã€‚è®¿é—®æœåŠ¡æ—¶ï¼ŒIPVS å°†æµé‡å®šå‘åˆ°åç«¯Podä¹‹ä¸€ã€‚ IPVSä»£ç†æ¨¡å¼åŸºäºç±»ä¼¼äº iptables æ¨¡å¼çš„ netfilter æŒ‚é’©å‡½æ•°ï¼Œ ä½†æ˜¯ä½¿ç”¨å“ˆå¸Œè¡¨ä½œä¸ºåŸºç¡€æ•°æ®ç»“æ„ï¼Œå¹¶ä¸”åœ¨å†…æ ¸ç©ºé—´ä¸­å·¥ä½œã€‚ è¿™æ„å‘³ç€ï¼Œä¸ iptables æ¨¡å¼ä¸‹çš„ kube-proxy ç›¸æ¯”ï¼ŒIPVS æ¨¡å¼ä¸‹çš„ kube-proxy é‡å®šå‘é€šä¿¡çš„å»¶è¿Ÿè¦çŸ­ï¼Œå¹¶ä¸”åœ¨åŒæ­¥ä»£ç†è§„åˆ™æ—¶å…·æœ‰æ›´å¥½çš„æ€§èƒ½ã€‚ ä¸å…¶ä»–ä»£ç†æ¨¡å¼ç›¸æ¯”ï¼ŒIPVS æ¨¡å¼è¿˜æ”¯æŒæ›´é«˜çš„ç½‘ç»œæµé‡ååé‡ã€‚ IPVS æä¾›äº†æ›´å¤šé€‰é¡¹æ¥å¹³è¡¡åç«¯ Pod çš„æµé‡ã€‚ è¿™äº›æ˜¯ï¼š rrï¼šè½®æ›¿ï¼ˆRound-Robinï¼‰ lcï¼šæœ€å°‘é“¾æ¥ï¼ˆLeast Connectionï¼‰ï¼Œå³æ‰“å¼€é“¾æ¥æ•°é‡æœ€å°‘è€…ä¼˜å…ˆ dhï¼šç›®æ ‡åœ°å€å“ˆå¸Œï¼ˆDestination Hashingï¼‰ shï¼šæºåœ°å€å“ˆå¸Œï¼ˆSource Hashingï¼‰ sedï¼šæœ€çŸ­é¢„æœŸå»¶è¿Ÿï¼ˆShortest Expected Delayï¼‰ nqï¼šä»ä¸æ’é˜Ÿï¼ˆNever Queueï¼‰ æ³¨æ„ï¼šå½“ kube-proxy ä»¥ IPVS ä»£ç†æ¨¡å¼å¯åŠ¨æ—¶ï¼Œå®ƒå°†éªŒè¯ IPVS å†…æ ¸æ¨¡å—æ˜¯å¦å¯ç”¨ã€‚ å¦‚æœæœªæ£€æµ‹åˆ° IPVS å†…æ ¸æ¨¡å—ï¼Œåˆ™ kube-proxy å°†é€€å›åˆ°ä»¥ iptables ä»£ç†æ¨¡å¼è¿è¡Œã€‚ 5.4 ClusterIPClusterIP ä¸»è¦åœ¨æ¯ä¸ª Node èŠ‚ç‚¹ä½¿ç”¨ iptables / IPVSï¼Œå°†å‘å‘ ClusterIP å¯¹åº”ç«¯å£çš„æ•°æ®ï¼Œè½¬å‘åˆ° kube-proxy ä¸­ï¼Œkube-proxy å†…éƒ¨å¯ä»¥å®ç°è´Ÿè½½å‡è¡¡ï¼Œå¹¶å¯ä»¥æŸ¥è¯¢åˆ°è¯¥ Service ä¸‹å¯¹åº” Pod çš„åœ°å€å’Œç«¯å£ï¼Œè¿›è€ŒæŠŠæ•°æ®è½¬å‘ç»™å¯¹åº”çš„ Pod çš„åœ°å€å’Œç«¯å£ã€‚ ç¤ºä¾‹ åˆ›å»º Deployment 1234567891011121314151617181920212223242526vim nginx_svc_deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment namespace: defaultspec: replicas: 3 selector: # åˆ›å»ºä¸¤ä¸ªæ ‡ç­¾ matchLabels: app: nginx version: latest template: metadata: labels: app: nginx version: latest spec: containers: - name: nginx-pod image: daocloud.io/library/nginx:latest # é‡Šæ”¾çš„ç«¯å£ ports: - name: http-port containerPort: 80 åˆ›å»º Service 12345678910111213141516vim clusterip_svc.yamlapiVersion: v1kind: Servicemetadata: name: nginx-clusterip-service namespace: defaultspec: type: ClusterIP # ç”¨æ¥åŒ¹é…Podä¸­çš„æ ‡ç­¾ï¼Œå…¨éƒ¨åŒ¹é…æ‰ä¼šç®¡ç†è¯¥Pod selector: app: nginx version: latest ports: - name: http-port port: 80 targetPort: 80 å¯ä»¥çœ‹åˆ° Deployment å’Œ SVC éƒ½å·²ç»åˆ›å»ºæˆåŠŸï¼Œä¸”ç›´æ¥è®¿é—® SVC çš„ ClusterIP åœ°å€å°±å¯ä»¥è®¿é—®åˆ° Pod äº† æµ‹è¯•è´Ÿè½½å‡è¡¡ï¼Œåœ¨å„å®¹å™¨å†…éƒ¨åˆ›å»ºä¸€ä¸ª html é¡µé¢ 1234kubectl exec -it nginx-deployment-*** -- /bin/bashecho 'this is node01-pod01' &gt; /usr/share/nginx/html/pod.htmlecho 'this is node02-pod01' &gt; /usr/share/nginx/html/pod.html... å¯ä»¥çœ‹åˆ°æ˜¯å®ç°äº†è´Ÿè½½å‡è¡¡çš„ 5.5 æ— å¤´æœåŠ¡ï¼ˆHeadless Servicesï¼‰æœ‰æ—¶ä¸éœ€è¦æˆ–ä¸æƒ³è¦è´Ÿè½½å‡è¡¡ï¼Œä»¥åŠå•ç‹¬çš„ Service IPã€‚ é‡åˆ°è¿™ç§æƒ…å†µï¼Œå¯ä»¥é€šè¿‡æŒ‡å®š Cluster IPï¼ˆspec.clusterIPï¼‰çš„å€¼ä¸º &quot;None&quot; æ¥åˆ›å»º Headless Serviceã€‚ å¯ä»¥ä½¿ç”¨æ— å¤´ Service ä¸å…¶ä»–æœåŠ¡å‘ç°æœºåˆ¶è¿›è¡Œæ¥å£ï¼Œè€Œä¸å¿…ä¸ Kubernetes çš„å®ç°æ†ç»‘åœ¨ä¸€èµ·ã€‚ å¯¹è¿™æ— å¤´ Service å¹¶ä¸ä¼šåˆ†é… Cluster IPï¼Œkube-proxy ä¸ä¼šå¤„ç†å®ƒä»¬ï¼Œ è€Œä¸”å¹³å°ä¹Ÿä¸ä¼šä¸ºå®ƒä»¬è¿›è¡Œè´Ÿè½½å‡è¡¡å’Œè·¯ç”±ã€‚ DNS å¦‚ä½•å®ç°è‡ªåŠ¨é…ç½®ï¼Œä¾èµ–äº Service æ˜¯å¦å®šä¹‰äº†é€‰æ‹©ç®—ç¬¦ã€‚ ç¤ºä¾‹ åˆ›å»º Headless Service 1234567891011121314vim headless_service.yamlapiVersion: v1kind: Servicemetadata: name: headless-service namespace: defaultspec: selector: app: nginx version: latest clusterIP: &quot;None&quot; ports: - port: 80 targetPort: 80 å¯ä»¥çœ‹åˆ°æ˜¯æ²¡æœ‰åˆ†é… VIP çš„ å®‰è£… bind-utils å·¥å…·æ¥æµ‹è¯•æ— å¤´æœåŠ¡çš„ä½œç”¨ï¼Œå¯ä»¥çœ‹åˆ°å³ä½¿æ²¡æœ‰äº† VIPï¼Œä½†ä¾æ—§å¯ä»¥é€šè¿‡åŸŸåæ¥è®¿é—®åˆ°ä¸åŒçš„ Pod 123456yum -y install bind-utils# k8så†…éƒ¨ä½¿ç”¨dnsè®¿é—®æ ¼å¼ï¼šSVCåç§°.å‘½åç©ºé—´.svc.é›†ç¾¤åŸŸ(é»˜è®¤é›†ç¾¤åŸŸä¸ºcluster.local)# digå‘½ä»¤å¯ä»¥ç”¨æ¥è·å–åŸŸåçš„è¯¦ç»†ä¿¡æ¯# 10.244.0.37æ˜¯å…¶ä¸­ä¸€ä¸ªcorednsçš„åœ°å€# -t A:æ˜¾ç¤ºAè®°å½•ï¼ŒAè®°å½•æ˜¯å°†åŸŸåæŒ‡å‘ä¸€ä¸ªIPv4åœ°å€ï¼Œå³ä¸€ä¸ªåŸŸåè§£æåˆ°ä¸€ä¸ªIPåœ°å€dig -t A headless-service.default.svc.cluster.local @10.244.0.37 5.6 NodePortNodePort çš„åŸç†åœ¨äºåœ¨ Node ä¸Šå¼€æ”¾äº†ä¸€ä¸ªç«¯å£ï¼Œå°†è¯¥ç«¯å£çš„æµé‡å¯¼å…¥åˆ° kube-proxy ä¸­ï¼Œç„¶åå†ç”± kube-proxy ä¼ é€ç»™ä¸åŒçš„ Podã€‚ ç¤ºä¾‹ åˆ›å»º Serviceï¼Œè¿™é‡Œçš„æ ‡ç­¾ä»ä¸ä¸Šé¢ ClusterIP ä¸­çš„ Deployment åˆ›å»ºçš„ Pod ç›¸åŒ¹é… 123456789101112131415vim nodeport_svc.yamlapiVersion: v1kind: Servicemetadata: name: nginx-nodeport-service namespace: defaultspec: type: NodePort selector: app: nginx version: latest ports: - name: http-port port: 80 targetPort: 80 å¯ä»¥çœ‹åˆ°ä¼šæš´éœ²ä¸€ä¸ªç«¯å£ï¼Œå¤–éƒ¨é€šè¿‡è¿™ä¸ªç«¯å£å°±å¯ä»¥è®¿é—®åˆ°å†…éƒ¨çš„ Podï¼Œä¸”æ˜¯æ¯ä¸€ä¸ª Node éƒ½å¼€å¯äº†è¿™ä¸ªç«¯å£ï¼Œæ‰€ä»¥ä¹Ÿå¯ä»¥å®ç°è´Ÿè½½å‡è¡¡ åœ¨ iptables / IPVS è§„åˆ™ä¸­å¯ä»¥çœ‹åˆ°å¼€å¯è¯¥ç«¯å£çš„è§„åˆ™ 12iptables -t nat -nvl | grep 31419ipvsadm -Ln | grep 31419 5.7 LoadBalancerLoadBalancer å°±æ˜¯åœ¨ NodePort çš„åŸºç¡€ä¸Šï¼Œé€šè¿‡ LAAS æ¥å®ç°è´Ÿè½½å‡è¡¡ï¼Œç”¨æˆ·æŒ‡è¦è®¿é—® LAASå³å¯ï¼ŒLAAS ä¼šå°†è¯·æ±‚é€šè¿‡è°ƒåº¦è½¬å‘ç»™ä¸åŒçš„ Nodeã€‚ 5.8 ExternalNameExternalName é€šè¿‡è¿”å› CNAME å’Œå®ƒçš„å€¼ï¼Œå°†æœåŠ¡æ˜ å°„åˆ° ExternalName å­—æ®µçš„å†…å®¹ï¼ŒExternalName æ²¡æœ‰ selectorï¼Œä¹Ÿæ²¡æœ‰ç«¯å£çš„è®¾ç½®ï¼Œå¯¹äºè¿è¡Œåœ¨é›†ç¾¤ä¹‹å¤–çš„æœåŠ¡ï¼ŒExternalName æ˜¯é€šè¿‡è¯¥å¤–éƒ¨æœåŠ¡çš„åˆ«åæ¥æä¾›æœåŠ¡çš„ã€‚ å½“è¿™ä¸ª Service åˆ›å»ºæˆåŠŸæ—¶ï¼Œå°±ä¼šæœ‰ externalname-service.default.svc.cluster.local çš„ fqdn è¢«åˆ›å»ºï¼Œå¦‚æœæœ‰ç”¨æˆ·è®¿é—®åˆ°è¿™ä¸ª fqdnï¼Œå°±ä¼šè¢«æ”¹å†™æˆ my.database.example.comï¼Œè¿™å°±æ˜¯ DNS å†…éƒ¨çš„ä¸€ä¸ª CNAME è®°å½•ï¼Œä¹Ÿå°±æ˜¯åˆ«åè®°å½•ã€‚ ç¤ºä¾‹ åˆ›å»ºæµ‹è¯•ç”¨çš„ Pod 123456789101112apiVersion: v1kind: Podmetadata: name: curl-podspec: containers: - name: curl-pod-container # curlé•œåƒåŒ…å«æµ‹è¯•ç½‘ç»œå’ŒDNSçš„å·¥å…· image: docker.io/appropriate/curl imagePullPolicy: IfNotPresent command: ['sh', '-c'] args: ['echo &quot;curl test&quot;; sleep 3600'] åˆ›å»º ExternalName 12345678apiVersion: v1kind: Servicemetadata: name: externalname-svcspec: type: externalname # å¼•å…¥ç™¾åº¦çš„ç½‘å€ externalName: www.baidu.com è¿›å…¥ Pod å†…éƒ¨æµ‹è¯•å¯ä»¥çœ‹åˆ°ï¼Œé€šè¿‡ nslookup å¯ä»¥è§£æåˆ°ç™¾åº¦çš„åœ°å€ 1nolookup SVCåç§°.å‘½åç©ºé—´.svc.é›†ç¾¤åŸŸ 5.9 ingress5.9.1 ä»€ä¹ˆæ˜¯ingressingress æ˜¯å¯¹é›†ç¾¤ä¸­æœåŠ¡çš„å¤–éƒ¨è®¿é—®è¿›è¡Œç®¡ç†çš„ API å¯¹è±¡ï¼Œå…¸å‹çš„è®¿é—®æ–¹å¼æ˜¯ HTTPã€‚ ingress å¯ä»¥æä¾›è´Ÿè½½å‡è¡¡ã€SSL ç»ˆç»“å’ŒåŸºäºåç§°çš„è™šæ‹Ÿæ‰˜ç®¡ã€‚ ingress ç”±ä¸¤éƒ¨åˆ†æ„æˆï¼š ingress controllerï¼šå°†æ–°åŠ å…¥çš„ ingress è½¬åŒ–æˆ Nginx çš„é…ç½®æ–‡ä»¶å¹¶ä½¿ä¹‹ç”Ÿæ•ˆã€‚ ingress æœåŠ¡ï¼šå°† Nginx çš„é…ç½®æŠ½è±¡æˆä¸€ä¸ª ingress å¯¹è±¡ï¼Œæ¯æ·»åŠ ä¸€ä¸ªæ–°çš„æœåŠ¡åªéœ€å†™ä¸€ä¸ªæ–°çš„ ingress çš„ yaml æ–‡ä»¶å³å¯ã€‚ ingress controller ä¸»è¦æœ‰ä¸¤ç§ï¼Œnginx-ingresså’Œtraefik-ingressï¼Œè¿™é‡Œä¸»è¦è®²nginx-ingressã€‚ ingress å®˜æ–¹ç½‘å€ï¼šhttps://kubernetes.github.io/nginx-ingress ingress GitHub ç½‘å€ï¼šhttps://github.com/kubernetes/nginx-ingress nginx-ingressåŠŸèƒ½ nginx-ingressä¸»è¦è´Ÿè´£å‘å¤–æš´éœ²æœåŠ¡ï¼ŒåŒæ—¶æä¾›è´Ÿè½½å‡è¡¡çš„åŠŸèƒ½ã€‚ Nginx å¯¹åç«¯è¿è¡Œçš„æœåŠ¡ï¼ˆService1ã€Service2ï¼‰æä¾›åå‘ä»£ç†ï¼Œåœ¨é…ç½®æ–‡ä»¶ä¸­é…ç½®äº†åŸŸåä¸åç«¯æœåŠ¡ Endpoints çš„å¯¹åº”å…³ç³»ã€‚å®¢æˆ·ç«¯é€šè¿‡ä½¿ç”¨ DNS æœåŠ¡æˆ–è€…ç›´æ¥é…ç½®æœ¬åœ°çš„ hosts æ–‡ä»¶ï¼Œå°†åŸŸåéƒ½æ˜ å°„åˆ° Nginx ä»£ç†æœåŠ¡å™¨ã€‚å½“å®¢æˆ·ç«¯è®¿é—® service1.com æ—¶ï¼Œæµè§ˆå™¨ä¼šæŠŠåŒ…å«åŸŸåçš„è¯·æ±‚å‘é€ç»™ Nginx æœåŠ¡å™¨ï¼ŒNginx æœåŠ¡å™¨æ ¹æ®ä¼ æ¥çš„åŸŸåï¼Œé€‰æ‹©å¯¹åº”çš„ Serviceï¼Œè¿™é‡Œå°±æ˜¯é€‰æ‹© Service1 åç«¯æœåŠ¡ï¼Œç„¶åæ ¹æ®ä¸€å®šçš„è´Ÿè½½å‡è¡¡ç­–ç•¥ï¼Œé€‰æ‹© Service1 ä¸­çš„æŸä¸ªå®¹å™¨æ¥æ”¶æ¥è‡ªå®¢æˆ·ç«¯çš„è¯·æ±‚å¹¶ä½œå‡ºå“åº”ã€‚è¿‡ç¨‹å¾ˆç®€å•ï¼ŒNginx åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­ä»¿ä½›æ˜¯ä¸€å°æ ¹æ®åŸŸåè¿›è¡Œè¯·æ±‚è½¬å‘çš„â€œè·¯ç”±å™¨â€ã€‚ nginx-ingresså·¥ä½œè¿‡ç¨‹ nginx-ingressæ¨¡å—åœ¨è¿è¡Œæ—¶ä¸»è¦åˆ†ä¸ºä¸‰ä¸ªä¸»ä½“ï¼š Storeï¼šStore ä¼šä¸ APIServer ä»¥åç¨‹çš„ Pod æ–¹å¼è¿›è¡Œä¸€ä¸ªç›‘å¬çŠ¶æ€ï¼Œå‘ç”Ÿæ–°çš„äº‹ä»¶ä¼šå†™å…¥å¾ªç¯é˜Ÿåˆ—é‡Œã€‚ NginxControllerï¼šNginxController ä¼šç›‘å¬å¾ªç¯é˜Ÿåˆ—é‡Œçš„äº‹ä»¶ï¼Œå‘ç”Ÿä¸€ä¸ªå¾ªç¯å°±ä¼šæ›´æ–°ä¸€ä¸ªäº‹ä»¶ï¼Œå¹¶å†™å…¥ SyncQueue é‡Œã€‚ SyncQueueï¼šSyncQueue åç¨‹ä¼šå®šæœŸæ‹‰å–éœ€è¦æ‰§è¡Œçš„ä»»åŠ¡ï¼ˆå¦‚æœæœ‰å¿…è¦çš„åˆ™ç›´æ¥ä» Store æ‹‰å–è¿‡æ¥è¿›è¡Œä¿®æ”¹ï¼‰ï¼Œæ¥ç€åˆ¤æ–­æ˜¯å¦éœ€è¦ reload nginxï¼Œæœ€åä¼šä»¥ nginx æ¨¡å—è¿è¡Œã€‚ 5.9.2 ingressè§„åˆ™æ¯ä¸ª HTTP è§„åˆ™éƒ½åŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š å¯é€‰çš„ hostã€‚åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼ŒæœªæŒ‡å®š hostï¼Œå› æ­¤è¯¥è§„åˆ™é€‚ç”¨äºé€šè¿‡æŒ‡å®š IP åœ°å€çš„æ‰€æœ‰å…¥ç«™ HTTP é€šä¿¡ã€‚ å¦‚æœæä¾›äº† hostï¼ˆä¾‹å¦‚ www.cqm.comï¼‰ï¼Œåˆ™ rules é€‚ç”¨äºè¯¥ hostã€‚ è·¯å¾„åˆ—è¡¨ pathsï¼ˆä¾‹å¦‚ï¼Œ/testpathï¼‰,æ¯ä¸ªè·¯å¾„éƒ½æœ‰ä¸€ä¸ªç”± serviceName å’Œ servicePort å®šä¹‰çš„å…³è”åç«¯ã€‚ åœ¨è´Ÿè½½å‡è¡¡å™¨å°†æµé‡å®šå‘åˆ°å¼•ç”¨çš„æœåŠ¡ä¹‹å‰ï¼Œä¸»æœºå’Œè·¯å¾„éƒ½å¿…é¡»åŒ¹é…ä¼ å…¥è¯·æ±‚çš„å†…å®¹ã€‚ backendï¼ˆåç«¯ï¼‰æ˜¯ Service æ–‡æ¡£ ä¸­æ‰€è¿°çš„æœåŠ¡å’Œç«¯å£åç§°çš„ç»„åˆã€‚ ä¸è§„åˆ™çš„ host å’Œ path åŒ¹é…çš„å¯¹ Ingress çš„ HTTPï¼ˆå’Œ HTTPS ï¼‰è¯·æ±‚å°†å‘é€åˆ°åˆ—å‡ºçš„ backendã€‚ è·¯å¾„ç±»å‹ Ingress ä¸­çš„æ¯ä¸ªè·¯å¾„éƒ½éœ€è¦æœ‰å¯¹åº”çš„è·¯å¾„ç±»å‹ï¼ˆPath Typeï¼‰ã€‚æœªæ˜ç¡®è®¾ç½® pathType çš„è·¯å¾„æ— æ³•é€šè¿‡åˆæ³•æ€§æ£€æŸ¥ã€‚å½“å‰æ”¯æŒçš„è·¯å¾„ç±»å‹æœ‰ä¸‰ç§ï¼š ImplementationSpecificï¼šå¯¹äºè¿™ç§è·¯å¾„ç±»å‹ï¼ŒåŒ¹é…æ–¹æ³•å–å†³äº IngressClassã€‚ å…·ä½“å®ç°å¯ä»¥å°†å…¶ä½œä¸ºå•ç‹¬çš„ pathType å¤„ç†æˆ–è€…ä¸ Prefix æˆ– Exact ç±»å‹ä½œç›¸åŒå¤„ç†ã€‚ Exactï¼šç²¾ç¡®åŒ¹é… URL è·¯å¾„ï¼Œä¸”åŒºåˆ†å¤§å°å†™ã€‚ Prefixï¼šåŸºäºä»¥ / åˆ†éš”çš„ URL è·¯å¾„å‰ç¼€åŒ¹é…ã€‚åŒ¹é…åŒºåˆ†å¤§å°å†™ï¼Œå¹¶ä¸”å¯¹è·¯å¾„ä¸­çš„å…ƒç´ é€ä¸ªå®Œæˆã€‚ è·¯å¾„å…ƒç´ æŒ‡çš„æ˜¯ç”± / åˆ†éš”ç¬¦åˆ†éš”çš„è·¯å¾„ä¸­çš„æ ‡ç­¾åˆ—è¡¨ã€‚ å¦‚æœæ¯ä¸ª p éƒ½æ˜¯è¯·æ±‚è·¯å¾„ p çš„å…ƒç´ å‰ç¼€ï¼Œåˆ™è¯·æ±‚ä¸è·¯å¾„ p åŒ¹é…ã€‚ 5.9.3 éƒ¨ç½²nginx-ingress é€šè¿‡ Bare-metalï¼ˆNodePortï¼‰ æ–¹å¼éƒ¨ç½²ï¼Œå…ˆä¸‹è½½ yaml æ–‡ä»¶ 123456789# åœ°å€ä¸€# https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v0.46.0/deploy/static/provider/baremetal/deploy.yaml# åœ°å€äºŒ# https://github.com/kubernetes/ingress-nginx/blob/master/deploy/static/provider/baremetal/deploy.yaml# ç”±äºé•œåƒåœ°å€ä¹Ÿåœ¨å›½å¤–ï¼Œæ‰€ä»¥é€šè¿‡å›½å†…é•œåƒæºæ‹‰å–docker pull registry.aliyuncs.com/google_containers/nginx-ingress-controller:v0.46.0docker tag registry.aliyuncs.com/google_containers/nginx-ingress-controller:v0.46.0 k8s.gcr.io/ingress-nginx/controller:v0.46.0 è·å–é•œåƒåœ°å€ï¼Œä¸‹è½½å¥½éœ€è¦çš„é•œåƒï¼Œå¹¶å¯¼å…¥é•œåƒåˆ°å…¶å®ƒ node ä¸Š é€šè¿‡ deploy.yaml æ–‡ä»¶ç”Ÿæˆ svc 1kubectl create -f deploy.yaml 5.9.4 ingress HTTPä»£ç†è®¿é—® ingress-nginxä¼šæ ¹æ®é…ç½®å¥½çš„ yaml æ–‡ä»¶ï¼Œè‡ªåŠ¨é…ç½® nginx.conf å’Œè™šæ‹Ÿä¸»æœºæ–‡ä»¶ã€‚ åˆ›å»º deployment1ã€deployment2ã€service1ã€service2 1234567891011121314151617181920212223242526272829303132333435vim nginx_deployment_svc1.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment1spec: replicas: 2 selector: matchLabels: name: nginx1 template: metadata: labels: name: nginx1 spec: containers: - name: nginx-pod image: daocloud.io/library/nginx:latest imagePullPolicy: IfNotPresent ports: - containerPort: 80---apiVersion: v1kind: Servicemetadata: name: nginx-service1spec: ports: - port: 80 targetPort: 80 protocol: TCP selector: name: nginx1 1234567891011121314151617181920212223242526272829303132333435vim nginx_deployment_svc2.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment2spec: replicas: 2 selector: matchLabels: name: nginx2 template: metadata: labels: name: nginx2 spec: containers: - name: nginx-pod image: daocloud.io/library/nginx:latest imagePullPolicy: IfNotPresent ports: - containerPort: 80---apiVersion: v1kind: Servicemetadata: name: nginx-service2spec: ports: - port: 80 targetPort: 80 protocol: TCP selector: name: nginx2 åˆ›å»º nginx-ingress1ã€nginx-ingress2 123456789101112131415161718192021222324252627282930313233343536373839vim nginx_ingress.yamlapiVersion: networking.k8s.io/v1kind: Ingressmetadata: name: nginx-ingress1spec: rules: # è®¾ç½®è™šæ‹Ÿä¸»æœºï¼Œé€šè¿‡è¯¥åŸŸåè®¿é—® - host: www.cqm1.com http: paths: # è·¯å¾„åˆ—è¡¨ - path: /pod.html # è·¯å¾„ç±»å‹ pathType: ImplementationSpecific # åç«¯ backend: # æŒ‡å®šè¿æ¥å“ªä¸ªSVC serviceName: nginx-service1 servicePort: 80---apiVersion: networking.k8s.io/v1kind: Ingressmetadata: name: nginx-ingress2spec: rules: - host: www.cqm2.com http: paths: - path: /pod.html pathType: ImplementationSpecific backend: service: name: nginx-service2 port: number: 80 åˆ›å»º 123kubectl create -f nginx_deployment_svc1.yamlkubectl create -f nginx_deployment_svc2.yamlkubectl create -f nginx_ingress.yaml ç»™æ¯ä¸ª Pod å†™å…¥ä¿¡æ¯ï¼Œæ–¹ä¾¿æŸ¥çœ‹è´Ÿè½½å‡è¡¡ 12kubectl exec -it nginx-deployment-... -- /bin/bashecho 'this is nginx-pod-1' &gt; /usr/share/nginx/html/pod.html æŸ¥çœ‹ ingress-nginx æ‰€åˆ›å»ºçš„ svc æš´éœ²çš„ç«¯å£ï¼Œä»¥åŠ service1ã€service2ã€nginx-ingress1ã€nginx-ingress2 123kubectl get svc -n ingress-nginxkubectl get svckubectl get ingress åœ¨ /etc/hosts æ–‡ä»¶ä¸‹å†™å…¥åŸŸåä¸ IP ç»‘å®šï¼Œè®¿é—®æµ‹è¯•ï¼Œå¯ä»¥çœ‹åˆ°å®ç°äº†è´Ÿè½½å‡è¡¡ å¯ä»¥è¿›å…¥ ingress æ§åˆ¶å™¨å†…éƒ¨æŸ¥çœ‹ nginx é…ç½®ï¼Œå¯ä»¥çœ‹åˆ°è‡ªåŠ¨æ·»åŠ çš„ä»£ç†é…ç½® 12kubectl exec -it -n ingress-nginx ingress-nginx-controller-... -- /bin/bashcat nginx.conf 5.9.5 ingress HTTPSä»£ç†è®¿é—® åˆ›å»ºç§é’¥ 12openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj &quot;/CN=nginxsvc/O=nginxsvc&quot;kubectl create secret tls tls-secret --key tls.key --cert tls.crt åˆ›å»º deployment3ã€service3ã€nginx-ingress3 1234567891011121314151617181920212223242526272829303132333435vim nginx_deployment_svc3.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment3spec: replicas: 2 selector: matchLabels: name: nginx3 template: metadata: labels: name: nginx3 spec: containers: - name: nginx-pod image: daocloud.io/library/nginx:latest imagePullPolicy: IfNotPresent ports: - containerPort: 80---apiVersion: v1kind: Servicemetadata: name: nginx-service3spec: ports: - port: 80 targetPort: 80 protocol: TCP selector: name: nginx3 12345678910111213141516171819vim nginx_ingress.yamlapiVersion: networking.k8s.io/v1kind: Ingressmetadata: name: nginx-ingress3spec: tls: - hosts: - www.cqm3.com secretName: tls-secret rules: - host: www.cqm3.com http: paths: - path: /pod.html pathType: ImplementationSpecific backend: serviceName: nginx-service3 servicePort: 80 åˆ›å»º 1kubectl create -f nginx_deployment_svc3.yaml nginx_ingress.yaml åœ¨æ¯ä¸ª Pod å†™å…¥ pod.htmlï¼Œä¾¿äºæŸ¥çœ‹è´Ÿè½½å‡è¡¡æ•ˆæœï¼Œå¹¶æµ‹è¯• 12kubectl exec -it ingress-nginx-... -- /bin/bashecho 'this is node01-pod' &gt; /usr/share/nginx/html/pod.html 5.9.5 Nginxè¿›è¡ŒåŸºç¡€è®¤è¯ï¼ˆBasicAuthï¼‰ é€šè¿‡ Apache åˆ›å»ºç”¨æˆ·è®¤è¯æ–‡ä»¶ 123yum -y install httpdhtpasswd -c auth cqmkubectl create secret generic basic-auth --from-file=auth åˆ›å»º ingress 1234567891011121314151617181920212223vim nginx_ingress.yamlapiVersion: networking.k8s.io/v1kind: Ingressmetadata: name: ingress-nginx-auth # æ·»åŠ åŸºç¡€è®¤è¯å­—æ®µ annotations: nginx.ingress.kubernetes.io/auth-type: basic nginx.ingress.kubernetes.io/auth-secret: basic-auth nginx.ingress.kubernetes.io/auth-realm: 'Authentication Required - cqm'spec: rules: - host: auth.cqm.com http: paths: - path: /pod.html pathType: ImplementationSpecific backend: service: # è¿™é‡Œä½¿ç”¨HTTPä»£ç†å®éªŒçš„service1 name: nginx-service1 port: number: 80 åˆ›å»º ingress åæµ‹è¯• 5.9.6 Nginxé‡å†™ åç§° æè¿° ç±»å‹ nginx.ingress.kubernetes.io/rewrite-target å¿…é¡»é‡å®šå‘æµé‡çš„ç›®æ ‡ URI string nginx.ingress.kubernetes.io/ssl-redirect æŒ‡ç¤ºä½ç½®éƒ¨åˆ†æ˜¯å¦ä»…å¯è®¿é—® SSLï¼ˆå½“ Ingress åŒ…å«è¯ä¹¦æ—¶é»˜è®¤ä¸º Trueï¼‰ bool nginx.ingress.kubernetes.io/force-ssl-redirect å³ä½¿ Ingress æœªå¯ç”¨ TLSï¼Œä¹Ÿå¼ºåˆ¶é‡å®šå‘åˆ° HTTPS bool nginx.ingress.kubernetes.io/app-root å®šä¹‰æ§åˆ¶å™¨å¿…é¡»é‡å®šå‘çš„åº”ç”¨ç¨‹åºæ ¹ï¼Œå¦‚æœå®ƒåœ¨â€œ/â€ä¸Šä¸‹æ–‡ä¸­ string nginx.ingress.kubernetes.io/use-regex æŒ‡ç¤º Ingress ä¸Šå®šä¹‰çš„è·¯å¾„æ˜¯å¦ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ bool å…ˆå‡†å¤‡å¥½è½¬å‘åçš„ deploymentã€ingressç­‰ï¼Œè¿™é‡Œç”¨ä¸Šè¾¹çš„ ingress1ï¼Œç”¨æˆ·è®¿é—® www.rewritecqm.com æ—¶å°±è·³è½¬åˆ° www.cqm1.com ç¼–å†™é‡å†™ ingress 1234567891011121314151617181920vim rewrite_ingress.yamlapiVersion: networking.k8s.io/v1kind: Ingressmetadata: name: rewrite-ingress annotations: # è®¿é—® www.rewritecqm.com:30779 å°†è·³è½¬åˆ° http://www.cqm1.com:30779/pod.html nginx.ingress.kubernetes.io/rewrite-target: http://www.cqm1.com:30779/pod.htmlspec: rules: - host: www.rewritecqm.com http: paths: - path: /pod.html pathType: Prefix backend: service: name: nginx-service1 port: number: 80 æµ‹è¯• å…­ã€k8så­˜å‚¨6.1 é…ç½®å­˜å‚¨å·é…ç½®å­˜å‚¨å·å¹¶ä¸æ˜¯ç”¨æ¥è¿›è¡Œå®¹å™¨é—´ç›¸äº’äº¤äº’æˆ– Pod é—´æ•°æ®å…±äº«çš„ï¼Œè€Œæ˜¯ç”¨äºå‘å„ä¸ª Pod æ³¨å…¥é…ç½®ä¿¡æ¯çš„ï¼Œä¸»è¦åˆ†ä¸ºä»¥ä¸‹ä¸‰ç§ï¼š ConfigMapï¼šå¯ä¼ é€’æ™®é€šä¿¡æ¯ Secretï¼šå¯ä¼ é€’å¯†ç ç­‰æ•æ„Ÿçš„é…ç½®ä¿¡æ¯ DownwardAPIï¼šå¯ä¼ é€’ Pod å’Œå®¹å™¨è‡ªèº«çš„è¿è¡Œä¿¡æ¯ 6.1.1 ConfigMapè®¸å¤šåº”ç”¨ç¨‹åºéƒ½ä¼šä»é…ç½®æ–‡ä»¶ã€å‘½ä»¤è¡Œå‚æ•°æˆ–ç¯å¢ƒå˜é‡ä¸­è¯»å–é…ç½®ä¿¡æ¯ã€‚ ConfigMap API ç»™æˆ‘ä»¬æä¾›äº†å‘å®¹å™¨å†…éƒ¨æ³¨å…¥ä¿¡æ¯çš„æœºåˆ¶ï¼ŒConfigMap å¯ä»¥è¢«ç”¨æ¥ä¿å­˜å•ä¸ªå±æ€§ï¼Œä¹Ÿå¯ä»¥ç”¨æ¥ä¿å­˜æ•´ä¸ªé…ç½®æ–‡ä»¶æˆ–è€… JSON äºŒè¿›åˆ¶å¯¹è±¡ã€‚ ConfigMap çš„åˆ›å»ºæ–¹å¼æœ‰ä¸‰ç§ï¼Œåˆ†åˆ«ä¸ºåŸºäºç›®å½•ã€æ–‡ä»¶å’Œå­—é¢å€¼æ¥åˆ›å»ºã€‚ åŸºäºç›®å½•åˆ›å»º ConfigMap åˆ›å»ºæŒ‡å®šç›®å½•ï¼Œä¸‹è½½å®˜æ–¹æµ‹è¯•æ–‡ä»¶ 1234mkdir -p /root/k8s/plugin/configmap/dir || cd /root/k8s/plugin/configmap/dirwget https://kubernetes.io/examples/configmap/game.propertieswget https://kubernetes.io/examples/configmap/ui.propertieskubectl create configmap configmap1 --from-file=./ æŸ¥çœ‹å‘½ä»¤ 12kubectl describe cm configmap1kubectl get cm configmap1 -o yaml åŸºäºæ–‡ä»¶åˆ›å»º ConfigMap é€šè¿‡ game.properties å’Œ ui.properties åˆ›å»º 1kubectl create configmap configmap2 --from-file=game.properties --from-file=ui.properties åŸºäºå­—é¢å€¼åˆ›å»º ConfigMap é€šè¿‡--from-literal=é”®å=é”®å€¼æ¥åˆ›å»º 1kubectl create configmap configmap3 --from-literal=special.how=very 6.1.1.1 Podä¸­ä½¿ç”¨ConfigMapä½¿ç”¨ ConfigMap ä»£æ›¿ç¯å¢ƒå˜é‡ åˆ›å»ºä¸¤ä¸ª ConfigMap 123456789vim special_cm.yamlapiVersion: v1kind: ConfigMapmetadata: name: special-cm namespace: defaultdata: special.how: very special.type: charm 12345678vim env_cm.yamlapiVersion: v1kind: ConfigMapmetadata: name: env-cm namespace: defaultdata: log_level: INFO å°†è¿™ä¸¤ä¸ª ConfigMap æ³¨å…¥åˆ° Podä¸­ 1234567891011121314151617181920212223242526272829303132vim pod1.yamlapiVersion: v1kind: Podmetadata: name: pod1spec: containers: - name: pod1-container image: busybox imagePullPolicy: IfNotPresent command: [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;env&quot;] # env:å–æŸä¸ª ConfigMap ä¸­çš„æŸä¸ªé”®å€¼ env: - name: SPECIAL_HOW_KEY # å®šä¹‰ç¯å¢ƒå˜é‡ valueFrom: # è¡¨ç¤ºä» ConfigMap ä¸­å¼•ç”¨ configMapKeyRef: # è¦å¼•ç”¨çš„ ConfigMap åç§° name: special-cm # å¼•ç”¨ ConfigMap ä¸­çš„å“ªä¸ªé”®å€¼å¯¹ key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-cm key: special.type # envFrom:å–æŸä¸ª ConfigMap çš„æ‰€æœ‰é”®å€¼ envFrom: - configMapRef: name: env-cm restartPolicy: Never ç”Ÿæˆ Pod åæŸ¥çœ‹æ—¥å¿—ï¼Œå¯ä»¥çœ‹åˆ°æ³¨å…¥æˆåŠŸ 1kubectl logs pod1 ä½¿ç”¨ ConfigMap è®¾ç½®å‘½ä»¤è¡Œå‚æ•° 1234567891011121314151617181920212223242526vim pod2.yamlapiVersion: v1kind: Podmetadata: name: pod2spec: containers: - name: pod2-container image: busybox imagePullPolicy: IfNotPresent command: [&quot;sh&quot;, &quot;-c&quot;, &quot;echo $(SPECIAL_HOW_KEY) $(SPECIAL_TYPE_KEY)&quot;] env: - name: SPECIAL_HOW_KEY valueFrom: configMapKeyRef: name: special-cm key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-cm key: special.type envFrom: - configMapRef: name: env-cm restartPolicy: Never å°† ConfigMap æ•°æ®æ·»åŠ åˆ°ä¸€ä¸ªå·ä¸­ åˆ›å»º Pod 123456789101112131415161718192021vim pod3.yamlapiVersion: v1kind: Podmetadata: name: pod3spec: containers: - name: pod3-container image: busybox imagePullPolicy: IfNotPresent command: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 1200&quot; ] # æŒ‚è½½config-volumeï¼ŒæŒ‚è½½åœ¨/etc/configç›®å½•ä¸‹ volumeMounts: - name: config-volume mountPath: /etc/config # åˆ›å»ºä¸€ä¸ªå·ï¼Œå°†special-cmå†…å®¹å†™å…¥config-volumeå· volumes: - name: config-volume configMap: name: special-cm restartPolicy: Never è¿›å…¥ Podï¼Œåœ¨æŒ‚è½½ç›®å½•ä¸‹æŸ¥çœ‹æ˜¯å¦å†™å…¥åˆ° config æ–‡ä»¶é‡Œ 6.1.1.2 ConfigMapçƒ­æ›´æ–°æœ¬ä¾‹å­é€šè¿‡ ConfigMap æ¥å®ç°çƒ­æ›´æ–°ï¼Œå¯ä»¥å®ç°çƒ­æ›´æ–° nginx.confï¼Œä½†éœ€è¿›å…¥å®¹å™¨å†…éƒ¨é‡è½½é…ç½®æ–‡ä»¶ï¼Œæ‰€ä»¥é€šè¿‡çƒ­æ›´æ–°ä¸€ä¸ª html æ¥å±•ç¤ºæ•ˆæœã€‚ ç¼–å†™ yaml æ–‡ä»¶ï¼Œå¹¶åˆ›å»º 123456789101112131415161718192021222324252627282930313233343536373839404142vim hotupdate.yaml# ConfigMapapiVersion: v1kind: ConfigMapmetadata: name: nginx-hotupdate-cm namespace: defaultdata: test.html: 'this is the fist test'---# DeploymentapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment namespace: defaultspec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx-pod image: daocloud.io/library/nginx:latest ports: - containerPort: 80 # æŒ‚è½½ä¸‹è¾¹åˆ›å»ºçš„volume volumeMounts: - name: test-html-volume mountPath: /usr/share/nginx/html # åˆ›å»ºä¸€ä¸ªvolumeï¼Œé€šè¿‡ConfigMapæ–¹å¼æŒ‚è½½ï¼Œä½¿ç”¨ä¸Šé¢åˆ›å»ºçš„nginx-hotupdate-cm volumes: - name: test-html-volume configMap: name: nginx-hotupdate-cm 1kubectl apply -f hotupdate.yaml æµ‹è¯•æ˜¯å¦èƒ½å¤Ÿè®¿é—®åˆ° ä¿®æ”¹ ConfigMapï¼Œå¹¶å†æ¬¡è®¿é—® 1kubectl edit cm nginx-hotupdate-cm 6.1.2 SecretSecret å¯¹è±¡ç±»å‹ç”¨æ¥ä¿å­˜æ•æ„Ÿä¿¡æ¯ï¼Œä¾‹å¦‚å¯†ç ã€OAuth ä»¤ç‰Œå’Œ SSH å¯†é’¥ã€‚ å°†è¿™äº›ä¿¡æ¯æ”¾åœ¨ secret ä¸­æ¯”æ”¾åœ¨ Pod çš„å®šä¹‰æˆ–è€… å®¹å™¨é•œåƒ ä¸­æ¥è¯´æ›´åŠ å®‰å…¨å’Œçµæ´»ã€‚ Secret çš„ç±»å‹ å†…ç½®ç±»å‹ ç”¨æ³• Opaque ç”¨æˆ·å®šä¹‰çš„ä»»æ„æ•°æ® kubernetes.io/service-account-token æœåŠ¡è´¦å·ä»¤ç‰Œ kubernetes.io/dockercfg ~/.dockercfg æ–‡ä»¶çš„åºåˆ—åŒ–å½¢å¼ kubernetes.io/dockerconfigjson ~/.docker/config.json æ–‡ä»¶çš„åºåˆ—åŒ–å½¢å¼ kubernetes.io/basic-auth ç”¨äºåŸºæœ¬èº«ä»½è®¤è¯çš„å‡­æ® kubernetes.io/ssh-auth ç”¨äº SSH èº«ä»½è®¤è¯çš„å‡­æ® kubernetes.io/tls ç”¨äº TLS å®¢æˆ·ç«¯æˆ–è€…æœåŠ¡å™¨ç«¯çš„æ•°æ® bootstrap.kubernetes.io/token å¯åŠ¨å¼•å¯¼ä»¤ç‰Œæ•°æ® 6.1.2.1 OpaqueOpaque ä½¿ç”¨base64ç¼–ç å­˜å‚¨ä¿¡æ¯ï¼Œå¯ä»¥é€šè¿‡ base64 --decode è§£ç è·å¾—åŸå§‹æ•°æ®ï¼Œå› æ­¤å®‰å…¨æ€§å¼±ã€‚ ä½¿ç”¨ç¤ºä¾‹ ç”Ÿæˆ base64 ç¼–ç  1234echo 'admin' | base64YWRtaW4Kecho '12345' | base64MTIzNDUK ç¼–å†™ yaml æ–‡ä»¶ 123456789vim opaque.yamlapiVersion: v1kind: Secretmetadata: name: secret-opaquetype: Opaquedata: username: YWRtaW4K password: MTIzNDUK 1kubectl apply -f opaque.yaml æŒ‚è½½åˆ° volume ä¸­ä½¿ç”¨ï¼ŒæŸ¥çœ‹æµ‹è¯•å¯ä»¥çœ‹åˆ°æŒ‚è½½åçš„ä¿¡æ¯è¢«è§£ç äº† 12345678910111213141516171819vim opaque-pod1.yamlapiVersion: v1kind: Podmetadata: name: opaque-pod1spec: containers: - name: opaque-pod1-nginx image: daocloud.io/library/nginx:latest # æŒ‚è½½ä¸‹è¾¹åˆ›å»ºçš„volume-opaque volumeMounts: - name: volume-opaque mountPath: /etc/secrets readOnly: yes # åˆ›å»ºä¸€ä¸ªsecretç±»å‹çš„volumeï¼Œå¼•ç”¨ä¸Šè¾¹åˆ›å»ºå¥½çš„secret-opaque volumes: - name: volume-opaque secret: secretName: secret-opaque å¯¼å…¥åˆ°ç¯å¢ƒå˜é‡ä¸­å¹¶æµ‹è¯• 123456789101112131415161718192021222324252627282930313233343536vim opaque-pod2.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: opaque-deploymentspec: replicas: 1 selector: matchLabels: app: nginx template: metadata: name: opaque-pod2 labels: app: nginx spec: containers: - name: opaque-pod2-nginx image: daocloud.io/library/nginx:latest ports: - containerPort: 80 # å°†secretå¯¼å…¥ç¯å¢ƒå˜é‡ä¸­ env: # å‘½åå˜é‡ - name: USER # å¼•ç”¨secret-opaqueä¸­çš„usernameçš„é”®å€¼ valueFrom: secretKeyRef: name: secret-opaque key: username - name: PASSWORD # å¼•ç”¨secret-opaqueä¸­çš„passwordçš„é”®å€¼ valueFrom: secretKeyRef: name: secret-opaque key: password 6.1.2.2 ImagePullSecretå¯ä»¥ä½¿ç”¨ä¸‹é¢ä¸¤ç§ type å€¼ä¹‹ä¸€æ¥åˆ›å»º Secretï¼Œç”¨ä»¥å­˜æ”¾è®¿é—® Docker ä»“åº“æ¥ä¸‹è½½é•œåƒçš„å‡­æ®ã€‚ kubernetes.io/dockercfg kubernetes.io/dockerconfigjson kubernetes.io/dockerconfigjson åˆ›å»º Secret ç¤ºä¾‹ åˆ›å»º Secret 1kubectl create secret docker-registry cqmregistry --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAIL åœ¨ Pod ä¸­è¿ç”¨ 1234567891011apiVersion: v1kind: Podmetadata: name: nginxspec: containers: - name: nginx-pod image: daocloud.io/library/nginx:latest # è°ƒç”¨åˆ›å»ºå¥½çš„Secret imagePullSecrets: - name: cqmregistry 6.1.2.3 Downward APIæœ‰æ—¶å€™ Pod éœ€è¦è·å–è‡ªèº«çš„ä¿¡æ¯ï¼Œè¿™æ—¶å€™ Downward API å°±æ´¾ä¸Šç”¨åœºäº†ã€‚ Downward API æ˜¯é€šè¿‡ fieldRef å‚æ•°è·å–ä¿¡æ¯çš„ã€‚ ç¤ºä¾‹ä¸€ 1234567891011121314151617181920apiVersion: v1kind: Podmetadata: name: test-pod1spec: containers: - name: test-pod1-container image: busybox imagePullPolicy: IfNotPresent command: [ 'sh', '-c' ] args: [ 'echo &quot;EnvPodName:${EnvPodName} EnvNodeName:${EnvNodeName}&quot;, sleep 3600' ] env: - name: EnvPodName valueFrom: fieldRef: fieldPath: metadata.name - name: EnvNodeName valueFrom: fieldRef: fieldPath: spec.nodeName ç¤ºä¾‹äºŒ 123456789101112131415161718192021222324apiVersion: v1kind: Podmetadata: name: test-pod2spec: containers: - name: test-pod2-container image: busybox imagePullPolicy: IfNotPresent command: [ 'sh', '-c' ] args: [ 'echo &quot;EnvPodName:${EnvPodName} EnvNodeName:${EnvNodeName}&quot;, sleep 3600' ] volumeMounts: - name: test-volume mountPath: /test volumes: - name: test-volume downwardAPI: items: - path: 'PodName' fieldRef: fieldPath: metadata.name - path: 'NodeName' fieldRef: fieldPath: spec.nodeName 6.2 æœ¬åœ°å­˜å‚¨å·Container ä¸­çš„æ–‡ä»¶åœ¨ç£ç›˜ä¸Šæ˜¯ä¸´æ—¶å­˜æ”¾çš„ï¼Œè¿™ç»™ Container ä¸­è¿è¡Œçš„è¾ƒé‡è¦çš„åº”ç”¨ç¨‹åºå¸¦æ¥ä¸€äº›é—®é¢˜ã€‚é—®é¢˜ä¹‹ä¸€æ˜¯å½“å®¹å™¨å´©æºƒæ—¶æ–‡ä»¶ä¸¢å¤±ã€‚kubelet ä¼šé‡æ–°å¯åŠ¨å®¹å™¨ï¼Œ ä½†å®¹å™¨ä¼šä»¥å¹²å‡€çš„çŠ¶æ€é‡å¯ã€‚ ç¬¬äºŒä¸ªé—®é¢˜ä¼šåœ¨åŒä¸€ Pod ä¸­è¿è¡Œå¤šä¸ªå®¹å™¨å¹¶å…±äº«æ–‡ä»¶æ—¶å‡ºç°ã€‚ Kubernetes Volume è¿™ä¸€æŠ½è±¡æ¦‚å¿µèƒ½å¤Ÿè§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ã€‚ Kubernetes æ”¯æŒå¾ˆå¤šç±»å‹çš„å·ã€‚ Pod å¯ä»¥åŒæ—¶ä½¿ç”¨ä»»æ„æ•°ç›®çš„å·ç±»å‹ã€‚ ä¸´æ—¶å·ç±»å‹çš„ç”Ÿå‘½å‘¨æœŸä¸ Pod ç›¸åŒï¼Œä½†æŒä¹…å·å¯ä»¥æ¯” Pod çš„å­˜æ´»æœŸé•¿ã€‚ å½“ Pod ä¸å†å­˜åœ¨æ—¶ï¼ŒKubernetes ä¹Ÿä¼šé”€æ¯ä¸´æ—¶å·ï¼›ä¸è¿‡ Kubernetes ä¸ä¼šé”€æ¯æŒä¹…å·ã€‚å¯¹äºç»™å®š Pod ä¸­ä»»ä½•ç±»å‹çš„å·ï¼Œåœ¨å®¹å™¨é‡å¯æœŸé—´æ•°æ®éƒ½ä¸ä¼šä¸¢å¤±ã€‚ å·çš„ç±»å‹åˆ†ä¸ºå¾ˆå¤šç§ï¼Œå¯é€šè¿‡å®˜æ–¹æ–‡æ¡£æŸ¥çœ‹ï¼šhttps://kubernetes.io/zh/docs/concepts/storage/volumes/ 6.2.1 emptyDirå½“ Pod åˆ†æ´¾åˆ°æŸä¸ª Node ä¸Šæ—¶ï¼ŒemptyDir å·ä¼šè¢«åˆ›å»ºï¼Œå¹¶ä¸”åœ¨ Pod åœ¨è¯¥èŠ‚ç‚¹ä¸Šè¿è¡ŒæœŸé—´ï¼Œå·ä¸€ç›´å­˜åœ¨ã€‚ å°±åƒå…¶åç§°è¡¨ç¤ºçš„é‚£æ ·ï¼Œå·æœ€åˆæ˜¯ç©ºçš„ã€‚ å°½ç®¡ Pod ä¸­çš„å®¹å™¨æŒ‚è½½ emptyDir å·çš„è·¯å¾„å¯èƒ½ç›¸åŒä¹Ÿå¯èƒ½ä¸åŒï¼Œè¿™äº›å®¹å™¨éƒ½å¯ä»¥è¯»å†™ emptyDir å·ä¸­ç›¸åŒçš„æ–‡ä»¶ã€‚ å½“ Pod å› ä¸ºæŸäº›åŸå› è¢«ä»èŠ‚ç‚¹ä¸Šåˆ é™¤æ—¶ï¼ŒemptyDir å·ä¸­çš„æ•°æ®ä¹Ÿä¼šè¢«æ°¸ä¹…åˆ é™¤ã€‚ éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå®¹å™¨å´©æºƒå¹¶ä¸ä¼šå¯¼è‡´ Pod è¢«ä»èŠ‚ç‚¹ä¸Šç§»é™¤ï¼Œå› æ­¤å®¹å™¨å´©æºƒæœŸé—´ emptyDir å·ä¸­çš„æ•°æ®æ˜¯å®‰å…¨çš„ã€‚ emptyDir çš„ä¸€äº›ç”¨é€”ï¼š ç¼“å­˜ç©ºé—´ï¼Œä¾‹å¦‚åŸºäºç£ç›˜çš„å½’å¹¶æ’åºã€‚ ä¸ºè€—æ—¶è¾ƒé•¿çš„è®¡ç®—ä»»åŠ¡æä¾›æ£€æŸ¥ç‚¹ï¼Œä»¥ï¥¥ä»»åŠ¡èƒ½æ–¹ï¥¥åœ°ä»å´©æºƒå‰çŠ¶æ€æ¢å¤æ‰§ï¨ˆã€‚ åœ¨ Web æœåŠ¡å™¨å®¹å™¨æœåŠ¡æ•°æ®æ—¶ï¼Œä¿å­˜å†…å®¹ç®¡ç†å™¨å®¹å™¨è·å–çš„æ–‡ä»¶ã€‚ ç¼–å†™ yaml æ–‡ä»¶ 12345678910111213141516171819202122apiVersion: v1kind: Podmetadata: name: emptydir-podspec: containers: - name: emptydir-container1 image: daocloud.io/library/nginx:latest imagePullPolicy: IfNotPresent volumeMounts: - mountPath: /empty1 name: emptydir-volume - name: emptydir-container2 image: busybox imagePullPolicy: IfNotPresent command: ['/bin/sh','-c','sleep 6000'] volumeMounts: - mountPath: /empty2 name: emptydir-volume volumes: - name: emptydir-volume emptyDir: {} è¿›å…¥ Pod ä¸­çš„ä¸åŒå®¹å™¨æŸ¥çœ‹æ˜¯å¦å…±äº«åŒä¸€ä¸ª volumeï¼Œ 6.2.2 hostPathhostPath å·èƒ½å°†ä¸»æœºèŠ‚ç‚¹æ–‡ä»¶ç³»ç»Ÿä¸Šçš„æ–‡ä»¶æˆ–ç›®å½•æŒ‚è½½åˆ°ä½ çš„ Pod ä¸­ï¼Œç±»ä¼¼ docker ä¸­çš„ volume æŒ‚è½½ã€‚ hostPath çš„ä¸€äº›ç”¨æ³•æœ‰ï¼š è¿è¡Œä¸€ä¸ªéœ€è¦è®¿é—® Docker å†…éƒ¨æœºåˆ¶çš„å®¹å™¨ï¼›å¯ä½¿ç”¨ hostPath æŒ‚è½½ /var/lib/docker è·¯å¾„ã€‚ åœ¨å®¹å™¨ä¸­è¿è¡Œ cAdvisorï¼ˆå®¹å™¨ç›‘æ§å·¥å…·ï¼‰ æ—¶ï¼Œä»¥ hostPath æ–¹å¼æŒ‚è½½ /sysã€‚ å…è®¸ Pod æŒ‡å®šç»™å®šçš„ hostPath åœ¨è¿è¡Œ Pod ä¹‹å‰æ˜¯å¦åº”è¯¥å­˜åœ¨ï¼Œæ˜¯å¦åº”è¯¥åˆ›å»ºä»¥åŠåº”è¯¥ä»¥ï§½ä¹ˆæ–¹å¼å­˜åœ¨ã€‚ é™¤äº†å¿…éœ€çš„ path å±æ€§ä¹‹å¤–ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©æ€§åœ°ä¸º hostPath å·æŒ‡å®š typeã€‚ æ”¯æŒçš„ type å€¼å¦‚ä¸‹ï¼š å–å€¼ è¡Œä¸º ç©ºå­—ç¬¦ä¸²ï¼ˆé»˜è®¤ï¼‰ç”¨äºå‘åå…¼å®¹ï¼Œè¿™æ„å‘³ç€åœ¨å®‰è£… hostPath å·ä¹‹å‰ä¸ä¼šæ‰§è¡Œä»»ä½•æ£€æŸ¥ã€‚ DirectoryOrCreate å¦‚æœåœ¨ç»™å®šè·¯å¾„ä¸Šä»€ä¹ˆéƒ½ä¸å­˜åœ¨ï¼Œé‚£ä¹ˆå°†æ ¹æ®éœ€è¦åˆ›å»ºç©ºç›®å½•ï¼Œæƒé™è®¾ç½®ä¸º 0755ï¼Œå…·æœ‰ä¸ kubelet ç›¸åŒçš„ç»„å’Œå±ä¸»ä¿¡æ¯ã€‚ Directory åœ¨ç»™å®šï¤·å¾„ä¸Šå¿…é¡»å­˜åœ¨çš„ç›®å½•ã€‚ FileOrCreate å¦‚æœåœ¨ç»™å®šè·¯å¾„ä¸Šä»€ä¹ˆéƒ½ä¸å­˜åœ¨ï¼Œé‚£ä¹ˆå°†åœ¨é‚£é‡Œæ ¹æ®éœ€è¦åˆ›å»ºç©ºæ–‡ä»¶ï¼Œæƒé™è®¾ç½®ä¸º 0644ï¼Œå…·æœ‰ä¸ kubelet ç›¸åŒçš„ç»„å’Œæ‰€æœ‰æƒã€‚ File åœ¨ç»™å®šè·¯å¾„ä¸Šå¿…é¡»å­˜åœ¨çš„æ–‡ä»¶ã€‚ Socket åœ¨ç»™å®šè·¯å¾„ä¸Šå¿…é¡»å­˜åœ¨çš„ UNIX å¥—æ¥å­—ã€‚ CharDevice åœ¨ç»™å®šè·¯å¾„ä¸Šå¿…é¡»å­˜åœ¨çš„å­—ç¬¦è®¾å¤‡ã€‚ BlockDevice åœ¨ç»™å®šè·¯å¾„ä¸Šå¿…é¡»å­˜åœ¨çš„å—è®¾å¤‡ã€‚ æ³¨æ„ï¼šå…·æœ‰ç›¸åŒé…ç½®ï¼ˆä¾‹å¦‚åŸºäºåŒä¸€ PodTemplate åˆ›å»ºï¼‰çš„å¤šä¸ª Pod ä¼šç”±äºèŠ‚ç‚¹ä¸Šæ–‡ä»¶çš„ï¥§åŒè€Œåœ¨ï¥§åŒèŠ‚ç‚¹ä¸Šæœ‰ï¥§åŒçš„ï¨ˆä¸ºï¼Œå³å‡å¦‚åŒä¸€ä¸ª template åˆ›å»ºå‡ºæ¥çš„ Pod åˆ†é…åœ¨äº†ä¸åŒçš„ Node ä¸Šæ—¶ï¼Œä¼šå› ä¸ºèŠ‚ç‚¹çš„ä¸åŒè€Œäº§ç”Ÿä¸åŒçš„è¡Œä¸ºã€‚ ç¼–å†™ yaml æ–‡ä»¶ 123456789101112131415161718apiVersion: v1kind: Podmetadata: name: hostpath-podspec: containers: - name: hostpath-pod-container image: daocloud.io/library/nginx:latest volumeMounts: - mountPath: /test name: hostpath-volume volumes: - name: hostpath-volume hostPath: # å®¿ä¸»æœºè¢«æŒ‚è½½ç›®å½• path: /data # å¦‚æœæ²¡æœ‰/dataç›®å½•åˆ™ä¼šè¢«åˆ›å»º type: DirectoryOrCreate æŸ¥çœ‹æ˜¯å¦æŒ‚è½½æˆåŠŸ éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨FileOrCreateä¸‹ï¼Œå¦‚æœè¢«æŒ‚è½½çš„ç›®å½•ä¸å­˜åœ¨ï¼Œé‚£ä¹ˆä¸ä¼šè‡ªåŠ¨åˆ›å»ºè¯¥ç›®å½•ï¼Œ ä¸ºäº†ç¡®ä¿è¿™ç§æ¨¡å¼èƒ½å¤Ÿå·¥ä½œï¼Œå¯ä»¥å°è¯•æŠŠæ–‡ä»¶å’Œå®ƒå¯¹åº”çš„ç›®å½•åˆ†å¼€æŒ‚è½½ã€‚ hostPath FileOrCreate é…ç½®ç¤ºä¾‹ 123456789101112131415161718192021222324apiVersion: v1kind: Podmetadata: name: hostpath-fileorcreate-podspec: containers: - name: hostpath-fileorcreate-pod-container image: daocloud.io/library/nginx:latest volumeMounts: - mountPath: /test name: mydir - mountPath: /test/test.txt name: myfile volumes: - name: mydir hostPath: path: /data # å¦‚æœå®¿ä¸»æœºæ²¡æœ‰/dataç›®å½•åˆ™ä¼šè‡ªåŠ¨åˆ›å»º type: DirectoryOrCreate - name: myfile hostPath: path: /data/test.txt # å› ä¸ºä¸Šé¢å·²ç»ç¡®ä¿ä¼šæœ‰/dataç›®å½•ï¼Œæ‰€ä»¥è¯¥æ–‡ä»¶çš„æŒ‚è½½ä¸å—å½±å“ type: FileOrCreate 6.3 æŒä¹…å­˜å‚¨å·6.3.1 PVå’ŒPVCPV å’Œ PVC æ˜¯ k8s æä¾›çš„ä¸¤ä¸ª api èµ„æºã€‚ PV æŒä¹…å·ï¼ˆPersistentVolumeï¼ŒPVï¼‰æ˜¯é›†ç¾¤ä¸­çš„ä¸€å—å­˜å‚¨ï¼Œå¯ä»¥ç”±ç®¡ç†å‘˜äº‹å…ˆä¾›åº”ï¼Œæˆ–è€…ä½¿ç”¨å­˜å‚¨ç±»æ¥åŠ¨æ€ä¾›åº”ï¼ŒPV æ˜¯é›†ç¾¤èµ„æºï¼Œå’Œæ™®é€šçš„ Volume ä¸€æ ·ï¼Œä¹Ÿæ˜¯ä½¿ç”¨å·æ’ä»¶æ¥å®ç°çš„ï¼Œåªæ˜¯å®ƒä»¬æ‹¥æœ‰ç‹¬ç«‹äºä»»ä½•ä½¿ç”¨ PV çš„ Pod çš„ç”Ÿå‘½å‘¨æœŸã€‚ PVC æŒä¹…å·ç”³é¢†ï¼ˆPersistentVolumeClaimï¼ŒPVCï¼‰è¡¨è¾¾çš„æ˜¯ç”¨æˆ·å¯¹å­˜å‚¨çš„è¯·æ±‚ã€‚æ¦‚å¿µä¸Šä¸ Pod ç±»ä¼¼ã€‚Pod ä¼šè€—ç”¨ Node èµ„æºï¼Œè€Œ PVC ç”³é¢†ä¼šè€—ç”¨ PV èµ„æºã€‚Pod å¯ä»¥è¯·æ±‚ç‰¹å®šæ•°é‡çš„èµ„æºï¼ˆCPU å’Œå†…å­˜ï¼‰ï¼ŒåŒæ · PVC ç”³é¢†ä¹Ÿå¯ä»¥è¯·æ±‚ç‰¹å®šçš„å¤§å°å’Œè®¿é—®æ¨¡å¼ã€‚ PV çš„ä¾›åº”æ–¹å¼æœ‰ä¸¤ç§ï¼š é™æ€ä¾›åº” é›†ç¾¤ç®¡ç†å‘˜åˆ›å»ºè‹¥å¹² PV å·ã€‚è¿™äº›å·å¯¹è±¡å¸¦æœ‰çœŸå®å­˜å‚¨çš„ç»†èŠ‚ä¿¡æ¯ï¼Œå¹¶ä¸”å¯¹é›†ç¾¤ç”¨æˆ·å¯ç”¨ï¼ˆå¯è§ï¼‰ã€‚PV å·å¯¹è±¡å­˜åœ¨äº Kubernetes API ä¸­ï¼Œå¯ä¾›ç”¨æˆ·æ¶ˆè´¹ï¼ˆä½¿ç”¨ï¼‰ã€‚ åŠ¨æ€ä¾›åº” å¦‚æœç®¡ç†å‘˜æ‰€åˆ›å»ºçš„æ‰€æœ‰é™æ€ PV å·éƒ½æ— æ³•ä¸ç”¨æˆ·çš„ PersistentVolumeClaim åŒ¹é…ï¼Œ é›†ç¾¤å¯ä»¥å°è¯•ä¸ºè¯¥ PVC ç”³é¢†åŠ¨æ€ä¾›åº”ä¸€ä¸ªå­˜å‚¨å·ã€‚ è¿™ä¸€ä¾›åº”æ“ä½œæ˜¯åŸºäº StorageClass æ¥å®ç°çš„ï¼šPVC ç”³é¢†å¿…é¡»è¯·æ±‚æŸä¸ª å­˜å‚¨ç±»ï¼ŒåŒæ—¶é›†ç¾¤ç®¡ç†å‘˜å¿…é¡» å·²ç»åˆ›å»ºå¹¶é…ç½®äº†è¯¥ç±»ï¼Œè¿™æ ·åŠ¨æ€ä¾›åº”å·çš„åŠ¨ä½œæ‰ä¼šå‘ç”Ÿã€‚ å¦‚æœ PVC ç”³é¢†æŒ‡å®šå­˜å‚¨ç±»ä¸º &quot;&quot;ï¼Œåˆ™ç›¸å½“äºä¸ºè‡ªèº«ç¦æ­¢ä½¿ç”¨åŠ¨æ€ä¾›åº”çš„å·ã€‚ ä¸ºäº†åŸºäºå­˜å‚¨ç±»å®ŒæˆåŠ¨æ€çš„å­˜å‚¨ä¾›åº”ï¼Œé›†ç¾¤ç®¡ç†å‘˜éœ€è¦åœ¨ API æœåŠ¡å™¨ä¸Šå¯ç”¨ DefaultStorageClass å‡†å…¥æ§åˆ¶å™¨ã€‚ ä¸¾ä¾‹è€Œè¨€ï¼Œå¯ä»¥é€šè¿‡ä¿è¯ DefaultStorageClass å‡ºç°åœ¨ API æœåŠ¡å™¨ç»„ä»¶çš„ --enable-admission-plugins æ ‡å¿—å€¼ä¸­å®ç°è¿™ç‚¹ï¼›è¯¥æ ‡å¿—çš„å€¼å¯ä»¥æ˜¯é€—å· åˆ†éš”çš„æœ‰åºåˆ—è¡¨ã€‚å…³äº API æœåŠ¡å™¨æ ‡å¿—çš„æ›´å¤šä¿¡æ¯ï¼Œå¯ä»¥å‚è€ƒ kube-apiserver æ–‡æ¡£ã€‚ ç»‘å®š é€šä¿—ç†è§£å°±æ˜¯ä¸€æ—¦ PV ä¸ PVC è¿›è¡Œäº†ç»‘å®šï¼Œé‚£ä¹ˆè¯¥ PV å°±æ— æ³•ä¸å…¶å®ƒ PVC è¿›è¡Œç»‘å®šäº†ã€‚ ä¿æŠ¤ å½“ä¸€ä¸ª PV ä¸ PVC ç»‘å®šä¹‹åï¼Œå‡è®¾ Pod è¢«åˆ é™¤ï¼Œé‚£ä¹ˆè¯¥ PV ä¸ PVC ä¾æ—§ä¼šæ˜¯ä¸€ä¸ªç»‘å®šçš„å…³ç³»ã€‚ æŒä¹…å·çš„ç±»å‹ PV æŒä¹…å·æ˜¯ç”¨æ’ä»¶çš„å½¢å¼æ¥å®ç°çš„ã€‚Kubernetes ç›®å‰æ”¯æŒä»¥ä¸‹æ’ä»¶ï¼š awsElasticBlockStore - AWS å¼¹æ€§å—å­˜å‚¨ï¼ˆEBSï¼‰ azureDisk - Azure Disk azureFile - Azure File cephfs - CephFS volume csi - å®¹å™¨å­˜å‚¨æ¥å£ (CSI) fc - Fibre Channel (FC) å­˜å‚¨ flexVolume - FlexVolume flocker - Flocker å­˜å‚¨ gcePersistentDisk - GCE æŒä¹…åŒ–ç›˜ glusterfs - Glusterfs å· hostPath - HostPath å· ï¼ˆä»…ä¾›å•èŠ‚ç‚¹æµ‹è¯•ä½¿ç”¨ï¼›ä¸é€‚ç”¨äºå¤šèŠ‚ç‚¹é›†ç¾¤ï¼› è¯·å°è¯•ä½¿ç”¨ local å·ä½œä¸ºæ›¿ä»£ï¼‰ iscsi - iSCSI (SCSI over IP) å­˜å‚¨ local - èŠ‚ç‚¹ä¸ŠæŒ‚è½½çš„æœ¬åœ°å­˜å‚¨è®¾å¤‡ nfs - ç½‘ç»œæ–‡ä»¶ç³»ç»Ÿ (NFS) å­˜å‚¨ portworxVolume - Portworx å· quobyte - Quobyte å· rbd - Rados å—è®¾å¤‡ (RBD) å· storageos - StorageOS å· vsphereVolume - vSphere VMDK å· è®¿é—®æ¨¡å¼ PV å·å¯ä»¥ç”¨èµ„æºæä¾›è€…æ‰€æ”¯æŒçš„ä»»ä½•æ–¹å¼æŒ‚è½½åˆ°å®¿ä¸»ç³»ç»Ÿä¸Šã€‚ å¦‚ä¸‹è¡¨æ‰€ç¤ºï¼Œæä¾›è€…ï¼ˆé©±åŠ¨ï¼‰çš„èƒ½åŠ›ä¸åŒï¼Œæ¯ä¸ª PV å·çš„è®¿é—®æ¨¡å¼éƒ½ä¼šè®¾ç½®ä¸º å¯¹åº”å·æ‰€æ”¯æŒçš„æ¨¡å¼å€¼ã€‚ ä¾‹å¦‚ï¼ŒNFS å¯ä»¥æ”¯æŒå¤šä¸ªè¯»å†™å®¢æˆ·ï¼Œä½†æ˜¯æŸä¸ªç‰¹å®šçš„ NFS PV å·å¯èƒ½åœ¨æœåŠ¡å™¨ ä¸Šä»¥åªè¯»çš„æ–¹å¼å¯¼å‡ºã€‚æ¯ä¸ª PV å·éƒ½ä¼šè·å¾—è‡ªèº«çš„è®¿é—®æ¨¡å¼é›†åˆï¼Œæè¿°çš„æ˜¯ ç‰¹å®š PV å·çš„èƒ½åŠ›ã€‚ è®¿é—®æ¨¡å¼æœ‰ï¼š ReadWriteOnceï¼šå·å¯ä»¥è¢«ä¸€ä¸ªèŠ‚ç‚¹ä»¥è¯»å†™æ–¹å¼æŒ‚è½½ï¼› ReadOnlyManyï¼šå·å¯ä»¥è¢«å¤šä¸ªèŠ‚ç‚¹ä»¥åªè¯»æ–¹å¼æŒ‚è½½ï¼› ReadWriteManyï¼šå·å¯ä»¥è¢«å¤šä¸ªèŠ‚ç‚¹ä»¥è¯»å†™æ–¹å¼æŒ‚è½½ã€‚ å¯¹äºä¸åŒç±»å‹çš„å­˜å‚¨å·è®¿é—®æ¨¡å¼ä¹Ÿæœ‰ä¸åŒï¼Œå¦‚ä¸‹è¡¨ å·æ’ä»¶ ReadWriteOnce ReadOnlyMany ReadWriteMany AWSElasticBlockStore âœ“ - - AzureFile âœ“ âœ“ âœ“ AzureDisk âœ“ - - CephFS âœ“ âœ“ âœ“ Cinder âœ“ - - CSI å–å†³äºé©±åŠ¨ å–å†³äºé©±åŠ¨ å–å†³äºé©±åŠ¨ FC âœ“ âœ“ - FlexVolume âœ“ âœ“ å–å†³äºé©±åŠ¨ Flocker âœ“ - - GCEPersistentDisk âœ“ âœ“ - Glusterfs âœ“ âœ“ âœ“ HostPath âœ“ - - iSCSI âœ“ âœ“ - Quobyte âœ“ âœ“ âœ“ NFS âœ“ âœ“ âœ“ RBD âœ“ âœ“ - VsphereVolume âœ“ - - (Pod è¿è¡ŒäºåŒä¸€èŠ‚ç‚¹ä¸Šæ—¶å¯è¡Œ) PortworxVolume âœ“ - âœ“ ScaleIO âœ“ âœ“ - StorageOS âœ“ - - ç±» æ¯ä¸ª PV å¯ä»¥å±äºæŸä¸ªç±»ï¼ˆClassï¼‰ï¼Œé€šè¿‡å°†å…¶ storageClassName å±æ€§è®¾ç½®ä¸ºæŸä¸ª StorageClass çš„åç§°æ¥æŒ‡å®šã€‚ ç‰¹å®šç±»çš„ PV å·åªèƒ½ç»‘å®šåˆ°è¯·æ±‚è¯¥ç±»å­˜å‚¨å·çš„ PVC ç”³é¢†ã€‚ æœªè®¾ç½® storageClassName çš„ PV å·æ²¡æœ‰ç±»è®¾å®šï¼Œåªèƒ½ç»‘å®šåˆ°é‚£äº›æ²¡æœ‰æŒ‡å®šç‰¹å®šå­˜å‚¨ç±»çš„ PVC ç”³é¢†ã€‚ å›æ”¶ç­–ç•¥ ç›®å‰çš„å›æ”¶ç­–ç•¥æœ‰ï¼š Retainï¼ˆä¿ç•™ï¼‰ â€“ æ‰‹åŠ¨å›æ”¶ Recycleï¼ˆå›æ”¶ï¼‰â€“ åŸºæœ¬æ“¦é™¤ (rm -rf /thevolume/*) Deleteï¼ˆåˆ é™¤ï¼‰â€“ è¯¸å¦‚ AWS EBSã€GCE PDã€Azure Disk æˆ– OpenStack Cinder å·è¿™ç±»å…³è”å­˜å‚¨èµ„äº§ä¹Ÿè¢«åˆ é™¤ ç›®å‰ï¼Œä»… NFS å’Œ HostPath æ”¯æŒå›æ”¶ï¼ˆRecycleï¼‰ã€‚ AWS EBSã€GCE PDã€Azure Disk å’Œ Cinder å·éƒ½æ”¯æŒåˆ é™¤ï¼ˆDeleteï¼‰ã€‚ é˜¶æ®µï¼ˆçŠ¶æ€ï¼‰ æ¯ä¸ªå·ä¼šå¤„äºä»¥ä¸‹é˜¶æ®µï¼ˆPhaseï¼‰ä¹‹ä¸€ï¼š Availableï¼ˆå¯ç”¨ï¼‰â€“ å·æ˜¯ä¸€ä¸ªç©ºé—²èµ„æºï¼Œå°šæœªç»‘å®šåˆ°ä»»ä½•ç”³é¢†ï¼› Boundï¼ˆå·²ç»‘å®šï¼‰â€“ è¯¥å·å·²ç»ç»‘å®šåˆ°æŸç”³é¢†ï¼› Releasedï¼ˆå·²é‡Šæ”¾ï¼‰â€“ æ‰€ç»‘å®šçš„ç”³é¢†å·²è¢«åˆ é™¤ï¼Œä½†æ˜¯èµ„æºå°šæœªè¢«é›†ç¾¤å›æ”¶ï¼› Failedï¼ˆå¤±è´¥ï¼‰â€“ å·çš„è‡ªåŠ¨å›æ”¶æ“ä½œå¤±è´¥ã€‚ ç¤ºä¾‹ä¸€ è¿™ä¸ªå®ä¾‹æ˜¯å…ˆååˆ›å»º PVã€PVCã€Deployment åˆ›å»º PV 1234567891011121314apiVersion: v1kind: PersistentVolumemetadata: name: test-pvspec: capacity: storage: 1Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Recycle storageClassName: nfs nfs: path: /nfs server: 192.168.88.100 åˆ›å»º PVC 1234567891011apiVersion: v1kind: PersistentVolumeClaimmetadata: name: test-pvcspec: accessModes: - ReadWriteMany storageClassName: nfs resources: requests: storage: 1Gi åˆ›å»º Deployment 1234567891011121314151617181920212223242526apiVersion: apps/v1kind: Deploymentmetadata: name: test-deploymentspec: replicas: 2 selector: matchLabels: app: nginx template: metadata: name: test-deployment-pod labels: app: nginx spec: containers: - name: test-deployment-pod-container image: daocloud.io/library/nginx:latest imagePullPolicy: IfNotPresent volumeMounts: - name: test-volume mountPath: /usr/share/nginx/html volumes: - name: test-volume persistentVolumeClaim: claimName: test-pvc ç¤ºä¾‹äºŒ è¿™ä¸ªå®ä¾‹ä¼šç”± StatefulSet è‡ªåŠ¨åˆ›å»º PVC éƒ¨ç½² NFS æœåŠ¡å™¨ï¼Œå¹¶åœ¨æ¯ä¸ªèŠ‚ç‚¹å®‰è£…nfs-utils éƒ¨ç½² PVï¼Œè¿™é‡Œåˆ›å»ºäº†å››ä¸ª PV 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970apiVersion: v1kind: PersistentVolumemetadata: name: nfs-pv1spec: # PVå®¹é‡å¤§å° capacity: storage: 1Gi # æœåŠ¡æ¨¡å¼ä¸ºRWOï¼Œå·å¯ä»¥è¢«ä¸€ä¸ªèŠ‚ç‚¹ä»¥è¯»å†™æ–¹å¼æŒ‚è½½ accessModes: - ReadWriteOnce # å›æ”¶ç­–ç•¥ä¸ºRetainï¼Œå³æ‰‹åŠ¨å›æ”¶ persistentVolumeReclaimPolicy: Retain # ç±»ä¸ºnfs storageClassName: nfs # åˆ¶å®šnfsæœåŠ¡å™¨åœ°å€å’Œè¢«æŒ‚è½½ç›®å½• nfs: path: /nfs1 server: 192.168.88.100---apiVersion: v1kind: PersistentVolumemetadata: name: nfs-pv2spec: capacity: storage: 2Gi accessModes: - ReadOnlyMany persistentVolumeReclaimPolicy: Retain storageClassName: nfs nfs: path: /nfs2 server: 192.168.88.100---apiVersion: v1kind: PersistentVolumemetadata: name: nfs-pv3spec: capacity: storage: 3Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain storageClassName: nfs nfs: path: /nfs3 server: 192.168.88.100---apiVersion: v1kind: PersistentVolumemetadata: name: slow-pvspec: capacity: storage: 1Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain storageClassName: slow nfs: path: /slow server: 192.168.88.100 åˆ›å»ºæ— å¤´ SVCã€StatefulSet 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657apiVersion: v1kind: Servicemetadata: name: nfs-pv-svc labels: app: nginxspec: ports: - port: 80 targetPort: 80 # ä¸åˆ†é…ipåœ°å€ï¼Œä¸ºStatefulSetä½¿ç”¨ clusterIP: None # åŒ¹é…æ ‡ç­¾ selector: app: nginx---apiVersion: apps/v1kind: StatefulSetmetadata: name: nfs-pv-statefulsetspec: # åŒ¹é…æ ‡ç­¾ selector: matchLabels: app: nginx serviceName: nfs-pv-svc replicas: 3 template: metadata: name: nfs-pv-pod # podæ ‡ç­¾ labels: app: nginx spec: containers: - name: nfs-pv-pod-container image: daocloud.io/library/nginx:latest imagePullPolicy: IfNotPresent ports: - containerPort: 80 # æŒ‚è½½æŒä¹…å· volumeMounts: - name: nfs-pv-volume mountPath: /usr/share/nginx/html # PVCæ¨¡æ¿ volumeClaimTemplates: - metadata: name: nfs-pv-volume spec: # åŒ¹é…è§„åˆ™ accessModes: [ 'ReadWriteOnce' ] storageClassName: 'nfs' resources: requests: storage: 1Gi å…ˆååˆ›å»ºåæŸ¥çœ‹ Pod åˆ›å»ºæƒ…å†µï¼Œå¯ä»¥çœ‹åˆ°åªåˆ›å»ºäº†ä¸€ä¸ª Podï¼Œå› ä¸ºç°æœ‰çš„ PV åªæœ‰ä¸€ä¸ªç¬¦åˆåŒ¹é…æ¡ä»¶ï¼Œè€Œ StatefulSet æ˜¯å‰ä¸€ä¸ª Pod åˆ›å»ºæˆåŠŸæ‰ä¼šåˆ›å»ºä¸‹ä¸€ä¸ªï¼Œå› ä¸ºç¬¬äºŒä¸ª Pod åˆ›å»ºä¸æˆåŠŸï¼Œæ‰€ä»¥ç¬¬ä¸‰ä¸ª Pod ä¸ä¼šè¢«åˆ›å»º è¿›å…¥å®¹å™¨å†…éƒ¨å¯ä»¥çœ‹åˆ°æŒ‚è½½æˆåŠŸï¼Œå»åˆ° NFS æœåŠ¡å™¨çš„/nfs1ç›®å½•ä¸‹åˆ›å»ºtest.htmlæ–‡ä»¶æµ‹è¯•æˆåŠŸ åˆ é™¤åˆ›å»ºå¤±è´¥çš„ Pod ä»¥åŠå¯¹åº”çš„ PVCï¼Œåˆ›å»ºæ–°çš„ä¸¤ä¸ª PVï¼Œä»¥æ»¡è¶³ StatefulSet çš„æŒ‚è½½è¦æ±‚ï¼Œå‰©ä¸‹çš„ Pod å°±ä¼šé€ä¸€åˆ›å»ºæˆåŠŸ åˆ é™¤ä¸Šé¢æµ‹è¯•çš„ Podï¼ŒStatefulSet ä¼šé‡æ–°åˆ›å»ºä¸€ä¸ª Podï¼Œä¸”æ•°æ®ä¸ä¼šä¸¢å¤± è¿™é‡Œä¼šæœ‰ä¸ªé—®é¢˜ï¼Œå¦‚æœåˆ é™¤äº† StatefulSetï¼Œé‚£ä¹ˆå¯¹åº”çš„ Pod ä¹Ÿä¼šè¢«åˆ é™¤ï¼Œå¯æ˜¯å·²ç»ç»‘å®šçš„ PV å¹¶ä¸ä¼šåˆ é™¤ï¼Œè¿™é‡Œå°±éœ€è¦æ‰‹åŠ¨å›æ”¶äº†ã€‚ æ‰‹åŠ¨å›æ”¶ åˆ é™¤ StatefulSet åˆ é™¤ PVC ä¿®æ”¹ PV 1234kubectl edit pv pvåç§°# åˆ é™¤ClaimRefçš„ä¿¡æ¯ClainRef:... 6.3.2 StorageClassä»¥ä¸Šçš„æ–¹æ³•éƒ½æ˜¯é™æ€åˆ›å»ºçš„ PVï¼Œä¼šå‡ºç° PVC æ‰¾ä¸åˆ°æ¡ä»¶ç¬¦åˆçš„ PV è¿›è¡Œç»‘å®šã€‚ è€Œ StorageClass çš„ä½œç”¨æ˜¯æ ¹æ® PVC çš„éœ€æ±‚åŠ¨æ€åˆ›å»º PVã€‚ ç¤ºä¾‹ä¸€ k8s åœ¨ 1.20 ç‰ˆæœ¬å¼€å§‹å°±ç¦ç”¨äº† selfLinkï¼Œæ‰€ä»¥éœ€åœ¨é…ç½®æ–‡ä»¶æ·»åŠ ä»¥ä¸‹å†…å®¹ StorageClass æ˜¯é€šè¿‡å­˜å‚¨åˆ†é…å™¨æ¥åŠ¨æ€åˆ›å»º PV çš„ï¼Œä½† k8s å†…éƒ¨çš„å­˜å‚¨åˆ†é…å™¨ä¸æ”¯æŒ NFSï¼Œæ‰€ä»¥é¦–å…ˆè¦å®‰è£… NFS å­˜å‚¨åˆ†é…å™¨ 12345678910111213141516171819202122232425262728293031323334353637383940vim nfs_provisioner.yamlkind: DeploymentapiVersion: apps/v1metadata: name: nfs-client-provisionerspec: replicas: 1 selector: matchLabels: app: nfs-client-provisioner strategy: # è®¾ç½®å‡çº§ç­–ç•¥ä¸ºåˆ é™¤å†åˆ›å»º(é»˜è®¤ä¸ºæ»šåŠ¨æ›´æ–°) type: Recreate template: metadata: labels: app: nfs-client-provisioner spec: serviceAccountName: nfs-client-provisioner containers: - name: nfs-client-provisioner image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner:latest volumeMounts: - name: nfs-client-root mountPath: /nfs-provision env: # nfså­˜å‚¨åˆ†é…å™¨åç§° - name: PROVISIONER_NAME value: nfs-client # nfsæœåŠ¡å™¨åœ°å€ - name: NFS_SERVER value: 192.168.88.100 # nfså…±äº«ç›®å½• - name: NFS_PATH value: /nfs volumes: - name: nfs-client-root nfs: server: 192.168.88.100 path: /nfs ç»™ NFS å­˜å‚¨åˆ†é…å™¨æˆæƒ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061vim nfs_provisioner_rbac.yamlapiVersion: v1kind: ServiceAccountmetadata: name: nfs-client-provisioner namespace: default---kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: nfs-client-provisioner-runnerrules: - apiGroups: [&quot;&quot;] resources: [&quot;persistentvolumes&quot;] verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;delete&quot;] - apiGroups: [&quot;&quot;] resources: [&quot;persistentvolumeclaims&quot;] verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;update&quot;] - apiGroups: [&quot;storage.k8s.io&quot;] resources: [&quot;storageclasses&quot;] verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;] - apiGroups: [&quot;&quot;] resources: [&quot;events&quot;] verbs: [&quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: run-nfs-client-provisionersubjects: - kind: ServiceAccount name: nfs-client-provisioner namespace: defaultroleRef: kind: ClusterRole name: nfs-client-provisioner-runner apiGroup: rbac.authorization.k8s.io---kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: leader-locking-nfs-client-provisioner namespace: defaultrules: - apiGroups: [&quot;&quot;] resources: [&quot;endpoints&quot;] verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]---kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: leader-locking-nfs-client-provisioner namespace: defaultsubjects: - kind: ServiceAccount name: nfs-client-provisioner namespace: defaultroleRef: kind: Role name: leader-locking-nfs-client-provisioner apiGroup: rbac.authorization.k8s.io åˆ›å»º StorageClass 1234567891011vim nfs_storageclass.yamlapiVersion: storage.k8s.io/v1kind: StorageClassmetadata: # storageclassåç§° name: nfs-storageclass# nfså­˜å‚¨åˆ†é…å™¨åç§°provisioner: nfs-clientparameters: # è¡¨ç¤ºpvcåˆ é™¤æ—¶ï¼Œæ‰€ç»‘å®šçš„pvä¸ä¼šè¢«ä¿ç•™ï¼Œtrueç›¸å archieveOnDelete: 'false' åˆ›å»º PVCï¼Œå¯ä»¥çœ‹åˆ° NFS å­˜å‚¨åˆ†é…å™¨å·²ç»è‡ªåŠ¨åˆ›å»ºäº† PV ä¸ä¹‹ç»‘å®š 12345678910111213vim nfs_storageclass_pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: nfs-storageclass-pvcspec: accessModes: - ReadWriteMany # storageclassåç§° storageClassName: 'nfs-client' resources: requests: storage: 500Mi åˆ›å»ºä¸€ä¸ª Deployment æµ‹è¯•æ˜¯å¦èƒ½ç”¨è¿™ä¸ª PVC 1234567891011121314151617181920212223242526vim nfs_provisioner_deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nfs-provisioner-deploymentspec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nfs-provisioner-deployment-nginx image: daocloud.io/library/nginx:latest imagePullPolicy: IfNotPresent volumeMounts: - name: nfs-storageclass-pvc mountPath: /usr/share/nginx/html/test volumes: - name: nfs-storageclass-pvc persistentVolumeClaim: claimName: nfs-storageclass-pvc åœ¨ NFS æœåŠ¡å™¨çš„å…±äº«ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ª test.html è®¿é—® Deployment åˆ›å»ºå‡ºæ¥çš„ Podï¼Œå¯ä»¥çœ‹åˆ°æ˜¯å¯ä»¥è®¿é—®çš„ 6.4 StatefulSetStatefulSet æ˜¯ä¸€ç§æä¾›æ’åºå’Œå”¯ä¸€æ€§ä¿è¯çš„ç‰¹æ®Š Pod æ§åˆ¶å™¨ï¼Œå½“æœ‰éƒ¨ç½²é¡ºåºã€æŒä¹…æ•°æ®æˆ–å›ºå®šç½‘ç»œç­‰ç›¸å…³çš„ç‰¹æ®Šéœ€æ±‚æ—¶ï¼Œå¯ä»¥ç”¨ StatefulSet æ§åˆ¶å™¨æ¥è¿›è¡Œæ§åˆ¶ã€‚ StatefulSet æä¾›æœ‰çŠ¶æ€æœåŠ¡ï¼Œä¸»è¦åŠŸèƒ½å¦‚ä¸‹ï¼š å®ç°ç¨³å®šçš„æŒä¹…åŒ–å­˜å‚¨ï¼šé€šè¿‡ PVC æ¥å®ç°ï¼ŒPod ä¹‹é—´ä¸èƒ½å…±ç”¨ä¸€ä¸ªå­˜å‚¨å·ï¼Œæ¯ä¸ª Pod éƒ½è¦æœ‰ä¸€ä¸ªè‡ªå·±ä¸“ç”¨çš„å­˜å‚¨å·ã€‚ å®ç°ç¨³å®šçš„ç½‘ç»œæ ‡è¯†ï¼šPod é‡æ–°è°ƒåº¦åå…¶ PodName å’Œ HostName ä¸å˜ï¼Œé€šè¿‡æ— å¤´ SVC æ¥å®ç°ã€‚ å®ç°æœ‰åºéƒ¨ç½²ã€æœ‰åºä¼¸ç¼©ï¼šPod æ˜¯æœ‰é¡ºåºçš„ï¼Œåªæœ‰å‰ä¸€ä¸ª Pod åˆ›å»ºæˆåŠŸæ‰ä¼šåˆ›å»ºä¸‹ä¸€ä¸ªï¼Œç›´åˆ°æœ€åã€‚ å®ç°æœ‰åºæ”¶ç¼©ã€æœ‰åºåˆ é™¤ï¼šä»æœ€åä¸€ä¸ªå¼€å§‹ï¼Œä¾æ¬¡åˆ é™¤åˆ°ç¬¬ä¸€ä¸ªã€‚ æ— å¤´ SVC ï¼šä¸º Pod ç”Ÿæˆå¯ä»¥è§£æçš„ DNS è®°å½•ã€‚ ç¤ºä¾‹ä¸€ åˆ›å»ºæ— å¤´ SVC 1234567891011121314vim statefulset_nginx_svc.yamlapiVersion: v1kind: Servicemetadata: name: statefulset-nginx-svcspec: selector: app: nginx clusterIP: None ports: - protocol: TCP port: 8080 targetPort: 80 type: ClusterIP åˆ›å»º StatefulSet 12345678910111213141516171819202122232425262728293031323334vim statefulset_nginx.yamlapiVersion: apps/v1kind: StatefulSetmetadata: name: statefulset-nginxspec: # åŒ¹é…æ— å¤´SVC serviceName: statefulset-nginx-svc replicas: 4 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: statefulset-nginx-container image: daocloud.io/library/nginx:latest imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 # PVCæ¨¡æ¿ volumeClaimTemplates: - metadata: name: statefulset-nginx-pvc spec: accessModes: [ 'ReadWriteOnce' ] storageClassName: 'nfs-storageclass' resources: requests: storage: 50Mi å¯ä»¥çœ‹åˆ° Pod æ˜¯æœ‰åºåˆ›å»ºçš„ï¼Œä¸”æ¯ä¸ª Pod éƒ½æ˜¯å•ç‹¬ä½¿ç”¨ä¸€ä¸ª PVC å’Œ PVï¼Œåˆ é™¤ StatefulSet ä¹Ÿå¯ä»¥çœ‹åˆ° Pod æ˜¯æœ‰åºåˆ é™¤çš„ï¼Œä¸”åˆ é™¤å PVC ä¸ PV ä¾æ—§å­˜åœ¨ï¼Œé‡æ–°ç”Ÿæˆ StatefulSet å¯ä»¥ç»§ç»­ä½¿ç”¨è¿™äº› PVC å’Œ PV æœ‰åºåˆ›å»º PVC ä¸ PV æœ‰åºåˆ é™¤ åˆ›å»ºä¸€ä¸ª Pod ç”¨æ¥æµ‹è¯•æ— å¤´ SVC æä¾›çš„ DNS æœåŠ¡ 1234567891011apiVersion: v1kind: Podmetadata: name: test-podspec: containers: - name: test-pod-container image: appropriate/curl:latest imagePullPolicy: IfNotPresent command: [ 'sh', '-c' ] args: [ 'echo &quot;this is test&quot;; sleep 36000' ] è¿›å…¥ Pod åå¯ä»¥é€šè¿‡nslookupæµ‹è¯•ï¼Œå½¢å¼ä¸º{ServiceName}.{NameSpace}.svc.{ClusterDomain} é€šè¿‡åŸŸåä¹Ÿå¯ä»¥è®¿é—®å„ä¸ª Podï¼Œå½¢å¼ä¸º{PodName}{ServiceName}.{NameSpace}.svc.{ClusterDomain} ä¸ƒã€k8sè°ƒåº¦å™¨scheduler æ˜¯ k8s é›†ç¾¤çš„è°ƒåº¦å™¨ï¼Œå¯¹æ¯ä¸€ä¸ªæ–°åˆ›å»ºçš„ Pod æˆ–è€…æ˜¯æœªè¢«è°ƒåº¦çš„ Podï¼Œscheduler ä¼šé€‰æ‹©ä¸€ä¸ªæœ€ä¼˜çš„ Node å»è¿è¡Œè¿™ä¸ª Podã€‚ç„¶è€Œï¼ŒPod å†…çš„æ¯ä¸€ä¸ªå®¹å™¨å¯¹èµ„æºéƒ½æœ‰ä¸åŒçš„éœ€æ±‚ï¼Œè€Œä¸” Pod æœ¬èº«ä¹Ÿæœ‰ä¸åŒçš„èµ„æºéœ€æ±‚ã€‚å› æ­¤ï¼ŒPod åœ¨è¢«è°ƒåº¦åˆ° Node ä¸Šä¹‹å‰ï¼Œ æ ¹æ®è¿™äº›ç‰¹å®šçš„èµ„æºè°ƒåº¦éœ€æ±‚ï¼Œéœ€è¦å¯¹é›†ç¾¤ä¸­çš„ Node è¿›è¡Œä¸€æ¬¡è¿‡æ»¤ã€‚ åœ¨åšè°ƒåº¦å†³å®šæ—¶éœ€è¦è€ƒè™‘çš„å› ç´ åŒ…æ‹¬ï¼šå•ç‹¬å’Œæ•´ä½“çš„èµ„æºè¯·æ±‚ã€ç¡¬ä»¶/è½¯ä»¶/ç­–ç•¥é™åˆ¶ã€ äº²å’Œä»¥åŠåäº²å’Œè¦æ±‚ã€æ•°æ®å±€åŸŸæ€§ã€è´Ÿè½½é—´çš„å¹²æ‰°ç­‰ç­‰ã€‚ è°ƒåº¦æµç¨‹ï¼š è¿‡æ»¤ï¼šè°ƒåº¦å™¨ä¼šå°†æ‰€æœ‰æ»¡è¶³ Pod è°ƒåº¦éœ€æ±‚çš„ Node é€‰å‡ºæ¥ã€‚ æ‰“åˆ†ï¼šè°ƒåº¦å™¨ä¼šä¸º Pod ä»æ‰€æœ‰å¯è°ƒåº¦èŠ‚ç‚¹ä¸­é€‰å–ä¸€ä¸ªæœ€åˆé€‚çš„ Nodeã€‚ 7.1 äº²å’Œæ€§ä¸åäº²å’Œæ€§7.1.1 Nodeäº²å’Œæ€§èŠ‚ç‚¹äº²å’Œæ€§æ˜¯é€šè¿‡pod.spec.nodeAffinityæ¥å®ç°çš„ï¼ŒåŒ…æ‹¬ä»¥ä¸‹ä¸¤ç§ï¼š preferredDuringSchedulingIgnoredDuringExecutionï¼šè½¯ç­–ç•¥ requiredDuringSchedulingIgnoredDuringExecutionï¼šç¡¬ç­–ç•¥ requiredDuringSchedulingIgnoredDuringExecutionç¡¬ç­–ç•¥ 1234567891011121314151617181920212223242526272829303132apiVersion: v1kind: Podmetadata: name: node-required-podspec: containers: - name: node-required-pod-container image: daocloud.io/library/nginx:latest imagePullPolicy: IfNotPresent # äº²å’Œæ€§è®¾ç½® affinity: # èŠ‚ç‚¹äº²å’Œæ€§è®¾ç½® nodeAffinity: # ç¡¬ç­–ç•¥ requiredDuringSchedulingIgnoredDuringExecution: # èŠ‚ç‚¹é€‰æ‹©å™¨ nodeSelectorTerms: # åŒ¹é…è¡¨è¾¾å¼ - matchExpressions: # åˆ¶å®škeyï¼Œå³ä»¥è¿™ä¸ªkeyçš„é”®å€¼ä¸ºåŒ¹é…æ¡ä»¶ # é€šè¿‡kubectl get node --show-labelså¯ä»¥è·å¾—æ›´å¤šæ ‡ç­¾ - key: kubernetes.io/hostname # In:labelçš„å€¼åœ¨æŸä¸ªåˆ—è¡¨ä¸­ # NotIn:labelçš„å€¼ä¸åœ¨æŸä¸ªåˆ—è¡¨ä¸­ # Gt:labelçš„å€¼å¤§äºæŸä¸ªå€¼ # Lt:labelçš„å€¼å°äºæŸä¸ªå€¼ # Exists:æŸä¸ªlabelå­˜åœ¨ # DoesNotExist:æŸä¸ªlabelä¸å­˜åœ¨ # è¿™é‡Œè®¾ç½®çš„æ„æ€æ˜¯ï¼Œæ ¹æ®kubernetes.io/hostnameçš„é”®å€¼ï¼Œæ°¸è¿œä¸åˆ†é…åˆ°é”®å€¼ä¸ºk8s-node01çš„èŠ‚ç‚¹ä¸Š operator: NotIn values: - k8s-node01 åˆ›å»ºåå¯ä»¥çœ‹åˆ° Pod ä¸ä¼šè¢«åˆ›å»ºåœ¨ k8s-node01 èŠ‚ç‚¹ä¸Š preferredDuringSchedulingIgnoredDuringExecutionè½¯ç­–ç•¥ 1234567891011121314151617181920212223apiVersion: v1kind: Podmetadata: name: node-preferred-podspec: containers: - name: node-preferred-container image: daocloud.io/library/nginx:latest imagePullPolicy: IfNotPresent affinity: nodeAffinity: # è½¯ç­–ç•¥ preferredDuringSchedulingIgnoredDuringExecution: # æƒé‡ï¼ŒèŒƒå›´ä¸º1-100 - weight: 1 # åå‘äº preference: # åŒ¹é…è¡¨è¾¾å¼ matchExpressions: - key: kubernetes.io/hostname operator: In values: - k8s-node03 å¯ä»¥çœ‹åˆ°è™½ç„¶è¦æ±‚éƒ¨ç½²åˆ° k8s-node03 èŠ‚ç‚¹ä¸Šï¼Œä½†ç”±äºæœ¬ç¯å¢ƒæ²¡æœ‰è¯¥èŠ‚ç‚¹ï¼Œæ‰€ä»¥å°±è¢«åˆ†é…åˆ°å…¶å®ƒçš„èŠ‚ç‚¹äº† è½¯ç¡¬åˆä½“ç‰ˆ 1234567891011121314151617181920apiVersion: v1kind: Podmetadata: name: node-preandreq-podspec: containers: - name: node-preandreq-container image: daocloud.io/library/nginx:latest imagePullPolicy: IfNotPresent affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - { key: cpu, operator: In, values: [4core] } preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - { key: disktype, operator: In, values: [ssd] } è½¯ç­–ç•¥å’Œç¡¬ç­–ç•¥ä¸€èµ·ä½¿ç”¨å°±ä¼šå…ˆæ»¡è¶³ç¡¬ç­–ç•¥å†åˆ†æè½¯ç­–ç•¥ï¼Œå¯ä»¥çœ‹åˆ°ç°æœ‰çš„èŠ‚ç‚¹æ²¡æœ‰å¯ä»¥æ»¡è¶³ä»¥ä¸Šæ¡ä»¶çš„ï¼Œæ‰€ä»¥ Pod ä¸€ç›´å¤„äº Pending çŠ¶æ€ 7.1.2 Podäº²å’Œæ€§æœ‰æ—¶å€™éœ€è¦å°†æŸäº› Pod ä¸æ­£åœ¨è¿è¡Œçš„å·²å…·æœ‰æŸäº›ç‰¹è´¨çš„ Pod è°ƒåº¦åˆ°ä¸€èµ·ï¼Œå› æ­¤å°±éœ€è¦ Pod äº²å’Œæ€§è°ƒåº¦æ–¹å¼ã€‚ Pod äº²å’Œæ€§æ˜¯é€šè¿‡spec.affinity.podAffinity/podAntiAffinityæ¥å®ç°çš„ï¼Œå‰è€…ä¸ºäº²å’Œæ€§ï¼Œåè€…ä¸ºåäº²å’Œæ€§ï¼ŒåŒ…æ‹¬ä»¥ä¸‹ä¸¤ç§ï¼š preferredDuringSchedulingIgnoredDuringExecutionï¼šè½¯ç­–ç•¥ requiredDuringSchedulingIgnoredDuringExecutionï¼šç¡¬ç­–ç•¥ requiredDuringSchedulingIgnoredDuringExecutionç¡¬ç­–ç•¥ é¦–å…ˆåˆ›å»ºä¸€ä¸ªæ ‡ç­¾ä¸ºapp:nginxçš„ Pod 1234567891011apiVersion: v1kind: Podmetadata: name: test-pod labels: app: nginxspec: containers: - name: test-pod-container-nginx image: daocloud.io/library/nginx:latest imagePullPolicy: IfNotPresent åˆ›å»ºç¡¬ç­–ç•¥äº²å’Œæ€§ Pod 1234567891011121314151617181920212223242526272829303132apiVersion: v1kind: Podmetadata: name: pod-requiredspec: containers: - name: pod-required-container image: daocloud.io/library/nginx:latest imagePullPolicy: IfNotPresent # äº²å’Œæ€§è®¾ç½® affinity: # Podäº²å’Œæ€§è®¾ç½® podAffinity: # ç¡¬ç­–ç•¥ requiredDuringSchedulingIgnoredDuringExecution: # æ ‡ç­¾é€‰æ‹©å™¨ - labelSelector: # åˆ—å‡ºè§„åˆ™ matchExpressions: # ç”„é€‰appè¿™ä¸ªæ ‡ç­¾ - key: app # In:labelçš„å€¼åœ¨æŸä¸ªåˆ—è¡¨ä¸­ # NotIn:labelçš„å€¼ä¸åœ¨æŸä¸ªåˆ—è¡¨ä¸­ # Exists:æŸä¸ªlabelå­˜åœ¨ # DoesNotExist:æŸä¸ªlabelä¸å­˜åœ¨ # è¡¨ç¤ºç¡¬æ€§åŒ¹é…æ ‡ç­¾ä¸ºapp=nginxçš„è¿™ä¸ªPod operator: In # é”®å€¼ values: - nginx # åˆ†é…åˆ°ä¸è¿™ä¸ªPodæ‰€å±çš„èŠ‚ç‚¹kubernetes.io/hostnameå€¼ç›¸åŒçš„èŠ‚ç‚¹ä¸Šï¼Œå¯ä»¥ç†è§£ä¸ºåˆ†é…åˆ°åŒä¸€èŠ‚ç‚¹ä¸Šï¼Œä½†å¯èƒ½æœ‰å¤šä¸ª topologyKey: kubernetes.io/hostname å¯ä»¥çœ‹åˆ°ä¼šåˆ†é…åœ¨åŒä¸€èŠ‚ç‚¹ä¸Š åˆ é™¤è¯¥ Podï¼Œå°†podAffinityæ”¹ä¸ºpodAntiAffinityï¼Œå°†ä¸ä¼šåˆ†é…åˆ°ä¸€èµ· 7.2 æ±¡ç‚¹å’Œå®¹å¿åº¦æ±¡ç‚¹ï¼ˆtaintï¼‰è¡¨ç¤ºä¸€ä¸ªèŠ‚ç‚¹ä¸Šå­˜åœ¨ä¸è‰¯çŠ¶å†µï¼Œæ±¡ç‚¹ä¼šå½±å“ Pod çš„è°ƒåº¦ï¼Œå…¶å®šä¹‰æ–¹å¼å¦‚ä¸‹ 1kubectl taint node {èŠ‚ç‚¹åç§°} {æ±¡ç‚¹åç§°}={æ±¡ç‚¹å€¼}:{æ±¡ç‚¹çš„å½±å“} æ±¡ç‚¹çš„å½±å“æœ‰ä¸‰ç§ï¼š NoExecuteï¼šä¸å°† Pod è°ƒåº¦åˆ°å…·å¤‡è¯¥æ±¡ç‚¹çš„èŠ‚ç‚¹ä¸Šï¼Œå¦‚æœ Pod å·²ç»åœ¨è¯¥èŠ‚ç‚¹è¿è¡Œï¼Œåˆ™ä¼šè¢«é©±é€ã€‚ NoScheduleï¼šä¸å°† Pod è°ƒåº¦åˆ°å…·å¤‡è¯¥æ±¡ç‚¹çš„èŠ‚ç‚¹ä¸Šï¼Œå¦‚æœ Pod å·²ç»åœ¨è¯¥èŠ‚ç‚¹è¿è¡Œï¼Œä¸ä¼šè¢«é©±é€ã€‚ PreferNoScheduleï¼šä¸æ¨èå°† Pod è°ƒåº¦åˆ°å…·å¤‡è¯¥æ±¡ç‚¹çš„èŠ‚ç‚¹ä¸Šã€‚ æ·»åŠ æ±¡ç‚¹ 1kubectl taint node k8s-node01 cpu=1:NoExecute åˆ é™¤æ±¡ç‚¹ 1kubectl taint node k8s-node01 cpu=1:NoExecute- ç¤ºä¾‹ä¸€ ç»™ k8s-node01 æ‰“ä¸Šæ±¡ç‚¹ 1kubectl taint node k8s-node01 cpu=1:NoExecute åˆ›å»º Pod 12345678910111213141516171819202122232425262728293031apiVersion: v1kind: Podmetadata: name: toleration-podspec: containers: - name: toleration-container image: daocloud.io/library/nginx:latest imagePullPolicy: IfNotPresent # æ·»åŠ èŠ‚ç‚¹äº²å’Œæ€§ç¡¬ç­–ç•¥ï¼Œè®©è¯¥Podè°ƒåº¦åˆ°k8s-node01ä¸Š affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - k8s-node01 # å®¹å¿è®¾ç½® tolerations: # å®¹å¿æ±¡ç‚¹ - key: &quot;cpu&quot; # Equal:æŒ‡ç­‰äºè¯¥å€¼ # Exist:æŒ‡æœ‰è¯¥keyå°±å¯ï¼Œå€¼æ— æ‰€è°“ operator: &quot;Equal&quot; value: &quot;1&quot; # æ±¡ç‚¹å½±å“ effect: &quot;NoExecute&quot; # å®¹å¿æ—¶é—´ï¼Œè¶…è¿‡è¯¥äº‹ä»¶å°±ä¼šè¢«é©±é™¤ï¼Œåªæœ‰æ±¡ç‚¹å½±å“è®¾ç½®ä¸ºNoExecuteæ‰å¯ç”¨ tolerationSeconds: 36 å¯ä»¥çœ‹åˆ°è¯¥ Pod ä¾æ—§å¯ä»¥è°ƒåº¦åˆ° k8s-node01 èŠ‚ç‚¹ä¸Šï¼Œä½†è¶…è¿‡ 3600 ç§’åå°±è¢«é©±é™¤äº† å®¹å¿åº¦è®¾ç½®ä¸€èˆ¬ç”¨äº DaemonSet æ§åˆ¶å™¨ï¼Œå› ä¸º DaemonSet æ§åˆ¶å™¨ä¸‹çš„åº”ç”¨ä¸€èˆ¬æ˜¯ä¸ºèŠ‚ç‚¹æœ¬èº«æä¾›æœåŠ¡çš„ã€‚ 7.3 ä¼˜å…ˆçº§å’ŒæŠ¢å å¼è°ƒåº¦å½“é›†ç¾¤çš„èµ„æºï¼ˆCPUã€å†…å­˜ã€ç£ç›˜ç­‰ï¼‰ä¸è¶³æ—¶ï¼Œæ–° Pod çš„åˆ›å»ºä¼šä¸€ç›´å¤„äº Pending çš„çŠ¶æ€ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œé™¤äº†ç³»ç»Ÿå¤–çš„ Podï¼Œå…¶å®ƒ Pod çš„ä¼˜å…ˆçº§éƒ½æ˜¯ç›¸åŒçš„ï¼Œå¦‚æœè°ƒé«˜äº† Pod çš„ä¼˜å…ˆçº§ï¼Œé‚£ä¹ˆèŠ‚ç‚¹å°±ä¼šå°†ä½ä¼˜å…ˆçº§çš„ Pod é©±é€ï¼Œè…¾å‡ºç©ºé—´ç»™ä¼˜å…ˆçº§é«˜çš„ Podï¼Œè¿™å°±è¢«ç§°ä¸ºæŠ¢å å¼è°ƒåº¦ã€‚ ç¤ºä¾‹ä¸€ è¦è°ƒæ•´ä¼˜å…ˆçº§ï¼Œéœ€è¦å…ˆåˆ›å»º PriorityClass 12345678910apiVersion: scheduling.k8s.io/v1kind: PriorityClassmetadata: name: test-priorityclass# ä¼˜å…ˆçº§è®¾ç½®value: 1000000# æ˜¯å¦åœ¨å…¨å±€ä¸‹ä½¿ç”¨ï¼Œåªå¯è®¾ç½®ä¸€ä¸ªglobalDefault: false# æè¿°description: &quot;this priorityclass is test&quot; åœ¨ Pod ä¸­è°ƒç”¨ 12345678910apiVersion: v1kind: Podmetadata: name: priorityclass-podspec: containers: - name: priorityclass-container image: daocloud.io/library/nginx:latest imagePullPolicy: IfNotPresentpriorityClassName: test-priorityclass 7.4 ä¸ºPodè®¾ç½®è®¡ç®—èµ„æºå®¹å™¨è¿è¡Œæ—¶ä¼šæä¾›ä¸€äº›æœºåˆ¶æ¥é™åˆ¶å®¹å™¨å¯ä»¥ä½¿ç”¨çš„è®¡ç®—èµ„æºï¼ˆCPUã€å†…å­˜å’Œç£ç›˜ç­‰ï¼‰ï¼ŒPod æ¨¡æ¿ä¸­ä¹Ÿæä¾›äº†è¿™ä¸ªåŠŸèƒ½ï¼Œä¸»è¦å¦‚ä¸‹ 1234567891011121314# è®¡ç®—èµ„æºè®¾ç½®resources: # èµ„æºé™åˆ¶è®¾ç½®ï¼Œè¶…è¿‡è®¾ç½®çš„å€¼å®¹å™¨ä¼šè¢«åœæ­¢ limits: # cpué™åˆ¶ cpu: # å†…å­˜é™åˆ¶ memory: # èµ„æºè¯·æ±‚è®¾ç½®ï¼Œè‡³å°‘éœ€è¦å¤šå°‘èµ„æºå®¹å™¨æ‰ä¼šè¢«è¿è¡Œ requests: # cpuè¯·æ±‚ cpu: # å†…å­˜è¯·æ±‚ memory: ç¤ºä¾‹ä¸€ 12345678910111213141516171819apiVersion: v1kind: Podmetadata: name: resources-podspec: containers: - name: resources-container # å‹æµ‹å·¥å…· image: vish/stress imagePullPolicy: IfNotPresent # è¿›è¡Œå‹æµ‹ï¼Œé˜ˆå€¼ä¸º150Mi,æ¯ä¸€ç§’å¢åŠ 5Miå‹åŠ› args: [ '-mem-total','150Mi','-mem-alloc-size','5Mi','-mem-alloc-sleep','1s' ] resources: limits: cpu: '1' memory: '100Mi' requests: cpu: '200m' memory: '50Mi' å¯ä»¥çœ‹åˆ° Pod æœ€åˆå¯ä»¥è¿è¡Œï¼Œä½†20ç§’åå°±ä¸è¡Œäº† 7.5 å‘½åç©ºé—´ç®¡ç†å‘½åç©ºé—´çš„ä¸»è¦ä½œç”¨æ˜¯å¯¹ k8s é›†ç¾¤çš„èµ„æºè¿›è¡Œåˆ’åˆ†ï¼Œè¿™ç§åˆ’åˆ†æ˜¯ä¸€ç§é€»è¾‘åˆ’åˆ†ï¼Œç”¨äºå®ç°å¤šç§Ÿæˆ·çš„èµ„æºéš”ç¦»ã€‚ å‘½åç©ºé—´çš„åˆ›å»º 1kubectl create namespace å‘½åç©ºé—´åç§° å‘½åç©ºé—´çš„èµ„æºé…é¢ 1234567891011121314151617181920212223242526272829303132333435363738apiVersion: v1kind: ResourceQuotametadata: name: namespace:spec: hard: # è®¡ç®—èµ„æºé…é¢ limits.cpu: limits.memory: requests.cpu: requests.memory: # å­˜å‚¨èµ„æºé…é¢ # åœ¨æ‰€æœ‰PVCä¸­ï¼Œå­˜å‚¨èµ„æºçš„éœ€æ±‚ä¸èƒ½è¶…è¿‡è¯¥å€¼ requests.storage: # å…è®¸å­˜åœ¨çš„PVCæ•°é‡ persistentvolumeclaims: # å…è®¸ä¸{storage-class-name}ç›¸å…³çš„PVCæ€»é‡ {storage-class-name}.storageclass.storage.k8s.io/requests.storage: # å¯¹è±¡æ•°é‡é…é¢ # å…è®¸å­˜åœ¨ConfigMapæ•°é‡ configmaps: # å…è®¸å­˜åœ¨çš„éç»ˆæ­¢çŠ¶æ€çš„Podæ•°é‡ pods: # å…è®¸å­˜åœ¨çš„RCæ•°é‡ replicationcontrollers: # å…è®¸å­˜åœ¨çš„èµ„æºé…é¢æ•°é‡ resourcequotas: # å…è®¸å­˜åœ¨çš„SVCæ•°é‡ services: # å…è®¸å­˜åœ¨çš„LoadBalancerç±»å‹çš„SVCæ•°é‡ services.loadbalancers: # å…è®¸å­˜åœ¨çš„NodePortç±»å‹çš„SVCæ•°é‡ services.nodeports: # å…è®¸å­˜åœ¨çš„Secretæ•°é‡ secrets: 7.5.1 å‘½åç©ºé—´çš„èµ„æºé…é¢ç¤ºä¾‹ä¸€ å…ˆåˆ›å»ºä¸€ä¸ªå‘½åç©ºé—´ 1kubectl create namespace test-ns åˆ›å»ºèµ„æºé…é¢ 12345678910apiVersion: v1kind: ResourceQuotametadata: name: test-rq namespace: test-nsspec: hard: pods: '2' services: '1' persistentvolumeclaims: '4' åˆ›å»ºä¸€ä¸ª Deployment 123456789101112131415161718192021apiVersion: apps/v1kind: Deploymentmetadata: name: test-ns-depolyment namespace: test-nsspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: test-ns-depolyment-container image: daocloud.io/library/nginx:latest imagePullPolicy: IfNotPresent ports: - containerPort: 80 é…é¢é™åˆ¶çš„ Pod æ•°é‡æ˜¯2ï¼Œä½† Deployment è®¾ç½®çš„å‰¯æœ¬æ•°æ˜¯3ï¼Œå¯ä»¥çœ‹åˆ°æ˜¯åˆ›å»ºä¸äº†ç¬¬ä¸‰ä¸ª Pod çš„ 7.5.2 å‘½åç©ºé—´å•ä¸ªèµ„æºçš„èµ„æºé…é¢é€šè¿‡è®¾ç½®èµ„æºé…é¢ï¼Œå¯ä»¥é™å®šä¸€ä¸ªå‘½åç©ºé—´ä¸‹ä½¿ç”¨çš„èµ„æºæ€»é‡ï¼Œä½†è¿™åªæ˜¯æ€»é‡é™åˆ¶ï¼Œå¯¹äºå•ä¸ªèµ„æºæ²¡æœ‰é™åˆ¶ï¼Œæœ‰æ—¶å€™ä¸€ä¸ª Pod å°±å¯èƒ½ç”¨å®Œæ•´ä¸ªå‘½åç©ºé—´æ‰€æŒ‡å®šçš„èµ„æºï¼Œä¸ºäº†é¿å…ï¼Œå¯ä»¥é€šè¿‡LimitRangeæ¥å¯¹å•ä¸ªèµ„æºè¿›è¡Œé™å®šã€‚ è®¾ç½®å®¹å™¨çš„é™é¢èŒƒå›´ 1234567891011121314151617181920apiVersion: v1kind: LimitRangemetadata: name: limitrange-container namespace: test-nsspec: limits: - max: cpu: '200m' memory: '300Mi' min: cpu: '100m' memory: '150Mi' default: cpu: '180m' memory: '250Mi' defaultRequest: cpu: '110m' memory: '160Mi' type: Container å½“ LimitRange åˆ›å»ºæˆåŠŸåï¼Œåˆ›å»ºè¯¥å‘½åç©ºé—´ä¸‹çš„ Pod æ—¶ï¼Œå„ä¸ªå®¹å™¨çš„resource.limitså’Œresource.requestså¿…é¡»æ»¡è¶³ Max å’Œ Min ä¹‹é—´çš„èŒƒå›´ã€‚ è€Œdefaultå’ŒdefaultRequestæ˜¯æŒ‡ï¼Œå½“åˆ›å»º Pod æ—¶æ²¡ç”¨è®¾ç½®é™é¢ï¼Œåˆ™æ ¹æ®æ­¤å±æ€§æ¥è®¾ç½®é™é¢ã€‚ è®¾ç½® Pod çš„é™é¢èŒƒå›´ 1234567891011121314apiVersion: v1kind: LimitRangemetadata: name: limitrange-pod namespace: test-nsspec: limits: - max: cpu: '1' memory: '600Mi' min: cpu: '500m' memory: '300Mi' type: Pod å½“ LimitRange åˆ›å»ºæˆåŠŸåï¼Œåˆ›å»ºè¯¥å‘½åç©ºé—´ä¸‹çš„ Pod æ—¶ï¼Œå„ä¸ª Pod çš„resource.limitså’Œresource.requestså¿…é¡»æ»¡è¶³ Max å’Œ Min ä¹‹é—´çš„èŒƒå›´ã€‚ è®¾ç½® PVC çš„é™é¢èŒƒå›´ 123456789101112apiVersion: v1kind: LimitRangemetadata: name: limitrange-pvc namespace: test-nsspec: limits: - max: storage: 1Gi min: storage: 200Mi type: PersistentVolumeClaim è®¾ç½® Pod æˆ–å®¹å™¨çš„æ¯”ä¾‹é™é¢èŒƒå›´ 12345678910apiVersion: v1kind: LimitRangemetadata: name: limitrange-ratio namespace: test-nsspec: limits: - maxLimitRequestRatio: memory: 2 type: Pod è®¾ç½®æ¯”ä¾‹é™é¢å¯ä»¥é™åˆ¶ Pod æˆ–å®¹å™¨è®¾ç½®çš„è¯·æ±‚èµ„æºå’Œä¸Šé™èµ„æºçš„æ¯”å€¼ï¼Œåœ¨è¯¥ç¤ºä¾‹ä¸­ï¼ŒPod æ‰€æœ‰å®¹å™¨çš„resources.limits.memoryçš„æ€»å’Œè¦ = Pod æ‰€æœ‰å®¹å™¨çš„resources.requests.memoryçš„æ€»å’Œçš„ä¸¤å€ï¼Œå³ä¸Šé™å¿…é¡»æ˜¯éœ€æ±‚çš„ä¸¤å€ï¼ŒPod æ‰èƒ½å¤Ÿåˆ›å»ºæˆåŠŸã€‚ 7.6 æ ‡ç­¾ã€é€‰æ‹©å™¨ã€æ³¨è§£7.6.1 æ ‡ç­¾k8s çš„æ ‡ç­¾ï¼ˆlabelï¼‰æ˜¯ä¸€ç§è¯­ä¹‰åŒ–æ ‡è®°æ ‡ç­¾ï¼Œå¯ä»¥é™„åŠ åˆ° k8s å¯¹è±¡ä¸Šï¼Œå¯¹å®ƒä»¬è¿›è¡Œæ ‡è®°å’Œåˆ’åˆ†ã€‚ æ ‡ç­¾çš„å½¢å¼æ˜¯é”®å€¼å¯¹ï¼Œæ¯ä¸ªèµ„æºå¯¹è±¡éƒ½å¯ä»¥æ‹¥æœ‰å¤šä¸ªæ ‡ç­¾ï¼Œä½†æ¯ä¸ªé”®éƒ½åªèƒ½æœ‰ä¸€ä¸ªå€¼ã€‚ å¯¹äºæ ‡ç­¾çš„è®¾ç½®ï¼Œæ˜¯é€šè¿‡metadataå±æ€§ä¸­å®ç°çš„ï¼Œå¦‚ä¸‹ 123456metadata: name: labels: key1: value1 key2: value2 ... è€Œå¯¹äºå·²æœ‰çš„èµ„æºï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤æ·»åŠ æˆ–åˆ é™¤æ ‡ç­¾ 12kubectl label èµ„æºç±»å‹ èµ„æºåç§° æ ‡ç­¾å=æ ‡ç­¾å€¼kubectl label èµ„æºç±»å‹ èµ„æºåç§° æ ‡ç­¾å=æ ‡ç­¾å€¼- 7.6.2 é€‰æ‹©å™¨é€šè¿‡æ ‡ç­¾é€‰æ‹©å™¨ï¼ˆselectorï¼‰å°±å¯ä»¥å¿«é€ŸæŸ¥æ‰¾åˆ°æŒ‡å®šæ ‡ç­¾çš„èµ„æºã€‚ é€šè¿‡-læŸ¥æ‰¾æ–¹å¼å¦‚ä¸‹ 1kubectl get pod -l æ ‡ç­¾å=/!=æ ‡ç­¾å€¼ é€šè¿‡in notinæŸ¥æ‰¾ 1kubectl get pod -l 'æ ‡ç­¾å1 in/notin (æ ‡ç­¾å€¼1,æ ‡ç­¾å€¼2)' æ¯ç§åŸºäºæ§åˆ¶å™¨çš„å¯¹è±¡ä¹Ÿå¯ä»¥ä½¿ç”¨æ ‡ç­¾æ¥é€‰æ‹©éœ€è¦æ“ä½œçš„ Podï¼Œå¦‚ Jobã€Deploymentã€DaemonSet ç­‰éƒ½å¯ä»¥åœ¨specä¸­æŒ‡å®šé€‰æ‹©å™¨ï¼Œä»¥æŸ¥æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ Podï¼Œå¦‚ä¸‹ 12345678spec: selector: matchLabels: app: nginx release: stable matchExpressions: - { key: env, operator: In, values: [dev] } - { key: track, operator: Exists } åœ¨åˆ›å»º SVC æ—¶ï¼Œéƒ½éœ€è¦åˆ¶å®šæ ‡ç­¾é€‰æ‹©å™¨æ¥ç¡®å®šéœ€è¦æ§åˆ¶çš„èµ„æºï¼Œå¦‚ä¸‹ 12345678apiVersion: v1kind: Servicemetadata: name: svcspec: selector: app: nginx release: stable åœ¨åˆ›å»º PVC æ—¶ï¼Œé™¤äº†ç”¨ç±»åŒ¹é…ä¹‹å¤–ï¼Œä¹Ÿå¯ä»¥ç”¨æ ‡ç­¾æ¥åŒ¹é…é€‚åˆçš„ PVï¼Œå¦‚ä¸‹ 12345678910111213141516171819202122232425apiVersion: v1kind: PersistentVolumemetadata: name: pv labels: pvnumber: pv01spec: capacity: storage: 1Gi accessModes: - ReadWriteMany storageClassName: nginx---apiVersion: v1kind: PersistentVolumeClaimmetadata: name: pvcspec: selector: matchLabels: pvnumber: pv01 resources: requests: storage: 1Gi storageClassName: nginx 7.6.3 æ³¨è§£æ³¨è§£ï¼ˆannotationï¼‰ä¹Ÿæ˜¯ä¸€ç§ç±»ä¼¼æ ‡ç­¾çš„æœºåˆ¶ï¼Œä½†åªæ˜¯ç»™èµ„æºæ·»åŠ æ›´å¤šä¿¡æ¯çš„æ–¹å¼ï¼Œç±»ä¼¼æ³¨é‡Šã€‚ è®¾ç½®æ³¨è§£ï¼Œæ˜¯é€šè¿‡metadataæ¥å®ç°çš„ï¼Œå¦‚ä¸‹ 1234567891011apiVersion: v1kind: Podmetadata: name: pod annotation: team: 'cqm' phone: '123456' email: '123456@789.com' ...spec: ... å…«ã€API ServerAPI Server æ˜¯é›†ç¾¤å†…å¸ƒå„ä¸ªç»„ä»¶é€šä¿¡çš„ä¸­ä»‹ï¼Œä¹Ÿæ˜¯å¤–éƒ¨æ§åˆ¶çš„å…¥å£ï¼Œk8s çš„å®‰å…¨æœºåˆ¶åŸºæœ¬éƒ½æ˜¯å›´ç»•ç€ä¿æŠ¤ API Server æ¥è®¾è®¡çš„ï¼Œé€šè¿‡è®¤è¯ã€é‰´æƒã€å‡†å…¥æ§åˆ¶ä¸‰æ­¥æ¥ä¿è¯ API Server çš„å®‰å…¨ã€‚ æˆ‘ä»¬åœ¨ä½¿ç”¨ k8s æ—¶ï¼Œéƒ½æ˜¯é€šè¿‡kubectlå·¥å…·æ¥è®¿é—® API Server çš„ï¼ŒkubectlæŠŠå‘½ä»¤è½¬æ¢ä¸ºå¯¹ API Server çš„ REST API è°ƒç”¨ã€‚ 8.1 èº«ä»½è®¤è¯èº«ä»½è®¤è¯ä¸»è¦ç”¨äºç¡®å®šç”¨æˆ·èƒ½ä¸èƒ½è®¿é—®ï¼Œæ˜¯è®¿é—® API Server çš„ç¬¬ä¸€ä¸ªå…³å¡ã€‚ é€šè¿‡å‘½ä»¤å¯ä»¥çœ‹åˆ°è®¤è¯æƒ…å†µï¼Œå¯ä»¥çœ‹åˆ°æ˜¯é€šè¿‡ 6443 ç«¯å£è¿›è¡Œè®¿é—®çš„ã€‚ è¦è®¿é—® API Serverï¼Œé¦–å…ˆå°±è¦è¿›è¡Œèº«ä»½è®¤è¯ï¼Œk8s çš„èº«ä»½è®¤è¯åˆ†ä¸ºä»¥ä¸‹ä¸¤ç±»ï¼š å¸¸è§„ç”¨æˆ·è®¤è¯ï¼šä¸»è¦æä¾›äºæ™®é€šç”¨æˆ·æˆ–ç‹¬ç«‹äº k8s ä¹‹å¤–çš„å…¶ä»–å¤–éƒ¨åº”ç”¨ä½¿ç”¨ï¼Œä»¥ä¾¿èƒ½ä»å¤–éƒ¨è®¿é—® API Serverã€‚ ServiceAccount è®¤è¯ï¼šä¸»è¦æä¾›äºå†…éƒ¨çš„ Pod ä½¿ç”¨ã€‚ 8.1.1 å¸¸è§„ç”¨æˆ·è®¤è¯å¸¸è§„ç”¨æˆ·è®¤è¯ä¸»è¦æœ‰ä¸‰ç§æ–¹å¼ï¼š HTTPS è¯ä¹¦è®¤è¯ï¼šåŸºäº CA è¯ä¹¦ç­¾åçš„æ•°å­—è¯ä¹¦è®¤è¯ã€‚ HTTP ä»¤ç‰Œè®¤è¯ï¼šé€šè¿‡ä»¤ç‰Œæ¥è¯†åˆ«ç”¨æˆ·ã€‚ HTTP Base è®¤è¯ï¼šé€šè¿‡ç”¨æˆ·åå’Œå¯†ç è®¤è¯ã€‚ ä»¤ç‰Œè®¤è¯æ˜¯æœ€å®ç”¨ä¹Ÿæœ€æ™®åŠçš„æ–¹å¼ï¼Œé¦–å…ˆç”Ÿæˆä¸€ä¸ªéšæœºä»¤ç‰Œ 1head -c 16 /dev/urandom | od -An -t x | tr -d ' ' æ¥ç€ç»™ k8s åˆ›å»ºä»¤ç‰Œè®¤è¯æ–‡ä»¶ 123vim /etc/kubernetes/pki/token_auth_file# æ ¼å¼ä¸º:ä»¤ç‰Œ1,ç”¨æˆ·1,ç”¨æˆ·IDec0f09bf9a3c40f9db1cc0f8e6664c12,cqm,1 è®¤è¯æ–‡ä»¶åˆ›å»ºå¥½åï¼Œåœ¨ API Server å¯åŠ¨æ–‡ä»¶ä¸­è¿›è¡Œå¼•ç”¨ 123vim /etc/kubernetes/manifests/kube-apiserver.yaml# åœ¨specä¸­æ·»åŠ --token-auth-file=/etc/kubernetes/pki/token_auth_file æ¥ç€å°±å¯ä»¥ç”¨è®¤è¯å¥½çš„ç”¨æˆ·è®¿é—® API Server æ¥è·å– Pod çš„ä¿¡æ¯äº† 1curl --insecure https://192.168.88.10:6443/api/v1/namespaces/default/pods -H &quot;Authorization:Bearer ec0f09bf9a3c40f9db1cc0f8e6664c12&quot; ä½†å¯ä»¥çœ‹åˆ°è¿˜æ˜¯å¤±è´¥ï¼Œå› ä¸ºè¿˜æ²¡æœ‰è¿›è¡Œæˆæƒï¼Œåè¾¹å°†è¿›è¡Œæˆæƒã€‚ 8.1.2 ServiceAccountè®¤è¯ServiceAccount è®¤è¯ä¸»è¦æä¾›äºé›†ç¾¤å†…å¸ƒçš„ Pod ä¸­çš„è¿›ç¨‹ä½¿ç”¨ï¼Œå¸¸è§„ç”¨æˆ·è®¤è¯æ˜¯ä¸é™åˆ¶å‘½åç©ºé—´çš„ï¼Œä½† ServiceAccount è®¤è¯çš„å±€é™äºå®ƒæ‰€åœ¨çš„å‘½åç©ºé—´ä¸­ã€‚ é»˜è®¤ ServiceAccount æ¯ä¸ªå‘½åç©ºé—´éƒ½æœ‰ä¸ªé»˜è®¤çš„ ServiceAccountï¼Œå¦‚æœåˆ›å»º Pod æ—¶æ²¡ç”¨æŒ‡å®šï¼Œé‚£ä¹ˆå°±ä¼šä½¿ç”¨é»˜è®¤çš„ ServiceAccountã€‚ é€šè¿‡å‘½ä»¤å¯ä»¥çœ‹åˆ°é»˜è®¤çš„ ServiceAccount åˆ›å»ºä¸€ä¸ª Pod è¿›è¡Œæµ‹è¯• 1234567891011apiVersion: v1kind: Podmetadata: name: sa-podspec: containers: - name: sa-pod-container image: appropriate/curl:latest imagePullPolicy: IfNotPresent command: ['sh', '-c'] args: ['echo &quot;this is sa test&quot;; sleep 3600'] æŸ¥çœ‹ Pod çš„è¯¦ç»†ä¿¡æ¯ï¼Œå¯ä»¥çœ‹åˆ°è¢«æŒ‚è½½äº†ä¸€ä¸ª Secret ç±»å‹çš„å·ï¼Œå®é™…ä¸Šè¿™é‡Œé¢å°±å­˜æ”¾äº† ServiceAccount çš„è®¤è¯ä¿¡æ¯ è¿›å…¥å®¹å™¨å†…éƒ¨ï¼Œé€šè¿‡ä»¥ä¸Šåœ°å€æ˜ å°„ä»¤ç‰Œåœ¨è¿›è¡Œè®¿é—® API Serverï¼Œå¯ä»¥çœ‹åˆ°ç”±äºæœªæˆæƒä¾æ—§ä¸è¡Œ 12curl --insecure https://192.168.88.10:6443/api/v1/namespaces/default/pods -H &quot;Authorization:Bearer $(cat /var/run/secrets/kubernetes.io/serviceaccount/token)&quot; è‡ªå®šä¹‰ ServiceAccount å¦‚æœæŸäº› Pod éœ€è¦è®¿é—® API Serverï¼Œé€šå¸¸ä¼šè®©å®ƒå¼•ç”¨è‡ªå®šä¹‰ ServiceAccountï¼Œå¹¶ä¸ºå…¶æˆæƒã€‚ é¦–å…ˆåˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰ ServiceAccount 1234apiVersion: v1kind: ServiceAccountmetadata: name: my-serviceaccount åˆ›å»ºå¥½åå¯ä»¥æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…å«äº†è¯ä¹¦å’Œä»¤ç‰Œç­‰ åˆ›å»º Pod å¼•ç”¨ 123456789101112apiVersion: v1kind: Podmetadata: name: my-sa-podspec: serviceAccountName: my-serviceaccount containers: - name: my-sa-pod-container image: appropriate/curl:latest imagePullPolicy: IfNotPresent command: ['sh', '-c'] args: ['echo &quot;this is sa test&quot;; sleep 3600'] å°±å¯ä»¥çœ‹åˆ° Pod ä¸­å·²ç»å¼•ç”¨äº† 8.2 RBACæˆæƒk8s ä¸­æœ‰åŸºäºå±æ€§çš„è®¿é—®æ§åˆ¶ï¼ˆABACï¼‰ï¼ŒåŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶ï¼ˆRBACï¼‰ï¼ŒåŸºäº HTTP å›è°ƒæœºåˆ¶çš„è®¿é—®æ§åˆ¶ï¼ˆWebhookï¼‰ã€Node è®¤è¯ç­‰æˆæƒæ¨¡å¼ï¼Œä½†1.6ç‰ˆæœ¬å¼€å§‹å°±é»˜è®¤å¯ç”¨ RBAC æ¨¡å¼ã€‚ RBAC æˆæƒä¸»è¦åˆ†ä¸ºä¸¤æ­¥ï¼š è§’è‰²å®šä¹‰ï¼šæŒ‡å®šè§’è‰²åç§°ï¼Œå®šä¹‰å…è®¸è®¿é—®å“ªäº›èµ„æºä»¥åŠå…è®¸çš„è®¿é—®æ–¹å¼ã€‚ è§’è‰²ç»‘å®šï¼šå°†è§’è‰²ä¸ç”¨æˆ·ï¼ˆå¸¸è§„ç”¨æˆ·æˆ– ServiceAccountï¼‰è¿›è¡Œç»‘å®šã€‚ è€Œè§’è‰²å®šä¹‰å’Œè§’è‰²ç»‘å®šåˆåˆ†ä¸ºä¸¤ç§ï¼š åªæœ‰å•ä¸€æŒ‡å®šå‘½åç©ºé—´è®¿é—®æƒé™çš„è§’è‰²ï¼šè§’è‰²å®šä¹‰å…³é”®å­—ä¸º Roleï¼Œè§’è‰²ç»‘å®šå…³é”®å­—ä¸º RoleBindingã€‚ æ‹¥æœ‰é›†ç¾¤çº§åˆ«ï¼ˆä¸é™å‘½åç©ºé—´ï¼‰è®¿é—®æƒé™çš„è§’è‰²ï¼šè§’è‰²å®šä¹‰ä¸º ClusterRoleï¼Œè§’è‰²ç»‘å®šå…³é”®å­—ä¸º ClusterRoleBindingã€‚ 8.2.1 æ™®é€šè§’è‰²çš„å®šä¹‰ä¸ç»‘å®šæ™®é€šè§’è‰²å®šä¹‰ åˆ›å»ºä¸€ä¸ªæ™®é€šè§’è‰² 1234567891011121314apiVersion: rbac.authorization.k8s.io/v1kind: Rolemetadata: # è§’è‰²å name: rbac-role namespace: default# è§’è‰²è§„åˆ™å®šä¹‰rules: # è¡¨ç¤ºå¯ä»¥å¯¹å“ªäº›APIç»„çš„èµ„æºè¿›è¡Œæ“ä½œï¼Œè¿™é‡Œä¸ºç©ºå³ä¸é™åˆ¶- apiGroups: [&quot;&quot;] # å¯ä»¥è®¿é—®çš„èµ„æºåˆ—è¡¨ï¼Œè¿™é‡Œä¸ºPod resources: [&quot;pods&quot;] # å¯ä»¥è¿›è¡Œçš„è®¿é—®æ–¹å¼ verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;] è®¿é—®æ–¹å¼å¯ä»¥é€šè¿‡å¼€å¯kubectlåå‘ä»£ç†æŸ¥çœ‹ï¼Œå…¶ä¸­çš„verbå°±æ˜¯å¯ä»¥è®¿é—®çš„æ–¹å¼ 12kubectl proxy --port:8080curl http://localhost:8080/{APIVersion} æ™®é€šè§’è‰²ç»‘å®š å®šä¹‰è§’è‰²åå°±å¯ä»¥è¿›è¡Œç»‘å®šè§’è‰²ï¼Œç»‘å®šå¯ä»¥é’ˆå¯¹å¸¸è§„ç”¨æˆ·è®¤è¯ï¼Œä¹Ÿå¯ä»¥è¿™å¯¹ ServiceAccount è®¤è¯ã€‚ åˆ›å»ºè§’è‰²ç»‘å®š 123456789101112131415161718192021apiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata: name: rbac-rolebinding namespace: default# å°†è§’è‰²ç»‘å®šç»™é‚£äº›è®¤è¯ä¸»ä½“ï¼Œå®ƒæ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œå°†å¸¸è§„ç”¨æˆ·è®¤è¯cqmå’ŒServiceAccountè®¤è¯my-serviceaccountåŠ å…¥åˆ°rabc-roleè§’è‰²ä¸­subjects: # å¸¸è§„ç”¨æˆ·è®¤è¯ç»‘å®š- kind: User name: cqm apiGroup: &quot;&quot; # ServiceAccountè®¤è¯ç»‘å®š- kind: ServiceAccount name: my-serviceaccount apiGroup: &quot;&quot;# è¦ç»‘å®šçš„è§’è‰²roleRef: # æ™®é€šè§’è‰² kind: Role name: rbac-role apiGroup: &quot;&quot; å°è¯•ç”¨ä¹‹å‰åˆ›å»ºçš„å¸¸è§„ç”¨æˆ·è®¤è¯å’Œ ServiceAccount è®¤è¯æ¥è®¿é—® API Serverï¼Œå¯ä»¥å‘ç°å°±å¯ä»¥è®¿é—®äº† 1curl --insecure https://192.168.88.10:6443/api/v1/namespaces/default/pods -H &quot;Authorization:Bearer ec0f09bf9a3c40f9db1cc0f8e6664c12&quot; 12curl --insecure https://192.168.88.10:6443/api/v1/namespaces/default/pods -H &quot;Authorization:Bearer $(cat /var/run/secrets/kubernetes.io/serviceaccount/token)&quot; 8.2.2 é›†ç¾¤è§’è‰²çš„å®šä¹‰ä¸ç»‘å®šé›†ç¾¤è§’è‰²ä¸æ™®é€šè§’è‰²çš„åŒºåˆ«å¦‚ä¸‹ï¼š ä½¿ç”¨çš„å…³é”®å­—ä¸åŒï¼šæ™®é€šè§’è‰²ä½¿ç”¨ Roleï¼Œç»‘å®šä½¿ç”¨ RoleBindingï¼Œé›†ç¾¤è§’è‰²ä½¿ç”¨ ClusterRoleï¼Œç»‘å®šä½¿ç”¨ ClusterRoleBindingã€‚ é›†ç¾¤è§’è‰²ä¸å±äºä»»ä½•å‘½åç©ºé—´ï¼Œæ¨¡æ¿ä¹Ÿä¸éœ€è¦æŒ‡å®šå‘½åç©ºé—´ï¼Œæ™®é€šè§’è‰²è¦æ±‚æŒ‡å®šå‘½åç©ºé—´ï¼Œå¦‚æœæ²¡æŒ‡å®šä¹é»˜è®¤ defaultã€‚ é›†ç¾¤è§’è‰²å¯ä»¥è®¿é—®æ‰€æœ‰å‘½åç©ºé—´ä¸‹çš„èµ„æºï¼Œä¹Ÿå¯ä»¥è®¿é—®ä¸åœ¨å‘½åç©ºé—´ä¸‹çš„èµ„æºã€‚ é›†ç¾¤è§’è‰²åˆ›å»ºå’Œç»‘å®šå¦‚ä¸‹ 123456789101112131415161718192021222324252627282930# é›†ç¾¤è§’è‰²å®šä¹‰apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: # é›†ç¾¤è§’è‰²å name: rbac-clusterrole# è§„åˆ™rules:- apiGroups: [&quot;&quot;] resources: [&quot;pods&quot;] verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;]---# é›†ç¾¤è§’è‰²ç»‘å®šapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: rbac-clusterrolebindingsubjects:- kind: User name: cqm apiGroup: &quot;&quot;- kind: ServiceAccount name: my-serviceaccount apiGroup: &quot;&quot; # ç”±äºmy-serviceaccountæ˜¯æŸä¸ªå‘½åç©ºé—´ä¸‹çš„ï¼Œæ‰€ä»¥è¦æŒ‡å®šå‘½åç©ºé—´ namespace: defaultroleRef: kind: ClusterRole name: clusterrole apiGroup: &quot;&quot; è¿™æ ·ä¸€æ¥ç”¨æˆ·ï¼ˆcqmï¼Œmy-serviceaccountï¼‰éƒ½å¯ä»¥è®¿é—®å…¨å±€çš„èµ„æºï¼Œå½“ç„¶ ClusterRole ä¹Ÿå¯ä»¥å’Œ RoleBinding ç»‘å®šåœ¨ä¸€èµ·ï¼Œå› ä¸º ClusterRole æ˜¯ä¸é™å‘½åç©ºé—´çš„ï¼Œå¦‚æœæ—¢æƒ³ç»™æŸä¸ªè®¤è¯ä¸»ä½“ç»‘å®š ClusterRoleï¼Œåˆæƒ³é™åˆ¶å®ƒèƒ½è®¿é—®çš„å‘½åç©ºé—´ï¼Œå°±å¯ä»¥é€šè¿‡ä¸ RoleBinding ç»‘å®šæ¥å®ç°ï¼Œæœ¬ä¾‹ä¸­æ˜¯æŒ‡rbac-clusterroleçš„è§’è‰²åœ¨ç»‘å®šrbac-rolebindingåï¼Œå¯ä»¥è®¿é—®åœ¨defaultå‘½åç©ºé—´ä¸‹çš„ä»»ä½•èµ„æºï¼Œå¦‚ä¸‹ 123456789101112apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: rbac-clusterrole...---apiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata: name: rbac-rolebinding namespace: default... 8.3 åˆ›å»ºä¸€ä¸ªç”¨æˆ·åªèƒ½ç®¡ç†æŒ‡å®šçš„å‘½åç©ºé—´åœ¨å®é™…çš„ç”Ÿäº§ç¯å¢ƒä¸­ï¼ŒMaster çš„ç®¡ç†è€…å¯èƒ½æœ‰å¾ˆå¤šä¸ªï¼Œä½†ä¸å¯èƒ½ç»™äººäººéƒ½èµ‹äºˆ root çš„æƒé™ï¼Œé‚£ä¹ˆå°±å¯ä»¥åˆ›å»ºæ–°ç”¨æˆ·ç»™å…¶ç®¡ç†æŒ‡å®šå‘½åç©ºé—´çš„æƒé™ã€‚ åˆ›å»ºæ–°ç”¨æˆ·ï¼Œè¿™æ—¶å€™è¯¥ç”¨æˆ·æ˜¯ä½¿ç”¨ä¸äº† k8s çš„ 123useradd cqmpasswd cqm... åˆ›å»ºè¯ä¹¦è¯·æ±‚ 123456789101112131415161718vim cqm-csr.json{ &quot;CN&quot;: &quot;cqm&quot;, &quot;hosts&quot;: [], &quot;key&quot;: { &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 }, &quot;names&quot;: [ { &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;ShenZhen&quot;, &quot;L&quot;: &quot;ShenZhen&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; } ]} ä¸‹è½½è¯ä¹¦ç”Ÿæˆå·¥å…· 12345678wget https://github.com/cloudflare/cfssl/releases/download/v1.6.0/cfssl_1.6.0_linux_amd64wget https://github.com/cloudflare/cfssl/releases/download/v1.6.0/cfssljson_1.6.0_linux_amd64wget https://github.com/cloudflare/cfssl/releases/download/v1.6.0/cfssl-certinfo_1.6.0_linux_amd64mv cfssl_1.6.0_linux_amd64 cfsslmv cfssl-certinfo_1.6.0_linux_amd64 cfssl-certinfomv cfssljson_1.6.0_linux_amd64 cfssljsonchmod a+x cfssl*mv cfssl* /usr/local/bin ç”Ÿæˆè¯ä¹¦ 12cd /etc/kubernetes/pkicfssl gencert -ca=ca.crt -ca-key=ca.key -profile=kubernetes ~/cqm-csr.json | cfssljson -bare cqm è®¾ç½®é›†ç¾¤å‚æ•° 123456export KUBE_APISERVER=&quot;192.168.88.10:6443&quot;kubectl config set-cluster kubernetes \\--certificate-authority=/etc/kubernetes/pki/ca.crt \\--embed-certs=true \\--server=${KUBE_APISERVER} \\--kubeconfig=cqm.kubeconfig è®¾ç½®å®¢æˆ·ç«¯è®¤è¯å‚æ•° 12345kubectl config set-credentials cqm \\--client-certificate=/etc/kubernetes/pki/cqm.pem \\--client-key=/etc/kubernetes/pki/cqm-key.pem \\--embed-certs=true \\--kubeconfig=cqm.kubeconfig è®¾ç½®ä¸Šä¸‹æ–‡å‚æ•° 12345kubectl config set-context kubernetes \\--cluster=kubernetes \\--user=cqm \\--namespace=dev \\--kubeconfig=cqm.kubeconfig è¿›è¡Œ RoleBindingï¼Œè¿™é‡Œçš„æ„æ€æ˜¯æŒ‡å°†å¸¸è§„ç”¨æˆ· cqm ä¸ ClusterRole çš„ admin è§’è‰²è¿›è¡Œç»‘å®šï¼Œä¸”æŒ‡å®š dev çš„å‘½åç©ºé—´ç»™ cqmï¼Œæœ€ç»ˆæ•ˆæœæ˜¯ cqm åªèƒ½å¤Ÿè®¿é—®å’Œç®¡ç† dev å‘½åç©ºé—´ä¸‹çš„æ‰€æœ‰èµ„æº 12345678910111213apiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata: name: cqm-rolebinding namespace: devsubjects:- kind: User name: cqm apiGroup: &quot;&quot;roleRef: kind: ClusterRole name: admin apiGroup: &quot;&quot; è®¾ç½®é»˜è®¤ä¸Šä¸‹æ–‡ 12345mkdir /home/cqm/.kubecp cqm.kubeconfig /home/cqm/.kube/configchown cqm:cqm /home/cqm/.kube/configsu cqmkubectl config use-context kubernetes --kubeconfig=/home/cqm/.kube/config ä¹ã€k8sæ‰©å±•9.1 å¯è§†åŒ–ç®¡ç†â€”â€”Kubernetes DashboardKubernetes Dashboard å¯ä»¥å®ç° k8s çš„å¯è§†åŒ–ç®¡ç†ï¼Œå¯ä»¥å®ç°å¯¹ Podã€æ§åˆ¶å™¨ã€Service ç­‰èµ„æºçš„åˆ›å»ºå’Œç»´æŠ¤ï¼Œå¹¶å¯¹å®ƒä»¬è¿›è¡ŒæŒç»­ç›‘æ§ã€‚ 9.1.1 å®‰è£…Kubernetes Dashboard ä¸‹è½½ 1wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.3.1/aio/deploy/recommended.yaml æ¨¡æ¿æ–‡ä»¶å¦‚ä¸‹ï¼Œå°†æ‹‰å–é•œåƒçš„åœ°å€æ”¹ä¸ºå›½å†…åœ°å€ï¼ŒåŒæ—¶ä¿®æ”¹ SVC æ¨¡å¼ä¸º NodePortï¼Œè¿™æ ·åœ¨é›†ç¾¤ä¹‹å¤–ä¹Ÿå¯ä»¥è®¿é—® Dashboard 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279apiVersion: v1kind: Namespacemetadata: name: kubernetes-dashboard---apiVersion: v1kind: ServiceAccountmetadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard---kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboardspec: type: NodePort ports: - port: 443 targetPort: 8443 selector: k8s-app: kubernetes-dashboard---apiVersion: v1kind: Secretmetadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-certs namespace: kubernetes-dashboardtype: Opaque---apiVersion: v1kind: Secretmetadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-csrf namespace: kubernetes-dashboardtype: Opaquedata: csrf: &quot;&quot;---apiVersion: v1kind: Secretmetadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-key-holder namespace: kubernetes-dashboardtype: Opaque---kind: ConfigMapapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-settings namespace: kubernetes-dashboard---kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboardrules: - apiGroups: [&quot;&quot;] resources: [&quot;secrets&quot;] resourceNames: [&quot;kubernetes-dashboard-key-holder&quot;, &quot;kubernetes-dashboard-certs&quot;, &quot;kubernetes-dashboard-csrf&quot;] verbs: [&quot;get&quot;, &quot;update&quot;, &quot;delete&quot;] - apiGroups: [&quot;&quot;] resources: [&quot;configmaps&quot;] resourceNames: [&quot;kubernetes-dashboard-settings&quot;] verbs: [&quot;get&quot;, &quot;update&quot;] - apiGroups: [&quot;&quot;] resources: [&quot;services&quot;] resourceNames: [&quot;heapster&quot;, &quot;dashboard-metrics-scraper&quot;] verbs: [&quot;proxy&quot;] - apiGroups: [&quot;&quot;] resources: [&quot;services/proxy&quot;] resourceNames: [&quot;heapster&quot;, &quot;http:heapster:&quot;, &quot;https:heapster:&quot;, &quot;dashboard-metrics-scraper&quot;, &quot;http:dashboard-metrics-scraper&quot;] verbs: [&quot;get&quot;]---kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboardrules: - apiGroups: [&quot;metrics.k8s.io&quot;] resources: [&quot;pods&quot;, &quot;nodes&quot;] verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]---apiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboardroleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: kubernetes-dashboardsubjects: - kind: ServiceAccount name: kubernetes-dashboard namespace: kubernetes-dashboard---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: kubernetes-dashboardroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: kubernetes-dashboardsubjects: - kind: ServiceAccount name: kubernetes-dashboard namespace: kubernetes-dashboard---kind: DeploymentapiVersion: apps/v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboardspec: replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: k8s-app: kubernetes-dashboard template: metadata: labels: k8s-app: kubernetes-dashboard spec: containers: - name: kubernetes-dashboard image: registery.cn-hangzhou.aliyuncs.com/google_containers/dashboard:v2.3.1 imagePullPolicy: Always ports: - containerPort: 8443 protocol: TCP args: - --auto-generate-certificates - --namespace=kubernetes-dashboard volumeMounts: - name: kubernetes-dashboard-certs mountPath: /certs - mountPath: /tmp name: tmp-volume livenessProbe: httpGet: scheme: HTTPS path: / port: 8443 initialDelaySeconds: 30 timeoutSeconds: 30 securityContext: allowPrivilegeEscalation: false readOnlyRootFilesystem: true runAsUser: 1001 runAsGroup: 2001 volumes: - name: kubernetes-dashboard-certs secret: secretName: kubernetes-dashboard-certs - name: tmp-volume emptyDir: {} serviceAccountName: kubernetes-dashboard nodeSelector: &quot;kubernetes.io/os&quot;: linux tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule---kind: ServiceapiVersion: v1metadata: labels: k8s-app: dashboard-metrics-scraper name: dashboard-metrics-scraper namespace: kubernetes-dashboardspec: type: NodePort ports: - port: 8000 targetPort: 8000 selector: k8s-app: dashboard-metrics-scraper---kind: DeploymentapiVersion: apps/v1metadata: labels: k8s-app: dashboard-metrics-scraper name: dashboard-metrics-scraper namespace: kubernetes-dashboardspec: replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: k8s-app: dashboard-metrics-scraper template: metadata: labels: k8s-app: dashboard-metrics-scraper annotations: seccomp.security.alpha.kubernetes.io/pod: 'runtime/default' spec: containers: - name: dashboard-metrics-scraper image: registery.cn-hangzhou.aliyuncs.com/google_containers/metrics-scraper:v1.0.6 ports: - containerPort: 8000 protocol: TCP livenessProbe: httpGet: scheme: HTTP path: / port: 8000 initialDelaySeconds: 30 timeoutSeconds: 30 volumeMounts: - mountPath: /tmp name: tmp-volume securityContext: allowPrivilegeEscalation: false readOnlyRootFilesystem: true runAsUser: 1001 runAsGroup: 2001 serviceAccountName: kubernetes-dashboard nodeSelector: &quot;kubernetes.io/os&quot;: linux tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule volumes: - name: tmp-volume emptyDir: {} å®‰è£… 1kubectl apply -f Kubernetes-dashboard.yaml åˆ›å»ºå®Œä¹‹åå¯ä»¥æŸ¥çœ‹å¯¹åº”çš„ SVCï¼Œå°±å¯ä»¥é€šè¿‡æµè§ˆå™¨è®¿é—®äº† RBAC æˆæƒ 12345678910111213141516171819202122# åˆ›å»ºServiceAccountè®¤è¯apiVersion: v1kind: ServiceAccountmetadata: name: dashboard-admin namespace: kubernetes-dashboard---# åˆ›å»ºClusterRoleBindingå°†dashboard-adminä¸é›†ç¾¤è§’è‰²cluster-adminè¿›è¡Œç»‘å®šapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: dashboardadmin-rbacsubjects:- kind: ServiceAccount name: dashboard-admin namespace: kubernetes-dashboardroleRef: apiGroup: &quot;&quot; kind: ClusterRole name: cluster-admin è·å–ä»¤ç‰Œå¹¶å¡«å…¥ 1kubectl describe secret dashboard-admin -n kubernetes-dashboard 9.1.2 Kubernetes Dashboardä½¿ç”¨ åˆ›å»ºä¸€ä¸ªç®€å•çš„ Pod æŸ¥çœ‹ Pod çŠ¶æ€ 9.2 èµ„æºç›‘æ§â€”â€”Prometheuså’ŒGrafana9.2.1 å®‰è£…Prometheus è¿›è¡Œ RBAC æˆæƒ 1kubectl apply -f https://github.com/realdigit/PrometheusAndGrafanaForK8S/blob/master/prometheus.rbac.yml é…ç½® ConfigMap 1kubectl apply -f https://github.com/realdigit/PrometheusAndGrafanaForK8S/blob/master/prometheus.configmap.yml é…ç½® Deployment 1kubectl apply -f https://github.com/realdigit/PrometheusAndGrafanaForK8S/blob/master/prometheus.deployment.yml é…ç½® SVC 1kubectl apply -f https://github.com/realdigit/PrometheusAndGrafanaForK8S/blob/master/prometheus.service.yml 9.2.2 å®‰è£…Grafana é…ç½® Deployment 1kubectl apply -f https://github.com/realdigit/PrometheusAndGrafanaForK8S/blob/master/grafana.deployment.yml é…ç½® SVC 1kubectl apply -f https://github.com/realdigit/PrometheusAndGrafanaForK8S/blob/master/grafana.service.yml 9.2.3 Prometheuså’ŒGrafanaçš„ä½¿ç”¨ æ·»åŠ æ•°æ®æº ä½¿ç”¨æ¨¡æ¿ï¼Œè¿™é‡Œä½¿ç”¨ä»£å·ä¸º 315 çš„ k8s ç›‘æ§æ¨¡æ¿ æ•ˆæœ 9.3 æ—¥å¿—ç®¡ç†â€”â€”ElasticSearchã€Fluentdã€Kibanak8s æ¨èé‡‡ç”¨ ElasticSearchã€Fluentdã€Kibanaï¼ˆç®€ç§°EFKï¼‰ä¸‰è€…ç»„åˆçš„æ–¹å¼ï¼Œå¯¹é›†ç¾¤çš„æ—¥å¿—è¿›è¡Œæ”¶é›†å’ŒæŸ¥è¯¢ï¼Œå…³ç³»å¦‚ä¸‹ï¼š ElasticSearch æ˜¯ä¸€ç§æœç´¢å¼•æ“ï¼Œç”¨äºå­˜å‚¨æ—¥å¿—å¹¶è¿›è¡ŒæŸ¥è¯¢ã€‚ Fluentd ç”¨äºå°†æ—¥å¿—æ¶ˆæ¯ä» k8s å‘é€åˆ° ElasticSearchã€‚ Kibana æ˜¯ä¸€ç§å›¾å½¢ç•Œé¢ï¼Œç”¨äºæŸ¥è¯¢ ElasticSearch ä¸­çš„æ—¥å¿—ã€‚ EFK ä¹‹é—´çš„äº¤äº’å¦‚ä¸‹ï¼š å®¹å™¨è¿è¡Œæ—¶ä¼šå°†æ—¥å¿—è¾“å‡ºåˆ°æ§åˆ¶å°ï¼Œå¹¶ä»¥ â€-json.logâ€œ ç»“å°¾å°†æ—¥å¿—æ–‡ä»¶å­˜æ”¾åˆ° /var/lib/docker/containers ç›®å½•ä¸­ï¼Œè€Œ /var/log æ˜¯ linux ç³»ç»Ÿçš„æ—¥å¿—ã€‚ åœ¨å„ä¸ª Node ä¸Šè¿è¡Œçš„ Fluentd å°†æ˜¯æ”¶é›†è¿™äº›æ—¥å¿—ï¼Œå¹¶å‘é€ç»™ ElasticSearchã€‚ Kibana æ˜¯ç›´æ¥ä¸ç”¨æˆ·äº¤äº’çš„ç•Œé¢ï¼Œå¯ä»¥æŸ¥è¯¢ ElasticSearch ä¸­çš„æ—¥å¿—ã€‚ 9.3.1 å®‰è£…EFK é…ç½®å‘½åç©ºé—´ 1kubectl apply -f https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/fluentd-elasticsearch/create-logging-namespace.yaml é…ç½® Fluentd çš„ ConfigMap 1kubectl apply -f https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/fluentd-elasticsearch/fluentd-es-configmap.yaml å®‰è£… Fluentd 1kubectl apply -f https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/fluentd-elasticsearch/fluentd-es-ds.yaml å®‰è£… ElasticSearch 1kubectl apply -f https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/fluentd-elasticsearch/es-statefulset.yaml é…ç½® ElasticSearch çš„ SVC 1kubectl apply -f https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/fluentd-elasticsearch/es-service.yaml å®‰è£… Kibana 1kubectl apply -f https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/fluentd-elasticsearch/kibana-deployment.yaml é…ç½® Kibana çš„ SVC 1kubectl applt -f https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/fluentd-elasticsearch/kibana-service.yaml è·å– Kibana è®¿é—®åœ°å€ 1kubectl cluster-info | grep Kibana åã€é¡¹ç›®éƒ¨ç½²10.1 æ— çŠ¶æ€é¡¹ç›®éƒ¨ç½²Guestbook æ˜¯ä¸€ä¸ªæ— çŠ¶æ€çš„å¤šå±‚ Web åº”ç”¨ç¨‹åºï¼Œæ˜¯ä¸€ä¸ªç®€å•çš„ç•™è¨€æ¿ç¨‹åºï¼ŒåŒ…å«ä¸€ä¸‹ä¸‰ä¸ªéƒ¨åˆ†ï¼Œå¹¶æ‹¥æœ‰è¯»å†™åˆ†ç¦»æœºåˆ¶ï¼š å‰ç«¯åº”ç”¨ï¼šGuestbook ç•™è¨€æ¿åº”ç”¨ï¼Œå°†éƒ¨ç½²å¤šä¸ªå®ä¾‹ä¾›ç”¨æˆ·è®¿é—®ã€‚ åç«¯å­˜å‚¨ï¼ˆå†™ï¼‰ï¼šRedis ä¸»åº”ç”¨ï¼Œç”¨äºå†™å…¥ç•™è¨€ä¿¡æ¯ï¼Œåªéƒ¨ç½²ä¸€ä¸ªæ¡ˆä¾‹ã€‚ åç«¯å­˜å‚¨ï¼ˆè¯»ï¼‰ï¼šRedis ä»å±åº”ç”¨ï¼Œç”¨åŸŸè¯»å–ç•™è¨€ä¿¡æ¯ï¼Œå°†éƒ¨ç½²å¤šä¸ªæ¡ˆä¾‹ã€‚ éƒ¨ç½² Redis ä¸»å®ä¾‹ 12345678910111213141516171819202122232425262728293031apiVersion: apps/v1kind: Deploymentmetadata: name: redis-master-deployment labels: app: redisspec: selector: matchLabels: app: redis role: master tier: backend replicas: 1 template: metadata: name: redis-master-pod labels: app: redis role: master tier: backend spec: containers: - name: redis-master-container image: daocloud.io/library/redis:latest imagePullPolicy: IfNotPresent resources: requests: cpu: 100m memory: 100Mi ports: - containerPort: 6379 éƒ¨ç½² Redis ä¸»å®ä¾‹ SVC 12345678910111213141516apiVersion: v1kind: Servicemetadata: name: redis-master-service labels: app: redis role: master tier: backendspec: ports: - port: 6379 targetPort: 6379 selector: app: redis role: master tier: backend éƒ¨ç½² Redis ä»å±å®ä¾‹ 12345678910111213141516171819202122232425262728293031323334apiVersion: apps/v1kind: Deploymentmetadata: name: redis-slave-deployment labels: app: redisspec: selector: matchLabels: app: redis role: slave tier: backend replicas: 2 template: metadata: name: redis-slave-pod labels: app: redis role: slave tier: backend spec: containers: - name: redis-slave-container image: daocloud.io/library/redis:latest imagePullPolicy: IfNotPresent resources: requests: cpu: 100m memory: 100Mi env: - name: GET_HOSTS_FROM value: dns ports: - containerPort: 6379 éƒ¨ç½² Redis ä»å±å®ä¾‹ SVC 1234567891011121314apiVersion: v1kind: Servicemetadata: name: redis-slave-service labels: app: redis role: slave tier: backendspec: ports: - port: 6379 targetPort: 6379 selector: app: redis éƒ¨ç½² Guestbook 1234567891011121314151617181920212223242526272829303132apiVersion: apps/v1kind: Deploymentmetadata: name: guestbook-deployment labels: app: guestbookspec: selector: matchLabels: app: guestbook tier: frontend replicas: 3 template: metadata: name: guestbook-pod labels: app: guestbook tier: frontend spec: containers: - name: guestbook-container image: kubeguide/guestbook-php-frontend imagePullPolicy: IfNotPresent resources: requests: cpu: 100m memory: 100Mi env: - name: GET_HOSTS_FROM value: dns ports: - containerPort: 80 éƒ¨ç½² Guestbook çš„ SVC 123456789101112131415apiVersion: v1kind: Servicemetadata: name: guestbook-service labels: app: guestbook tier: frontendspec: type: NodePort selector: app: guestbook tier: frontend ports: - port: 80 nodePort: 30222 10.2 æœ‰çŠ¶æ€é¡¹ç›®éƒ¨ç½²WordPress æ˜¯ä½¿ç”¨ PHP å¼€å‘çš„å¼€æºä¸ªäººåšå®¢å¹³å°ï¼Œæ˜¯ä¸€å¥—éå¸¸å®Œå–„çš„å†…å®¹ç®¡ç†ç³»ç»Ÿï¼Œæ”¯æŒéå¸¸ä¸°å¯Œçš„æ’ä»¶å’Œæ¨¡æ¿ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹ä¸¤ä¸ªéƒ¨åˆ†ï¼š å‰ç«¯åº”ç”¨ï¼šWordPressã€‚ åç«¯åº”ç”¨ï¼šMySQL æ•°æ®åº“ï¼Œä½¿ç”¨ PVC æ¥å­˜å‚¨åšå®¢çš„æ•°æ®ã€‚ é¦–å…ˆç”Ÿæˆä¸€ä¸ªæ•°æ®åº“å¯†ç  1echo -n 'toortoor' | base64 åˆ›å»ºä¸€ä¸ª Secret å­˜æ”¾å¯†ç  1234567apiVersion: v1kind: Secretmetadata: name: mysql-secrettype: Qpaquedata: mysql_password: dG9vcnRvb3I= éƒ¨ç½² nfs-clientï¼Œå®ç°è‡ªåŠ¨åˆ†é… PV ç»™ PVCï¼Œæ­¥éª¤å‚ç…§ 6.3.2 éƒ¨ç½² MySQL 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172apiVersion: v1kind: Servicemetadata: name: mysql-service labels: app: wordpressspec: selector: app: wordpress tier: mysql ports: - port: 3306 clusterIP: None---apiVersion: v1kind: PersistentVolumeClaimmetadata: name: mysql-pvc labels: app: wordpressspec: accessModes: - ReadWriteOnce storageClassName: nfs-storageclass resources: requests: storage: 2Gi---apiVersion: apps/v1kind: Deploymentmetadata: name: mysql-deployment labels: app: wordpressspec: replicas: 1 selector: matchLabels: app: wordpress tier: mysql strategy: type: Recreate template: metadata: name: mysql-pod labels: app: wordpress tier: mysql spec: containers: - name: mysql-container image: daocloud.io/library/mysql:5.7 imagePullPolicy: IfNotPresent ports: - containerPort: 3306 env: - name: MYSQL_ROOT_PASSWORD valueFrom: secretKeyRef: name: mysql-secret key: mysql_password volumeMounts: - name: mysql-datadir mountPath: /var/lib/mysql volumes: - name: mysql-datadir persistentVolumeClaim: claimName: mysql-pvc éƒ¨ç½² WordPress 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778apiVersion: v1kind: Servicemetadata: name: wordpress-service labels: app: wordpressspec: ports: - port: 80 nodePort: 30111 selector: app: wordpress tier: frontend type: NodePort---apiVersion: v1kind: PersistentVolumeClaimmetadata: name: wordpress-pvc labels: app: wordpressspec: storageClassName: nfs-storageclass accessModes: - ReadWriteOnce resources: requests: storage: 2Gi---apiVersion: apps/v1kind: Deploymentmetadata: name: wordpress-deployment labels: app: wordpress tier: frontendspec: selector: matchLabels: app: wordpress tier: frontend strategy: type: Recreate template: metadata: name: wordpress-pod labels: app: wordpress tier: frontend spec: containers: - name: wordpress-container image: daocloud.io/daocloud/dao-wordpress:latest imagePullPolicy: IfNotPresent ports: - containerPort: 80 name: wordpress # è¿™é‡Œç”¨åˆ°äº†MySQLçš„å˜é‡å‚æ•° env: # Mysqlçš„SVCåç§° - name: WORDPRESS_DB_HOST value: mysql-service - name: WORDPRESS_DB_PASSWORD valueFrom: secretKeyRef: name: mysql-secret key: mysql_password volumeMounts: - name: wordpress-datadir mountPath: /var/www/html volumes: - name: wordpress-datadir persistentVolumeClaim: claimName: wordpress-pvc éƒ¨ç½² Ingressï¼Œé€šè¿‡ www.cqm.com:30111 å°±èƒ½è®¿é—® WordPress 123456789101112131415161718apiVersion: networking.k8s.io/v1kind: Ingressmetadata: name: wordpress-ingress-nginx labels: app: wordpressspec: rules: - host: www.cqm.com http: paths: - path: /var/www/html pathType: ImplementationSpecific backend: service: name: wordpress-service port: number: 30111 æµ‹è¯• 10.3 ä½¿ç”¨Helméƒ¨ç½²é¡¹ç›®Helm æ˜¯ k8s çš„ä¸€ä¸ªå­é¡¹ç›®ï¼Œæ˜¯ä¸€ç§ k8s åŒ…ç®¡ç†å¹³å°ï¼Œå®ƒèƒ½å¤Ÿå®šä¹‰ã€éƒ¨ç½²ã€å‡çº§éå¸¸å¤æ‚çš„ k8s åº”ç”¨é›†åˆï¼Œå¹¶è¿›è¡Œç‰ˆæœ¬ç®¡ç†ã€‚ Helm å®¢æˆ·ç«¯ï¼šæ˜¯ä¸€ç§è¿œç¨‹å‘½ä»¤å®¢æˆ·ç«¯å·¥å…·ï¼Œä¸»è¦ç”¨äº Chart æ–‡ä»¶çš„åˆ›å»ºã€æ‰“åŒ…å’Œå‘å¸ƒéƒ¨ç½²ï¼Œä»¥åŠå’Œ Chart ä»“åº“çš„ç®¡ç†ã€‚Helm å‘å‡ºçš„è¯·æ±‚ï¼Œæ ¹æ® Chart ç»“æ„ç”Ÿæˆå‘å¸ƒå¯¹è±¡ï¼Œå¹¶å°† Chart è§£ææˆå„ä¸ª k8s èµ„æºçš„å®é™…éƒ¨ç½²æ–‡ä»¶ï¼Œä¾› k8s åˆ›å»ºç›¸åº”èµ„æºï¼ŒåŒæ—¶è¿˜æä¾›å‘å¸ƒå¯¹è±¡çš„æ›´æ–°ã€å›æ»šã€ç»Ÿä¸€åˆ é™¤ç­‰åŠŸèƒ½ã€‚ Chartï¼šæ˜¯åº”ç”¨ç¨‹åºçš„éƒ¨ç½²å®šä¹‰ï¼ŒåŒ…å«å„ç§ yaml æ–‡ä»¶ï¼Œå¯ä»¥é‡‡ç”¨ TAR æ ¼å¼æ‰“åŒ…ã€‚ Chart ä»“åº“ï¼šHelm ä¸­å­˜æ”¾äº†å„ç§åº”ç”¨ç¨‹åºçš„ Chart åŒ…ä»¥ä¾›ç”¨æˆ·ä¸‹è½½ï¼ŒHelm å¯ä»¥åŒæ—¶ç®¡ç†å¤šä¸ª Chart ä»“åº“ï¼Œé»˜è®¤æƒ…å†µä¸‹ç®¡ç†ä¸€ä¸ªæœ¬åœ°ä»“åº“å’Œä¸€ä¸ªè¿œç¨‹ä»“åº“ã€‚ å‘å¸ƒå¯¹è±¡ï¼šåœ¨ k8s é›†ç¾¤ä¸­éƒ¨ç½²çš„ Chart ç§°ä¸ºå‘å¸ƒå¯¹è±¡ï¼ŒChart å’Œå‘å¸ƒå¯¹è±¡çš„å…³ç³»ç±»ä¼¼äºé•œåƒå’Œå®¹å™¨ï¼Œå‰è€…æ˜¯éƒ¨ç½²çš„å®šä¹‰ï¼Œåè€…æ˜¯å®é™…éƒ¨ç½²å¥½çš„åº”ç”¨ç¨‹åºã€‚ 10.3.1 Helmå®‰è£… å®‰è£… 123wget https://get.helm.sh/helm-v3.6.2-linux-amd64.tar.gztar -xf helm-v3.6.2-linux-amd64.tar.gzcp linux-amd64/helm /usr/local/bin/ è®¾ç½®ç¯å¢ƒå˜é‡ KUBECONFIG æ¥æŒ‡å®šå­˜æœ‰ ApiServre çš„åœ°å€ä¸ token çš„é…ç½®æ–‡ä»¶åœ°å€ï¼Œé»˜è®¤ä¸º~/.kube/config 1export KUBECONFIG=/root/.kube/config é…ç½® Helm ä»“åº“ 12helm repo add stable https://kubernetes.oss-cn-hangzhou.aliyuncs.com/chartshelm repo add incubator https://aliacs-app-catalog.oss-cn-hangzhou.aliyuncs.com/charts-incubator/ 10.3.2 Helm Chartçš„åŸºæœ¬æ“ä½œChart çš„åˆ›å»º åˆ›å»º Chart 1helm create chartåç§° æ‰§è¡Œåä¼šåœ¨å½“å‰ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªæ–‡ä»¶ï¼Œå¯ç”¨ tree å‘½ä»¤æŸ¥çœ‹è¯¥ç›®å½•ç»“æ„ charsï¼šå­˜æ”¾è¯¥ Chart ä»¥æ¥çš„æ‰€æœ‰å­ Chart çš„ç›®å½•ï¼Œè¿™äº›å­ Chart ä¹Ÿæ‹¥æœ‰è¿™ 4 ä¸ªéƒ¨åˆ†ï¼Œå¦‚æœæœ‰å­ Chart ï¼Œåˆ™éœ€è¦åœ¨çˆ¶ Chart åˆ›å»ºä¸€ä¸ª requirements.yaml æ–‡ä»¶ï¼Œåœ¨æ–‡ä»¶ä¸­è®°å½•è¿™äº›å­ Chartã€‚ Chart.yamlï¼šè®°å½•è¯¥ Chart çš„ç›¸å…³ä¿¡æ¯ï¼Œå¹¶å®šä¹‰åœ¨æ–‡ä»¶ä¸­çš„ .Chart å¼€å¤´çš„å±æ€§å€¼ã€‚ templateï¼šå­˜æ”¾äº† k8s éƒ¨ç½²æ–‡ä»¶çš„ Helm æ¨¡æ¿ï¼Œå…¶ä¸­æ‰©å±•äº† Go Template è¯­æ³•ã€‚ values.yamlï¼šå®šä¹‰åœ¨æ–‡ä»¶ä¸­çš„ .Values å¼€å¤´çš„å±æ€§å€¼ã€‚ _helpers.tplï¼šå®ƒæ˜¯ä¸€ä¸ªiæ¨¡æ¿åŠ©æ‰‹æ–‡ä»¶ï¼Œç”¨äºå®šä¹‰é€šç”¨ä¿¡æ¯ï¼Œç„¶ååœ¨å…¶ä»–åœ°æ–¹ä½¿ç”¨ã€‚ NOTES.txtï¼šä¼šåœ¨ Chart éƒ¨ç½²å‘½ä»¤åï¼Œä»£å…¥å…·ä½“çš„å‚æ•°å€¼ï¼Œäº§ç”Ÿè¯´æ˜ä¿¡æ¯ã€‚ test-connection.yamlï¼šç”¨äºå®šä¹‰éƒ¨ç½²å®Œæˆåéœ€è¦æ‰§è¡Œçš„æµ‹è¯•å†…å®¹ï¼Œä»¥ä¾¿æµ‹è¯•æ˜¯å¦éƒ¨ç½²æˆåŠŸã€‚ Chart çš„éªŒè¯ åœ¨å‘å¸ƒ Chart ä¹‹å‰ï¼Œå¯ä»¥é€šè¿‡å‘½ä»¤æ£€æŸ¥ Chart æ–‡ä»¶æ˜¯å¦æœ‰è¯¯ï¼Œå¦‚ä¸‹ 1helm lint chartç›®å½•/ åŒæ—¶ä¹Ÿå¯ä»¥ç”¨å‘½ä»¤å°†å„é¡¹å€¼ç»„åˆä¸º k8s çš„ yaml æ–‡ä»¶ï¼ŒæŸ¥çœ‹æ˜¯å¦ä¸ºé¢„æœŸå†…å®¹ï¼Œæ¯”å¦‚ä¸‹å›¾å°±æ˜¯å…¶ä¸­ Deployment çš„å†…å®¹ 1helm install --dry-run --debug å‘å¸ƒåç§° -name chartç›®å½•åç§° Chart çš„å‘å¸ƒ Chart çš„å‘å¸ƒå‘½ä»¤å¦‚ä¸‹ 1helm install å‘å¸ƒç‰ˆæœ¬åç§° chartæ–‡ä»¶ç›®å½• æŸ¥çœ‹ç›®å‰å‘å¸ƒçš„ç‰ˆæœ¬ 1helm list å°† Chart æ‰“åŒ…åˆ°ä»“åº“ä¸­ æŸ¥çœ‹ä»“åº“å‘½ä»¤ 1helm repo list æŸ¥çœ‹ä»“åº“ä¸­çš„åŒ… 123helm search repo/hub# ä¹Ÿå¯ä»¥åœ¨åé¢åŠ ä¸Šåº”ç”¨åï¼Œå¦‚helm search repo/hub nginx é¦–å…ˆæ‰“åŒ… 1helm package chartç›®å½• å®‰è£… Push æ’ä»¶ 1helm plugin install https://github.com/chartmuseum/helm-push.git ä¸Šä¼  1helm push taråŒ…å ä»“åº“ å‘å¸ƒç‰ˆæœ¬çš„æ›´æ–°ã€å›æ»šå’Œåˆ é™¤ æ›´æ–° 1helm upgrade å‘å¸ƒç‰ˆæœ¬åç§° chartç›®å½•æˆ–tar flags æŸ¥çœ‹å†å²ç‰ˆæœ¬ 1helm history å‘å¸ƒç‰ˆæœ¬åç§° å›æ»š 1helm rollback å‘å¸ƒç‰ˆæœ¬åç§° ç‰ˆæœ¬å· åˆ é™¤ 1helm delete å‘å¸ƒç‰ˆæœ¬åç§°","link":"/2024/02/18/kubernetes/"},{"title":"SUSE ç¬¬ä¸€å‘¨äº§å“éƒ¨ç½²ä½¿ç”¨éšè®°","text":"å®‰è£…å•ç‚¹çš„ RKE2è¯¥ RKE2 ä½œä¸º localï¼Œç”¨äºéƒ¨ç½² rancher 1234567891011121314151617181920212223242526272829303132333435363738394041# é…ç½®ç›®å½•å’Œæ–‡ä»¶å‡†å¤‡mkdir -pv /etc/rancher/rke2cat &gt; /etc/rancher/rke2/config.yaml &lt;&lt;EOFtoken: my-shared-secrettls-san: - 172.16.170.200system-default-registry: registry.cn-hangzhou.aliyuncs.comdebug: trueEOF# å®‰è£… rke2-server ç­‰äºŒè¿›åˆ¶curl -sfL https://rancher-mirror.rancher.cn/rke2/install.sh | INSTALL_RKE2_MIRROR=cn sh -# å¯åŠ¨ç¬¬ä¸€å° server èŠ‚ç‚¹systemctl enable rke2-server --now# æ–¹ä¾¿åç»­è¿ç»´çš„é…ç½®mkdir -pv ~/.kubeln -s /etc/rancher/rke2/rke2.yaml ~/.kube/configecho &quot;export CONTAINER_RUNTIME_ENDPOINT=\\&quot;unix:///run/k3s/containerd/containerd.sock\\&quot;&quot; &gt;&gt; ~/.bashrcecho &quot;export CONTAINERD_ADDRESS=\\&quot;/run/k3s/containerd/containerd.sock\\&quot;&quot; &gt;&gt; ~/.bashrcecho &quot;export CONTAINERD_NAMESPACE=\\&quot;k8s.io\\&quot;&quot; &gt;&gt; ~/.bashrcecho &quot;export PATH=$PATH:/var/lib/rancher/rke2/bin&quot; &gt;&gt; ~/.bashrcecho &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrccurl https://rancher-mirror.rancher.cn/helm/get-helm-3.sh | INSTALL_HELM_MIRROR=cn bash -s -- --version v3.17.1echo &quot;source &lt;(helm completion bash)&quot; &gt;&gt; ~/.bashrcexport NERDCTL_VERSION=1.7.6wget &quot;https://files.m.daocloud.io/github.com/containerd/nerdctl/releases/download/v$NERDCTL_VERSION/nerdctl-$NERDCTL_VERSION-linux-amd64.tar.gz&quot;tar Czvxf /usr/local/bin nerdctl-$NERDCTL_VERSION-linux-amd64.tar.gz &amp;&amp; rm -rf nerdctl-$NERDCTL_VERSION-linux-amd64.tar.gz å®‰è£… Rancher123456789101112131415161718192021222324# é€šè¿‡ helm chart æ–¹å¼å®‰è£…helm repo add rancher-stable https://releases.rancher.com/server-charts/stable# å®‰è£… cert-managerhelm repo add jetstack https://charts.jetstack.iohelm repo updatehelm install \\ cert-manager jetstack/cert-manager \\ --namespace cert-manager \\ --create-namespace \\ --version v1.15.3 \\ --set installCRDs=true# å®‰è£… rancherhelm install rancher rancher-stable/rancher \\ --namespace cattle-system \\ --create-namespace \\ --set hostname=xxx.com \\ --set replicas=1 \\ --set bootstrapPassword=xxx \\ --set rancherImage=registry.cn-hangzhou.aliyuncs.com/rancher/rancher \\ --set systemDefaultRegistry=registry.cn-hangzhou.aliyuncs.com RKE2 é»˜è®¤ä¼šå®‰è£… Nginx Ingress Controllerï¼Œç›‘å¬èŠ‚ç‚¹çš„ 80/443 ç«¯å£ï¼Œè€Œå®‰è£… Rancher çš„æ—¶å€™è®¾ç½®å¥½ hostname çš„è¯ä¼šåˆ›å»ºä¸€ä¸ª Ingressï¼Œæ‰€ä»¥å¯ä»¥é€šè¿‡è¯¥ Ingress è¿›è¡Œè®¿é—® åˆ›å»ºé›†ç¾¤åœ¨ UI åˆ›å»ºé›†ç¾¤åï¼Œä¼šæä¾›æ³¨å†Œå‘½ä»¤ï¼Œåœ¨èŠ‚ç‚¹ä¸Šæ‰§è¡Œè¯¥å‘½ä»¤è¿›è¡Œæ³¨å†Œ 1234567891011121314151617181920212223root@rke2-test-controller-0:~# curl --insecure -fL https://xxx.com/system-agent-install.sh | sudo sh -s - --server https://xxx.com --label 'cattle.io/os=linux' --token xxx --ca-checksum xxx --etcd --controlplane --worker --node-name rke2-test-controller-0[INFO] Label: cattle.io/os=linux[INFO] Role requested: etcd[INFO] Role requested: controlplane[INFO] Role requested: worker[INFO] Using default agent configuration directory /etc/rancher/agent[INFO] Using default agent var directory /var/lib/rancher/agent[INFO] Determined CA is necessary to connect to Rancher[INFO] Successfully downloaded CA certificate[INFO] Value from https://xxx.com/cacerts is an x509 certificate[INFO] Successfully tested Rancher connection[INFO] Downloading rancher-system-agent binary from https://xxx.com/assets/rancher-system-agent-amd64[INFO] Successfully downloaded the rancher-system-agent binary.[INFO] Downloading rancher-system-agent-uninstall.sh script from https://xxx.com/assets/system-agent-uninstall.sh[INFO] Successfully downloaded the rancher-system-agent-uninstall.sh script.[INFO] Generating Cattle ID[INFO] Successfully downloaded Rancher connection information[INFO] systemd: Creating service file[INFO] Creating environment file /etc/systemd/system/rancher-system-agent.env[INFO] Enabling rancher-system-agent.serviceCreated symlink /etc/systemd/system/multi-user.target.wants/rancher-system-agent.service â†’ /etc/systemd/system/rancher-system-agent.service.[INFO] Starting/restarting rancher-system-agent.serviceroot@rke2-test-controller-0:~# æ³¨å†Œåå‘ç° cattle-cluster-agent ä¸€ç›´åœ¨å´©æºƒé‡å¯ 123456root@rke2-test-controller-0:~# kubectl -n cattle-system get podNAME READY STATUS RESTARTS AGEcattle-cluster-agent-767b67b66f-bcl2s 0/1 CrashLoopBackOff 5 (79s ago) 10mroot@rke2-test-controller-0:~# kubectl -n cattle-system logs cattle-cluster-agent-767b67b66f-bcl2s -p...ERROR: https://xxx.com/ping is not accessible (Could not resolve host: xxx.com) è¿™æ˜¯ç”±äºè¯¥åŸŸåæ²¡æœ‰ DNS å»åšè§£æï¼Œå¯ä»¥é€šè¿‡ CoreDNS å®ç°æš‚æ—¶çš„æ˜ å°„ï¼Œç„¶åé‡å¯å³å¯ 12345678910111213141516171819202122.:53 { errors health { lameduck 5s } ready kubernetes cluster.local cluster.local in-addr.arpa ip6.arpa { pods insecure fallthrough in-addr.arpa ip6.arpa ttl 30 } prometheus 0.0.0.0:9153 forward . /etc/resolv.conf cache 30 loop reload loadbalance hosts { 172.16.170.200 xxx.com fallthrough }} é›†ç¾¤ Ready Monitoringé€šè¿‡ UI é€‰æ‹© monitoring helm chart å³å¯å®Œæˆå®‰è£…ï¼Œä¼šæœ‰ä¸€äº›åŸºæœ¬çš„ç»„ä»¶ï¼ˆe.g. prometheus/alertmanagerâ€¦ï¼‰ WebHook é…ç½®å‘Šè­¦å¯ä»¥å¯¹æ¥å¤šç§å½¢å¼ï¼ŒWebHook åˆ™æ˜¯é€šè¿‡ AlertmanagerConfig çš„ CR å®Œæˆé…ç½® 123456789101112131415161718192021cat &lt;&lt;EOF | kubectl apply -f -apiVersion: monitoring.coreos.com/v1alpha1kind: AlertmanagerConfigmetadata: name: test-webhook namespace: defaultspec: receivers: - name: test-webhook webhookConfigs: - httpConfig: tlsConfig: {} sendResolved: false url: https://webhook.site/xxx route: groupBy: [] groupInterval: 5m groupWait: 30s matchers: [] repeatInterval: 4hEOF Loggingé€šè¿‡ UI é€‰æ‹© logging helm chart å³å¯å®Œæˆå®‰è£…ï¼Œä¸»è¦æ˜¯ä½¿ç”¨äº† Logging Operator é…ç½®æ—¥å¿—æµæ°´çº¿ Logging Operator ä¼šéƒ¨ç½²ä¸€ä¸ª FluentBit DaemonSet ç”¨äºæ”¶é›†æ—¥å¿—ï¼Œç„¶åå°†æ•°æ®ä¼ è¾“åˆ° Fluentdï¼Œå†ç”± Fluentd ä¼ åˆ°ä¸åŒçš„ output ä¸»è¦çš„ CR æœ‰: Flow: æ˜¯ä¸€ä¸ªå‘½åç©ºé—´è‡ªå®šä¹‰èµ„æºï¼Œå®ƒä½¿ç”¨è¿‡æ»¤å™¨å’Œé€‰æ‹©å™¨å°†æ—¥å¿—æ¶ˆæ¯è·¯ç”±åˆ°å¯¹åº”çš„ Output æˆ–è€… ClusterOutput ClusterFlow: ç”¨äºè·¯ç”±é›†ç¾¤çº§åˆ«çš„æ—¥å¿—æ¶ˆæ¯ Output: ç”¨äºè·¯ç”±å‘½åç©ºé—´çº§åˆ«çš„æ—¥å¿—æ¶ˆæ¯ ClusterOutput: Flow å’Œ ClusterFlow éƒ½å¯ä¸å…¶å¯¹æ¥ éƒ¨ç½² ES å’Œ KibanaåŸºäº ECK Operator çš„èƒ½åŠ›ï¼Œéƒ¨ç½² ES å’Œ Kibanaï¼Œåç»­å¯é€šè¿‡é…ç½® OutPut è¾“å‡ºåˆ° ES ä¸­ 123# Install ECK Operatorkubectl create -f https://download.elastic.co/downloads/eck/2.14.0/crds.yamlkubectl apply -f https://download.elastic.co/downloads/eck/2.14.0/operator.yaml å®‰è£… ES å’Œ Kibanaï¼Œå­˜å‚¨æš‚æ—¶ç”¨æœ¬åœ°å­˜å‚¨å§ - - 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849cat &lt;&lt;EOF | kubectl apply -f -apiVersion: elasticsearch.k8s.elastic.co/v1kind: Elasticsearchmetadata: name: logging namespace: cattle-logging-systemspec: version: 7.15.2 nodeSets: - name: logging count: 1 config: node.store.allow_mmap: falseEOFcat &lt;&lt;EOF | kubectl apply -f -apiVersion: kibana.k8s.elastic.co/v1kind: Kibanametadata: name: logging namespace: cattle-logging-systemspec: version: 7.15.2 count: 1 elasticsearchRef: name: loggingEOFcat &lt;&lt;EOF | kubectl apply -f -apiVersion: networking.k8s.io/v1kind: Ingressmetadata: annotations: nginx.ingress.kubernetes.io/backend-protocol: HTTPS name: logging-kb namespace: cattle-logging-systemspec: ingressClassName: nginx rules: - host: kibana.warnerchen.io http: paths: - backend: service: name: logging-kb-http port: number: 5601 path: / pathType: Prefix åˆ›å»º Flow å’Œ Outputéœ€è¦å…ˆåˆ›å»º Output 1234567891011121314151617181920212223242526272829303132cat &lt;&lt;EOF | kubectl apply -f -apiVersion: v1data: elastic: xxxkind: Secretmetadata: name: logging-es-elastic-user namespace: defaulttype: Opaque---apiVersion: logging.banzaicloud.io/v1beta1kind: Outputmetadata: name: output-to-es namespace: defaultspec: elasticsearch: host: logging-es-http.cattle-logging-system.svc.cluster.local index_name: ns-default password: valueFrom: secretKeyRef: key: elastic name: logging-es-elastic-user port: 9200 scheme: https ssl_verify: false ssl_version: TLSv1_2 suppress_type_name: false user: elasticEOF åˆ›å»º Flowï¼Œæ”¶é›†æ ‡ç­¾ä¸º app=nginx çš„ Pod æ—¥å¿— 1234567891011121314cat &lt;&lt;EOF | kubectl apply -f -apiVersion: logging.banzaicloud.io/v1beta1kind: Flowmetadata: name: flow-for-default namespace: defaultspec: localOutputRefs: - output-to-es match: - select: labels: app: nginxEOF æŸ¥çœ‹æ˜¯å¦æœ‰å¯¹åº”çš„ç´¢å¼• åˆ›å»º Pattern æŸ¥çœ‹æ—¥å¿— NeuVectoré€šè¿‡ UI é€‰æ‹© NeuVector helm chart å³å¯å®Œæˆå®‰è£… LongHornå®‰è£… LongHorn ä¹‹å‰ï¼Œéœ€è¦åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šå®‰è£…ä¾èµ– 123apt updateapt -y install open-iscsi nfs-commonsystemctl enable iscsid --now ç„¶åé€šè¿‡ UI å®‰è£… LongHorn æ•°æ®å·çš„å¿«ç…§å’Œæ¢å¤LongHorn æ”¯æŒ SnapShotï¼Œå¯ä»¥ç›´æ¥åˆ›å»ºå¿«ç…§å’Œæ¢å¤ åœ¨ UI ä¸­ï¼Œåˆ›å»ºä¸€ä¸ªå¿«ç…§ ç„¶ååˆ é™¤æ•°æ®æ–‡ä»¶ 1kubectl exec -it nginx-7f6d5dcf8c-tvxcw -- rm -rf /data/test.txt åœæ­¢æœåŠ¡ 1kubectl scale deployment nginx --replicas=0 é€šè¿‡ç»´æŠ¤æ¨¡å¼é‡æ–° Attach æŒ‚è½½åè¿›å…¥è¯¥ Volumeï¼Œç„¶åé€‰æ‹©å¿«ç…§è¿›è¡Œæ¢å¤ æ¢å¤åï¼ŒDetach è¯¥ Volumeï¼Œå¯åŠ¨æœåŠ¡åï¼Œå³å¯çœ‹åˆ°æ•°æ®çš„æ¢å¤ æ•°æ®å·çš„å¤‡ä»½å’Œç¾éš¾æ¢å¤æµ‹è¯•é€šè¿‡ LongHorn èƒ½åŠ›å®ç°è·¨é›†ç¾¤çš„æ•°æ®å¤‡ä»½å’Œæ¢å¤ï¼Œå¯å¤‡ä»½è‡³é›†ç¾¤å¤–çš„ S3 or NFS MinIO éƒ¨ç½²ï¼Œä½¿ç”¨äº† operator çš„èƒ½åŠ› 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116cat &lt;&lt;EOF | kubectl apply -f -apiVersion: v1data: accesskey: bWluaW8= secretkey: VGpCcFkwVTNZVGcyU3c9PQ==kind: Secretmetadata: name: backup-minio-secret namespace: defaulttype: Opaque---apiVersion: v1data: config.env: ZXhwb3J0IE1JTklPX0JST1dTRVI9Im9uIgpleHBvcnQgTUlOSU9fUk9PVF9VU0VSPSJtaW5pbyIKZXhwb3J0IE1JTklPX1JPT1RfUEFTU1dPUkQ9IlRqQnBZMFUzWVRnMlN3PT0iCg==kind: Secretmetadata: name: backup-minio-env-configuration namespace: defaulttype: Opaque---apiVersion: minio.min.io/v2kind: Tenantmetadata: name: backup-minio namespace: defaultspec: buckets: - name: longhorn configuration: name: backup-minio-env-configuration # credsSecret: # name: backup-minio-secret env: - name: MINIO_PROMETHEUS_AUTH_TYPE value: public - name: MINIO_SERVER_URL value: http://minio-hl.warnerchen.io image: quay.m.daocloud.io/minio/minio:RELEASE.2023-10-07T15-07-38Z initContainers: - command: - sh - -c - chown -R 1000:1000 /export/* || true image: quay.m.daocloud.io/minio/minio:RELEASE.2023-10-07T15-07-38Z name: change-permission securityContext: capabilities: add: - CHOWN volumeMounts: - mountPath: /export name: &quot;0&quot; pools: - name: pool-0 resources: limits: cpu: 500m memory: 500Mi requests: cpu: 50m memory: 100Mi servers: 1 volumeClaimTemplate: metadata: {} spec: accessModes: - ReadWriteOnce resources: requests: storage: 10Gi volumesPerServer: 1 requestAutoCert: false serviceMetadata: minioServiceLabels: mcamel/exporter-type: minio---apiVersion: networking.k8s.io/v1kind: Ingressmetadata: name: minio namespace: defaultspec: rules: - host: minio.warnerchen.io http: paths: - backend: service: name: minio port: number: 443 path: / pathType: Prefix---apiVersion: networking.k8s.io/v1kind: Ingressmetadata: name: minio-hl namespace: defaultspec: rules: - host: minio-hl.warnerchen.io http: paths: - backend: service: name: backup-minio-hl port: number: 9000 path: / pathType: PrefixEOF å‡†å¤‡ä¸€ä¸ª Bucket åœ¨ä¸¤ä¸ªé›†ç¾¤çš„ longhorn-system ä¸‹åˆ›å»º Secretï¼Œä¸»è¦æœ‰è¿™å‡ ä¸ªå†…å®¹ AWS_ACCESS_KEY_ID: Access Key AWS_SECRET_ACCESS_KEY: Secret Key AWS_ENDPOINTS: S3 URL AWS_CERT: å¦‚æœä½¿ç”¨äº†è‡ªç­¾è¯ä¹¦åˆ™éœ€è¦é…ç½® åˆ›å»ºå¥½ Secret åï¼Œéœ€è¦åœ¨ LongHorn UI é…ç½® Backup Target åœ¨ä»»æ„é›†ç¾¤åšæ“ä½œï¼Œåˆ›å»ºä¸€ä¸ª PVC 1234567891011121314cat &lt;&lt;EOF | kubectl apply -f -apiVersion: v1kind: PersistentVolumeClaimmetadata: name: nginx-pvc namespace: defaultspec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi storageClassName: longhornEOF ç»™ Nginx æŒ‚è½½åï¼Œéšæ„å†™å…¥ä¸€äº›æ•°æ® åœ¨è¯¥é›†ç¾¤çš„ LongHorn åˆ›å»ºä¸€ä¸ªå¤‡ä»½ åœ¨ MinIO å°±å¯ä»¥çœ‹åˆ°è¿™ä¸ªå¤‡ä»½ è‡³æ­¤ï¼Œä¸¤ä¸ªé›†ç¾¤çš„ LongHorn éƒ½æ˜¯å¯ä»¥çœ‹åˆ°è¿™ä¸ªå¤‡ä»½çš„ï¼Œè¿™æ˜¯å› ä¸ºä½¿ç”¨äº†åŒä¸€ä¸ª Backup Target åœ¨å¦ä¸€ä¸ªé›†ç¾¤ï¼Œé€šè¿‡æ­¤å¤‡ä»½åˆ›å»ºä¸€ä¸ª Volume åˆ›å»ºå¥½åå³å¯çœ‹åˆ°è¯¥ Volumeï¼Œæ­¤æ—¶å¦‚æœæœ‰æ›´å¤šæ•°æ®å†™å…¥ Nginxï¼ŒVolume ä¹Ÿä¼šè‡ªåŠ¨è¿›è¡ŒåŒæ­¥ å½“ä¸€ä¾§é›†ç¾¤å®•æœºï¼Œæˆ–è€…æœåŠ¡ä¸å¯ç”¨æ—¶ï¼Œå¯ä»¥ä½¿ç”¨è¯¥ Volume è¿›è¡Œæ¢å¤ é¦–å…ˆéœ€è¦æ¿€æ´»è¿™ä¸ª Volume æ¿€æ´»åä½¿ç”¨è¿™ä¸ª Volume åˆ›å»º PV/PVC åœ¨é›†ç¾¤ä¸­å°±å¯ä»¥çœ‹åˆ°ï¼Œç„¶åé€šè¿‡è¿™ä¸ª PV/PVC é‡æ–°åˆ›å»º Nginxï¼Œå¯ä»¥çœ‹åˆ°åŸæœ¬çš„æ•°æ® Istioåœ¨ UI ä¸­å¯ä»¥ç›´æ¥é€‰æ‹© Istio è¿›è¡Œå®‰è£… éƒ¨ç½²ä¸¤ä¸ªç‰ˆæœ¬çš„ Nginx 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104cat &lt;&lt;EOF | kubectl apply -f -apiVersion: v1data: index.html.v1: | &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;title&gt;Welcome to nginx V1!&lt;/title&gt; &lt;/html&gt; index.html.v2: | &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;title&gt;Welcome to nginx V2!&lt;/title&gt; &lt;/html&gt;kind: ConfigMapmetadata: name: nginx-conf namespace: default---apiVersion: v1kind: Servicemetadata: name: nginx namespace: defaultspec: ports: - name: port-80 port: 80 protocol: TCP targetPort: 80 selector: app: nginx type: ClusterIP---apiVersion: apps/v1kind: Deploymentmetadata: labels: app: nginx version: v1 name: nginx-v1 namespace: defaultspec: selector: matchLabels: app: nginx version: v1 template: metadata: labels: app: nginx version: v1 sidecar.istio.io/inject: 'true' spec: containers: - image: docker.io/library/nginx:mainline imagePullPolicy: IfNotPresent name: nginx-v1 volumeMounts: - mountPath: /usr/share/nginx/html/index.html name: nginx-conf subPath: index.html.v1 volumes: - configMap: defaultMode: 420 name: nginx-conf name: nginx-conf---apiVersion: apps/v1kind: Deploymentmetadata: labels: app: nginx version: v2 name: nginx-v2 namespace: defaultspec: selector: matchLabels: app: nginx version: v2 template: metadata: labels: app: nginx version: v2 sidecar.istio.io/inject: 'true' spec: containers: - image: docker.io/library/nginx:mainline imagePullPolicy: IfNotPresent name: nginx-v2 volumeMounts: - mountPath: /usr/share/nginx/html/index.html name: nginx-conf subPath: index.html.v2 volumes: - configMap: defaultMode: 420 name: nginx-conf name: nginx-confEOF åˆ›å»º Istio Gateway 12345678910111213141516cat &lt;&lt;EOF | kubectl apply -f -apiVersion: networking.istio.io/v1alpha3kind: Gatewaymetadata: name: nginx-gatewayspec: selector: istio: ingressgateway servers: - port: number: 80 name: http protocol: HTTP hosts: - &quot;*&quot;EOF åˆ›å»º Destination Rule 123456789101112131415cat &lt;&lt;EOF | kubectl apply -f -apiVersion: networking.istio.io/v1alpha3kind: DestinationRulemetadata: name: nginxspec: host: nginx subsets: - name: v1 labels: version: v1 - name: v2 labels: version: v2EOF åˆ›å»º Virtual Serviceï¼Œå…ˆå°†æµé‡å…¨éƒ¨è½¬å‘åˆ° Nginx V1 12345678910111213141516171819202122cat &lt;&lt;EOF | kubectl apply -f -apiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata: name: nginxspec: hosts: - &quot;*&quot; gateways: - nginx-gateway http: - match: - uri: prefix: / route: - destination: host: nginx port: number: 80 subset: v1 weight: 100EOF é€šè¿‡ Istio Gateway è®¿é—® Nginxï¼Œä¼šå‘ç°è¿”å›éƒ½æ˜¯ V1 ç‰ˆæœ¬ ä¿®æ”¹ Virtual Serviceï¼Œå°† 20% çš„æµé‡è½¬å‘è‡³ V2 12345678910111213141516171819202122232425262728cat &lt;&lt;EOF | kubectl apply -f -apiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata: name: nginxspec: hosts: - &quot;*&quot; gateways: - nginx-gateway http: - match: - uri: prefix: / route: - destination: host: nginx port: number: 80 subset: v1 weight: 80 - destination: host: nginx port: number: 80 subset: v2 weight: 20EOF å¯ä»¥çœ‹åˆ°ä¼šæœ‰éƒ¨ä»½æµé‡è½¬å‘è‡³ V2 ç†”æ–­ä¹Ÿæ˜¯é€šè¿‡ Destination Rule å®ç° 123456789101112131415161718cat &lt;&lt;EOF | kubectl apply -f -apiVersion: networking.istio.io/v1beta1kind: DestinationRulemetadata: name: nginx-circuit-breakerspec: host: nginx trafficPolicy: connectionPool: http: # HTTP1 æœ€å¤§ç­‰å¾…è¯·æ±‚æ•° http1MaxPendingRequests: 1 # æ¯ä¸ªè¿æ¥çš„ HTTP æœ€å¤§è¯·æ±‚æ•° maxRequestsPerConnection: 1 tcp: # TCP æœ€å¤§è¿æ¥æ•° maxConnections: 1EOF K3sK3s éƒ¨ç½² 12345678mkdir -pv /etc/rancher/k3scat &gt; /etc/rancher/k3s/config.yaml &lt;&lt;EOFtoken: 12345system-default-registry: registry.cn-hangzhou.aliyuncs.comEOFcurl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh -","link":"/2024/08/21/SUSE-%E7%AC%AC%E4%B8%80%E5%91%A8%E4%BA%A7%E5%93%81%E9%83%A8%E7%BD%B2%E4%BD%BF%E7%94%A8%E9%9A%8F%E8%AE%B0/"},{"title":"Kafka","text":"ä¸€ã€kafkaæ¶æ„kafka æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼çš„åŸºäºå‘å¸ƒå’Œè®¢é˜…æ¨¡å¼çš„æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆmessage queueï¼‰ï¼Œä¸»è¦ç”¨äºå¤§æ•°æ®å®æ—¶å¤„ç†é¢†åŸŸã€‚ 1.1 æ¶ˆæ¯é˜Ÿåˆ—åŒæ­¥é€šä¿¡ å¼‚æ­¥é€šä¿¡ ä½¿ç”¨æ¶ˆæ¯é˜Ÿåˆ—çš„å¥½å¤„å¦‚ä¸‹ï¼š è§£è€¦ï¼šå…è®¸ç‹¬ç«‹çš„æ‰©å±•æˆ–ä¿®æ”¹ä¸¤è¾¹çš„å¤„ç†è¿‡ç¨‹ å¯æ¢å¤æ€§ï¼šç³»ç»Ÿçš„ä¸€éƒ¨åˆ†ç»„ä»¶å¤±æ•ˆæ—¶ï¼Œä¸ä¼šå½±å“åˆ°æ•´ä¸ªç³»ç»Ÿ ç¼“å†²ï¼šæ§åˆ¶å’Œä¼˜åŒ–æ•°æ®ç»è¿‡ç³»ç»Ÿçš„é€Ÿåº¦ çµæ´»æ€§å’Œå³°å€¼å¤„ç†èƒ½åŠ›ï¼šåœ¨ç‰¹æ®Šæƒ…å†µä¸‹ï¼Œé€šä¿¡ä¸­çš„è¯·æ±‚é‡ä¼šæ€¥å‰§å¢å¤§ï¼ˆå¦‚åŒåä¸€ç­‰æ´»åŠ¨ï¼‰ï¼Œä½†è¿™ç§æƒ…å†µå¹¶ä¸å¸¸è§ï¼Œå¦‚æœæŠ•å…¥èµ„æºæ¥å¾…å‘½æ˜¯å¾ˆæµªè´¹çš„ï¼Œä½¿ç”¨æ¶ˆæ¯é˜Ÿåˆ—å°±å¯ä»¥é¡¶ä½çªå‘çš„è®¿é—®å‹åŠ›ï¼Œè€Œä¿æŠ¤é›†ç¾¤ä¸ä¼šå› ä¸ºè¯·æ±‚é‡è¿‡å¤šè€Œå´©æºƒ å¼‚æ­¥é€šä¿¡ï¼šæœ‰æ—¶å€™ç”¨æˆ·ä¸æƒ³ä¹Ÿä¸éœ€è¦ç«‹å³å¤„ç†æ¶ˆæ¯ï¼Œè¿™ç§æ—¶å€™å°±å…è®¸ç”¨æˆ·æŠŠæ¶ˆæ¯æ”¾åœ¨é˜Ÿåˆ—ä¸­ï¼Œç­‰å¾…å¤„ç† æ¶ˆæ¯é˜Ÿåˆ—åˆ†ä¸ºç‚¹å¯¹ç‚¹æ¨¡å¼å’Œå‘å¸ƒ/è®¢é˜…æ¨¡å¼ ç‚¹å¯¹ç‚¹æ¨¡å¼ æ¶ˆæ¯ç”Ÿäº§è€…ç”Ÿäº§æ¶ˆæ¯å‘é€åˆ° queue ä¸­ï¼Œæ¶ˆè´¹è€…å†ä» queue æ‹‰å–æ¶ˆæ¯å¹¶æ¶ˆè´¹ï¼Œæ¶ˆæ¯è¢«æ¶ˆè´¹ä¹‹åå°±ä¸å†å­˜åœ¨äº queue ä¸­ï¼Œqueue å¯ä»¥æœ‰å¤šä¸ªæ¶ˆè´¹è€…ï¼Œä½†å¯¹äºæ¶ˆæ¯è€Œè¨€åªèƒ½æœ‰ä¸€ä¸ªæ¶ˆè´¹è€…ã€‚ å‘å¸ƒ/è®¢é˜…æ¨¡å¼ æ¶ˆæ¯ç”Ÿäº§è€…å°†æ¶ˆæ¯å‘é€åˆ° topic ä¸­ï¼Œå¯ä»¥åŒæ—¶æœ‰å¤šä¸ªæ¶ˆè´¹è€…è®¢é˜…è¯¥æ¶ˆæ¯ï¼Œå‘å¸ƒåˆ° topic çš„æ¶ˆæ¯å¯ä»¥è¢«æ‰€æœ‰æ¶ˆè´¹è€…è®¢é˜…ã€‚ 1.2 kafkaåŸºç¡€æ¶æ„kafka æœ‰å››ä¸ªæ ¸å¿ƒçš„ APIï¼š The Producer APIï¼šå…è®¸ä¸€ä¸ªåº”ç”¨ç¨‹åºå‘å¸ƒä¸€ä¸²æµå¼çš„æ•°æ®åˆ°ä¸€ä¸ªæˆ–è€…å¤šä¸ª topic The Consumer APIï¼šå…è®¸ä¸€ä¸ªåº”ç”¨ç¨‹åºè®¢é˜…ä¸€ä¸ªæˆ–å¤šä¸ª topic ï¼Œå¹¶ä¸”å¯¹å‘å¸ƒç»™ä»–ä»¬çš„æµå¼æ•°æ®è¿›è¡Œå¤„ç† The Streams APIï¼šå…è®¸ä¸€ä¸ªåº”ç”¨ç¨‹åºä½œä¸ºä¸€ä¸ªæµå¤„ç†å™¨ï¼Œæ¶ˆè´¹ä¸€ä¸ªæˆ–è€…å¤šä¸ª topic äº§ç”Ÿçš„è¾“å…¥æµï¼Œç„¶åç”Ÿäº§ä¸€ä¸ªè¾“å‡ºæµåˆ°ä¸€ä¸ªæˆ–å¤šä¸ª topic ä¸­å»ï¼Œåœ¨è¾“å…¥è¾“å‡ºæµä¸­è¿›è¡Œæœ‰æ•ˆçš„è½¬æ¢ The Connector APIï¼šå…è®¸æ„å»ºå¹¶è¿è¡Œå¯é‡ç”¨çš„ç”Ÿäº§è€…æˆ–è€…æ¶ˆè´¹è€…ï¼Œå°† topics è¿æ¥åˆ°å·²å­˜åœ¨çš„åº”ç”¨ç¨‹åºæˆ–è€…æ•°æ®ç³»ç»Ÿ producerï¼šæ¶ˆæ¯ç”Ÿäº§è€… consumerï¼šæ¶ˆæ¯æ¶ˆè´¹è€… topicï¼šæ•°æ®ä¸»é¢˜ï¼Œæ˜¯æ•°æ®è®¢é˜…/å‘å¸ƒçš„åœ°æ–¹ï¼Œå¯ä»¥è¢«å¤šä¸ªæ¶ˆè´¹è€…è®¢é˜… partitionï¼šåˆ†åŒºï¼Œæ¯ä¸ª topic åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªåˆ†åŒºï¼Œåˆ†åŒºæ˜¯ä¸€ä¸ªæœ‰åºçš„é˜Ÿåˆ—ï¼Œåˆ†åŒºä¸­çš„æ¶ˆæ¯éƒ½ä¼šè¢«åˆ†é…ä¸€ä¸ª offsetï¼Œkafka ä¿è¯æŒ‰æ¯ä¸€ä¸ªåˆ†åŒºä¸­çš„é¡ºåºå°†æ¶ˆæ¯å‘é€ç»™æ¶ˆè´¹è€…ï¼Œä½†ä¸ä¿è¯æŒ‰æ¯ä¸€ä¸ª topic ä¸­çš„é¡ºåºå°†æ¶ˆæ¯å‘é€ç»™æ¶ˆè´¹è€…ï¼›ä¸” partition æ˜¯æ¶ˆè´¹è€…å’Œç”Ÿäº§è€…æ“ä½œçš„æœ€å°å•å…ƒ offsetï¼ˆåç§»é‡ï¼‰ï¼škafka çš„å­˜å‚¨æ–‡ä»¶éƒ½æ˜¯æŒ‰ç…§ offset.kafka æ¥å‘½åï¼Œæ–¹ä¾¿æŸ¥æ‰¾æ•°æ® leader å‰¯æœ¬ï¼šæ¶ˆæ¯çš„è®¢é˜…/å‘å¸ƒéƒ½ç”± leader æ¥å®Œæˆ follower å‰¯æœ¬ï¼šè¿›è¡Œæ¶ˆæ¯æ•°æ®çš„å¤‡ä»½ï¼Œå½“ leader æŒ‚äº†ä¹‹åï¼Œå°±æˆä¸ºæ–°çš„ leader æ¥ä»£æ›¿æ—§çš„ leader brokerï¼šä¸€ä¸ª kafka å°±æ˜¯ä¸€ä¸ª brokerï¼Œä¸€ä¸ªé›†ç¾¤ç”±å¤šä¸ª broker ç»„æˆ consumer groupï¼šæ¶ˆè´¹è€…ç»„ï¼Œç»„ä¸­æœ‰å¤šä¸ªæ¶ˆè´¹è€…ï¼Œç»„ä¸­çš„æ¶ˆè´¹è€…éƒ½åªèƒ½å¤Ÿæ¥æ”¶ä¸€ä¸ªåˆ†åŒºçš„æ¶ˆæ¯ zookeeperï¼šä¿å­˜ kafka é›†ç¾¤çŠ¶æ€çš„ä¿¡æ¯ï¼Œ2.8.0ç‰ˆæœ¬å¼€å§‹æ”¯æŒ kraft æ¨¡å¼ï¼Œå¯ä¸ä¾èµ– zk è¿è¡Œ kafka é›†ç¾¤ replicasï¼šå‰¯æœ¬æ•° 1.3 kafka å­˜å‚¨æœºåˆ¶kafka å†…éƒ¨ä¼šè‡ªå·±åˆ›å»ºä¸€ä¸ª _consumer_offsets å¹¶åŒ…å« 50 ä¸ªåˆ†åŒºï¼Œè¿™äº›ä¸»é¢˜ç”¨æ¥ä¿å­˜æ¶ˆè´¹è€…æ¶ˆè´¹æŸä¸ª topic çš„åç§»é‡ã€‚ æ¯ä¸ª partitions éƒ½è¢«åˆ‡å‰²æˆç›¸åŒå¤§å°çš„ segmentï¼Œsegment ç”±å››ä¸ªéƒ¨åˆ†æ„æˆï¼Œå…·ä½“å¦‚ä¸‹ï¼š logï¼šæ•°æ®æ–‡ä»¶ indexï¼šç´¢å¼•æ–‡ä»¶ï¼Œç”¨æ¥ä¿å­˜æ¶ˆæ¯çš„ç´¢å¼•ï¼Œèƒ½å¤Ÿä½¿æŸ¥æ‰¾æ•°æ®æ›´åŠ é«˜æ•ˆ timeindexï¼šå…·ä½“æ—¶é—´æ—¥å¿— leader-epoch-checkpointï¼šä¿å­˜äº†æ¯ä¸€ä»» leader å¼€å§‹å†™å…¥æ¶ˆæ¯æ—¶çš„ offsetï¼Œä¼šå®šæ—¶æ›´æ–° 1.4 ç”Ÿäº§è€…åˆ†åŒºç­–ç•¥kafka å…è®¸ä¸ºæ¯æ¡æ¶ˆæ¯å®šä¹‰æ¶ˆæ¯ keyï¼Œå¯ä»¥æ ¹æ® key æ¥ä¸ºæ¶ˆæ¯é€‰æ‹©åˆ†åŒºã€‚ åˆ†åŒºç­–ç•¥å³å†³å®šç”Ÿäº§è€…å°†æ¶ˆæ¯å‘é€åˆ°å“ªä¸ªåˆ†åŒºçš„ç®—æ³•ï¼Œä¸»è¦æœ‰ä»¥ä¸‹å‡ ç§ï¼š è½®è¯¢ç­–ç•¥ï¼ˆæ²¡ç»™å®šåˆ†åŒºå·å’Œ key å€¼ï¼‰ï¼šå¯ä»¥æä¾›ä¼˜ç§€çš„è´Ÿè½½å‡è¡¡èƒ½åŠ›ï¼Œä¿è¯æ¶ˆæ¯è¢«å¹³å‡çš„åˆ†é…åˆ°å„ä¸ªåˆ†åŒºä¸Šï¼Œä½†ä¸èƒ½ä¿è¯æ¶ˆæ¯çš„æœ‰åºæ€§ã€‚ éšå³ç­–ç•¥ï¼šçåˆ†ï¼ŒåŸºæœ¬ä¸ç”¨ã€‚ hash ç­–ç•¥ï¼ˆæ²¡ç»™å®šåˆ†åŒºå·ï¼Œä½†ç»™äº† key å€¼ï¼‰ï¼šå°† key çš„ hash å€¼ä¸ topic çš„ partition æ•°è¿›è¡Œå–ä½™å¾—åˆ°partitionå€¼ è‡ªå®šä¹‰åˆ†åŒº 1.5 ç”Ÿäº§è€…ISRISR å³åŒæ­¥å‰¯æœ¬ï¼Œleader ç»´æŠ¤äº†ä¸€ä¸ªåŠ¨æ€çš„ ISRï¼Œä¸º leader ä¿æŒåŒæ­¥çš„ follower é›†åˆï¼Œå½“ ISR ä¸­çš„ follower å®Œæˆæ•°æ®çš„åŒæ­¥ä¹‹åï¼Œleader å°±ä¼šç»™ follower å‘é€ acksï¼Œå¦‚æœ follower é•¿æ—¶é—´æ²¡æœ‰å‘ leader åŒæ­¥æ•°æ®ï¼Œåˆ™è¯¥ follower å°†è¢«è¸¢å‡º ISRã€‚leader å‘ç”Ÿæ•…éšœä¹‹åå°±ä¼šåœ¨ ISR ä¸­é€‰å–å‡ºæ–°çš„ leaderã€‚ 1.6 ç”Ÿäº§è€…ACKSkafka å‘é€ç¡®è®¤å‚æ•° acks çš„å‡ ç§æ¨¡å¼ï¼š acks = 0ï¼šæ„å‘³ç€ç”Ÿäº§è€…èƒ½å¤Ÿé€šè¿‡ç½‘ç»œæŠŠæ¶ˆæ¯å‘é€å‡ºå»ï¼Œbroker æ¥æ”¶åˆ°æ•°æ®è¿˜æ²¡å†™å…¥å°±å‘é€ï¼Œå®¹æ˜“ä¸¢æ•°æ® acks = 1ï¼šç­‰å¾… leader å†™å…¥æ•°æ®ï¼ˆä¸ç­‰å¾… follower åŒæ­¥ï¼‰ï¼Œå°±å¯ä»¥å‘é€æ•°æ®ï¼Œå¯èƒ½ä¼šä¸¢æ•°æ® acks = all/-1ï¼šç­‰å¾… leader å’Œ followerï¼ˆISR ä¸­çš„ï¼‰å†™å…¥æ•°æ®ï¼Œå°±å¯ä»¥å‘é€æ•°æ®ï¼Œæ•°æ®ä¸å®¹æ˜“ä¸¢ï¼Œä½†æ•ˆç‡åº• 1.7 kafkaæ•°æ®ä¸€è‡´æ€§åŸç† HWï¼šæ‰€æœ‰å‰¯æœ¬ä¸­çš„æœ€å° LEO LEOï¼šæ¯ä¸ªå‰¯æœ¬çš„æœ€åä¸€ä¸ªï¼ˆæœ€å¤§çš„ï¼‰ offset å‡è®¾åˆ†åŒºçš„å‰¯æœ¬ä¸º3ï¼Œå‰¯æœ¬0ä¸º leaderï¼Œå‰¯æœ¬1ã€2ä¸º followerï¼Œå¹¶ä¸”éƒ½åœ¨ ISR åˆ—è¡¨ä¸­ã€‚è™½ç„¶ leader å·²ç»å†™å…¥äº† message3ï¼Œä½†æ¶ˆè´¹è€…åªèƒ½è¯»åˆ° message1ï¼Œå› ä¸ºæ‰€æœ‰çš„ ISR éƒ½åŒæ­¥äº† message1ï¼Œåªæœ‰åœ¨ HW ä¹‹ä¸Šçš„æ¶ˆæ¯æ‰æ”¯æŒè¢«æ¶ˆè´¹ï¼Œè€Œ HW å–å†³äº LEOï¼ŒåŸç†ç±»ä¼¼äºæœ¨æ¡¶åŸç†ã€‚ è¿™ä¹ˆåšçš„åŸå› æ˜¯å¦‚æœ leader å´©æºƒäº†ï¼Œä¸€ä¸ª follower æˆä¸ºæ–°çš„ leader åï¼Œç”±äºè¯¥æ–°çš„ leader æ²¡æœ‰åšå¥½æ•°æ®çš„åŒæ­¥ï¼Œå¦‚æœå…è®¸æ¶ˆè´¹è€…è¯»å– HW ä¹‹ä¸‹çš„æ•°æ®çš„è¯ï¼Œé‚£ä¹ˆå°±ä¼šå‡ºç°æ•°æ®ä¸ä¸€è‡´çš„é—®é¢˜ã€‚ 1.7 Exactly-onceå½“ç”Ÿäº§è€…å‘é€æ¶ˆæ¯åˆ° topic æ—¶ï¼Œå¾ˆå¯èƒ½ä¼šå‡ºç°å®•æœºçš„æƒ…å†µï¼Œæˆ–è€…å‡ºç°äº†ç½‘ç»œæ•…éšœï¼Œå¯¼è‡´ç”Ÿäº§è€…æ¶ˆæ¯å‘é€å¤±è´¥ï¼Œè€Œç”Ÿäº§è€…è¦å¦‚ä½•å¤„ç†è¿™æ ·çš„é”™è¯¯ï¼Œå°±äº§ç”Ÿäº†å¦‚ä¸‹å‡ ç§ä¸åŒçš„è¯­ä¹‰ï¼š At least onceï¼šè‡³å°‘ä¸€æ¬¡ï¼Œå¦‚æœç”Ÿäº§è€…æ”¶åˆ°äº† broker å‘é€è¿‡æ¥çš„ acksï¼Œä¸” acks è®¾ç½®ä¸ºäº† all/-1ï¼Œè¿™å°±ä»£è¡¨æ¶ˆæ¯å·²ç»è¢«å†™å…¥ topic ä¸”åŒæ­¥å¥½äº†ã€‚å¦‚æœç”Ÿäº§è€…åœ¨æ—¶é—´å†…æ²¡å—åˆ° acks æˆ–æ”¶åˆ°çš„ acks æœ‰è¯¯ï¼Œé‚£ä¹ˆå°±ä¼šé‡æ–°å‘é€æ¶ˆæ¯ã€‚å¦‚æœ broker æ°å¥½åœ¨æ¶ˆæ¯å·²ç»å†™å…¥ topic æ—¶ï¼Œå‘é€ acks å‰å‡ºäº†æ•…éšœï¼Œé‚£ä¹ˆå°±ä¼šå¯¼è‡´ç”Ÿäº§è€…å‘é€åŒæ ·çš„æ¶ˆæ¯ä¸¤æ¬¡ï¼Œæ¶ˆè´¹è€…æ¶ˆè´¹ä¸¤æ¬¡ã€‚ At more onceï¼šæœ€å¤šä¸€æ¬¡ï¼Œå¦‚æœç”Ÿäº§è€…åœ¨æ¥æ”¶ acks è¶…æ—¶æˆ–è¿”å›æœ‰é—®é¢˜çš„æ—¶å€™ä¸é‡æ–°å‘é€æ¶ˆæ¯ï¼Œé‚£ä¹ˆæ¶ˆæ¯å¾ˆå¯èƒ½æ²¡å†™å…¥ topic ä¸­ï¼Œå› æ­¤æ¶ˆè´¹è€…ä¹Ÿä¸ä¼šæ¶ˆè´¹è¯¥æ¡æ¶ˆæ¯ï¼Œä¸ä¼šå‡ºç°æ•°æ®é‡å¤çš„ç°è±¡ï¼Œä½†å¾ˆå®¹æ˜“ç¼ºæ•°æ®ã€‚ Exactly onceï¼šç²¾ç¡®ä¸€æ¬¡ï¼Œå³ä½¿ç”Ÿäº§è€…é‡æ–°å‘é€æ¶ˆæ¯ï¼Œä¹Ÿåªä¼šè¢«æ¶ˆè´¹è€…æ¶ˆè´¹ä¸€æ¬¡ï¼Œå®é™…ä¸Šå°±æ˜¯åœ¨ kafka é›†ç¾¤ä¸­åšä¸€æ¬¡å»é‡çš„æ“ä½œã€‚kafka é›†ç¾¤ä¼šç»™ç”Ÿäº§è€…åˆ†é…ä¸€ä¸ª PIDï¼Œç”Ÿäº§è€…æ¯æ¬¡å‘é€æ¶ˆæ¯åˆ° broker æ—¶éƒ½ä¼šé™„å¸¦ PIDã€åˆ†åŒºä»¥åŠåºåˆ—å·ï¼Œbroker å°±ä¼šå¯¹æ•°æ®åšä¸€ä¸ªä¿å­˜ï¼Œå¦‚æœç”Ÿäº§è€…å†å‘é€åŒæ ·æ¶ˆæ¯ï¼Œé‚£ä¹ˆ broker å°±ä¼šå¯¹æ•°æ®è¿›è¡Œå»é‡ï¼Œä½†å¦‚æœç”Ÿäº§è€…å®•æœºé‡å¯äº†ï¼Œå°±ä¼šè¢«åˆ†é…ä¸€ä¸ªæ–°çš„ PIDï¼Œæ‰€ä»¥å»é‡æ— æ³•åšåˆ°ç²¾å‡†çš„æ•°æ®å†™å…¥ã€‚è¦å¼€å¯ exactly-onceï¼Œéœ€è¦åœ¨ broker ä¸­é…ç½® enable.idempotence = true ï¼Œè¿™æ—¶å€™ acks é»˜è®¤è¢«è®¾ç½®ä¸º -1ã€‚ 1.8 æ¶ˆè´¹è€…åˆ†åŒºåˆ†é…ç­–ç•¥æ¶ˆè´¹è€…æ˜¯é‡‡ç”¨ pull çš„æ–¹å¼åœ¨ kafka é›†ç¾¤ä¸­è·å–æ¶ˆæ¯çš„ã€‚ push æ¨¡å¼å¾ˆéš¾é€‚åº”æ¶ˆè´¹é€Ÿç‡ä¸åŒçš„æ¶ˆè´¹è€…ï¼Œå› ä¸ºæ¶ˆæ¯çš„å‘é€é€Ÿç‡æ˜¯ç”± broker å†³å®šçš„ï¼›è€Œ pull æ–¹å¼å½“ kafka é›†ç¾¤æ²¡æœ‰æ•°æ®çš„æ—¶å€™ï¼Œæ¶ˆè´¹è€…å¯èƒ½ä¼šé™·å…¥å¾ªç¯ä¹‹ä¸­ï¼Œä¸€ç›´å–åˆ°ç©ºæ•°æ®ã€‚ ä¸€ä¸ªæ¶ˆè´¹è€…ç»„é‡Œç”±å¤šä¸ªæ¶ˆè´¹è€…ï¼Œä¸€ä¸ª topic é‡Œç”±å¤šä¸ªåˆ†åŒºï¼Œé‚£ä¹ˆæ•°æ®åœ¨æ¶ˆè´¹çš„æ—¶å€™å°±ä¼šæ¶‰åŠåˆ°åˆ†é…çš„é—®é¢˜ï¼Œå³ç¡®å®šé‚£äº›åˆ†åŒºç”±æ¶ˆè´¹è€…ç»„é‡Œçš„å“ªäº›æ¶ˆè´¹è€…æ¥æ¶ˆè´¹ã€‚ kakfa æœ‰ä¸‰ç§åˆ†é…ç­–ç•¥ï¼Œå¦‚ä¸‹ï¼š RangeAssignorï¼ˆé»˜è®¤ï¼‰ï¼šRangeAssignor æ˜¯é’ˆå¯¹ topic è€Œè¨€çš„ï¼Œé¦–å…ˆä¼šå¯¹ topic ä¸­çš„åˆ†åŒºæŒ‰ç…§åºå·è¿›è¡Œæ’åˆ—ï¼Œå¹¶å¯¹æ¶ˆè´¹è€…æ ¹æ®å­—å…¸åºæ’åˆ—ï¼Œç„¶åç”¨åˆ†åŒºä¸ªæ•°é™¤ä»¥æ¶ˆè´¹è€…çº¿ç¨‹çš„æ€»æ•°æ¥å†³å®šåˆ†åŒºçš„åˆ†é…ï¼Œä½†å¦‚æœé™¤ä¸å°½ï¼Œé‚£ä¹ˆå‰é¢çš„æ¶ˆè´¹è€…å°±ä¼šå¤šåˆ†é…ä¸€äº›åˆ†åŒºã€‚ RoundRobinï¼šå°†æ¶ˆè´¹ç»„å†…æ‰€æœ‰æ¶ˆè´¹è€…ä»¥åŠæ¶ˆè´¹è€…æ‰€è®¢é˜…çš„æ‰€æœ‰ topic çš„ partition æŒ‰ç…§å­—å…¸åºæ’åºï¼Œç„¶åé€šè¿‡è½®è¯¢çš„æ–¹å¼é€ä¸ªåˆ†é…ç»™ç»„å†…çš„æ¶ˆè´¹è€…ã€‚å¦‚æœåŒæ—¶æ¶ˆè´¹å¤šä¸ª topicï¼Œé‚£ä¹ˆæ¶ˆè´¹è€…ä¼šå°†è¿™äº› topic è§†ä¸ºä¸€ä¸ªã€‚ä½†å¦‚æœåŒä¸€ä¸ªæ¶ˆè´¹ç»„å†…çš„æ¶ˆè´¹è€…æ‰€è®¢é˜…çš„ä¿¡æ¯æ˜¯ä¸ç›¸åŒçš„ï¼Œé‚£ä¹ˆåœ¨æ‰§è¡Œåˆ†åŒºåˆ†é…çš„æ—¶å€™å°±ä¸æ˜¯å®Œå…¨çš„è½®è¯¢åˆ†é…ï¼Œæœ‰å¯èƒ½ä¼šå¯¼è‡´åˆ†åŒºåˆ†é…çš„ä¸å‡åŒ€ã€‚ StickyAssignorï¼šStickyAssignor è¦å®ç°çš„æ˜¯åˆ†åŒºçš„åˆ†é…è¦å°½å¯èƒ½çš„å‡åŒ€ï¼Œåˆ†é…ç»™æ¶ˆè´¹è€…è€…çš„ä¸»é¢˜åˆ†åŒºæ•°æœ€å¤šç›¸å·®ä¸€ä¸ªï¼Œå‡è®¾ä¸€ä¸ªæ¶ˆè´¹è€…ç»„æœ‰ä¸‰ä¸ªæ¶ˆè´¹è€…ï¼Œéƒ½è®¢é˜…äº†å››ä¸ª topicï¼Œä¸”æ¯ä¸ª topic ä¸­æœ‰äºŒä¸ªåˆ†åŒºï¼Œé‚£ä¹ˆè¿™æ—¶å€™åˆ†é…çš„ç»“æœä¸ RoundRobin ä¼šå¾ˆç›¸ä¼¼ï¼Œå³æ¶ˆè´¹è€…Aä¸‰ä¸ªåˆ†åŒºã€æ¶ˆè´¹è€…Bä¸‰ä¸ªåˆ†åŒºã€æ¶ˆè´¹è€…Cä¸¤ä¸ªåˆ†åŒºï¼Œå‡è®¾æ¶ˆè´¹è€…Cé€€å‡ºäº†æ¶ˆè´¹è€…ç»„ï¼Œè¿™æ—¶å€™ StickyAssignor ä¼šä¿ç•™ä¹‹å‰æ¶ˆè´¹è€…Aå’ŒBåˆ†é…åˆ°çš„åˆ†åŒºï¼Œç„¶åå†å°†æ¶ˆè´¹è€…Cä¹‹å‰åˆ†é…åˆ°çš„åˆ†åŒºå†åˆ†é…ç»™æ¶ˆè´¹è€…Aå’ŒBï¼Œå³ä½“ç°äº†ç²˜æ€§ï¼Œä¸éœ€è¦æ¶ˆè´¹è€…å°†ä¹‹å‰å¤„ç†è¿‡çš„æ•°æ®é€åˆ°æ–°çš„æ¶ˆè´¹è€…å†å¤„ç†ä¸€æ¬¡ã€‚ 1.9 offsetå­˜å‚¨kafka åœ¨0.9ç‰ˆæœ¬ä¹‹å‰ï¼Œoffset æ˜¯å­˜å‚¨åœ¨ zk ä¸­ï¼Œåœ¨ä¹‹åçš„ç‰ˆæœ¬åˆ™æ˜¯å­˜å‚¨åœ¨ kafka å†…ç½®çš„ä¸€ä¸ª topic ä¸­ï¼Œå³ _consumer_offsetsï¼Œä¸€ä¸ª offset æäº¤çš„ä¿¡æ¯åŒ…æ‹¬ä»¥ä¸‹ï¼š Fields Content Key Consumer Groupã€Topicã€Partition Payload Offsetã€Metadataã€Timestamp offset çš„æäº¤ä¼šæ ¹æ®æ¶ˆè´¹è€…ç»„çš„ keyï¼ˆGTPï¼‰ è¿›è¡Œåˆ†åŒºï¼Œå¯¹äºä¸€ä¸ªç»™å®šçš„æ¶ˆè´¹è€…ï¼Œå®ƒæ‰€æœ‰çš„æ¶ˆæ¯éƒ½ä¼šå‘é€åˆ°å”¯ä¸€çš„ brokerï¼Œè¿™æ ·æ¶ˆè´¹è€…å°±ä¸éœ€è¦å¯¹å¤šä¸ª broker æ‹‰å–æ•°æ®ï¼Œä½†å¦‚æœæ¶ˆè´¹è€…ç»„æ¶ˆè´¹å¾ˆå¤šæ•°é‡çš„åˆ†åŒºï¼Œä¼šå¯¹ broker é€ æˆæ€§èƒ½ç“¶é¢ˆã€‚ 1.10 kafkaå†™æœºåˆ¶ é¡ºåºå†™å…¥ç£ç›˜ é›¶æ‹·è´ 1.11 kafka-controllerkafka é›†ç¾¤ä¸­ä¼šæœ‰ä¸€ä¸ª broker è¢«é€‰ä¸¾ä¸º controllerï¼Œç”¨æ¥è´Ÿè´£ç®¡ç† broker çš„ä¸Šä¸‹çº¿ï¼Œæ‰€æœ‰ topic çš„åˆ†åŒºã€å‰¯æœ¬åˆ†é…å’Œ leader é€‰ä¸¾ç­‰ã€‚ 1.12 kafkaäº‹åŠ¡äº‹åŠ¡å¯ä»¥ä¿è¯åœ¨ Exactly-Once çš„åŸºç¡€ä¸Šï¼Œç”Ÿäº§å’Œæ¶ˆè´¹å¯ä»¥è·¨åˆ†åŒºè·¨ä¼šè¯ï¼Œå³ç”Ÿäº§è€…åœ¨åŒä¸€ä¸ªäº‹åŠ¡å†…æäº¤åˆ°å¤šä¸ªåˆ†åŒºçš„æ¶ˆæ¯ï¼Œè¦ä¹ˆåŒæ—¶æäº¤æˆåŠŸï¼Œè¦ä¹ˆåŒæ—¶å¤±è´¥ï¼Œè¿™æ ·å°±ä¿è¯äº†ç”Ÿäº§è€…åœ¨è¿è¡Œæ—¶å‡ºç°å¼‚å¸¸æˆ–å®•æœºä¹‹åä»ç„¶æˆç«‹ã€‚ ç”Ÿäº§è€…äº‹åŠ¡ ä¸ºäº†å®ç°è·¨åˆ†åŒºè·¨ä¼šè¯çš„äº‹åŠ¡ï¼Œéœ€è¦å¼•å…¥å…¨å±€å”¯ä¸€çš„ Transaction IDï¼ˆç”±å®¢æˆ·ç«¯ç»™å®šï¼‰ï¼Œå¹¶å°†ç”Ÿäº§è€…çš„ PID ä¸ä¹‹ç»‘å®šï¼Œè¿™æ ·ä»¥æ¥ç”Ÿäº§è€…å³ä½¿å®•æœºé‡å¯ä¹Ÿå¯ä»¥ä¸åŸæ¥çš„ PID è¿›è¡Œç»‘å®šã€‚ ä¸ºäº†ç®¡ç† Transaction IDï¼Œkafka ä¸­å¼•å…¥äº†ä¸€ä¸ªæ–°çš„ç»„ä»¶ Transaction Coordinatorï¼Œç”Ÿäº§è€…å°±æ˜¯ä¸ Transaction Coordinator äº¤äº’æ¥è·å¾— Transaction ID å¯¹åº”çš„ä»»åŠ¡çŠ¶æ€ã€‚Transaction Coordinator è¿˜è´Ÿè´£å°†äº‹åŠ¡å†™å…¥ topicï¼Œè¿™æ ·å³ä½¿æœåŠ¡é‡å¯ï¼Œä¹Ÿå¯ä»¥å¾—åˆ°æ¢å¤ã€‚ æ¶ˆè´¹è€…äº‹åŠ¡ äº‹åŠ¡ä¸»è¦æ˜¯ä¸ºç”Ÿäº§è€…ä½œä¿è¯ï¼Œæ— æ³•ä¿è¯æ¶ˆè´¹è€…çš„ç²¾å‡†æ¶ˆè´¹ï¼Œæ˜¯å› ä¸ºæ¶ˆè´¹è€…å¯ä»¥æ ¹æ® offset æ¥è®¿é—®æ¶ˆæ¯ã€‚ äºŒã€kafkaåŸºç¡€2.1 kafkaå®‰è£…é€šè¿‡äºŒè¿›åˆ¶åŒ…éƒ¨ç½² ä¸‹è½½ kafka 12curl -O https://mirrors.tuna.tsinghua.edu.cn/apache/kafka/2.8.0/kafka_2.13-2.8.0.tgztar -xf kafka_2.13-2.8.0.tgz ä¿®æ”¹ server.properties 1234# brokerçš„idå¿…é¡»ä¸ºå”¯ä¸€çš„æ•´æ•°ï¼Œè®¾ç½®ä¸º-1æ—¶éšæœºç”Ÿæˆbroker.id=-1# ä¿®æ”¹ä¸ºå®é™…zookeeperèŠ‚ç‚¹åœ°å€+2181ç«¯å£zookeeper.connect=... å¼€å¯ zookeeper å’Œ kafka 123# daemonå‚æ•°:ä¸è¾“å‡ºå¯åŠ¨æ—¥å¿—ä¿¡æ¯./bin/zookeeper-server-start.sh -daemon ../config/zookeeper.properties./bin/kafka-server-start.sh -daemon ./config/server.properties é€šè¿‡ docker-compose éƒ¨ç½² docker-compose.yaml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647version: &quot;3.8&quot;services: zookeeper: container_name: zookeeper image: docker.io/bitnami/zookeeper:3.7 ports: - &quot;12181:2181&quot; volumes: - &quot;./data/zookeeper_data:/zookeeper_data&quot; environment: - ALLOW_ANONYMOUS_LOGIN=yes kafka1: container_name: kafka1 image: docker.io/bitnami/kafka:2.8.0 ports: - &quot;19092:9092&quot; volumes: - &quot;./data/kafka1_data:/data&quot; environment: - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181 - ALLOW_PLAINTEXT_LISTENER=yes depends_on: - zookeeper kafka2: container_name: kafka2 image: docker.io/bitnami/kafka:2.8.0 ports: - &quot;19093:9092&quot; volumes: - &quot;./data/kafka2_data:/data&quot; environment: - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181 - ALLOW_PLAINTEXT_LISTENER=yes depends_on: - zookeeper kafka3: container_name: kafka3 image: docker.io/bitnami/kafka:2.8.0 ports: - &quot;19094:9092&quot; volumes: - &quot;./data/kafka3_data:/data&quot; environment: - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181 - ALLOW_PLAINTEXT_LISTENER=yes depends_on: - zookeeper è¿›å…¥ zookeeper å†…éƒ¨æŸ¥çœ‹ brokers æ˜¯å¦å­˜åœ¨ 123zkCli.shls /brokers/ids... kraft æ¨¡å¼éƒ¨ç½² kraft/server.properties 1234# æ ¹æ®èŠ‚ç‚¹æ•°æ”¹node.id=1# æ§åˆ¶èŠ‚ç‚¹controller.quorum.voters=1@master:9093,2@slave1:9093,3@slave2:9093 ç”Ÿæˆé›†ç¾¤ID 1./bin/kafka-storage.sh random-uuid ç”Ÿæˆ /tmp/kraft-combined-logs ç›®å½• 1./bin/kafka-storage.sh format -t &lt;uuid&gt; -c ./config/kraft/server.properties å„èŠ‚ç‚¹å¯åŠ¨ kafka 1./bin/kafka-server-start.sh -daemon ./config/kraft/server.properties kraft æ¨¡å¼ docker-compose éƒ¨ç½² 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647version: &quot;3.8&quot;services: kafka1: container_name: kafka1 image: docker.io/bitnami/kafka:2.8.0 command: - /bin/bash - -c - | kafka-storage.sh format -t &lt;uuid&gt; -c /opt/bitnami/kafka/config/kraft/server.properties kafka-server-start.sh /opt/bitnami/kafka/config/kraft/server.properties ports: - &quot;19092:9092&quot; volumes: - &quot;./conf/kafka1:/opt/bitnami/kafka/config/kraft&quot; environment: - ALLOW_PLAINTEXT_LISTENER=yes kafka2: container_name: kafka2 image: docker.io/bitnami/kafka:2.8.0 command: - /bin/bash - -c - | kafka-storage.sh format -t &lt;uuid&gt; -c /opt/bitnami/kafka/config/kraft/server.properties kafka-server-start.sh /opt/bitnami/kafka/config/kraft/server.properties ports: - &quot;19093:9092&quot; volumes: - &quot;./conf/kafka2:/opt/bitnami/kafka/config/kraft&quot; environment: - ALLOW_PLAINTEXT_LISTENER=yes kafka3: container_name: kafka3 image: docker.io/bitnami/kafka:2.8.0 command: - /bin/bash - -c - | kafka-storage.sh format -t &lt;uuid&gt; -c /opt/bitnami/kafka/config/kraft/server.properties kafka-server-start.sh /opt/bitnami/kafka/config/kraft/server.properties ports: - &quot;19094:9092&quot; volumes: - &quot;./conf/kafka3:/opt/bitnami/kafka/config/kraft&quot; environment: - ALLOW_PLAINTEXT_LISTENER=yes 2.2 kafkaåŸºæœ¬ä½¿ç”¨ åˆ—å‡ºæŸä¸ª zookeeper ä¸­çš„ topic 1./kafka-topics.sh --list --zookeeper zookeeper_ip:2181 åˆ›å»º topic 123# --replication-factor:å‰¯æœ¬æ•°ï¼Œæ€»å‰¯æœ¬æ•°ä¸º(åˆ†åŒºæ•° * å‰¯æœ¬æ•°å‚æ•°)ï¼Œä¸‹é¢çš„ä¾‹å­æ€»å‰¯æœ¬æ•°ä¸º4# --partitions:åˆ†åŒºæ•°./kafka-topics.sh --create --zookeeper zookeeper_ip:2181 --replication-factor 2 --partitions 2 --topic test åˆ é™¤ topic 12# delete.topic.enableä¸ºtrueæ—¶æ‰ä¼šçœŸæ­£åˆ é™¤./kafka-topics.sh --delete --zookeeper zookeeper_ip:2181 --topic test æŸ¥çœ‹ topic 1./kafka-topics.sh --describe --zookeeper zookeeper_ip:2181 --topic test å¯åŠ¨ producer 12# --broker-list:é’ˆå¯¹ç”Ÿäº§è€…ä½¿ç”¨ï¼ŒæŒ‡å®šé›†ç¾¤ä¸­çš„ä¸€ä¸ªæˆ–è€…å¤šä¸ªkafkaæœåŠ¡å™¨./kafka-console-producer.sh --broker-list kafka_id:9092 --topic test å¯åŠ¨ consumer 123# --bootstrap-server:é’ˆå¯¹æ¶ˆè´¹è€…ä½¿ç”¨ï¼ŒæŒ‡å®šé›†ç¾¤ä¸­çš„ä¸€ä¸ªæˆ–è€…å¤šä¸ªkafkaæœåŠ¡å™¨# --from-beginning:æŸ¥çœ‹æ‰€æœ‰æ¶ˆæ¯æ•°æ®./kafka-console-consumer.sh --bootstrap-server kafka_id:9092 --topic test --from-beginning 2.3 å•æ’­æ¶ˆæ¯å¦‚æœå¤šä¸ªæ¶ˆè´¹è€…åœ¨åŒä¸€ä¸ªæ¶ˆè´¹è€…ç»„ï¼Œåªæœ‰ä¸€ä¸ªæ¶ˆè´¹è€…å¯ä»¥æ”¶åˆ°åŒä¸€ä¸ªè®¢é˜…çš„ topic çš„æ¶ˆæ¯ã€‚ å¦‚æœ topic è¿›è¡Œäº†åˆ†åŒºï¼Œé‚£ä¹ˆä¸€ä¸ª partition åªèƒ½è¢«æ¶ˆè´¹è€…ç»„å†…çš„ä¸€ä¸ªæ¶ˆè´¹è€…æ¶ˆè´¹ï¼Œä½†æ¶ˆè´¹è€…å¯ä»¥æ¶ˆè´¹å¤šä¸ªä¸åŒçš„ partitionï¼Œè€Œè¿™äº› partition ä¹Ÿå¯ä»¥è¢«ä¸åŒæ¶ˆè´¹è€…ç»„çš„æ¶ˆè´¹è€…æ¶ˆè´¹ã€‚ 12# --consumer-property group.id:æŒ‡å®šè¯¥æ¶ˆè´¹è€…ä»å±äºå“ªä¸ªæ¶ˆè´¹è€…ç»„./kafka-console-consumer.sh --bootstrap-server kafka_id:9092 --consumer-property group.id=testgroup --topic test 2.4 å¤šæ’­æ¶ˆæ¯å¦‚æœå¤šä¸ªä¸åŒæ¶ˆè´¹è€…ç»„ä¸­çš„æ¶ˆè´¹è€…æ¶ˆè´¹åŒä¸€ä¸ªè®¢é˜…çš„ topic çš„æ¶ˆæ¯ï¼Œé‚£ä¹ˆè¿™äº›æ¶ˆè´¹è€…éƒ½å¯ä»¥æ¶ˆè´¹åŒæ ·çš„æ¶ˆæ¯ã€‚ 2.5 æŸ¥çœ‹æ¶ˆè´¹è€…ç»„ä¿¡æ¯ æŸ¥çœ‹æŒ‡å®šèŠ‚ç‚¹æœ‰å“ªäº›æ¶ˆè´¹è€…ç»„ 1./kafka-consumer-groups.sh --bootstrap-server kafka_id:9092 --list æŸ¥çœ‹æ¶ˆè´¹è€…ç»„è¯¦ç»†ä¿¡æ¯ 1234./kafka-consumer-groups.sh --bootstrap-server kafka_id:9092 --describe --group testgroup# CURRENT-OFFSET:ä¸Šæ¬¡æ¶ˆè´¹æ¶ˆæ¯åç§»é‡# LOG-END-OFFSET:å½“å‰topicæœ€åæ¶ˆæ¯åç§»é‡# LAG:æœªæ¶ˆè´¹ä¿¡æ¯çš„æ•°é‡ 2.6 kafkaé›†ç¾¤æ“ä½œ æ¶ˆæ¯å‘é€ 1./kafka-console-producer.sh --broker-list kafka_01:9092 kafka_02:9092 kafka_03:9092 --topic test æ¶ˆæ¯æ¶ˆè´¹ 1./kafka-console-consumer.sh --bootstrap-server kafka_01:9092 kafka_02:9092 kafka_03:9092 --from-beginning --topic test æ¶ˆè´¹è€…ç»„æ¶ˆè´¹ä¿¡æ¯ 1./kafka-consumer-groups.sh --bootstrap-server kafka_01:9092 kafka_02:9092 kafka_03:9092 --from-beginning --consumer-property group.id=testgroup --topic test ä¸‰ã€kafkaä¼˜åŒ–3.1 å¦‚ä½•é˜²æ­¢æ¶ˆæ¯ä¸¢å¤± å‘é€æ–¹ï¼šè®¾ç½® ack çš„å€¼ä¸º 1 æˆ– -1/all æ¶ˆè´¹æ–¹ï¼šè®¾ç½® offset ä¸ºæ‰‹åŠ¨æäº¤ 3.2 å¦‚ä½•é˜²æ­¢æ¶ˆæ¯çš„é‡å¤æ¶ˆè´¹å¦‚æœ broker æ”¶åˆ°äº†æ¶ˆæ¯å¹¶å‘é€äº† ack ç»™ç”Ÿäº§è€…ï¼Œå› ä¸ºç½‘ç»œåŸå› ç”Ÿäº§è€…åœ¨ä¸€å®šæ—¶é—´å†…æ²¡æœ‰æ”¶åˆ° ack å°±ä¼šè¿›è¡Œæ¶ˆæ¯çš„é‡æ–°å‘é€ï¼Œè¿™æ · broker å°±ä¼šæœ‰ä¸¤æ¡ä¸€æ ·çš„æ¶ˆæ¯ï¼Œå°±å¯èƒ½ä¼šé€ æˆæ¶ˆè´¹è€…é‡å¤æ¶ˆè´¹ã€‚ åœ¨æ¶ˆè´¹è€…ç«¯è¿›è¡Œéå¹‚ç­‰æ€§ï¼ˆå¤šæ¬¡è®¿é—®çš„ç»“æœæ˜¯ä¸€æ ·çš„ï¼‰æ¶ˆè´¹é—®é¢˜ï¼Œå°±å¯ä»¥è§£å†³ã€‚ æ–¹æ³•ä¸€ï¼šåœ¨æ•°æ®åº“ä¸­åˆ›å»ºä¸€ä¸ªè”åˆä¸»é”®ï¼ˆidï¼Œuuidï¼‰ï¼Œè¿™æ ·åªæœ‰è”åˆä¸»é”®åŒ¹é…æˆåŠŸæ‰èƒ½å†™å…¥æ•°æ® æ–¹æ³•äºŒï¼šä½¿ç”¨åˆ†å¸ƒå¼é”ï¼Œä¾‹å¦‚ Redission.lockï¼ˆuuidï¼‰ 3.3 å¦‚ä½•åšåˆ°é¡ºåºæ¶ˆè´¹é¡ºåºæ¶ˆè´¹çš„ä½¿ç”¨åœºæ™¯å¹¶ä¸å¤šï¼Œå› ä¸ºä¼šç‰ºç‰²è¾ƒå¤šçš„æ€§èƒ½ã€‚ å‘é€æ–¹ï¼šack ä¸èƒ½è®¾ç½®ä¸º 0ï¼ˆå¦åˆ™å¯èƒ½ä¼šä¸¢å¤±æ¶ˆæ¯ï¼‰ï¼Œå…³é—­é‡è¯•å¹¶ä½¿ç”¨åŒæ­¥å‘é€ï¼ˆé‡è¯•å¯èƒ½ä¼šå¯¼è‡´æ¶ˆæ¯é‡å¤ï¼Œå¼‚æ­¥å‘é€ä¼šå¯¼è‡´æ¶ˆæ¯å‘é€é¡ºåºä¸ä¸€è‡´ï¼‰ï¼Œæ¶ˆæ¯å‘é€æˆåŠŸåæ‰ä¼šå‘é€ä¸‹ä¸€æ¡ï¼Œä»¥ä¿è¯æ¶ˆæ¯çš„é¡ºåºå‘é€ æ¶ˆè´¹æ–¹ï¼šæ¶ˆæ¯éƒ½æ˜¯å‘é€åˆ°ä¸€ä¸ª partition ä¸­ï¼Œåªèƒ½æœ‰ä¸€ä¸ªæ¶ˆè´¹è€…æ¥æ¶ˆè´¹è¯¥ partition çš„æ¶ˆæ¯ 3.4 æ¶ˆæ¯ç§¯å‹å½“æ¶ˆè´¹è€…çš„æ¶ˆè´¹é€Ÿåº¦è¿œè¿œè·Ÿä¸ä¸Šç”Ÿäº§è€…çš„æ¶ˆæ¯ç”Ÿäº§é€Ÿåº¦ï¼Œé‚£ä¹ˆ kafka ä¸­å°±ä¼šæœ‰å¤§é‡çš„æ¶ˆæ¯æ²¡æœ‰è¢«æ¶ˆè´¹ï¼Œæ¶ˆè´¹è€…å¯»å€çš„æ€§èƒ½ä¹Ÿä¼šè¶Šæ¥è¶Šå·®ï¼Œæœ€åå¯¼è‡´æœåŠ¡é›ªå´©ã€‚ æ–¹æ³•ä¸€ï¼šä½¿ç”¨å¤šçº¿ç¨‹ æ–¹æ³•äºŒï¼šåˆ›å»ºå¤šä¸ªæ¶ˆè´¹è€…ç»„å’Œå¤šä¸ªæ¶ˆè´¹è€…ï¼Œä¸€èµ·æ¶ˆè´¹ æ–¹æ³•ä¸‰ï¼šåˆ›å»ºä¸€ä¸ªæ¶ˆè´¹è€…ï¼Œè¯¥æ¶ˆè´¹è€…æ–°å»ºä¸€ä¸ª topicï¼Œå¹¶åˆ’åˆ†å¤šä¸ªåˆ†åŒºï¼Œå¤šä¸ªåˆ†åŒºå†åˆ’åˆ†ç»™å¤šä¸ªæ¶ˆè´¹è€…ï¼Œè¿™æ—¶å€™è¯¥æ¶ˆè´¹è€…å°†æ¶ˆæ¯æ‹‰å–ä¸‹æ¥ä½†ä¸è¿›è¡Œæ¶ˆè´¹ï¼Œè€Œæ˜¯æ”¾åœ¨æ–°çš„ topic ä¸Šè®©å¤šä¸ªæ¶ˆè´¹è€…è¿›è¡Œæ¶ˆè´¹ã€‚ 3.5 å»¶æ—¶é˜Ÿåˆ—å¦‚æœåœ¨è®¢å•åˆ›å»ºæˆåŠŸå 30 åˆ†é’Ÿå†…æ²¡æœ‰ä»˜æ¬¾ï¼Œåˆ™è‡ªåŠ¨å–æ¶ˆè®¢å•ï¼Œåœ¨è¿™å°±å¯ä»¥é€šè¿‡å»¶æ—¶é˜Ÿåˆ—æ¥å®ç°ã€‚ æ–¹æ³•ï¼š kafka åˆ›å»ºç›¸åº” topic æ¶ˆè´¹è€…è½®è¯¢æ¶ˆè´¹è¯¥ topic çš„æ¶ˆæ¯ æ¶ˆè´¹è€…åˆ¤æ–­è¯¥ topic çš„åˆ›å»ºæ—¶é—´ä¸å½“å‰æ—¶é—´æ˜¯å¦è¶…è¿‡ 30 åˆ†é’Ÿï¼ˆå‰ææ˜¯è®¢å•æœªæ”¯ä»˜ï¼‰ å¦‚æœæ˜¯ï¼šåœ¨æ•°æ®åº“ä¸­ä¿®æ”¹è®¢å•çŠ¶æ€ä¸ºå–æ¶ˆ å¦‚æœä¸æ˜¯ï¼šè®°å½•å½“å‰æ¶ˆæ¯çš„ offsetï¼Œå¹¶ä¸å†ç»§ç»­æ¶ˆè´¹ å››ã€kafka-eagleç›‘æ§å¹³å° ä¸‹è½½ kafka-eagle 1curl -O https://github.com/smartloli/kafka-eagle-bin/archive/v2.0.8.tar.gz ä¿®æ”¹ system-config.properties 12345678# zkåœ°å€efak.zk.cluster.alias=cluster1cluster1.zk.list=localhost:12181# mysqlåœ°å€efak.driver=com.mysql.cj.jdbc.Driverefak.url=jdbc:mysql://127.0.0.1:3306/ke?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNullefak.username=rootefak.password=toortoor ä¿®æ”¹ç¯å¢ƒå˜é‡ 1234567vim /etc/profileexport JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.302.b08-0.el7_9.x86_64export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar.:$JAVA_HOME/lib/dt.jar.:$JAVA_HOME/lib/tools.jarexport PATH=$PATH:$JAVA_HOME/binexport KE_HOME=/root/kafka/kafka-eagle/efak-web-2.0.8export PATH=$PATH:$KE_HOME/binsource /etc/profile è®¿é—®","link":"/2024/02/18/kafka/"},{"title":"linuxæ–‡ä»¶ç³»ç»Ÿ","text":"æ–‡ä»¶ç³»ç»Ÿæ˜¯ä¸€ç§ç”¨äºç»„ç»‡å’Œç®¡ç†è®¡ç®—æœºå­˜å‚¨è®¾å¤‡ä¸Šæ•°æ®çš„ç³»ç»Ÿã€‚å®ƒå°†å­˜å‚¨è®¾å¤‡ä¸Šçš„ç‰©ç†ç©ºé—´åˆ’åˆ†ä¸ºé€»è¾‘ç»“æ„ï¼Œå¹¶æä¾›å¯¹æ•°æ®çš„è®¿é—®å’Œç®¡ç†æœºåˆ¶ã€‚ æ–‡ä»¶ç³»ç»Ÿçš„åŸºæœ¬åŠŸèƒ½åŒ…æ‹¬ï¼š å°†æ•°æ®ç»„ç»‡æˆæ–‡ä»¶å’Œç›®å½• æä¾›å¯¹æ–‡ä»¶çš„è¯»å†™è®¿é—® ç®¡ç†å­˜å‚¨ç©ºé—´ æä¾›æ–‡ä»¶å®‰å…¨å’Œä¿æŠ¤ å¸¸è§çš„æ–‡ä»¶ç³»ç»Ÿæœ‰ï¼š ext4ï¼šæœ€å¸¸ç”¨çš„ Linux æ–‡ä»¶ç³»ç»Ÿä¹‹ä¸€ï¼Œæ”¯æŒå¤§å®¹é‡å­˜å‚¨ã€é«˜æ€§èƒ½å’Œè‰¯å¥½çš„æ‰©å±•æ€§ xfsï¼šå¦ä¸€ç§é«˜æ€§èƒ½æ–‡ä»¶ç³»ç»Ÿï¼Œæ”¯æŒå¤§æ–‡ä»¶å’Œé«˜ I/O è´Ÿè½½ fat32ï¼šå…¼å®¹ Windows å’Œå…¶ä»–æ“ä½œç³»ç»Ÿçš„æ–‡ä»¶ç³»ç»Ÿï¼Œé€‚ç”¨äºéœ€è¦è·¨å¹³å°æ–‡ä»¶å…±äº«çš„åœºæ™¯ ntfsï¼šWindows çš„é»˜è®¤æ–‡ä»¶ç³»ç»Ÿï¼Œæ”¯æŒå¤§å®¹é‡å­˜å‚¨å’Œä¸€äº›é«˜çº§åŠŸèƒ½ï¼Œä¾‹å¦‚æ–‡ä»¶æƒé™å’ŒåŠ å¯† ext4 å’Œ xfs çš„åŒºåˆ« xfs ç›¸æ¯”äº ext4 æœ‰æ›´é«˜çš„æ€§èƒ½ï¼Œä¾‹å¦‚åœ¨ IO å¯†é›†å‹çš„è´Ÿè½½ä¸‹ ext4 çš„æœ€å¤§æ–‡ä»¶ç³»ç»Ÿå¤§å°ä¸º 1EBï¼Œè€Œ xfs çš„æœ€å¤§æ–‡ä»¶ç³»ç»Ÿå¤§å°ä¸º 8EB ext4 çš„æœ€å¤§æ–‡ä»¶å¤§å°ä¸º 16TBï¼Œè€Œ xfs çš„æœ€å¤§æ–‡ä»¶å¤§å°ä¸º 16EB ext4 ç›¸æ¯”äº xfs æœ‰ç€æ›´é«˜çš„å…¼å®¹æ€§ï¼Œè¢«å¤§å¤šæ•° linux å‘è¡Œç‰ˆéƒ½æ”¯æŒ","link":"/2024/03/17/linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"title":"MySQL","text":"MySQL æ˜¯ä¸€æ¬¾å…³ç³»å‹æ•°æ®åº“ç®¡ç†ç³»ç»Ÿã€‚ ä¸€ã€MySQLåŸºç¡€1.1 å®‰è£…MySQLdocker-compose 12345678910111213141516version: '3.8'services: db: image: mysql:5.7.35 command: --default-authentication-plugin=mysql_native_password restart: always ports: - 3306:3306 environment: MYSQL_ROOT_PASSWORD: toortoor adminer: image: adminer:latest restart: always ports: - 8080:8080 1.2 åŸºç¡€SQLè¯­å¥ åˆ·æ–°æƒé™ 1flush privileges; æ•°æ®åº“åŸºæœ¬æ“ä½œ 123456-- åˆ›å»ºcreate database [if not exists] `db_name`;-- åˆ é™¤drop database [if exists] `db_name`;-- ä½¿ç”¨use `db_name`; è¡¨åŸºæœ¬æ“ä½œ 12345678910111213141516171819202122232425-- åˆ›å»ºcreate table [if not exists] `table_name`;-- åˆ é™¤drop table [if exists] `table_name`;-- æŸ¥çœ‹describe `table_name`;-- åˆ›å»ºä¸€ä¸ªå­¦ç”Ÿè¡¨create table if not exists `students`( -- åˆ›å»ºidåˆ—ï¼Œæ•°æ®ç±»å‹ä¸º4ä½çš„intç±»å‹ï¼Œä¸å…è®¸ä¸ºç©ºï¼Œè‡ªå¢ `id` int(4) not null auto_increment comment 'å­¦å·', -- åˆ›å»ºnameåˆ—ï¼Œæ•°æ®ç±»å‹ä¸º30ä½çš„varcharç±»å‹ï¼Œä¸å…è®¸ä¸ºç©ºï¼Œé»˜è®¤å€¼ä¸ºåŒ¿å `name` varchar(30) not null default 'åŒ¿å' comment 'å§“å', `pwd` varchar(20) not null default '123456' comment 'å¯†ç ', `gender` varchar(2) not null default 'å¥³' comment 'æ€§åˆ«', -- åˆ›å»ºbirthdayåˆ—ï¼Œdatetimeç±»å‹ï¼Œé»˜è®¤ä¸ºç©º `brithday` datetime default null comment 'å‡ºç”Ÿæ—¥æœŸ', `address` varchar(100) default null comment 'å®¶åº­ä½å€', `email` varchar(50) default null comment 'é‚®ç®±', -- è®¾ç½®ä¸»é”®ï¼Œä¸€èˆ¬ä¸€ä¸ªè¡¨åªæœ‰ä¸€ä¸ªä¸»é”® primary key(`id`))-- è®¾ç½®å¼•æ“engine=innodb-- é»˜è®¤ç¼–ç default charset=utf8; ä¿®æ”¹è¡¨ 12345678910-- ä¿®æ”¹è¡¨åç§°alter table `table_name` rename as new_`table_name`;-- å¢åŠ å­—æ®µalter table `table_name` add age int(10);-- ä¿®æ”¹çº¦æŸalter table `table_name` modify age varchar(10);-- é‡å‘½åå­—æ®µalter table `table_name` change age new_age int(10);-- åˆ é™¤å­—æ®µalter table `table_name` drop age; æŸ¥çœ‹åˆ›å»ºè¯­å¥ 12show create database `db_name`;show create table `table_name`; 1.3 å¼•æ“INNODBå’ŒMYISAMåŒºåˆ« ç‰¹æ€§ INNODB MYISAM äº‹åŠ¡ æ”¯æŒ ä¸æ”¯æŒ æ•°æ®è¡Œé”å®š æ”¯æŒ ä¸æ”¯æŒ å¤–é”® æ”¯æŒ ä¸æ”¯æŒ å…¨æ–‡ç´¢å¼• ä¸æ”¯æŒ æ”¯æŒ ç©ºé—´å ç”¨ çº¦ä¸ºMYSIAMçš„2å€ è¾ƒå° ä¸åŒå¼•æ“åœ¨æ–‡ä»¶ä¸Šçš„åŒºåˆ« innodbï¼š *.frmï¼šè¡¨ç»“æ„å®šä¹‰æ–‡ä»¶ ibdata1ï¼šæ•°æ®æ–‡ä»¶ mysiamï¼š *.frmï¼šè¡¨ç»“æ„å®šä¹‰æ–‡ä»¶ *.MYDï¼šæ•°æ®æ–‡ä»¶ *.MYIï¼šç´¢å¼•æ–‡ä»¶ äºŒã€MySQLæ•°æ®æ“ä½œ2.1 å¤–é”®å¤–é”®å°±æ˜¯ä¸€ä¸ªè¡¨çš„æŸä¸€åˆ—å»å¼•ç”¨å¦ä¸€ä¸ªè¡¨çš„æŸä¸€åˆ— 12345678910111213141516-- è¯¥ç¤ºä¾‹ä¸ºstudentsä¸­çš„grade_idåˆ—å¼•ç”¨gradeä¸­çš„grade_idåˆ—create table `grade`( `grade_id` int(10) not null auto_increment comment 'å¹´çº§' primary key(`grade_id`))engine=innodb default charset=utf8create table `students`( `id` int(4) not null auto_increment comment 'å­¦å·', `name` varchar(30) not null default 'åŒ¿å' comment 'å§“å', `grade_id` int(10) not null comment 'å¹´çº§', primary key(`id`), -- å®šä¹‰å¤–é”® key `FK_grade_id` (`grade_id`), -- ç»™å¤–é”®æ·»åŠ çº¦æŸ constraint `FK_grade_id` foreign key (`grade_id`) references `grade` (`grade_id`))engine=innodb default charset=utf8 å¦‚æœè¦ç»™å·²ç»å­˜åœ¨çš„è¡¨æ·»åŠ å¤–é”® 1alter table `table_name` add constraint `FK_name` foreign key (`åˆ—åç§°`) references `å¼•ç”¨çš„è¡¨å` (`å¼•ç”¨çš„åˆ—åç§°`) åˆ é™¤å¤–é”® 1alter table `table_name` drop foreign key 'FK_name' 2.2 DMLæ•°æ®æ“çºµè¯­è¨€2.2.1 insert1234insert into `table_name`(`å­—æ®µ1`,`å­—æ®µ2`,`å­—æ®µ3`) values('å€¼1'),('å€¼2'),('å€¼3');insert into `students`(`name`) values('cqm'),('lwt');-- å­—æ®µå¯ä»¥çœç•¥ï¼Œä½†åé¢çš„å€¼å¿…é¡»ä¸€ä¸€å¯¹åº”insert into `students`(`name`,`pwd`,`email`) values('lwt','111','lwt@qq.com'); 2.2.2 update1234567-- å¦‚æœä¸æŒ‡å®šæ¡ä»¶ï¼Œé‚£ä¹ˆä¼šä¿®æ”¹æ‰€æœ‰çš„å€¼update `table_name` set `å­—æ®µ`='å€¼' where æ¡ä»¶;-- æ¡ä»¶å¯ä»¥æ˜¯ =|&lt;|&gt;|!=|between|and|or ç­‰ç­‰update `students` set `name`='handsome_cqm' where `id`=1;update `students` set `name`='cqm' where `name`='handsome_cqm'update `students` set `name`='newlwt',`email`='new@qq.com' where `name`='lwt';update `students` set `name`='cqm' where id between 1 and 2; 2.2.3 delete1234delete from `table_name` where æ¡ä»¶;delete from `students` where `id`=1;-- æ¸…ç©ºè¡¨truncate `table_name`; delete å’Œ truncate åŒºåˆ«ï¼š éƒ½å¯ä»¥æ¸…ç©ºè¡¨ï¼Œéƒ½ä¸ä¼šåˆ é™¤è¡¨ç»“æ„ truncate å¯ä»¥é‡ç½®è‡ªå¢åˆ—ï¼Œä¸”ä¸ä¼šå½±å“äº‹åŠ¡ delete æ¸…ç©ºè¡¨åï¼Œå¦‚æœå¼•æ“æ˜¯ innodbï¼Œé‡å¯æ•°æ®åº“è‡ªå¢åˆ—å°±ä¼šå˜å›1ï¼Œå› ä¸ºæ˜¯å­˜å‚¨åœ¨å†…å­˜ä¸­çš„ï¼›å¦‚æœå¼•æ“æ˜¯ myisamï¼Œåˆ™ä¸ä¼šï¼Œå› ä¸ºæ˜¯å­˜å‚¨åœ¨æ–‡ä»¶ä¸­çš„ 2.3 DQLæ•°æ®åº“æŸ¥è¯¢è¯­è¨€2.3.1 select æŸ¥è¯¢æ‰€æœ‰æ•°æ® 1select * from `table_name`; æŸ¥è¯¢æŸåˆ—æ•°æ® 1select `name`,`gander` from `students`; ç»™å­—æ®µç»“æœèµ·åˆ«å 1select `name` as 'å§“å',`gender` as 'æ€§åˆ«' from `students`; concat å‡½æ•° 1select concat('å§“åï¼š',`name`) from `students`; å»é‡ 1select distinct `å­—æ®µ` from `table_name` æ‰¹é‡æ“ä½œæ•°æ® 1select `score`+1 as `new_score` from `table_name`; 2.3.2 where é€»è¾‘è¿ç®—ç¬¦è¿ç”¨ 123select `score` from `table_name` where `score` &gt;= 95 and `score` &lt;= 100;select `score` from `table_name` where `score` between 95 and 100;select `score` from `table_name` where not `score` != 95 and `score` != 100; æ¨¡ç³ŠæŸ¥è¯¢ è¿ç®—ç¬¦ è¯­æ³• æè¿° is null a is null a ä¸ºç©ºï¼Œç»“æœä¸ºçœŸ is not null a is not null a ä¸ä¸ºç©ºï¼Œç»“æœä¸ºçœŸ between a between b and c è‹¥ a åœ¨ b å’Œ c ä¹‹é—´ï¼Œç»“æœä¸ºçœŸ like a like b å¦‚æœ a åŒ¹é… bï¼Œç»“æœä¸ºçœŸ in a in ( b,c,d,e ) å¦‚æœ a åœ¨æŸä¸ªé›†åˆä¸­çš„å€¼ç›¸åŒï¼Œç»“æœä¸ºçœŸ æŸ¥æ‰¾èŠ±åå†Œä¸­å§“é™ˆçš„åå­— 1234-- %:åŒ¹é…ä¸€ä¸ªæˆ–å¤šä¸ªå­—ç¬¦-- _:åŒ¹é…ä¸€ä¸ªå­—ç¬¦select `name` from `table_name` where `name` like 'é™ˆ%';select `name` from `table_name` where `name` like 'é™ˆ_æ˜'; æŸ¥æ‰¾ç‰¹å®šå­¦å·çš„ä¿¡æ¯ 1select `name` from `table_name` where `id` in (1,2,3); æŸ¥æ‰¾åœ°å€ä¸ºç©ºæˆ–ä¸ç©ºçš„åŒå­¦ 12select `name` from `table_name` where `address` is null;select `name` from `table_name` where `address` is not null; 2.3.3 è”è¡¨æŸ¥è¯¢è”è¡¨æŸ¥è¯¢åŒ…æ‹¬ï¼š innerï¼ˆå†…è¿æ¥ï¼‰ï¼šå¦‚æœè¡¨ä¸­æœ‰è‡³å°‘ä¸€ä¸ªåŒ¹é…ï¼Œåˆ™è¿”å›è¡Œ leftï¼ˆå¤–è¿æ¥ï¼‰ï¼šå³ä½¿å³è¡¨ä¸­æ²¡æœ‰åŒ¹é…ï¼Œä¹Ÿä»å·¦è¡¨è¿”å›æ‰€æœ‰çš„è¡Œ rightï¼ˆå¤–è¿æ¥ï¼‰ï¼šå³ä½¿å·¦è¡¨ä¸­æ²¡æœ‰åŒ¹é…ï¼Œä¹Ÿä»å³è¡¨è¿”å›æ‰€æœ‰çš„è¡Œ fullï¼ˆå¤–è¿æ¥ï¼‰ï¼šåªè¦å…¶ä¸­ä¸€ä¸ªè¡¨ä¸­å­˜åœ¨åŒ¹é…ï¼Œåˆ™è¿”å›è¡Œ inner å®é™…å°±æ˜¯å–ä¸¤ä¸ªè¡¨çš„äº¤é›†ï¼Œä¾‹å¦‚æœ‰ä¸¤ä¸ªè¡¨ï¼Œä¸€ä¸ªè¡¨æœ‰å­¦ç”Ÿçš„åŸºæœ¬ä¿¡æ¯ï¼Œå¦ä¸€ä¸ªè¡¨æœ‰å­¦ç”Ÿçš„æˆç»©ï¼Œä¸¤ä¸ªè¡¨éƒ½æœ‰å­¦ç”Ÿçš„å­¦å·åˆ—ï¼Œé‚£ä¹ˆå°±å¯ä»¥è”åˆèµ·æ¥æŸ¥è¯¢ 1select `name`,`subjectno`,`score` from `students` inner join `result` where student.id = result.id left å‡è®¾å­¦ç”Ÿè¡¨ä¸­æœ‰ ccc è¿™ä¹ˆä¸€ä¸ªå­¦ç”Ÿï¼Œä½†æˆç»©è¡¨é‡Œæ²¡æœ‰ ccc å­¦ç”Ÿçš„æˆç»©ï¼Œå¦‚æœä½¿ç”¨äº†å·¦è¿æ¥ï¼Œå·¦è¡¨æ˜¯å­¦ç”Ÿè¡¨ï¼Œå³è¡¨æ˜¯æˆç»©è¡¨ï¼Œé‚£ä¹ˆä¹Ÿä¼šè¿”å› cqm å­¦ç”Ÿçš„å€¼ï¼Œæ˜¾ç¤ºä¸ºç©º right ç›¸åï¼Œå¦‚æœæˆç»©è¡¨é‡Œæœ‰ä¸ª ddd å­¦ç”Ÿçš„æˆç»©ï¼Œä½†å­¦ç”Ÿè¡¨é‡Œæ²¡æœ‰è¿™ä¸ªå­¦ç”Ÿçš„ä¿¡æ¯ï¼Œå¦‚æœä½¿ç”¨äº†å³è¿æ¥ï¼Œå·¦è¡¨æ˜¯å­¦ç”Ÿè¡¨ï¼Œå³è¡¨æ˜¯æˆç»©è¡¨ï¼Œé‚£ä¹ˆä¹Ÿä¼šè¿”å› ddd å­¦ç”Ÿçš„æˆç»©ï¼Œæ³¨æ„è¿™æ—¶å€™å°±çœ‹ä¸åˆ° ccc å­¦ç”Ÿçš„æˆç»©ä¿¡æ¯äº†ï¼Œå› ä¸ºå·¦è¡¨ä¸­æ²¡æœ‰ ccc å­¦ç”Ÿçš„æˆç»©ä¿¡æ¯ é€šè¿‡è”è¡¨æŸ¥è¯¢å°±å¯ä»¥æŸ¥å‡ºç¼ºè€ƒçš„åŒå­¦ æŸ¥è¯¢å‚åŠ è€ƒè¯•äº†çš„åŒå­¦ä¿¡æ¯ 1select distinct `name` from `students` right join `result` on students.id = result.id where `score` is not null; æŸ¥è¯¢å‚åŠ äº†è€ƒè¯•çš„åŒå­¦ä»¥åŠæ‰€å¯¹åº”çš„å­¦ç§‘æˆç»© 2.3.4 whereå’Œonçš„åŒºåˆ«åœ¨è¿›è¡Œè”è¡¨æŸ¥è¯¢çš„æ—¶å€™ï¼Œæ•°æ®åº“éƒ½ä¼šåœ¨ä¸­é—´ç”Ÿæˆä¸€å¼ ä¸´æ—¶è¡¨ï¼Œåœ¨ä½¿ç”¨å¤–è¿æ¥æ—¶ï¼Œon å’Œ where åŒºåˆ«å¦‚ä¸‹ï¼š on æ¡ä»¶æ˜¯åœ¨ç”Ÿæˆä¸´æ—¶è¡¨æ—¶ä½¿ç”¨çš„æ¡ä»¶ï¼Œå®ƒä¸ç®¡ on ä¸­çš„æ¡ä»¶æ˜¯å¦ä¸ºçœŸï¼Œéƒ½ä¼šè¿”å›å·¦è¾¹è¡¨ä¸­çš„è®°å½•ã€‚ where æ¡ä»¶æ˜¯åœ¨ä¸´æ—¶è¡¨ç”Ÿæˆå¥½åï¼Œå†å¯¹ä¸´æ—¶è¡¨è¿›è¡Œè¿‡æ»¤çš„æ¡ä»¶ã€‚è¿™æ—¶å·²ç»æ²¡æœ‰ left join çš„å«ä¹‰ï¼ˆå¿…é¡»è¿”å›å·¦è¾¹è¡¨çš„è®°å½•ï¼‰äº†ï¼Œæ¡ä»¶ä¸ä¸ºçœŸçš„å°±å…¨éƒ¨è¿‡æ»¤æ‰ã€‚ å¦‚æœæ˜¯ inner joinï¼Œåˆ™æ— åŒºåˆ« 2.3.5 è‡ªè¿æ¥è‡ªè¿æ¥å®é™…ä¸Šå°±æ˜¯ä¸€å¼ è¡¨ä¸è‡ªå·±è¿æ¥ï¼Œå°†ä¸€å¼ è¡¨æ‹†ä¸ºä¸¤å¼ è¡¨ åŸè¡¨ categoryid pid categoryname 2 1 è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯å­¦é™¢ 3 1 å¿ƒç†å­¦é™¢ 4 1 ä½“è‚²å­¦é™¢ 5 2 python 6 3 å¿ƒç†å­¦ 7 4 çŸ­è·‘ 8 4 ç¯®çƒ çˆ¶ç±»è¡¨ category categoryname 2 è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯å­¦é™¢ 3 å¿ƒç†å­¦é™¢ 4 ä½“è‚²å­¦é™¢ å­ç±»è¡¨ category æ‰€å±çˆ¶ç±» categoryname 5 è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯å­¦é™¢ python 6 å¿ƒç†å­¦é™¢ å¿ƒç†å­¦ 7 ä½“è‚²å­¦é™¢ çŸ­è·‘ 8 ä½“è‚²å­¦é™¢ ç¯®çƒ è‡ªæŸ¥è¯¢ç»“æœ 2.3.6 åˆ†é¡µå’Œæ’åºæ’åº order by descï¼šé™åº ascï¼šå‡åº 12-- è¯­æ³•order by desc|asc æŸ¥è¯¢è¯­æ–‡æˆç»©å¹¶æ’åº åˆ†é¡µ limit 12-- è¯­æ³•limit èµ·å§‹å€¼,é¡µé¢æ˜¾ç¤ºå¤šå°‘æ¡æ•°æ® æ‰“å°ç¬¬ä¸€é¡µè¯­æ–‡æˆç»© æ‰“å°ç¬¬äºŒé¡µæ•°å­¦æˆç»© åˆ†é¡µå’Œæ’åºé…åˆèµ·æ¥å°±å¯ä»¥æŸ¥è¯¢å­¦ç”Ÿçš„å‰å‡ åæˆç»©ï¼Œä¾‹å¦‚è¯­æ–‡æˆç»©å‰ä¸‰å 2.3.7 å­æŸ¥è¯¢æœ¬è´¨ä¸Šå°±æ˜¯åœ¨åˆ¤æ–­è¯­å¥é‡ŒåµŒå¥—ä¸€ä¸ªæŸ¥è¯¢è¯­å¥ï¼Œä¾‹å¦‚è¦æŸ¥è¯¢æ‰€æœ‰è¯­æ–‡æˆç»©å¹¶é™åºæ’åºï¼Œå¯ä»¥é€šè¿‡è”è¡¨æŸ¥è¯¢å’Œå­æŸ¥è¯¢ä¸¤ç§æ–¹å¼å®ç° 2.4 èšåˆå‡½æ•°2.4.1 countcount å‡½æ•°ç”¨äºè®¡æ•°ï¼Œä¾‹å¦‚æŸ¥è¯¢æœ‰å¤šå°‘å­¦ç”Ÿ 1select count(`name`) from students; å‡½æ•°å†…æ‰€å¸¦çš„å‚æ•°ä¸åŒï¼ŒèƒŒåè¿è¡Œä¹Ÿä¸åŒï¼š count(å­—æ®µ)ï¼šä¼šå¿½ç•¥ç©ºå€¼ï¼Œä¸è®¡æ•° count(*)ï¼šä¸ä¼šå¿½ç•¥ç©ºå€¼ count(1)ï¼šä¸ä¼šå¿½ç•¥ç©ºå€¼ ä»æ•ˆç‡ä¸Šçœ‹ï¼šå¦‚æœæŸ¥è¯¢çš„åˆ—ä¸ºä¸»é”®ï¼Œé‚£ä¹ˆ count(å­—æ®µ) æ¯” count(1) å¿«ï¼Œä¸ä¸ºä¸»é”®åˆ™åä¹‹ï¼›å¦‚æœè¡¨ä¸­åªæœ‰ä¸€åˆ—ï¼Œåˆ™ count(*) æœ€å¿« 2.4.2 sumé¡¾åæ€ä¹‰ï¼Œç”¨äºæ±‚å’Œï¼Œä¾‹å¦‚æŸ¥è¯¢æ‰€æœ‰æˆç»©ä¹‹å’Œ 1select sum(`score`) as 'æ€»åˆ†' from result 2.4.3 avg1select avg(`score`) as 'å¹³å‡åˆ†' from result 2.4.4 maxå’Œmin1select max(`score`) as 'æœ€é«˜åˆ†' from result 1select min(`score`) as 'æœ€ä½åˆ†' from result æŸ¥è¯¢æ‰€æœ‰ç§‘ç›®çš„å¹³å‡åˆ†ã€æœ€é«˜åˆ†å’Œæœ€ä½åˆ† 123456select subjectname, avg(studentresult), max(studentresult), min(studentresult)from `result`inner join `subject`on `result`.subjectno = `subject`.subjectno-- å®šä¹‰å­—æ®µè¿›è¡Œåˆ†ç»„group by result.subjectno; é€šè¿‡åˆ†ç»„åçš„æ¬¡è¦æ¡ä»¶ï¼ŒæŸ¥è¯¢å¹³å‡åˆ†å¤§äº 80 åˆ†çš„ç§‘ç›® 1234567select subjectname, avg(studentresult) as å¹³å‡åˆ†from `result`inner join `subject`on `result`.subjectno = `subject`.subjectnogroup by `result`.subjectno-- åˆ†ç»„åçš„æ¬¡è¦æ¡ä»¶having å¹³å‡åˆ† &gt; 80; 2.5 MD5åŠ å¯†åœ¨æ•°æ®åº“ä¸­ï¼Œå¯†ç ç­‰æ•æ„Ÿä¿¡æ¯éƒ½ä¸ä¼šä»¥æ˜æ–‡çš„å½¢å¼å­˜å‚¨çš„ï¼Œå¯ä»¥é€šè¿‡md5 è¿›è¡ŒåŠ å¯† 12-- æ›´æ–°å¯†ç ä»¥è¾¾æˆåŠ å¯†update students set pwd=md5(pwd); 12-- æ’å…¥çš„æ—¶å€™å°±è¿›è¡ŒåŠ å¯†insert into students values(1, 'cqm', md5('12345')) 2.6 äº‹åŠ¡äº‹åŠ¡å°±æ˜¯ä¸€ç³»åˆ— SQL è¯­å¥ï¼Œè¦ä¹ˆå…¨éƒ¨æ‰§è¡Œï¼Œè¦ä¹ˆå…¨éƒ¨ä¸æ‰§è¡Œã€‚ äº‹åŠ¡çš„ç‰¹æ€§ï¼ˆACIDï¼‰ï¼š åŸå­æ€§ï¼ˆAtomicityï¼‰ï¼šæ‰€æœ‰æ“ä½œè¦ä¹ˆå…¨éƒ¨æˆåŠŸï¼Œè¦ä¹ˆå…¨éƒ¨å¤±è´¥ ä¸€è‡´æ€§ï¼ˆConsistencyï¼‰ï¼šäº‹åŠ¡çš„æ‰§è¡Œçš„å‰åæ•°æ®çš„å®Œæ•´æ€§ä¿æŒä¸€è‡´ éš”ç¦»æ€§ï¼ˆIsolationï¼‰ï¼šä¸€ä¸ªäº‹åŠ¡æ‰§è¡Œçš„è¿‡ç¨‹ä¸­ï¼Œä¸å—åˆ°åˆ«çš„äº‹åŠ¡çš„å¹²æ‰° æŒä¹…æ€§ï¼ˆDurabilityï¼‰ï¼šäº‹åŠ¡ä¸€æ—¦ç»“æŸï¼Œå°±ä¼šæŒä¹…åˆ°æ•°æ®åº“ éš”ç¦»æ‰€å¯¼è‡´çš„ä¸€äº›é—®é¢˜ï¼š è„è¯»ï¼šä¸€ä¸ªäº‹åŠ¡è¯»å–åˆ°äº†å¦ä¸€ä¸ªäº‹åŠ¡æ²¡æäº¤çš„æ•°æ® ä¸å¯é‡å¤è¯»ï¼šä¸€ä¸ªäº‹åŠ¡çš„å¤šæ¬¡æŸ¥è¯¢ç»“æœä¸åŒï¼Œæ˜¯å› ä¸ºæŸ¥è¯¢æœŸé—´æ•°æ®è¢«å¦ä¸€ä¸ªäº‹åŠ¡æäº¤è€Œä¿®æ”¹äº† è™šè¯»ï¼šä¸€ä¸ªäº‹åŠ¡Aåœ¨è¿›è¡Œä¿®æ”¹æ•°æ®çš„æ“ä½œæ—¶ï¼Œå¦ä¸€ä¸ªäº‹åŠ¡Bæ’å…¥äº†æ–°çš„ä¸€è¡Œæ•°æ®ï¼Œè€Œå¯¹äºäº‹åŠ¡Aæ¥çœ‹äº‹åŠ¡Bæ·»åŠ çš„é‚£è¡Œå°±æ²¡æœ‰åšä¿®æ”¹ï¼Œå°±å‘ç”Ÿäº†è™šè¯» äº‹åŠ¡å…³é—­è‡ªåŠ¨æäº¤ 1set autocommit = 0; äº‹åŠ¡å¼€å¯ 1start transaction; äº‹åŠ¡æäº¤ 1commit; äº‹åŠ¡å›æ»š 1rollback; äº‹åŠ¡ç»“æŸ 1set autocommit = 1; ä¿å­˜ç‚¹ 123456-- æ·»åŠ ä¿å­˜ç‚¹savepoint ä¿å­˜ç‚¹åç§°-- å›æ»šåˆ°ä¿å­˜ç‚¹rollback to savepoint ä¿å­˜ç‚¹åç§°-- åˆ é™¤ä¿å­˜ç‚¹release savepoint ä¿å­˜ç‚¹åç§° 2.7 ç´¢å¼•ç´¢å¼•æ˜¯å¸®åŠ© MySQL é«˜æ•ˆè·å–æ•°æ®çš„æ•°æ®ç»“æ„ã€‚ ç´¢å¼•çš„åˆ†ç±»ï¼š ä¸»é”®ç´¢å¼•ï¼ˆprimary keyï¼‰ï¼šåªæœ‰ä¸€åˆ—å¯ä»¥ä½œä¸ºä¸»é”®ï¼Œä¸”ä¸»é”®çš„å€¼ä¸å¯é‡å¤ï¼Œä¸€èˆ¬ç”¨äºç”¨æˆ·IDä¹‹ç±»çš„ å”¯ä¸€ç´¢å¼•ï¼ˆunique keyï¼‰ï¼šå”¯ä¸€ç´¢å¼•å¯ä»¥æœ‰å¤šä¸ªï¼Œä¸”å€¼å”¯ä¸€ å¸¸è§„ç´¢å¼•ï¼ˆkeyï¼‰ï¼šä¾‹å¦‚ä¸€ä¸ªè¡¨ä¸­çš„æ•°æ®ç»å¸¸ç”¨åˆ°ï¼Œå°±å¯ä»¥æ·»åŠ ä¸ªå¸¸è§„ç´¢å¼• å…¨æ–‡ç´¢å¼•ï¼ˆfulltextï¼‰ï¼šå¿«é€Ÿå®šä½æ•°æ® æŸ¥çœ‹æŸä¸ªè¡¨çš„æ‰€æœ‰ç´¢å¼• 1show index from `table_name`; æ·»åŠ å…¨æ–‡ç´¢å¼• 1alter table `table_name` add fulltext index `index_name`(`è¦æ·»åŠ ç´¢å¼•çš„å­—æ®µå`); æ·»åŠ å¸¸è§„ç´¢å¼• 12-- è¿™æ ·ä¼šç»™è¡¨ä¸­æŸä¸ªå­—æ®µçš„æ•°æ®å…¨éƒ¨éƒ½æ·»åŠ ä¸Šç´¢å¼•ï¼Œåœ¨æ•°æ®é‡å¤§çš„æ—¶å€™å¯ä»¥æé«˜æŸ¥è¯¢æ•ˆç‡create index `id_table_name_å­—æ®µå` on `table_name`('å­—æ®µå'); ç´¢å¼•ä½¿ç”¨åŸåˆ™ï¼š å¹¶ä¸æ˜¯ç´¢å¼•è¶Šå¤šè¶Šå¥½ ä¸è¦å¯¹è¿›ç¨‹å˜åŠ¨çš„æ•°æ®æ·»åŠ ç´¢å¼• æ•°æ®é‡å°çš„è¡¨ä¸éœ€è¦ç´¢å¼• ç´¢å¼•ä¸€èˆ¬ç”¨äºå¸¸æŸ¥è¯¢çš„å­—æ®µä¸Š 2.8 æƒé™ç®¡ç†åœ¨ MySQL ä¸­ï¼Œç”¨æˆ·è¡¨ä¸º mysql.userï¼Œè€Œæƒé™ç®¡ç†å…¶å®éƒ½æ˜¯åœ¨è¯¥è¡¨ä¸Šæ“ä½œã€‚ åˆ›å»ºç”¨æˆ· 123456-- hostå¯ä»¥ä¸ºä»¥ä¸‹çš„å€¼-- %:å…è®¸æ‰€æœ‰ipè¿æ¥-- localhost:åªå…è®¸æœ¬åœ°è¿æ¥-- 192.168.88.%:åªå…è®¸ç»™ç½‘æ®µè¿æ¥-- 192.168.88.10:åªå…è®¸è¯¥ipè¿æ¥create user 'user_name'@'host' identified by 'user_password'; ä¿®æ”¹å½“å‰ç”¨æˆ·å¯†ç  1set password = password('new_password'); ä¿®æ”¹æŒ‡å®šç”¨æˆ·å¯†ç  1set password for user_name = password('new_password'); é‡å‘½å 1rename user user_name to new_user_name; æˆæƒ 12-- æƒé™:selectã€insertã€deleteç­‰ç­‰ï¼Œæ‰€æœ‰æƒé™åˆ™ä¸ºallgrant æƒé™ on `db_name`.`table_name` to 'user_name'@'host'; æˆäºˆæŸä¸ªç”¨æˆ·éƒ¨åˆ†æƒé™ 1grant select,insert on mysql.user to 'cqm'@'%'; ç»™æŸä¸ªç”¨æˆ·æˆäºˆå…¨éƒ¨æ•°æ®åº“çš„æƒé™ 12-- åŸºæœ¬æƒé™éƒ½æœ‰ï¼Œä½†ä¸ä¼šç»™grantæƒé™grant all privileges on *.* to 'cqm'@'%'; åˆ é™¤ç”¨æˆ· 1drop user 'user_name'@'host'; å–æ¶ˆæƒé™ 1revoke æƒé™ on `db_name`.`table_name` from 'user_name'@'host'; æŸ¥è¯¢ç”¨æˆ·æƒé™ 1show grants for 'user_name'@'host'; 2.9 å¤‡ä»½å¤‡ä»½æ–‡ä»¶éƒ½æ˜¯ä»¥ .sql ä¸ºåç¼€çš„æ–‡ä»¶ã€‚ å¯¼å‡º 12345# -d:è¦æ“ä½œçš„æ•°æ®åº“# -h:æŒ‡å®šä¸»æœº# -P:æŒ‡å®šç«¯å£# --all-databases:æ“ä½œæ‰€æœ‰æ•°æ®åº“mysqldump -uroot -ppassword -d db1_name db2_name &gt; db_backup.sql å¯¼å…¥ 1mysqldump -uroot -ppassword -d db_name &lt; db_backup.sql ä¸‰ã€MySQLé…ç½®3.1 ä¸»ä»åŒæ­¥/å¤åˆ¶MySQL ä¸»ä»åŒæ­¥å³æ¯å½“ä¸»æ•°æ®åº“è¿›è¡Œäº†æ•°æ®çš„æ“ä½œåï¼Œå°±ä¼šå°†æ“ä½œå†™å…¥ binlog æ–‡ä»¶ï¼Œä»æ•°æ®åº“ä¼šå¯åŠ¨ä¸€ä¸ª IO çº¿ç¨‹å»ç›‘æ§ä¸»æ•°æ®åº“çš„ binlog æ–‡ä»¶ï¼Œå¹¶å°† binlog æ–‡ä»¶çš„å†…å®¹å†™å…¥è‡ªå·±çš„ relaylog æ–‡ä»¶ä¸­ï¼ŒåŒæ—¶ä¼šå¯åŠ¨ä¸€ä¸ª SQL çº¿ç¨‹å»ç›‘æ§ relaylog æ–‡ä»¶ï¼Œå¦‚æœå‘ç”Ÿå˜åŒ–å°±æ›´æ–°æ•°æ®ã€‚ ä¸»ä»å¤åˆ¶çš„ç±»å‹ï¼š statementæ¨¡å¼ï¼ˆsbrï¼‰ï¼šåªæœ‰ä¿®æ”¹æ•°æ®çš„ SQL è¯­å¥ä¼šè®°å½•åˆ° binlog ä¸­ï¼Œä¼˜ç‚¹æ˜¯å‡å°‘äº†æ—¥å¿—é‡ï¼ŒèŠ‚çœ IOï¼Œæé«˜æ€§èƒ½ï¼Œä¸è¶³æ˜¯å¯èƒ½ä¼šå¯¼è‡´ä¸»ä»èŠ‚ç‚¹ä¹‹é—´çš„æ•°æ®æœ‰å·®å¼‚ã€‚ rowæ¨¡å¼ï¼ˆrbrï¼‰ï¼šä»…è®°å½•è¢«ä¿®æ”¹çš„æ•°æ®ï¼Œä¸æ€•æ— æ³•æ­£ç¡®å¤åˆ¶çš„é—®é¢˜ï¼Œä½†ä¼šäº§ç”Ÿå¤§é‡çš„ binlogã€‚ mixedæ¨¡å¼ï¼ˆmbrï¼‰ï¼šsbr å’Œ rbr çš„æ··åˆæ¨¡å¼ï¼Œä¸€èˆ¬å¤åˆ¶ç”¨ sbrï¼Œsbr æ— æ³•å¤åˆ¶çš„ç”¨ rbrã€‚ ä¸»ä»åŒæ­¥å®ç° docker-compose.yaml 1234567891011121314151617181920212223version: '3.8'services: mysql_master: image: mysql:5.7.35 command: --default-authentication-plugin=mysql_native_password restart: always environment: MYSQL_ROOT_PASSWORD: toortoor ports: - 3306:3306 volumes: - ./master/my.cnf:/etc/mysql/my.cnf mysql_slave: image: mysql:5.7.35 command: --default-authentication-plugin=mysql_native_password restart: always environment: MYSQL_ROOT_PASSWORD: toortoor ports: - 3307:3306 volumes: - ./slave/my.cnf:/etc/mysql/my.cnf master/my.cnf 12345678910111213[mysqld]server-id = 1 #èŠ‚ç‚¹IDï¼Œç¡®ä¿å”¯ä¸€log-bin = mysql-bin #å¼€å¯mysqlçš„binlogæ—¥å¿—åŠŸèƒ½sync_binlog = 1 #æ§åˆ¶æ•°æ®åº“çš„binlogåˆ·åˆ°ç£ç›˜ä¸Šå»ï¼Œ0ä¸æ§åˆ¶ï¼Œæ€§èƒ½æœ€å¥½ï¼›1æ¯æ¬¡äº‹ç‰©æäº¤éƒ½ä¼šåˆ·åˆ°æ—¥å¿—æ–‡ä»¶ä¸­ï¼Œæ€§èƒ½æœ€å·®ï¼Œæœ€å®‰å…¨binlog_format = mixed #binlogæ—¥å¿—æ ¼å¼ï¼Œmysqlé»˜è®¤é‡‡ç”¨statementï¼Œå»ºè®®ä½¿ç”¨mixedexpire_logs_days = 7 #binlogè¿‡æœŸæ¸…ç†æ—¶é—´max_binlog_size = 100m #binlogæ¯ä¸ªæ—¥å¿—æ–‡ä»¶å¤§å°binlog_cache_size = 4m #binlogç¼“å­˜å¤§å°max_binlog_cache_size= 512m #æœ€å¤§binlogç¼“å­˜å¤§binlog-ignore-db=mysql #ä¸ç”Ÿæˆæ—¥å¿—æ–‡ä»¶çš„æ•°æ®åº“ï¼Œå¤šä¸ªå¿½ç•¥æ•°æ®åº“å¯ä»¥ç”¨é€—å·æ‹¼æ¥ï¼Œæˆ–è€…å¤åˆ¶è¿™å¥è¯ï¼Œå†™å¤šè¡Œauto-increment-offset = 1 #è‡ªå¢å€¼çš„åç§»é‡auto-increment-increment = 1 #è‡ªå¢å€¼çš„è‡ªå¢é‡slave-skip-errors = all #è·³è¿‡ä»åº“é”™è¯¯ slave/my.cnf 1234567[mysqld]server-id = 2log-bin=mysql-binrelay-log = mysql-relay-binreplicate-wild-ignore-table=mysql.%replicate-wild-ignore-table=test.%replicate-wild-ignore-table=information_schema.% åœ¨ master åˆ›å»ºå¤åˆ¶ç”¨æˆ·å¹¶æˆæƒ 123create user 'repl_user'@'%' identified by 'toortoor';grant replication slave on *.* to 'repl_user'@'%' identified by 'toortoor';flush privileges; æŸ¥çœ‹ master çŠ¶æ€ 123456show master status;+------------------+----------+...| File | Position |...+------------------+----------+...| mysql-bin.000003 | 844 |...+------------------+----------+... åœ¨ä»æ•°æ®åº“é…ç½® 123456789change master toMASTER_HOST = '172.19.0.3',MASTER_USER = 'repl_user', MASTER_PASSWORD = 'toortoor',MASTER_PORT = 3306,MASTER_LOG_FILE='mysql-bin.000003',MASTER_LOG_POS=844,MASTER_RETRY_COUNT = 60,MASTER_HEARTBEAT_PERIOD = 10000; å¯åŠ¨ä»é…ç½® 12start slave;show slave status\\G; å¦‚æœé…ç½®å¤±è´¥ï¼Œå¯ä»¥æ‰§è¡Œ 12stop slave;set global sql_slave_skip_counter=1; 3.2 Mycatè¯»å†™åˆ†ç¦»åœ¨ä¸€èˆ¬é¡¹ç›®ä¸­ï¼Œå¯¹äºæ•°æ®åº“çš„æ“ä½œè¯»è¦è¿œå¤§äºå†™ï¼Œè€Œå¦‚æœæ‰€æœ‰çš„æ“ä½œéƒ½æ”¾åœ¨ä¸€ä¸ªèŠ‚ç‚¹ä¸Šï¼Œé‚£ä¹ˆå°±å¾ˆå®¹æ˜“å‡ºç°å‹åŠ›è¿‡å¤§è€Œå®•æœºï¼Œè¯»å†™åˆ†ç¦»å°±å¯ä»¥å¾ˆå¥½è§£å†³è¯¥é—®é¢˜ï¼Œä¸»è¦é€šè¿‡ mycat çš„ä¸­é—´ä»¶æ¥å®ç°ã€‚ åˆ†åº“åˆ†è¡¨ç±»å‹ï¼š æ°´å¹³æ‹†åˆ†ï¼šå°†ä¸åŒç­‰çº§çš„ä¼šå‘˜ä¿¡æ¯å†™åˆ°ä¸åŒçš„è¡¨ä¸­ å‚ç›´æ‹†åˆ†ï¼šå°†ä¹°å®¶ä¿¡æ¯ã€å–å®¶ä¿¡æ¯ã€å•†å“ä¿¡æ¯ã€æ”¯ä»˜ä¿¡æ¯ç­‰ä¸åŒä¿¡æ¯å†™åˆ°ä¸åŒçš„è¡¨ä¸­ Mycatçš„ä¸»è¦æ–‡ä»¶ï¼š æ–‡ä»¶ è¯´æ˜ server.xml è®¾ç½® Mycat è´¦å·ã€å‚æ•°ç­‰ schema.xml è®¾ç½® Mycat å¯¹åº”çš„ç‰©ç†æ•°æ®åº“å’Œè¡¨ç­‰ rule.xml åˆ†åº“åˆ†è¡¨è®¾ç½® server.xml 123456789101112131415161718192021222324252627282930&lt;!-- Mycatç”¨æˆ·å --&gt;&lt;user name=&quot;root&quot; defaultAccount=&quot;true&quot;&gt; &lt;!-- å¯†ç  --&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;!-- é€»è¾‘åº“å --&gt; &lt;property name=&quot;schemas&quot;&gt;TESTDB&lt;/property&gt; &lt;!-- é»˜è®¤é€»è¾‘åº“ --&gt; &lt;property name=&quot;defaultSchema&quot;&gt;TESTDB&lt;/property&gt; &lt;!--No MyCAT Database selected é”™è¯¯å‰ä¼šå°è¯•ä½¿ç”¨è¯¥schemaä½œä¸ºschemaï¼Œä¸è®¾ç½®åˆ™ä¸ºnull,æŠ¥é”™ --&gt; &lt;!-- è¡¨çº§ DML æƒé™è®¾ç½® --&gt; &lt;!-- 0ä¸ºç¦æ­¢ï¼Œ1ä¸ºå¼€å¯ --&gt; &lt;!-- æŒ‰é¡ºåºåˆ†åˆ«ä¸ºinsertã€updateã€selectã€delete --&gt; &lt;!-- &lt;privileges check=&quot;false&quot;&gt; &lt;schema name=&quot;TESTDB&quot; dml=&quot;0110&quot; &gt; &lt;table name=&quot;tb01&quot; dml=&quot;0000&quot;&gt;&lt;/table&gt; &lt;table name=&quot;tb02&quot; dml=&quot;1111&quot;&gt;&lt;/table&gt; &lt;/schema&gt; &lt;/privileges&gt; --&gt; &lt;/user&gt; &lt;!-- å…¶ä»–ç”¨æˆ·è®¾ç½® --&gt; &lt;user name=&quot;user&quot;&gt; &lt;property name=&quot;password&quot;&gt;user&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;TESTDB&lt;/property&gt; &lt;property name=&quot;readOnly&quot;&gt;true&lt;/property&gt; &lt;property name=&quot;defaultSchema&quot;&gt;TESTDB&lt;/property&gt; &lt;/user&gt; schema.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;!-- nameä¸ºé€»è¾‘åº“åç§°ï¼Œä¸server.xmlæ–‡ä»¶å¯¹åº” checkSQLschemaä¸ºtrueï¼Œsqlä¸ºselect * from table_name checkSQLschemaä¸ºfalseï¼Œsqlä¸ºselect * from TESTDB.table_name sqlMaxLimitæ˜¯æŒ‡å¦‚æœsqlä¸­æ²¡æœ‰limitï¼Œåˆ™è‡ªåŠ¨æ·»åŠ ï¼Œå¦‚æœæœ‰åˆ™ä¸æ·»åŠ  --&gt; &lt;schema name=&quot;TESTDB&quot; checkSQLschema=&quot;true&quot; sqlMaxLimit=&quot;100&quot; randomDataNode=&quot;dn1&quot;&gt; &lt;!-- nameä¸ºé€»è¾‘è¡¨å dataNodeä¸ºæ•°æ®èŠ‚ç‚¹åç§° ruleä¸ºè§„åˆ™ --&gt; &lt;table name=&quot;customer&quot; primaryKey=&quot;id&quot; dataNode=&quot;dn1,dn2&quot; rule=&quot;sharding-by-intfile&quot; autoIncrement=&quot;true&quot; fetchStoreNodeByJdbc=&quot;true&quot;&gt; &lt;childTable name=&quot;customer_addr&quot; primaryKey=&quot;id&quot; joinKey=&quot;customer_id&quot; parentKey=&quot;id&quot;&gt; &lt;/childTable&gt; &lt;/table&gt; &lt;/schema&gt; &lt;!-- nameä¸ºæ•°æ®èŠ‚ç‚¹åç§° dataHostä¸ºæ•°æ®åº“åœ°å€ databaseä¸ºmysqlä¸­çš„database å®é™…å°±æ˜¯å°†TESTDBé€»è¾‘åº“æ‹†æˆdn1å’Œdn2ï¼Œè€Œdn1å’Œdn2åˆå¯¹åº”db1å’Œdb2 --&gt; &lt;dataNode name=&quot;dn1&quot; dataHost=&quot;localhost1&quot; database=&quot;db1&quot; /&gt; &lt;dataNode name=&quot;dn2&quot; dataHost=&quot;localhost1&quot; database=&quot;db2&quot; /&gt; &lt;dataNode name=&quot;dn3&quot; dataHost=&quot;localhost1&quot; database=&quot;db3&quot; /&gt; &lt;!-- balance: 0:ä¸å¼€å¯è¯»å†™åˆ†ç¦»ï¼Œæ‰€æœ‰æ“ä½œéƒ½åœ¨writeHostä¸Š 1:æ‰€æœ‰è¯»æ“ä½œéƒ½éšæœºå‘é€åˆ°å½“å‰çš„writeHostå¯¹åº”çš„readHostå’Œå¤‡ç”¨çš„writeHost 2:æ‰€æœ‰è¯»æ“ä½œéƒ½éšæœºå‘é€åˆ°æ‰€æœ‰çš„ä¸»æœºä¸Š 3:æ‰€æœ‰è¯»æ“ä½œåªå‘é€åˆ°readHostä¸Š writeType: 0:æ‰€æœ‰å†™æ“ä½œéƒ½åœ¨ç¬¬ä¸€å°writeHostä¸Šï¼Œç¬¬ä¸€å°æŒ‚äº†å†åˆ‡åˆ°ç¬¬äºŒå° 1:æ‰€æœ‰å†™æ“ä½œéƒ½éšæœºåˆ†é…åˆ°writeHost switchType: ç”¨äºæ˜¯å¦å…è®¸writeHostå’ŒreadHostä¹‹é—´è‡ªåŠ¨åˆ‡æ¢ -1:ä¸å…è®¸ 1:å…è®¸ 2:åŸºäºmysqlçš„ä¸»ä»åŒæ­¥çš„çŠ¶æ€å†³å®šæ˜¯å¦åˆ‡æ¢ --&gt; &lt;dataHost name=&quot;localhost1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;!-- ç”¨æ­¤å‘½ä»¤æ¥è¿›è¡Œå¿ƒè·³æ£€æµ‹ --&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;!-- è®¾ç½®è¯»å†™åˆ†ç¦» --&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;jdbc:mysql://localhost:3306&quot; user=&quot;root&quot; password=&quot;root&quot;&gt; &lt;readHost host=&quot;hostS1&quot; url=&quot;jdbc:mysql://localhost:3306&quot; user=&quot;root&quot; password=&quot;root&quot; /&gt; &lt;/readHost&gt; &lt;/writeHost&gt; &lt;/dataHost&gt;&lt;/mycat:schema&gt; rule.xml 12345678910111213&lt;!-- å¹³å‡åˆ†ç®—æ³• --&gt;&lt;tableRule name=&quot;mod-long&quot;&gt; &lt;rule&gt; &lt;!-- æ ¹æ®idå€¼å¹³å‡åˆ† --&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;mod-long&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;...&lt;function name=&quot;mod-long&quot; class=&quot;io.mycat.route.function.PartitionByMod&quot;&gt; &lt;!-- åˆ‡ç‰‡ä¸ªæ•° --&gt; &lt;property name=&quot;count&quot;&gt;2&lt;/property&gt;&lt;/function&gt; åœ¨ master èŠ‚ç‚¹åˆ›å»ºæ•°æ®åº“ 123-- ä¸schema.xmlä¸­çš„databaseå‚æ•°ç›¸åŒcreate database db1;create database db2; åœ¨æ¯ä¸ªåº“é‡Œåˆ›å»ºè¡¨ 12345create table students( id int(4), name varchar(10), primary key(`id`))engine=innodb default charset=utf8; å¼€å¯ Mycatï¼Œé»˜è®¤å¼€å¯8066æœåŠ¡ç«¯ç«¯å£å’Œ9066ç®¡ç†ç«¯ç«¯å£ 1./mycat start åœ¨æœ‰å®‰è£… mysql çš„ä¸»æœºç™»å½• Mycatï¼Œä¹Ÿå¯ä»¥é€šè¿‡ navicat è¿æ¥ 1mysql -uroot -ptoortoor -h 192.168.88.136 -P 8066 åªè¦åœ¨ Mycat è¿›è¡Œ SQL æ“ä½œï¼Œéƒ½ä¼šæµåˆ° mysql é›†ç¾¤ä¸­è¢«å¤„ç†ï¼Œä¹Ÿå¯ä»¥çœ‹åˆ°å·²ç»å®ç°äº†åˆ†åº“åˆ†è¡¨ 3.3 ä½¿ç”¨haproxyå®ç°Mycaté«˜å¯ç”¨haproxy å¯ä»¥å®ç° Mycat é›†ç¾¤çš„é«˜å¯ç”¨å’Œè´Ÿè½½å‡è¡¡ï¼Œè€Œ haproxy çš„é«˜å¯ç”¨é€šè¿‡ keepalived æ¥å®ç°ã€‚ å®‰è£… haproxy 1yum -y install haproxy ä¿®æ”¹æ—¥å¿—æ–‡ä»¶ 12345vim /etc/rsyslog.conf# Provides UDP syslog reception$ModLoad imudp$UDPServerRun 514systemctl restart rsyslog é…ç½® haproxy 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263vim /etc/haproxy/haproxy.cfg# haproxyçš„é…ç½®æ–‡ä»¶ç”±ä¸¤ä¸ªéƒ¨åˆ†æ„æˆï¼Œå…¨å±€è®¾å®šå’Œä»£ç†è®¾å®š# åˆ†ä¸ºäº”æ®µ:globalã€defaultsã€frontendã€backendã€listenglobal # å®šä¹‰å…¨å±€çš„syslogæœåŠ¡å™¨ log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy # è®¾ç½®haproxyåå°å®ˆæŠ¤è¿›ç¨‹å½¢å¼è¿è¡Œ daemon stats socket /var/lib/haproxy/statsdefaults # å¤„ç†æ¨¡å¼ # http:ä¸ƒå±‚ # tcp:å››å±‚ # health:çŠ¶æ€æ£€æŸ¥,åªä¼šè¿”å›OK mode tcp # ç»§æ‰¿globalä¸­logçš„å®šä¹‰ log global option tcplog option dontlognull option http-server-close # option forwardfor except 127.0.0.0/8 # serverIdå¯¹åº”çš„æœåŠ¡å™¨æŒ‚æ‰å,å¼ºåˆ¶å®šå‘åˆ°å…¶ä»–å¥åº·çš„æœåŠ¡å™¨ option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000frontend mycat # å¼€å¯æœ¬åœ°ç›‘æ§ç«¯å£ bind 0.0.0.0:8066 bind 0.0.0.0:9066 mode tcp log global default_backend mycatbackend mycat balance roundrobin # ç›‘æ§çš„Mycat server mycat1 192.168.88.135:8066 check inter 5s rise 2 fall 3 server mycat2 192.168.88.135:8066 check inter 5s rise 2 fall 3 server mycatadmin1 192.168.88.136:9066 check inter 5s rise 2 fall 3 server mycatadmin2 192.168.88.136:9066 check inter 5s rise 2 fall 3 listen stats mode http # è®¿é—®haproxyçš„ç«¯å£ bind 0.0.0.0:9999 stats enable stats hide-version # urlè·¯å¾„ stats uri /haproxy stats realm Haproxy\\ Statistics # ç”¨æˆ·å/å¯†ç  stats auth admin:admin stats admin if TRUE è®¿é—® haproxy 3.4 ä½¿ç”¨keepalivedå®ç°å»ä¸­å¿ƒåŒ– å®‰è£… keepalived 1yum -y install keepalived é…ç½® Master èŠ‚ç‚¹ 1234567891011121314151617181920212223242526272829303132333435363738394041424344vim /etc/keepalived/keepalived.conf! Configuration File for keepalivedglobal_defs { # è¯†åˆ«èŠ‚ç‚¹çš„id router_id haproxy01}vrrp_instance VI_1 { # è®¾ç½®è§’è‰²ï¼Œç”±äºæŠ¢å å®¹æ˜“å‡ºç° VIP åˆ‡æ¢è€Œé—ªæ–­å¸¦æ¥çš„é£é™©ï¼Œæ‰€ä»¥è¯¥é…ç½®ä¸ºä¸æŠ¢å æ¨¡å¼ state BACKUP # VIPæ‰€ç»‘å®šçš„ç½‘å¡ interface ens33 # è™šæ‹Ÿè·¯ç”±IDå·ï¼Œä¸¤ä¸ªèŠ‚ç‚¹å¿…é¡»ä¸€æ · virtual_router_id 30 # æƒé‡ priority 100 # å¼€å¯ä¸æŠ¢å  # nopreempt # ç»„æ’­ä¿¡æ¯å‘é€é—´éš”ï¼Œä¸¤ä¸ªèŠ‚ç‚¹å¿…é¡»ä¸€æ · advert_int 1 # è®¾ç½®éªŒè¯ä¿¡æ¯ authentication { auth_type PASS auth_pass 1111 } # VIPåœ°å€æ± ï¼Œå¯ä»¥å¤šä¸ª virtual_ipaddress { 192.168.88.200 } # å°† track_script å—åŠ å…¥ instance é…ç½®å— track_script{ chk_haproxy }}# å®šä¹‰ç›‘æ§è„šæœ¬vrrp_script chk_haproxy { script &quot;/etc/keepalived/haproxy_check.sh&quot; # æ—¶é—´é—´éš” interval 2 # æ¡ä»¶æˆç«‹æƒé‡+2 weight 2} é…ç½® Slave èŠ‚ç‚¹ 12345678910111213141516171819202122232425262728293031vim /etc/keepalived/keepalived.conf! Configuration File for keepalivedglobal_defs { router_id haproxy02}vrrp_instance VI_1 { state BACKUP interface ens33 virtual_router_id 30 priority 80 # nopreempt advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.88.200 } track_script{ chk_haproxy }}vrrp_script chk_haproxy { script &quot;/etc/keepalived/haproxy_check.sh&quot; interval 2 weight 2} ç¼–å†™ç›‘æ§è„šæœ¬ 1234567891011121314151617181920212223242526vim /etc/keepalived/haproxy_check.sh#!/bin/bashSTART_HAPROXY=&quot;systemctl start haproxy&quot;STOP_KEEPALIVED=&quot;systemctl stop keepalived&quot;LOG_DIR=&quot;/etc/keepalived/haproxy_check.log&quot;HAPS=`ps -C haproxy --no-header | wc -l`date &quot;+%F %H:%M:%S&quot; &gt; $LOG_DIRecho &quot;Check haproxy status&quot; &gt;&gt; $LOG_DIRif [ $HAPS -eq 0 ];then echo &quot;Haproxy is down&quot; &gt;&gt; $LOG_DIR echo &quot;Try to turn on Haproxy...&quot; &gt;&gt; $LOG_DIR echo $START_HAPROXY | sh sleep 3 if [ `ps -C haproxy --no-header | wc -l` -eq 0 ]; then echo -e &quot;Start Haproxy failed, killall keepalived\\n&quot; &gt;&gt; $LOG_DIR echo $STOP_KEEPALIVED | sh else echo -e &quot;Start Haproxy successed\\n&quot; &gt;&gt; $LOG_DIR fielse echo -e &quot;Haproxy is running\\n&quot; &gt;&gt; $LOG_DIRfi å¯åŠ¨ keepalived åå¯ä»¥çœ‹åˆ° VIP è¢«å“ªå°æœåŠ¡å™¨æŠ¢å äº†ï¼Œé€šè¿‡è¯¥ VIP å°±å¯ä»¥è®¿é—®åˆ°å¯¹åº”çš„ haproxyï¼Œhaproxy å°±ä¼šå°†æµé‡æµåˆ°åé¢çš„ Mycatï¼Œå†ç”± Mycat æ¥å®ç°åˆ†è¡¨åˆ†åº“ï¼›haproxy åœæ­¢å keepalived ä¹Ÿä¼šé€šè¿‡è„šæœ¬å°è¯•å»é‡æ–°å¼€å¯ï¼Œå¦‚æœå¼€å¯ä¸æˆåŠŸå°±ä¼šåœæ­¢ keepalivedï¼ŒVIP å°±ç”± slave èŠ‚ç‚¹æŠ¢å ï¼Œç”¨æˆ·ä¾æ—§å¯ä»¥é€šè¿‡ VIP æ¥æ“æ§æ•°æ®åº“ï¼Œä¸”æ— æ„ŸçŸ¥ã€‚ é€šè¿‡ VIP å»è¿æ¥ Mycat æ’å…¥æ•°æ®ï¼Œå°è¯•èƒ½å¦å®ç°åˆ†åº“åˆ†è¡¨ å¯ä»¥çœ‹åˆ°æ’å…¥çš„æ•°æ®éƒ½åˆ†åˆ°äº† db1ã€db2 ä¸­ 3.5 Sharding JDBCè¯»å†™åˆ†ç¦»Apache ShardingSphere æ˜¯ä¸€å¥—å¼€æºçš„åˆ†å¸ƒå¼æ•°æ®åº“è§£å†³æ–¹æ¡ˆç»„æˆçš„ç”Ÿæ€åœˆï¼Œå®ƒç”± JDBCã€Proxy å’Œ Sidecarï¼ˆè§„åˆ’ä¸­ï¼‰è¿™ 3 æ¬¾æ—¢èƒ½å¤Ÿç‹¬ç«‹éƒ¨ç½²ï¼Œåˆæ”¯æŒæ··åˆéƒ¨ç½²é…åˆä½¿ç”¨çš„äº§å“ç»„æˆã€‚ Sharding JDBC åŒæ ·ä¹Ÿå¯ä»¥å®ç°åˆ†åº“åˆ†è¡¨ã€æ•°æ®åˆ†ç‰‡ã€è¯»å†™åˆ†ç¦»ç­‰åŠŸèƒ½ï¼Œä½†ä¸ Mycat ä¸åŒçš„æ˜¯ï¼ŒMycat æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ç¨‹åºï¼Œè€Œ Sharding JDBC æ˜¯ä»¥ jar åŒ…çš„å½¢å¼ä¸åº”ç”¨ç¨‹åºèåˆåœ¨ä¸€èµ·è¿è¡Œçš„ã€‚","link":"/2024/02/18/mysql/"},{"title":"linuxåŸºç¡€ç½‘ç»œæœåŠ¡","text":"ä¸€ã€DHCPæœåŠ¡1.1 DHCPæœåŠ¡ä»‹ç»DHCPæœåŠ¡å³åŠ¨æ€ä¸»æœºé…ç½®åè®®ï¼Œè¢«è¿ç”¨åœ¨å±€åŸŸç½‘ä¸­ï¼Œä¸»è¦çš„ä½œç”¨æ˜¯åˆ†é…IPåœ°å€ã€‚ DHCPæœåŠ¡é‡‡ç”¨çš„æ˜¯UDPåè®®ï¼Œå‘é€é‡‡ç”¨UDP67ç«¯å£ï¼Œæ¥å—åˆ™é‡‡ç”¨UDP68ç«¯å£ã€‚ 1.2 DHCPæœåŠ¡éƒ¨ç½² å®‰è£…DHCP 1yum -y install dhcp DHCPé…ç½®æ–‡ä»¶è¯¦è§£ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150cp /usr/share/doc/dhcp*/dhcpd.conf.example /etc/dhcp/dhcpd.confcat /etc/dhcp/dhcpd.conf# DHCPæœåŠ¡é…ç½®æ–‡ä»¶åˆ†ä¸ºå…¨å±€é…ç½®å’Œä½œç”¨åŸŸé…ç½®ï¼Œå¾ˆå¥½åŒºåˆ†ï¼šsubnetçš„å°±æ˜¯ä½œç”¨åŸŸ ä¸åœ¨subneté‡Œé¢çš„å°±æ˜¯å…¨å±€è®¾ç½®ã€‚# dhcpd.conf## Sample configuration file for ISC dhcpd## DNSå…¨å±€é€‰é¡¹ï¼ŒæŒ‡å®šDNSæœåŠ¡å™¨çš„åœ°å€ï¼Œå¯ä»¥æ˜¯IPï¼Œä¹Ÿå¯ä»¥æ˜¯åŸŸåã€‚# option definitions common to all supported networks...# DNSçš„åŸŸåoption domain-name &quot;example.org&quot;;# å…·ä½“çš„DNSæœåŠ¡å™¨option domain-name-servers ns1.example.org, ns2.example.org;# ç§Ÿçº¦è®¾ç½®ï¼Œé»˜è®¤ç§Ÿçº¦ä¸º600sdefault-lease-time 600;# ç§Ÿçº¦è®¾ç½®ï¼Œæœ€å¤§ç§Ÿçº¦ä¸º7200sï¼Œå½“å®¢æˆ·ç«¯æœªè¯·æ±‚æ˜ç¡®çš„ç§Ÿçº¦æ—¶é—´ã€‚max-lease-time 7200;# åŠ¨æ€DNSæ›´æ–°æ–¹å¼(none:ä¸æ”¯æŒï¼›interim:äº’åŠ¨æ›´æ–°æ¨¡å¼ï¼›ad-hoc:ç‰¹æ®Šæ›´æ–°æ¨¡å¼)# Use this to enble / disable dynamic dns updates globally.# ddns-update-style none;# å¦‚æœè¯¥DHCPæœåŠ¡å™¨æ˜¯æœ¬åœ°å®˜æ–¹DHCPå°±å°†æ­¤é€‰é¡¹æ‰“å¼€ï¼Œé¿å…å…¶ä»–DHCPæœåŠ¡å™¨çš„å¹²æ‰°ã€‚# å½“ä¸€ä¸ªå®¢æˆ·ç«¯è¯•å›¾è·å¾—ä¸€ä¸ªä¸æ˜¯è¯¥DHCPæœåŠ¡å™¨åˆ†é…çš„IPä¿¡æ¯ï¼ŒDHCPå°†å‘é€ä¸€ä¸ªæ‹’ç»æ¶ˆæ¯ï¼Œè€Œä¸ä¼šç­‰å¾…è¯·æ±‚è¶…æ—¶ã€‚# å½“è¯·æ±‚è¢«æ‹’ç»ï¼Œå®¢æˆ·ç«¯ä¼šé‡æ–°å‘å½“å‰DHCPå‘é€IPè¯·æ±‚è·å¾—æ–°åœ°å€ã€‚# ä¿è¯IPæ˜¯è‡ªå·±å‘å‡ºå»çš„## If this DHCP server is the official DHCP server for the local# network, the authoritative directive should be uncommented.# å¼€å¯æ­¤é¡¹è¡¨æƒå¨DHCP# authoritative;# Use this to send dhcp log messages to a different log file (you also# have to hack syslog.conf to complete the redirection).# æ—¥å¿—çº§åˆ«log-facility local7;# No service will be given on this subnet, but declaring it helps the # DHCP server to understand the network topology.#ä½œç”¨åŸŸç›¸å…³è®¾ç½®æŒ‡ä»¤# subnet å®šä¹‰ä¸€ä¸ªä½œç”¨åŸŸ# netmask å®šä¹‰ä½œç”¨åŸŸçš„æ©ç # range å…è®¸å‘æ”¾çš„IPèŒƒå›´# option routers æŒ‡å®šç½‘å…³åœ°å€# option domain-name-servers æŒ‡å®šDNSæœåŠ¡å™¨åœ°å€# option broadcast-address å¹¿æ’­åœ°å€### æ¡ˆä¾‹:å®šä¹‰ä¸€ä¸ªä½œç”¨åŸŸ ç½‘æ®µä¸º10.152.187.0 æ©ç ä¸º255.255.255.0# æ­¤ä½œç”¨åŸŸä¸æä¾›ä»»ä½•æœåŠ¡subnet 10.152.187.0 netmask 255.255.255.0 {}# This is a very basic subnet declaration.# æ¡ˆä¾‹:å®šä¹‰ä¸€ä¸ªåŸºæœ¬çš„ä½œç”¨åŸŸ# ç½‘æ®µ10.254.239.0 æ©ç 255.255.255.224# åˆ†å‘èŒƒå›´10.254.239.10-20# ç½‘å…³ä¸ºrtr-239-0-1.example.org, rtr-239-0-2.example.orgsubnet 10.254.239.0 netmask 255.255.255.224 { range 10.254.239.10 10.254.239.20; option routers rtr-239-0-1.example.org, rtr-239-0-2.example.org;}# This declaration allows BOOTP clients to get dynamic addresses,# which we don't really recommend.# æ¡ˆä¾‹:å…è®¸é‡‡ç”¨bootpåè®®çš„å®¢æˆ·ç«¯åŠ¨æ€è·å¾—åœ°å€# bootp DHCPçš„å‰èº«# BOOTPç”¨äºæ— ç›˜å·¥ä½œç«™çš„å±€åŸŸç½‘ä¸­ï¼Œå¯ä»¥è®©æ— ç›˜å·¥ä½œç«™ä»ä¸€ä¸ªä¸­å¿ƒæœåŠ¡å™¨ä¸Šè·å¾—IPåœ°å€ã€‚é€šè¿‡BOOTPåè®®å¯ä»¥ä¸ºå±€åŸŸç½‘ä¸­çš„æ— ç›˜å·¥ä½œç«™åˆ†é…åŠ¨æ€IPåœ°å€ï¼Œ# è¿™æ ·å°±ä¸éœ€è¦ç®¡ç†å‘˜å»ä¸ºæ¯ä¸ªç”¨æˆ·å»è®¾ç½®é™æ€IPåœ°å€ã€‚subnet 10.254.239.32 netmask 255.255.255.224 { range dynamic-bootp 10.254.239.40 10.254.239.60; option broadcast-address 10.254.239.31; option routers rtr-239-32-1.example.org;}# æ¡ˆä¾‹:ä¸€ä¸ªç®€å•çš„ä½œç”¨åŸŸæ¡ˆä¾‹# A slightly different configuration for an internal subnet.subnet 10.5.5.0 netmask 255.255.255.224 { range 10.5.5.26 10.5.5.30; option domain-name-servers ns1.internal.example.org; option domain-name &quot;internal.example.org&quot;; option routers 10.5.5.1; option broadcast-address 10.5.5.31; default-lease-time 600; max-lease-time 7200;}# Hosts which require special configuration options can be listed in# host statements. If no address is specified, the address will be# allocated dynamically (if possible), but the host-specific information# will still come from the host declaration.## ä¿ç•™åœ°å€:å¯ä»¥å°†æŒ‡å®šçš„IPåˆ†å‘ç»™æŒ‡å®šçš„æœºå™¨ï¼Œæ ¹æ®ç½‘å¡çš„MACåœ°å€æ¥åšè§¦å‘# host: å¯ç”¨ä¿ç•™ã€‚# hardware:æŒ‡å®šå®¢æˆ·ç«¯çš„macåœ°å€# filename:æŒ‡å®šæ–‡ä»¶å# server-name:æŒ‡å®šä¸‹ä¸€è·³æœåŠ¡å™¨åœ°å€# fixed-address: æŒ‡å®šä¿ç•™IPåœ°å€### æ¡ˆä¾‹:è¿™ä¸ªæ¡ˆä¾‹ä¸­åˆ†å‘ç»™å®¢æˆ·ç«¯çš„ä¸æ˜¯IPåœ°å€ä¿¡æ¯ï¼Œè€Œæ˜¯å‘Šè¯‰å®¢æˆ·ç«¯å»æ‰¾toccata.fugue.comæœåŠ¡å™¨ï¼Œå¹¶ä¸”ä¸‹è½½vmunix.passacagliaæ–‡ä»¶host passacaglia { hardware ethernet 0:0:c0:5d:bd:95; filename &quot;vmunix.passacaglia&quot;; server-name &quot;toccata.fugue.com&quot;;}# Fixed IP addresses can also be specified for hosts. These addresses# should not also be listed as being available for dynamic assignment.# Hosts for which fixed IP addresses have been specified can boot using# BOOTP or DHCP. Hosts for which no fixed address is specified can only# be booted with DHCP, unless there is an address range on the subnet# to which a BOOTP client is connected which has the dynamic-bootp flag# set.# æ¡ˆä¾‹:ä¿ç•™åœ°å€ï¼Œå°†æŒ‡å®šIP(fantasia.fugue.comå¯¹åº”çš„IP)åˆ†ç»™æŒ‡å®šå®¢æˆ·ç«¯ç½‘å¡(MAC:08:00:07:26:c0:a5)host fantasia { hardware ethernet 08:00:07:26:c0:a5; fixed-address fantasia.fugue.com;}# è¶…çº§ä½œç”¨åŸŸ# è¶…çº§ä½œç”¨åŸŸæ˜¯DHCPæœåŠ¡ä¸­çš„ä¸€ç§ç®¡ç†åŠŸèƒ½ï¼Œä½¿ç”¨è¶…çº§ä½œç”¨åŸŸï¼Œå¯ä»¥å°†å¤šä¸ªä½œç”¨åŸŸç»„åˆä¸ºå•ä¸ªç®¡ç†å®ä½“ã€‚# You can declare a class of clients and then do address allocation# based on that. The example below shows a case where all clients# in a certain class get addresses on the 10.17.224/24 subnet, and all# other clients get addresses on the 10.0.29/24 subnet.# åœ¨å±€åŸŸç½‘ä¸­ï¼Œå¯ä»¥é…ç½®ç­–ç•¥æ ¹æ®å„ä¸ªæœºå™¨çš„å…·ä½“ä¿¡æ¯åˆ†é…IPåœ°å€å’Œå…¶ä»–çš„ç½‘ç»œå‚æ•°ï¼Œå®¢æˆ·æœºçš„å…·ä½“ä¿¡æ¯ï¼šå®¢æˆ·æœºèƒ½å¤Ÿç»™dhcpæœåŠ¡æä¾›çš„ä¿¡æ¯ç”±ä¸¤ä¸ªï¼Œ# ç¬¬ä¸€ä¸ªå°±æ˜¯ç½‘å¡çš„dhcp-client-identifierï¼ˆmacåœ°å€ï¼‰ï¼Œ# ç¬¬äºŒä¸ªå°±æ˜¯è®¾å¤‡çš„vendor-class-identifierã€‚# ç®¡ç†å‘˜å¯ä»¥æ ¹æ®è¿™ä¸¤ä¸ªä¿¡æ¯ç»™ä¸åŒçš„æœºå™¨åˆ†ç»„ã€‚# æ¡ˆä¾‹:# æŒ‰clientæŸç§ç±»å‹åˆ†ç»„DHCP,è€Œä¸æ˜¯æŒ‰ç‰©ç†æ¥å£ç½‘æ®µ# ä¾‹å­: SUNW åˆ†é…åœ°å€æ®µ10.17.224.0/24# éSUNWçš„ä¸»æœº,åˆ†é…åœ°å€æ®µ10.0.29.0/24# å®šä¹‰ä¸€ä¸ªdhcpç±»:foo# requestå¹¿æ’­ä¸­vendor-class-identifierå­—æ®µå¯¹åº”çš„å€¼å‰å››ä¸ªå­—èŠ‚å¦‚æœæ˜¯&quot;SUNW&quot;,åˆ™è§†åˆæ³•å®¢æˆ·ç«¯.class &quot;foo&quot; { match if substring (option vendor-class-identifier, 0, 4) = &quot;SUNW&quot;;}# å®šä¹‰ä¸€ä¸ªè¶…çº§ä½œç”¨åŸŸ: 224-29shared-network 224-29 {# å®šä¹‰ç¬¬ä¸€ä¸ªä½œç”¨åŸŸ subnet 10.17.224.0 netmask 255.255.255.0 { option routers rtr-224.example.org; }# å®šä¹‰ç¬¬äºŒä¸ªä½œç”¨åŸŸ subnet 10.0.29.0 netmask 255.255.255.0 { option routers rtr-29.example.org; }# å…³è¿æ± ,å¦‚æœå®¢æˆ·ç«¯åŒ¹é…fooç±»ï¼Œå°†è·å¾—è¯¥æ± åœ°å€ pool { allow members of &quot;foo&quot;; range 10.17.224.10 10.17.224.250; }# å…³è¿æ± ,å¦‚æœå®¢æˆ·ç«¯é…ç½®fooç±»ï¼Œåˆ™æ‹’ç»è·å¾—è¯¥æ®µåœ°å€ pool { deny members of &quot;foo&quot;; range 10.0.29.10 10.0.29.230; }} 1.3 é…ç½®ä½œç”¨åŸŸ é…ç½®ä½œç”¨åŸŸ 12345678subnet 192.168.88.0 netmask 255.255.255.0 { range 192.168.88.150 192.168.88.160; # å‘æ”¾åœ°å€èŒƒå›´ option routers 192.168.88.0; # ç½‘å…³ option broadcast-address 192.168.88.255; # å¹¿æ’­åœ°å€ option domain-name-servers 8.8.8.8, 114.114.114.114; # è®¾ç½®DNS default-lease-time 7200; # é»˜è®¤ç§Ÿçº¦2å°æ—¶ max-lease-time 10800; # æœ€å¤§ç§Ÿçº¦3å°æ—¶} å°†å¦ä¸€å°ä¸»æœºç½‘å¡è®¾ç½®ä¸ºDHCPæ¨¡å¼ 12# é‡å¯ç½‘ç»œæœåŠ¡systemctl restart network ç”¨dhclientå‘½ä»¤è¿›è¡Œæµ‹è¯• 1234# é‡Šæ”¾IPdhclient -r ens33# è·å–IPdhclient -d ens33 æŸ¥çœ‹æ˜¯å¦è·å–äº†150-160ç½‘æ®µå†…çš„åœ°å€ 1.4 ä¿ç•™åœ°å€å½“ç§Ÿçº¦åˆ°æœŸçš„æ—¶å€™ï¼Œclientç«¯åªèƒ½ä¹–ä¹–äº¤å‡ºIPåœ°å€ï¼Œä¸‹ä¸€æ¬¡è·å–å°±æœªå¿…æ˜¯åŒæ ·çš„åœ°å€äº†ï¼Œä½†å…¬å¸ä¸­å¾€å¾€æœ‰äº›æœºå™¨è¦ç”¨å›ºå®šçš„åœ°å€ï¼Œä¾‹å¦‚æ‰“å°æœºã€æ–‡ä»¶æœåŠ¡å™¨ç­‰ç­‰ï¼Œæ‰€ä»¥åœ¨DHCPä¸­å¯ä»¥è®¾ç½®ä¿ç•™åœ°å€ä¸ºå…¶ä½¿ç”¨ã€‚ DHCPæ˜¯æ ¹æ®ä¸»æœºç½‘å¡çš„MACåœ°å€æ¥åšåŒ¹é…ï¼Œå°†ä¿ç•™çš„IPåœ°å€åˆ†ç»™ç›¸åº”çš„ä¸»æœºç½‘å¡MACåœ°å€ã€‚ è·å–ç½‘å¡MACåœ°å€ æ·»åŠ ä¿ç•™åœ°å€é…ç½® 12345vim /etc/dhcp/dhcpd.confhost fantasia { hardware ethernet 00:0c:29:6c:6f:0d; fixed-address 192.168.88.155;} æŸ¥çœ‹æ˜¯å¦è·å–ç›¸åº”åœ°å€ 12dhclient -r ens37dhclient -d ens37 1.5 è¶…çº§ä½œç”¨åŸŸè¶…çº§ä½œç”¨åŸŸç®€å•æ¥è¯´å°±æ˜¯å°†ä¸¤ä¸ªæˆ–ä¸¤ä¸ªä»¥ä¸Šçš„ä¸åŒç½‘æ®µçš„ä½œç”¨åŸŸåˆæˆä¸€ä¸ªä½œç”¨åŸŸã€‚ æ·»åŠ è¶…çº§ä½œç”¨åŸŸ 12345678910111213141516171819202122# æ·»åŠ ä½œç”¨åŸŸä¹‹å‰DHCPå¿…é¡»æ‹¥æœ‰ä¸¤ä¸ªç½‘æ®µçš„ç½‘å¡shared-network supernet { subnet 192.168.88.0 netmask 255.255.255.0 { range 192.168.88.150 192.168.88.160; option routers 192.168.88.2; option broadcast-address 192.168.88.255; option domain-name-servers 8.8.8.8, 114.114.114.114; default-lease-time 7200; max-lease-time 10800; } subnet 192.168.99.0 netmask 255.255.255.0 { range 192.168.99.150 192.168.99.160; option routers 192.168.99.0; option broadcast-address 192.168.99.255; option domain-name-servers 8.8.8.8, 114.114.114.114; default-lease-time 7200; max-lease-time 10800; }} äºŒã€DNSæœåŠ¡2.1 DNSæœåŠ¡ä»‹ç»DNSå³åŸŸåç³»ç»Ÿï¼Œåœ¨äº’è”ç½‘ä¸­ä¸ºåŸŸåå’ŒIPåœ°å€è¿›è¡Œç›¸äº’æ˜ å°„çš„ä¸€ä¸ªåˆ†å¸ƒå¼æ•°æ®åº“ã€‚ DNSé‡‡ç”¨UDPåè®®ï¼Œä½¿ç”¨UDP53ç«¯å£è¿›è¡Œä¼ è¾“ã€‚ DNSè®°å½•ç±»å‹ï¼š Aï¼šipv4 è®°å½•ï¼Œå°†åŸŸåæ˜ å°„åˆ° ipv4 åœ°å€ AAAAï¼šipv6 è®°å½•ï¼Œå°†åŸŸåæ˜ å°„åˆ° ipv6 åœ°å€ CNAMEï¼šåˆ«åè®°å½•ï¼Œå°†åŸŸåæ˜ å°„åˆ°å¦ä¸€ä¸ªåŸŸå MXï¼šç”µé‚®äº¤äº’è®°å½•ï¼Œå°†åŸŸåæ˜ å°„åˆ°é‚®ä»¶æœåŠ¡å™¨åœ°å€ TXTï¼šæ–‡æœ¬è®°å½•ï¼Œæ˜¯ä»»æ„å¯è¯»çš„æ–‡æœ¬ DNS è®°å½• SRVï¼šæœåŠ¡å™¨èµ„æºè®°å½•ï¼Œç”¨æ¥æ ‡è¯†æŸä¸ªæœåŠ¡å™¨ä½¿ç”¨äº†æŸä¸ªæœåŠ¡ï¼Œåˆ›å»ºäºå¾®è½¯ç³»ç»Ÿçš„ç›®å½•ç®¡ç† NSï¼šåç§°æœåŠ¡å™¨è®°å½•ï¼Œæ”¯æŒå°†å­åŸŸåå§”æ‰˜ç»™å…¶ä»– DNS æœåŠ¡å•†è§£æ CAAï¼šCAA èµ„æºè®°å½•ï¼Œå¯ä»¥é™å®šåŸŸåé¢å‘è¯ä¹¦å’Œ CA ä¹‹é—´çš„å…³ç³» 2.2 DNSæœåŠ¡éƒ¨ç½² å®‰è£…DNS 12yum -y install bind bind-chroot# bind-chrootæ˜¯bindçš„ä¸€ä¸ªåŠŸèƒ½,ä½¿bindå¯ä»¥åœ¨ä¸€ä¸ªchrootçš„æ¨¡å¼ä¸‹è¿è¡Œ.ä¹Ÿå°±æ˜¯è¯´,bindè¿è¡Œæ—¶çš„/(æ ¹)ç›®å½•,å¹¶ä¸æ˜¯ç³»ç»ŸçœŸæ­£çš„/(æ ¹)ç›®å½•,åªæ˜¯ç³»ç»Ÿä¸­çš„ä¸€ä¸ªå­ç›®å½•è€Œå·².è¿™æ ·åšçš„ç›®çš„æ˜¯ä¸ºäº†æé«˜å®‰å…¨æ€§.å› ä¸ºåœ¨chrootçš„æ¨¡å¼ä¸‹,bindå¯ä»¥è®¿é—®çš„èŒƒå›´ä»…é™äºè¿™ä¸ªå­ç›®å½•çš„èŒƒå›´é‡Œ,æ— æ³•è¿›ä¸€æ­¥æå‡,è¿›å…¥åˆ°ç³»ç»Ÿçš„å…¶ä»–ç›®å½•ä¸­ã€‚bindçš„é»˜è®¤å¯åŠ¨æ–¹å¼å°±æ˜¯chrootæ–¹å¼ã€‚ å°†é…ç½®æ–‡ä»¶å’ŒåŒºåŸŸæ•°æ®åº“æ–‡ä»¶æ‹·è´åˆ°chrootç›®å½•ä¸‹ 12345cp -p /etc/named.conf /var/named/chroot/etc/cp -pr /var/named/name* /var/named/chroot/var/named/chown -R named:named /var/named/chroot/*# é…ç½®æ–‡ä»¶ /var/named/chroot/etc/named.conf# åŒºåŸŸæ•°æ®åº“æ–‡ä»¶ /var/named/chroot/var/named/ é…ç½®æ–‡ä»¶è¯¦è§£ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274/* Sample named.conf BIND DNS server 'named' configuration file for the Red Hat BIND distribution. See the BIND Administrator's Reference Manual (ARM) for details about the configuration located in /usr/share/doc/bind-{version}/Bv9ARM.html*/options{ // Put files that named is allowed to write in the data/ directory: #æŒ‡å®šåŒºåŸŸæ•°æ®åº“æ–‡ä»¶çš„è·¯å¾„ç›®å½• directory &quot;/var/named&quot;; // &quot;Working&quot; directory #CACHEæ–‡ä»¶è·¯å¾„,æŒ‡å®šæœåŠ¡å™¨åœ¨æ”¶åˆ°rndc dumpå‘½ä»¤æ—¶ï¼Œè½¬å‚¨æ•°æ®åˆ°æ–‡ä»¶çš„è·¯å¾„ã€‚é»˜è®¤named_dump.db dump-file &quot;data/cache_dump.db&quot;; #é™æ€æ–‡ä»¶è·¯å¾„,æŒ‡å®šæœåŠ¡å™¨åœ¨æ”¶åˆ°rndc statså‘½ä»¤æ—¶ï¼Œè¿½åŠ ç»Ÿè®¡æ•°æ®çš„æ–‡ä»¶è·¯å¾„ã€‚é»˜è®¤named.stats statistics-file &quot;data/named_stats.txt&quot;; #å†…å­˜é™æ€æ–‡ä»¶è·¯å¾„,æœåŠ¡å™¨åœ¨é€€å‡ºæ—¶ï¼Œå°†å†…å­˜ç»Ÿè®¡å†™åˆ°æ–‡ä»¶çš„è·¯å¾„ã€‚é»˜è®¤named.memstats memstatistics-file &quot;data/named_mem_stats.txt&quot;; # æŒ‡å®šæœåŠ¡å™¨åœ¨é€šè¿‡rndc recursingå‘½ä»¤æŒ‡å®šè½¬å‚¨å½“å‰é€’å½’è¯·æ±‚åˆ°çš„æ–‡ä»¶è·¯å¾„ã€‚é»˜è®¤named.recursing recursing-file &quot;data/named.recursing&quot;; #åœ¨æ”¶åˆ°rndc secrootsæŒ‡ä»¤åï¼ŒæœåŠ¡å™¨è½¬å‚¨å®‰å…¨æ ¹çš„ç›®çš„æ–‡ä»¶çš„è·¯å¾„åã€‚é»˜è®¤named.secroots secroots-file &quot;data/named.secroots&quot;; /* Specify listenning interfaces. You can use list of addresses (';' is delimiter) or keywords &quot;any&quot;/&quot;none&quot; */ #IPV4ç›‘å¬ç«¯å£ä¸º53,å…è®¸ä»»ä½•äººè¿æ¥ //listen-on port 53 { any; }; #IPv4ç›‘å¬ç«¯å£ä¸º53ï¼Œåªå…è®¸æœ¬æœºè¿æ¥ listen-on port 53 { 127.0.0.1; }; #IPV6ç›‘å¬ç«¯å£ä¸º53,å…è®¸ä»»ä½•äººè¿æ¥ //listen-on-v6 port 53 { any; }; #IPv6ç›‘å¬ç«¯å£ä¸º53ï¼Œåªå…è®¸æœ¬æœºè¿æ¥ listen-on-v6 port 53 { ::1; }; /* è®¿é—®æ§åˆ¶ Access restrictions ä¸¤ä¸ªé‡è¦é€‰é¡¹ There are two important options: allow-query { argument; }; - allow queries for authoritative data å…è®¸æŸ¥è¯¢æ¥è‡ªæƒå¨æ•°æ® allow-query-cache { argument; }; - allow queries for non-authoritative data (mostly cached data) å…è®¸æŸ¥è¯¢æ¥è‡ªéæƒå¨æ•°æ® You can use address, network address or keywords &quot;any&quot;/&quot;localhost&quot;/&quot;none&quot; as argument å¤§æ‹¬å·ä¸­å¯ä»¥ä½¿ç”¨IPåœ°å€ã€ç½‘æ®µã€æˆ–è€…å…³é”®å­— anyä»»ä½•äºº localhostæœ¬æœº noneä»»ä½•äººä¸å…è®¸ Examples: allow-query { localhost; 10.0.0.1; 192.168.1.0/8; }; allow-query-cache { ::1; fe80::5c63:a8ff:fe2f:4526; 10.0.0.1; }; */ #æŒ‡å®šå…è®¸å“ªäº›ä¸»æœºå¯ä»¥è¿›è¡Œæ™®é€šçš„DNSæŸ¥è¯¢,å¯ä»¥æ˜¯å…³é”®å­—:any/localhost/none,ä¹Ÿå¯ä»¥æ˜¯IPV4,IPV6åœ°å€ allow-query { localhost; }; #æŒ‡å®šå…è®¸å“ªäº›ä¸»æœºå¯ä»¥å¯¹ç¼“å­˜çš„è®¿é—® allow-query-cache { localhost; }; /* Enable/disable recursion - recursion yes/no; é€’å½’æŸ¥è¯¢å¼€å…³ - If you are building an AUTHORITATIVE DNS server, do NOT enable recursion. å‡å¦‚ä½ å»ºç«‹çš„æ˜¯ä¸€ä¸ªæƒå¨DNSä½ ä¸éœ€è¦å¼€å¯é€’å½’ - If you are building a RECURSIVE (caching) DNS server, you need to enable recursion. å‡å¦‚ä½ å»ºç«‹çš„æ˜¯ä¸€ä¸ªé€’å½’DNS,ä½ éœ€è¦å¼€å¯é€’å½’æœåŠ¡ - If your recursive DNS server has a public IP address, you MUST enable access å¦‚æœä½ çš„é€’å½’DNSæ˜¯å…·æœ‰å…¬ç½‘IPï¼Œä½ å¿…é¡»è¦è®¾ç½®è®¿é—®æ§åˆ¶æ¥é™åˆ¶å¯¹åˆæ³•ç”¨æˆ·çš„æŸ¥è¯¢. control to limit queries to your legitimate users. Failing to do so will cause your server to become part of large scale DNS amplification å¦è€…ä½ çš„DNSä¼šè¢«å¤§è§„æ¨¡çš„æ”»å‡» attacks. Implementing BCP38 within your network would greatly åœ¨æ‚¨çš„ç½‘ç»œä¸­å®ç°BCP38å°†éå¸¸é‡è¦å‡å°‘æ­¤ç±»æ”»å‡»é¢ reduce such attack surface */ #å¼€å¯é€’å½’ recursion yes; #Domain Name System Security Extensions (DNSå®‰å…¨æ‰©å±•ï¼‰ /* DNSSEC related options. See information about keys (&quot;Trusted keys&quot;, bellow) */ /* Enable serving of DNSSEC related data - enable on both authoritative and recursive servers DNSSEC aware servers */ #å¼€å¯DNSSECåœ¨æƒå¨æˆ–è€…é€’å½’æœåŠ¡å™¨ä¹‹é—´ä¿¡ä»»æœåŠ¡ dnssec-enable yes; /* Enable DNSSEC validation on recursive servers */ #å¼€å¯DNSSECéªŒè¯åœ¨é€’å½’æœåŠ¡å™¨ dnssec-validation yes; /* In RHEL-7 we use /run/named instead of default /var/run/named so we have to configure paths properly. */ #PIDæ–‡ä»¶è·¯å¾„ pid-file &quot;/run/named/named.pid&quot;; #session-keyfileæ–‡ä»¶è·¯å¾„ session-keyfile &quot;/run/named/session.key&quot;; #æŒ‡å®šç›®å½•ï¼Œå…¶ä¸­ä¿å­˜ç€è·Ÿè¸ªè¢«ç®¡ç†DNSSECå¯†é’¥æ–‡ä»¶ã€‚é»˜è®¤ä¸ºå·¥ä½œç›®å½•ã€‚ managed-keys-directory &quot;/var/named/dynamic&quot;;};logging {#å¼€å¯DNSæ—¥å¿—è®°å½•/* If you want to enable debugging, eg. using the 'rndc trace' command, * named will try to write the 'named.run' file in the $directory (/var/named). * By default, SELinux policy does not allow named to modify the /var/named directory, * so put the default debug log file in data/ : */ channel default_debug { file &quot;data/named.run&quot;; severity dynamic; };/*##æ—¥å¿—åˆ†ä¸ºä¸¤ç§ å‘Šè­¦å’Œè®¿é—®logging { channel warning { file &quot;data/dns_warning&quot; versions 10 size 10m; severity warning; print-category yes; print-severity yes; print-time yes; }; channel general_dns { file &quot;data/dns_log&quot; versions 10 size 100m; severity info; print-category yes; print-severity yes; print-time yes; }; #é»˜è®¤æ—¥å¿— warning category default { warning; }; #è®¿é—®æ—¥å¿—çº§åˆ« general_dns info category queries { general_dns; };};*/};/*é€šè¿‡ViewsæŒ‡ä»¤é…ç½®æ™ºèƒ½æŸ¥è¯¢DNS Views let a name server answer a DNS query differently depending on who is asking. By default, if named.conf contains no &quot;view&quot; clauses, all zones are in the &quot;default&quot; view, which matches all clients. Views are processed sequentially. The first match is used so the last view should match &quot;any&quot; - it's fallback and the most restricted view. If named.conf contains any &quot;view&quot; clause, then all zones MUST be in a view.*/#é…ç½®ä¸€ä¸ªæ˜ç§°ä¸ºlocalhost_resolverçš„æ™ºèƒ½è®¿é—®è§†å›¾view &quot;localhost_resolver&quot;{/* This view sets up named to be a localhost resolver ( caching only nameserver ). * If all you want is a caching-only nameserver, then you need only define this view: */ #å…è®¸ä½¿ç”¨è¯¥è§†å›¾è§£æçš„å®¢æˆ·ç«¯ localhostæœ¬æœº any ä»»ä½•æœºå™¨ æˆ–è€…ç½‘æ®µ match-clients { localhost; }; #å…è®¸é€’å½’ recursion yes; # all views must contain the root hints zone: #æ ¹åŸŸ zone &quot;.&quot; IN { #åŸŸç±»å‹ä¸ºhint,è¿˜æœ‰master slave forwardç­‰ç±»å‹ type hint; #åŒºåŸŸæ•°æ®åº“æ–‡ä»¶è·¯å¾„ file &quot;/var/named/named.ca&quot;; }; /* these are zones that contain definitions for all the localhost * names and addresses, as recommended in RFC1912 - these names should * not leak to the other nameservers: */ #åŒ…å«å­é…ç½®æ–‡ä»¶ include &quot;/etc/named.rfc1912.zones&quot;;};#å®šä¹‰è§†å›¾internalview &quot;internal&quot;{/* This view will contain zones you want to serve only to &quot;internal&quot; clients that connect via your directly attached LAN interfaces - &quot;localnets&quot; . */ match-clients { localnets; }; recursion yes; zone &quot;.&quot; IN { type hint; file &quot;/var/named/named.ca&quot;; }; /* these are zones that contain definitions for all the localhost * names and addresses, as recommended in RFC1912 - these names should * not leak to the other nameservers: */ include &quot;/etc/named.rfc1912.zones&quot;; // These are your &quot;authoritative&quot; internal zones, and would probably // also be included in the &quot;localhost_resolver&quot; view above : /* NOTE for dynamic DNS zones and secondary zones: DO NOT USE SAME FILES IN MULTIPLE VIEWS! If you are using views and DDNS/secondary zones it is strongly recommended to read FAQ on ISC site (www.isc.org), section &quot;Configuration and Setup Questions&quot;, questions &quot;How do I share a dynamic zone between multIPle views?&quot; and &quot;How can I make a server a slave for both an internal and an external view at the same time?&quot; */ zone &quot;my.internal.zone&quot; { type master; file &quot;my.internal.zone.db&quot;; }; zone &quot;my.slave.internal.zone&quot; { type slave; file &quot;slaves/my.slave.internal.zone.db&quot;; masters { /* put master nameserver IPs here */ 127.0.0.1; } ; // put slave zones in the slaves/ directory so named can update them }; zone &quot;my.ddns.internal.zone&quot; { type master; allow-update { key ddns_key; }; file &quot;dynamic/my.ddns.internal.zone.db&quot;; // put dynamically updateable zones in the slaves/ directory so named can update them }; };#è®¾ç½®DDNS_key#ä¸»ä»å¤åˆ¶åŠ å¯†ä½¿ç”¨key ddns_key{ #åŠ å¯†æ–¹å¼ hmac-md5 algorithm hmac-md5; secret &quot;use /usr/sbin/dnssec-keygen to generate TSIG keys&quot;;};view &quot;external&quot;{/* This view will contain zones you want to serve only to &quot;external&quot; clients * that have addresses that are not match any above view: */ match-clients { any; }; zone &quot;.&quot; IN { type hint; file &quot;/var/named/named.ca&quot;; }; recursion no; // you'd probably want to deny recursion to external clients, so you don't // end up providing free DNS service to all takers // These are your &quot;authoritative&quot; external zones, and would probably // contain entries for just your web and mail servers: zone &quot;my.external.zone&quot; { type master; file &quot;my.external.zone.db&quot;; };};/* Trusted keys#å®šä¹‰ä¿¡ä»»çš„dnssecå¯†é’¥ã€‚ This statement contains DNSSEC keys. If you want DNSSEC aware resolver you have to configure at least one trusted key. Note that no key written below is valid. Especially root key because root zone is not signed yet.*//*trusted-keys {// Root Key&quot;.&quot; 257 3 3 &quot;BNY4wrWM1nCfJ+CXd0rVXyYmobt7sEEfK3clRbGaTwSJxrGkxJWoZu6I7PzJu/ E9gx4UC1zGAHlXKdE4zYIPRhaBKnvcC2U9mZhkdUpd1Vso/HAdjNe8LmMlnzY3 zy2Xy4klWOADTPzSv9eamj8V18PHGjBLaVtYvk/ln5ZApjYghf+6fElrmLkdaz MQ2OCnACR817DF4BBa7UR/beDHyp5iWTXWSi6XmoJLbG9Scqc7l70KDqlvXR3M /lUUVRbkeg1IPJSidmK3ZyCllh4XSKbje/45SKucHgnwU5jefMtq66gKodQj+M iA21AfUVe7u99WzTLzY3qlxDhxYQQ20FQ97S+LKUTpQcq27R7AT3/V5hRQxScI Nqwcz4jYqZD2fQdgxbcDTClU0CRBdiieyLMNzXG3&quot;;// Key for forward zoneexample.com. 257 3 5 &quot;AwEAAaxPMcR2x0HbQV4WeZB6oEDX+r0QM65KbhTjrW1ZaARmPhEZZe 3Y9ifgEuq7vZ/zGZUdEGNWy+JZzus0lUptwgjGwhUS1558Hb4JKUbb OTcM8pwXlj0EiX3oDFVmjHO444gLkBO UKUf/mC7HvfwYH/Be22GnC lrinKJp1Og4ywzO9WglMk7jbfW33gUKvirTHr25GL7STQUzBb5Usxt 8lgnyTUHs1t3JwCY5hKZ6CqFxmAVZP20igTixin/1LcrgX/KMEGd/b iuvF4qJCyduieHukuY3H4XMAcR+xia2 nIUPvm/oyWR8BW/hWdzOvn SCThlHf3xiYleDbt/o1OTQ09A0=&quot;;// Key for reverse zone.2.0.192.IN-ADDRPA.NET. 257 3 5 &quot;AQOnS4xn/IgOUpBPJ3bogzwcxOdNax071L18QqZnQQQA VVr+iLhGTnNGp3HoWQLUIzKrJVZ3zggy3WwNT6kZo6c0 tszYqbtvchmgQC8CzKojM/W16i6MG/ea fGU3siaOdS0 yOI6BgPsw+YZdzlYMaIJGf4M4dyoKIhzdZyQ2bYQrjyQ 4LB0lC7aOnsMyYKHHYeRv PxjIQXmdqgOJGq+vsevG06 zW+1xgYJh9rCIfnm1GX/KMgxLPG2vXTD/RnLX+D3T3UL 7HJYHJhAZD5L59VvjSPsZJHeDCUyWYrvPZesZDIRvhDD 52SKvbheeTJUm6EhkzytNN2SN96QRk8j/iI8ib&quot;;};*/ é…ç½®ä¸»é…æ–‡ä»¶ 12345678910111213141516171819202122232425262728293031vim /var/named/chroot/etc/named.confoptions { listen-on port 53 { 192.168.88.132; }; #listen-on-v6 port 53 { ::1; }; directory &quot;/var/named&quot;; dump-file &quot;/var/named/data/cache_dump.db&quot;; statistics-file &quot;/var/named/data/named_stats.txt&quot;; memstatistics-file &quot;/var/named/data/named_mem_stats.txt&quot;; recursing-file &quot;/var/named/data/named.recursing&quot;; secroots-file &quot;/var/named/data/named.secroots&quot;; allow-query { any; }; recursion yes; dnssec-enable yes; dnssec-validation yes; pid-file &quot;/run/named/named.pid&quot;; session-keyfile &quot;/run/named/session.key&quot;;};zone &quot;.&quot; IN { type hint; file &quot;named.ca&quot;;};include &quot;/etc/named.rfc1912.zones&quot;;include &quot;/etc/named.root.key&quot;;systemctl start named-chroot åŒºåŸŸæ•°æ®åº“æ–‡ä»¶è¯¦è§£ 123456789101112131415161718192021222324252627282930# æ­£å‘è§£æ named.localhost;ç¼“å­˜æ—¶é—´$TTL 1D;@è¡¨ç¤ºç›¸åº”çš„åŸŸå@ IN SOA @ rname.invalid. (;è§£æçš„åŸŸå ç±»å‹ æˆæƒåŸŸ æˆæƒåŸŸåæœåŠ¡å™¨ ç®¡ç†å‘˜é‚®ç®± 0 ; serial åºåˆ—å·,æ¯æ¬¡æ›´æ–°è¯¥æ–‡ä»¶ç³»åˆ—å·éƒ½åº”è¯¥å˜å¤§ 1D ; refresh åˆ·æ–°æ—¶é—´,å³è§„å®šä»åŸŸåæœåŠ¡å™¨å¤šé•¿æ—¶é—´æŸ¥è¯¢ä¸€ä¸ªä¸»æœåŠ¡å™¨ï¼Œä»¥ä¿è¯ä»æœåŠ¡å™¨çš„æ•°æ®æ˜¯æœ€æ–°çš„ 1H ; retry é‡è¯•æ—¶é—´,å³å½“ä»æœåŠ¡è¯•å›¾åœ¨ä¸»æœåŠ¡å™¨ä¸ŠæŸ¥è¯¢æ›´æ—¶ï¼Œè€Œè¿æ¥å¤±è´¥äº†ï¼Œåˆ™è¿™ä¸ªå€¼è§„å®šäº†ä»æœåŠ¡å¤šé•¿æ—¶é—´åå†è¯• 1W ; expire è¿‡æœŸæ—¶é—´,ä»æœåŠ¡å™¨åœ¨å‘ä¸»æœåŠ¡æ›´æ–°å¤±è´¥åå¤šé•¿æ—¶é—´åæ¸…é™¤å¯¹åº”çš„è®°å½• 3H ) ; minimum è¿™ä¸ªæ•°æ®ç”¨æ¥è§„å®šç¼“å†²æœåŠ¡å™¨ä¸èƒ½ä¸ä¸»æœåŠ¡è”ç³»ä¸Šåå¤šé•¿æ—¶é—´æ¸…é™¤ç›¸åº”çš„è®°å½• NS @ ;NS åç§°æœåŠ¡å™¨ï¼Œè¡¨ç¤ºè¿™ä¸ªä¸»æœºä¸ºåŸŸåæœåŠ¡å™¨ A 127.0.0.1;ä¸»æœºå¤´ Aè®°å½• IP AAAA ::1; AAAA è§£æä¸ºIPV6åœ°å€# åå‘è§£æ named.loopback$TTL 1D@ IN SOA @ rname.invalid. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS @ PTR localhost;IP åå‘æŒ‡é’ˆ åŸŸå;PTR åå‘æŒ‡é’ˆ åè§£ 2.3 æ­£å‘è§£æ ä¿®æ”¹ä¸»é…æ–‡ä»¶ 1234zone &quot;cqm.com&quot; IN { type master; file &quot;cqm.com.zone&quot;;}; åˆ›å»ºåŒºåŸŸæ•°æ®åº“æ–‡ä»¶ 12345678910111213141516171819202122232425cp /var/named/chroot/var/named/named.localhost /var/named/chroot/var/named/cqm.com.zonechgrp named cqm.com.zonevim /var/named/chroot/var/named/cqm.com.zone$TTL 1Dcqm.com. IN SOA dns.cqm.com. rname.invalid. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum# A:IPv4è§£æä¸ºåŸŸå# PTR:åŸŸåè§£æä¸ºIP# MX# CNAME:è®¾ç½®åˆ«å NS dns.cqm.com.# è§£ædnsä¸º192.168.88.132dns A 192.168.88.132# è§£æwwwä¸º192.168.88.132www A 192.168.88.132# ç”¨newsè®¿é—®ä¹Ÿè§£æä¸ºwwwnews CNAME www# æ£€æµ‹æ–‡ä»¶æ˜¯å¦æœ‰è¯¯named-checkzone cqm.com cqm.com.zone åœ¨å®¢æˆ·ç«¯ä¸Šé…ç½®DNS 12vim /etc/resolve.confnameserver 192.168.88.132 é€šè¿‡hostå‘½ä»¤è¿›è¡Œæµ‹è¯• 1234567yum -y install bind-utilshost www.cqm.comwww.cqm.com has address 192.168.88.132host news.cqm.comnews.cqm.com is an alias for www.cqm.com.www.cqm.com has address 192.168.88.132 2.4 åå‘è§£æ ä¿®æ”¹ä¸»é…æ–‡ä»¶ 1234zone &quot;88.168.192.in-addr.arpa&quot; IN { type master; file &quot;192.168.88.arpa&quot;;}; åˆ›å»ºåŒºåŸŸæ•°æ®åº“æ–‡ä»¶ 1234567891011121314cp /var/named/chroot/var/named/named.loopback /var/named/chroot/var/named/192.168.88.arpavim /var/named/chroot/var/named/192.168.88.arpa$TTL 1D88.168.192.in-addr.arpa. IN SOA dns.cqm.com. rname.invalid. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS dns.cqm.com.132 PTR www.cqm.com.named-checkzone 88.168.192.in-addr.arpa 192.168.88.arpa æµ‹è¯• 12host 192.168.88.132132.88.168.192.in-addr.arpa domain name pointer www.cqm.com. 2.5 ä¸»ä»åŒæ­¥å³é…ç½®ä¸¤å°DNSæœåŠ¡å™¨ï¼Œç”±äºä¸Šè¾¹æˆ‘ä»¬ä»¥åŠé…ç½®è¿‡ä¸»DNSäº†ï¼Œæ¥ä¸‹æ¥å†é…ç½®ä¸€å°è¾…DNSæœåŠ¡å™¨å³å¯ã€‚ ä¸»DNSæœåŠ¡å™¨IPï¼š192.168.88.132 è¾…DNSæœåŠ¡å™¨IPï¼š192.168.88.135 å®‰è£…DNS 1yum -y install bind bind-chroot é…ç½®ä¸»é…ç½®æ–‡ä»¶ 123456789101112131415161718192021222324252627282930313233343536373839404142434445scp root@192.168.88.132:/var/named/chroot/etc/named.conf /var/named/chroot/etc/named.confchgrp named /var/named/chroot/etc/named.confvim /var/named/chroot/etc/named.confoptions { listen-on port 53 { 192.168.88.135; }; #listen-on-v6 port 53 { ::1; }; directory &quot;/var/named&quot;; dump-file &quot;/var/named/data/cache_dump.db&quot;; statistics-file &quot;/var/named/data/named_stats.txt&quot;; memstatistics-file &quot;/var/named/data/named_mem_stats.txt&quot;; recursing-file &quot;/var/named/data/named.recursing&quot;; secroots-file &quot;/var/named/data/named.secroots&quot;; allow-query { any; }; # ä»ä¸»DNSæœåŠ¡å™¨æ‹·è¿‡æ¥çš„æ•°æ®ä¸è¿›è¡ŒåŠ å¯† masterfile-format text; recursion yes; dnssec-enable yes; dnssec-validation yes; pid-file &quot;/run/named/named.pid&quot;; session-keyfile &quot;/run/named/session.key&quot;;};zone &quot;.&quot; IN { type hint; file &quot;named.ca&quot;;};zone &quot;cqm.com&quot; IN { type slave; file &quot;cqm.com.zone&quot;; masters { 192.168.88.132; };};zone &quot;88.168.192.in-addr.arpa&quot; IN { type slave; file &quot;192.168.88.arpa&quot;; masters { 192.168.88.132; };};include &quot;/etc/named.rfc1912.zones&quot;;include &quot;/etc/named.root.key&quot;; é…ç½®å’Œä¸»DNSæœåŠ¡å™¨ç›¸åŒçš„åŒºåŸŸæ•°æ®åº“æ–‡ä»¶ 1234vim cqm.com.zone...vim 192.168.88.arpa... å°†DNSæœåŠ¡å™¨è®¾ä¸ºè‡ªå·±åè¿›è¡Œæµ‹è¯• 1234vim /etc/reslove.comfnameserver 192.168.88.135host www.cqm.com... 2.6 æ™ºèƒ½è§£æåœ¨DNSä¸­æ¤å…¥å…¨ä¸–ç•Œçš„IPåº“ä»¥åŠIPå¯¹åº”çš„åœ°åŸŸï¼Œå½“ç”¨æˆ·å‘æ¥è¯·æ±‚æ—¶ï¼Œä¼šæ ¹æ®ç”¨æˆ·å±äºå“ªä¸ªåœ°åŒºæ¥æ‰¾é‚£ä¸ªåœ°åŒºçš„åŒºåŸŸæ•°æ®åº“æ–‡ä»¶æ¥è¿›è¡Œè§£æï¼Œä»è€Œä½¿å¾—ä¸åŒåœ°åŸŸçš„ç”¨æˆ·è§£æä¸åŒã€‚ ä¾‹å­ï¼š éƒ¨ç½²ä¸€å°æ™ºèƒ½è§£æDNSæœåŠ¡å™¨ï¼Œå¯¹cqm.comè¿›è¡Œè§£æ æ·±åœ³ç”¨æˆ·è§£æä¸º1.1.1.1 å¹¿å·ç”¨æˆ·è§£æä¸º2.2.2.2 ä½›å±±ç”¨æˆ·è§£æä¸º3.3.3.3 ä¿®æ”¹ä¸»é…æ–‡ä»¶ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071options { listen-on port 53 { 192.168.88.132; }; #listen-on-v6 port 53 { ::1; }; directory &quot;/var/named&quot;; dump-file &quot;/var/named/data/cache_dump.db&quot;; statistics-file &quot;/var/named/data/named_stats.txt&quot;; memstatistics-file &quot;/var/named/data/named_mem_stats.txt&quot;; recursing-file &quot;/var/named/data/named.recursing&quot;; secroots-file &quot;/var/named/data/named.secroots&quot;; allow-query { any; }; recursion yes; dnssec-enable yes; dnssec-validation yes; pid-file &quot;/run/named/named.pid&quot;; session-keyfile &quot;/run/named/session.key&quot;;};acl sz { # å‡è®¾è¯¥ç½‘æ®µæ˜¯æ·±åœ³çš„IPåœ°å€æ®µ 192.168.77.0/24;};acl gz { 192.168.88.0/24;};acl fs { 192.168.99.0/24;};view shenzhen {match-clients { sz; }; zone &quot;.&quot; IN { type hint; file &quot;named.ca&quot;; }; zone &quot;cqm.com&quot; IN { type master; file &quot;cqm.com.zone.SZ&quot;; };};view guangzhou {match-clients { gz; }; zone &quot;.&quot; IN { type hint; file &quot;named.ca&quot;; }; zone &quot;cqm.com&quot; IN { type master; file &quot;cqm.com.zone.GZ&quot;; };};view foshan {match-clients { fs; }; zone &quot;.&quot; IN { type hint; file &quot;named.ca&quot;; }; zone &quot;cqm.com&quot; IN { type master; file &quot;cqm.com.zone.FS&quot;; };}; æ·»åŠ åŒºåŸŸæ•°æ®åº“æ–‡ä»¶ 12345678910111213141516171819202122232425262728293031323334353637383940414243cp cqm.com.zone cqm.com.zone.SZcp cqm.com.zone cqm.com.zone.GZcp cqm.com.zone cqm.com.zone.FSchgrp named cqm.com.zone.*# æ·±åœ³$TTL 1Dcqm.com. IN SOA dns.cqm.com. rname.invalid. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS dns.cqm.com.dns A 192.168.88.132www A 1.1.1.1news CNAME www# å¹¿å·$TTL 1Dcqm.com. IN SOA dns.cqm.com. rname.invalid. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS dns.cqm.com.dns A 192.168.88.132www A 2.2.2.2news CNAME www# ä½›å±±$TTL 1Dcqm.com. IN SOA dns.cqm.com. rname.invalid. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS dns.cqm.com.dns A 192.168.88.132www A 3.3.3.3news CNAME www æµ‹è¯• 123# æµ‹è¯•ä¸»æœºçš„åœ°å€æ®µä¸º192.168.88.0/24ç½‘æ®µçš„ï¼Œæ‰€ä»¥å±äºå¹¿å·åŒºåŸŸï¼Œå³åŒ¹é…è§£æåˆ°2.2.2.2host www.cqm.comwww.cqm.com has address 2.2.2.2 ä¸‰ã€FTPæ–‡ä»¶ä¼ è¾“æœåŠ¡3.1 FTPæœåŠ¡ä»‹ç»FTPå³æ–‡ä»¶ä¼ è¾“åè®®ï¼Œæ˜¯TCP/IPåè®®ç»„çš„åè®®ä¹‹ä¸€ã€‚ FTPé»˜è®¤é‡‡ç”¨TCP20å’Œ21ç«¯å£ï¼Œ20ç”¨äºä¼ è¾“æ•°æ®ï¼Œ21ç”¨äºæ§åˆ¶ä¼ è¾“ä¿¡æ¯ã€‚ FTPåˆ†åˆ«æœ‰ä¸»åŠ¨ä¼ è¾“æ–¹å¼å’Œè¢«åŠ¨ä¼ è¾“æ–¹å¼ä¸¤ç§ï¼Œå½“FTPä¸ºä¸»åŠ¨ä¼ è¾“æ–¹å¼æ—¶è¿ç”¨20å’Œ21ç«¯å£ï¼Œè€Œå½“FTPä¸ºè¢«åŠ¨ä¼ è¾“æ–¹å¼æ—¶åˆ™ä¼šéšå³æ‰“å¼€ä¸€ä¸ªå¤§äº1024çš„ç«¯å£æ¥è¿›è¡Œæ•°æ®çš„ä¼ è¾“ã€‚ 3.2 FTPæœåŠ¡éƒ¨ç½² å®‰è£…vsftpd 1yum -y install vsftpd ä¸»é…æ–‡ä»¶è¯¦è§£ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167# Example config file /etc/vsftpd/vsftpd.conf## The default compiled in settings are fairly paranoid. This sample file# loosens things up a bit, to make the ftp daemon more usable.# Please see vsftpd.conf.5 for all compiled in defaults.## READ THIS: This example file is NOT an exhaustive list of vsftpd options.# Please read the vsftpd.conf.5 manual page to get a full idea of vsftpd's# capabilities.##åŒ¿åç”¨æˆ·è®¿é—®,YESæ˜¯å…è®¸ï¼ŒNOæ˜¯æ‹’ç»# Allow anonymous FTP? (Beware - allowed by default if you comment this out).anonymous_enable=YES## Uncomment this to allow local users to log in.# æœ¬åœ°ç”¨æˆ·ç™»å½•,YESæ˜¯å…è®¸ï¼ŒNOæ˜¯æ‹’ç».é»˜è®¤è®¿é—®çš„æ˜¯æœ¬åœ°ç”¨æˆ·å®¶ç›®å½•ï¼Œå¦‚æœä½ å¼€å¯äº†selinux# è¯·è®¾ç½®å¼€å¯å¸ƒå°”å€¼ftp_home_dirä¸ºON# When SELinux is enforcing check for SE bool ftp_home_dirlocal_enable=YES##å…è®¸æœ¬åœ°ç”¨æˆ·ä¸Šä¼ # Uncomment this to enable any form of FTP write command.write_enable=YES## Default umask for local users is 077. You may wish to change this to 022,# ä¸Šä¼ çš„æƒé™æ˜¯022ï¼Œä½¿ç”¨çš„æ˜¯umaskæƒé™ã€‚å¯¹åº”çš„ç›®å½•æ˜¯755ï¼Œæ–‡ä»¶æ˜¯644# if your users expect that (022 is used by most other ftpd's)local_umask=022## Uncomment this to allow the anonymous FTP user to upload files. This only# has an effect if the above global write enable is activated. Also, you will# obviously need to create a directory writable by the FTP user.# When SELinux is enforcing check for SE bool allow_ftpd_anon_write, allow_ftpd_full_access# å¼€å¯åŒ¿åç”¨æˆ·ä¸Šä¼ åŠŸèƒ½ï¼Œé»˜è®¤æ˜¯æ‹’ç»çš„#anon_upload_enable=YES## Uncomment this if you want the anonymous FTP user to be able to create# new directories.# å¼€å¯åŒ¿åç”¨æˆ·åˆ›å»ºæ–‡ä»¶æˆ–æ–‡ä»¶å¤¹æƒé™#anon_mkdir_write_enable=YES## Activate directory messages - messages given to remote users when they# go into a certain directory.# å¼€å¯ç›®å½•æ¬¢è¿æ¶ˆæ¯ï¼Œä¸€èˆ¬å¯¹å‘½ä»¤è¡Œç™»é™†æœ‰æ•ˆdirmessage_enable=YES## Activate logging of uploads/downloads.# å¼€å¯ä¸Šä¼ å’Œä¸‹è½½æ—¥å¿—è®°å½•åŠŸèƒ½xferlog_enable=YES##ä½¿ç”¨æ ‡å‡†æ¨¡å¼# Make sure PORT transfer connections originate from port 20 (ftp-data).connect_from_port_20=YES## If you want, you can arrange for uploaded anonymous files to be owned by# a different user. Note! Using &quot;root&quot; for uploaded files is not# recommended!# å£°æ˜åŒ¿åç”¨æˆ·ä¸Šä¼ æ–‡ä»¶çš„æ‰€æœ‰è€…# å…è®¸æ›´æ”¹åŒ¿åç”¨æˆ·ä¸Šä¼ æ–‡ä»¶çš„æ‰€æœ‰è€…#chown_uploads=YES#æ‰€æœ‰è€…ä¸ºwhoever#chown_username=whoever## You may override where the log file goes if you like. The default is shown# below.# æ—¥å¿—æ–‡ä»¶è·¯å¾„#xferlog_file=/var/log/xferlog## If you want, you can have your log file in standard ftpd xferlog format.# Note that the default log file location is /var/log/xferlog in this case.# æ—¥å¿—æ–‡ä»¶é‡‡ç”¨æ ‡å‡†æ ¼æ–¯xferlog_std_format=YES## You may change the default value for timing out an idle session.# ä¼šè¯è¶…æ—¶æ—¶é—´#idle_session_timeout=600## You may change the default value for timing out a data connection.# æ•°æ®ä¼ è¾“è¶…æ—¶æ—¶é—´#data_connection_timeout=120## It is recommended that you define on your system a unique user which the# ftp server can use as a totally isolated and unprivileged user.# FTPå­è¿›ç¨‹ç®¡ç†ç”¨æˆ·#nopriv_user=ftpsecure## Enable this and the server will recognise asynchronous ABOR requests. Not# recommended for security (the code is non-trivial). Not enabling it,# however, may confuse older FTP clients.# æ˜¯å¦å…è®¸å®¢æˆ·ç«¯å‘èµ·â€œasync ABORâ€è¯·æ±‚ï¼Œè¯¥æ“ä½œæ˜¯ä¸å®‰å…¨çš„é»˜è®¤ç¦æ­¢ã€‚#async_abor_enable=YES## By default the server will pretend to allow ASCII mode but in fact ignore# the request. Turn on the below options to have the server actually do ASCII# mangling on files when in ASCII mode. The vsftpd.conf(5) man page explains# the behaviour when these options are disabled.# Beware that on some FTP servers, ASCII support allows a denial of service# attack (DoS) via the command &quot;SIZE /big/file&quot; in ASCII mode. vsftpd# predicted this attack and has always been safe, reporting the size of the# raw file.# ASCII mangling is a horrible feature of the protocol.# è¯¥é€‰é¡¹ç”¨äºæŒ‡å®šæ˜¯å¦å…è®¸ä¸Šä¼ æ—¶ä»¥ASCIIæ¨¡å¼ä¼ è¾“æ•°æ®#ascii_upload_enable=YES#è¯¥é€‰é¡¹ç”¨äºæŒ‡å®šæ˜¯å¦å…è®¸ä¸‹è½½æ—¶ä»¥ASCIIæ¨¡å¼ä¼ è¾“æ•°æ®#ascii_download_enable=YES## You may fully customise the login banner string:# FTPæ–‡æœ¬ç•Œé¢ç™»é™†æ¬¢è¿è¯#ftpd_banner=Welcome to blah FTP service.## You may specify a file of disallowed anonymous e-mail addresses. Apparently# useful for combatting certain DoS attacks.# æ˜¯å¦å¼€å¯æ‹’ç»çš„EmailåŠŸèƒ½#deny_email_enable=YES# (default follows)# æŒ‡å®šä¿å­˜è¢«æ‹’æ¥çš„Emailåœ°å€çš„æ–‡ä»¶#banned_email_file=/etc/vsftpd/banned_emails## You may specify an explicit list of local users to chroot() to their home# directory. If chroot_local_user is YES, then this list becomes a list of# users to NOT chroot().# (Warning! chroot'ing can be very dangerous. If using chroot, make sure that# the user does not have write access to the top level directory within the# chroot)# æ˜¯å¦å¼€å¯å¯¹æœ¬åœ°ç”¨æˆ·chrootçš„é™åˆ¶ï¼ŒYESä¸ºé»˜è®¤æ‰€æœ‰ç”¨æˆ·éƒ½ä¸èƒ½åˆ‡å‡ºå®¶ç›®å½•ï¼ŒNOä»£è¡¨é»˜è®¤ç”¨æˆ·éƒ½å¯ä»¥åˆ‡å‡ºå®¶ç›®å½•# è®¾ç½®æ–¹æ³•ç±»ä¼¼äºï¼šYESæ‹’ç»æ‰€æœ‰å…è®¸ä¸ªåˆ«ï¼›NOå…è®¸æ‰€æœ‰æ‹’ç»ä¸ªåˆ«#chroot_local_user=YES# å¼€å¯ç‰¹ä¾‹åˆ—è¡¨#chroot_list_enable=YES# (default follows)# å¦‚æœchroot_local_userçš„å€¼æ˜¯YESåˆ™è¯¥æ–‡ä»¶ä¸­çš„ç”¨æˆ·æ˜¯å¯ä»¥åˆ‡å‡ºå®¶ç›®å½•ï¼Œå¦‚æœæ˜¯NOï¼Œè¯¥æ–‡ä»¶ä¸­çš„ç”¨æˆ·åˆ™ä¸èƒ½åˆ‡å‡ºå®¶ç›®å½•# ä¸€è¡Œä¸€ä¸ªç”¨æˆ·ã€‚#chroot_list_file=/etc/vsftpd/chroot_list## You may activate the &quot;-R&quot; option to the builtin ls. This is disabled by# default to avoid remote users being able to cause excessive I/O on large# sites. However, some broken FTP clients such as &quot;ncftp&quot; and &quot;mirror&quot; assume# the presence of the &quot;-R&quot; option, so there is a strong case for enabling it.# æ˜¯å¦å¼€å¯ls é€’å½’æŸ¥è¯¢åŠŸèƒ½ ls -R#ls_recurse_enable=YES## When &quot;listen&quot; directive is enabled, vsftpd runs in standalone mode and# listens on IPv4 sockets. This directive cannot be used in conjunction# with the listen_ipv6 directive.# æ˜¯å¦å¼€å¯ftpç‹¬ç«‹æ¨¡å¼åœ¨IPV4listen=NO## This directive enables listening on IPv6 sockets. By default, listening# on the IPv6 &quot;any&quot; address (::) will accept connections from both IPv6# and IPv4 clients. It is not necessary to listen on *both* IPv4 and IPv6# sockets. If you want that (perhaps because you want to listen on specific# addresses) then you must run two copies of vsftpd with two configuration# files.# Make sure, that one of the listen options is commented !!# æ˜¯å¦å¼€å¯ftpç‹¬ç«‹æ¨¡å¼åœ¨ipv6listen_ipv6=YES#å¯ç”¨pamæ¨¡å—éªŒè¯pam_service_name=vsftpd#æ˜¯å¦å¼€å¯userliståŠŸèƒ½.å®šä¹‰å¯¹åˆ—è¡¨ä¸­çš„ç”¨æˆ·åšå®šä¹‰userlist_deny=NO#NOæ‹’ç»æ‰€æœ‰äººè®¿é—®ï¼Œå¯¹åº”åˆ—è¡¨ä¸­çš„ç”¨æˆ·å¯ä»¥è®¿é—®ï¼ŒYESå…è®¸æ‰€æœ‰äººè®¿é—®ï¼Œåˆ—è¡¨ä¸­çš„ç”¨æˆ·æ— æ³•è®¿é—®ã€‚#åªæœ‰userlist_file=/etc/vsftpd/user_listå®šä¹‰çš„ç”¨æˆ·æ‰å¯ä»¥è®¿é—®æˆ–æ‹’ç»è®¿é—®userlist_enable=YES#æ˜¯å¦å¼€å¯tcp_wrappersç®¡ç†ï¼ŒTCP_Wrappersæ˜¯ä¸€ä¸ªå·¥ä½œåœ¨ç¬¬å››å±‚ï¼ˆä¼ è¾“å±‚ï¼‰çš„çš„å®‰å…¨å·¥å…·ï¼Œ#å¯¹æœ‰çŠ¶æ€è¿æ¥çš„ç‰¹å®šæœåŠ¡è¿›è¡Œå®‰å…¨æ£€æµ‹å¹¶å®ç°è®¿é—®æ§åˆ¶tcp_wrappers=YES åŒ¿åç”¨æˆ·å’Œæœ¬åœ°ç”¨æˆ· éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒåŒ¿åç”¨æˆ·è®¿é—®çš„æ˜¯/var/ftpï¼Œè€Œæœ¬åœ°ç”¨æˆ·è®¿é—®çš„è¯æ˜¯å®¶ç›®å½•ã€‚ å…³äºæƒé™ï¼Œåœ¨ä¸»é…æ–‡ä»¶ä¸­è®¾ç½®çš„æƒé™æ˜¯åç ï¼Œæ–‡ä»¶å®é™…æƒé™ = 666 - åç ã€‚ å‡å¦‚ä¸»é…æ–‡ä»¶ä¸­è®¾ç½®ä¸º022ï¼Œé‚£ä¹ˆæ–‡ä»¶å®é™…æƒé™ = 666 - 022 = 644ï¼Œæ–‡ä»¶å¤¹å®é™…æƒé™ = 777 - 022 = 755ã€‚ åœ¨linuxç«¯è®¿é—®FTPæœåŠ¡å™¨æ—¶ï¼Œæ— è®ºFTPæœåŠ¡å™¨æ˜¯å¦å¼€å¯äº†åŒ¿åç”¨æˆ·è®¿é—®ï¼Œå®¢æˆ·è®¿é—®æ—¶éƒ½è¦è¾“å…¥ç”¨æˆ·åå’Œå¯†ç ï¼ŒåŒ¿åç”¨æˆ·ç”¨æˆ·åftpï¼Œå¯†ç éšæ„ï¼Œä½†æ˜¯éœ€è¦ä¸ºå¸¦æœ‰@çš„emailåœ°å€ã€‚ å¼€å¯chroot 12345678910# æ˜¯å¦å¼€å¯å¯¹æœ¬åœ°ç”¨æˆ·chrootçš„é™åˆ¶ï¼ŒYESä¸ºé»˜è®¤æ‰€æœ‰ç”¨æˆ·éƒ½ä¸èƒ½åˆ‡å‡ºå®¶ç›®å½•ï¼ŒNOä»£è¡¨é»˜è®¤ç”¨æˆ·éƒ½å¯ä»¥åˆ‡å‡ºå®¶ç›®å½•# è®¾ç½®æ–¹æ³•ç±»ä¼¼äºï¼šYESæ‹’ç»æ‰€æœ‰å…è®¸ä¸ªåˆ«ï¼›NOå…è®¸æ‰€æœ‰æ‹’ç»ä¸ªåˆ«chroot_local_user=YESchroot_list_enable=YES# ç‰¹ä¾‹åˆ—è¡¨chroot_list_file=/etc/vsftpd/chroot_list# å¦‚æœç”¨æˆ·å®¶ç›®å½•æœ‰å†™æƒé™çš„è¯ï¼Œåˆ™è¯¥ç”¨æˆ·ç™»é™†ä¸ä¸Š# å¦‚æœæƒ³åœ¨æœ‰å†™æƒé™çš„å®¶ç›®å½•ç™»å½•çš„è¯ï¼Œéœ€åœ¨é…ç½®æ–‡ä»¶åŠ ä¸Šallow_writeable_chroot=YES 3.3 FTPå‘½ä»¤ç™»å½•åˆ°FTPæœåŠ¡å™¨åï¼ŒåŸºæœ¬å‘½ä»¤å¦‚ä¸‹ 123456789help # æ‰“å°å‘½ä»¤èœå•!+linuxå‘½ä»¤ # æ‰§è¡Œlinuxå‘½ä»¤lcd ç›®å½•è·¯å¾„ # åˆ‡æ¢linuxå½“å‰è·¯å¾„put mput # ä¸Šä¼  æ‰¹é‡ä¸Šä¼ get mget # ä¸‹è½½ æ‰¹é‡ä¸‹è½½ls dir # åˆ—å‡ºç›®å½•å†…å®¹mkdir cd delete rmdir # åˆ›å»ºç›®å½• è¿›å…¥ç›®å½• åˆ é™¤æ–‡ä»¶ åˆ é™¤ç›®å½•pwd # ç°å®FTPå½“å‰è·¯å¾„open close bye # å¼€å¯/å…³é—­/é€€å‡ºFTP 3.4 è™šæ‹Ÿç”¨æˆ·ç”±äºFTPæ˜¯é‡‡ç”¨æœ¬åœ°ç”¨æˆ·æ¥è¿›è¡Œç™»å½•çš„ï¼Œæ‰€ä»¥ä¼šå°†æœ¬åœ°ç”¨æˆ·æš´éœ²åœ¨äº’è”ç½‘ä¸­ï¼Œå¦‚æœæ²¡æœ‰ç›¸å…³å®‰å…¨è®¾ç½®ï¼Œå°±ä¼šé€ æˆFTPä¸å®‰å…¨ã€‚ å› æ­¤FTPå¯ä»¥è®¾ç½®è™šæ‹Ÿç”¨æˆ·æ¥è§£å†³è¯¥é—®é¢˜ã€‚ åœ¨ä¸»é…æ–‡ä»¶ä¸­å¼€å¯è™šæ‹Ÿç”¨æˆ· 123456guest_enable=YESguest_username=cqm# è™šæ‹Ÿç”¨æˆ·ä¸ç”¨æœ¬åœ°ç”¨æˆ·çš„æƒé™virtual_use_local_privs=NO# ç”¨æˆ·æ–‡ä»¶å­˜æ”¾åœ°å€user_config_dir=/etc/vsftpd/vconf.d 3.5 åŸºäºè™šæ‹Ÿç”¨æˆ·é…ç½®çš„å®‰å…¨FTPæ¡ˆä¾‹è¦æ±‚ï¼š å…¬å¸å…¬å…±æ–‡ä»¶å¯ä»¥é€šè¿‡åŒ¿åä¸‹è½½ å…¬å¼Aéƒ¨é—¨ã€Béƒ¨é—¨ã€Céƒ¨é—¨åˆ†åˆ«ç”±è‡ªå·±çš„æ–‡ä»¶å¤¹ï¼Œå¹¶ç›¸äº’éš”ç¦» éƒ¨é—¨ä¹‹é—´åªæœ‰ä¸»ç®¡æ‹¥æœ‰ä¸Šä¼ æƒé™ï¼Œéƒ¨é—¨å‘˜å·¥åªæœ‰ä¸‹è½½æƒé™ ç¦æ­¢ç”¨æˆ·æŸ¥çœ‹å®¶ç›®å½•ä»¥å¤–çš„æ•°æ® ç¡®ä¿FTPè´¦å·å®‰å…¨ åˆ›å»ºè™šæ‹Ÿç”¨æˆ·æ˜ å°„æœ¬åœ°è´¦å· 1useradd -s /sbin/nologin -d /var/tmp/vuser_ftp cqm åˆ›å»ºç›®å½•ï¼Œæ‰€æœ‰æ“ä½œéƒ½åªèƒ½åœ¨æ­¤ç›®å½•è¿›è¡Œ 1234chmod 500 /var/tmp/vuser_ftpmkdir /var/tmp/vuser_ftp/{A,B,C}chmod 700 /var/tmp/vuser_ftp/*chown -R cqm:cqm /var/tmp/vuser_ftp åˆ›å»ºè™šæ‹Ÿç”¨æˆ·è´¦å·å¯†ç æ–‡ä»¶ï¼Œå¹¶ç”Ÿæˆdbæ–‡ä»¶ 123456789101112131415vim /etc/vsftpd/vuserA_01123B_01123C_01123A_02123B_02123C_02123db_load -T -t hash -f /etc/vsftpd/vuser /etc/vsftpd/vuser.dbchmod 600 /etc/vsftpd/vuser.db è®¾ç½®è™šæ‹Ÿç”¨æˆ·pamè®¤è¯ 123vim /etc/pam.d/vsftpdauth sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/vuseraccount sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/vuser è¦æ±‚ä¸èƒ½åˆ‡å‡ºå®¶ç›®å½•ï¼Œæ‰€ä»¥è¦è®¾ç½®chroot_list 1234567vim /etc/vsftpd/chroot_listA_01B_01C_01A_02B_02C_02 åˆ›å»ºå­é…ç½®æ–‡ä»¶ 1234567891011121314151617181920mkdir /etc/vsftpd/vconf.d# Aä¸»ç®¡æ–‡ä»¶vim /etc/vsftpd/vconf.d/A_01# æŒ‡å®šå®¶ç›®å½•local_root=/var/tmp/vuser_ftp/A# æŒ‡å®šæƒé™anon_umask=077# ä¸‹è½½æƒé™anon_world_readable_only=NO# ä¸Šä¼ æƒé™anon_upload_enable=YES# åˆ›å»ºç›®å½•æƒé™anon_mkdir_write_enable=YES# åˆ é™¤å’Œé‡å‘½åç›®å½•æƒé™anon_other_write_enable=YES# Aå‘˜å·¥æ–‡ä»¶vim /etc/vsftpd/vconf.d/A_02local_root=/var/tmp/vuser_ftp/Aanon_world_readable_only=NO é…ç½®ä¸»é…æ–‡ä»¶ 123456789101112131415161718192021vim /etc/vsftpd/vsftpd.confanonymous_enable=YESlocal_enable=YESwrite_enable=YESlocal_umask=022dirmessage_enable=YESxferlog_enable=YESconnect_from_port_20=YESxferlog_std_format=YESchroot_local_user=YESchroot_list_enable=YESchroot_list_file=/etc/vsftpd/chroot_listlisten=YESlisten_ipv6=NOpam_service_name=vsftpduserlist_enable=YEStcp_wrappers=YESguest_enable=YESguest_username=cqmvirtual_use_local_privs=NOuser_config_dir=/etc/vsftpd/vconf.d æµ‹è¯•ä¸»ç®¡ç”¨æˆ·å’Œå‘˜å·¥ç”¨æˆ·çš„æƒé™ 1234ftp 192.168.88.132A_01123230 Login successful å››ã€SambaæœåŠ¡4.1 SambaæœåŠ¡ä»‹ç»Sambaæ˜¯å¯ä»¥å®ç°ä¸åŒè®¡ç®—æœºç³»ç»Ÿä¹‹é—´æ–‡ä»¶å…±äº«çš„æœåŠ¡ï¼Œå³æ˜¯åœ¨Linuxå’ŒUNIXç³»ç»Ÿä¸Šå®ç°SMBåè®®çš„ä¸€ä¸ªå…è´¹è½¯ä»¶ã€‚ SMBï¼ˆServer Messages Blockï¼Œä¿¡æ¯æœåŠ¡å—ï¼‰æ˜¯ä¸€ç§åœ¨å±€åŸŸç½‘ä¸Šå…±äº«æ–‡ä»¶å’Œæ‰“å°æœºçš„ä¸€ç§é€šä¿¡åè®®ï¼Œå®ƒä¸ºå±€åŸŸç½‘å†…çš„ä¸åŒè®¡ç®—æœºä¹‹é—´æä¾›æ–‡ä»¶åŠæ‰“å°æœºç­‰èµ„æºçš„å…±äº«æœåŠ¡ã€‚ Sambaé‡‡ç”¨åˆ°çš„ç«¯å£æœ‰ï¼š UDP 137ï¼šNetBIOS åå­—æœåŠ¡ UDP 138ï¼šNetBIOS æ•°æ®æŠ¥æœåŠ¡ UDP 139ï¼šSMB TCP 389ï¼šç”¨äº LDAP (Active Directory Mode) TCP 445ï¼šNetBIOSæœåŠ¡åœ¨windos 2000åŠä»¥åç‰ˆæœ¬ä½¿ç”¨æ­¤ç«¯å£, (Common Internet File Systemï¼ŒCIFSï¼Œå®ƒæ˜¯SMBåè®®æ‰©å±•åˆ°Internetåï¼Œå®ç°Internetæ–‡ä»¶å…±äº«) TCP 901ï¼šç”¨äº SWATï¼Œç”¨äºç½‘é¡µç®¡ç†Samba 4.2 SambaæœåŠ¡éƒ¨ç½² å®‰è£…samba 12yum -y install samba samba-clientsystemctl start smb nmb ä¸»é…æ–‡ä»¶è¯¦è§£ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351cat /etc/samba/smb.conf.example# This is the main Samba configuration file. For detailed information about the# options listed here, refer to the smb.conf(5) manual page. Samba has a huge# number of configurable options, most of which are not shown in this example.## The Samba Wiki contains a lot of step-by-step guides installing, configuring,# and using Samba:# https://wiki.samba.org/index.php/User_Documentation## In this file, lines starting with a semicolon (;) or a hash (#) are# comments and are ignored. This file uses hashes to denote commentary and# semicolons for parts of the file you may wish to configure.## NOTE: Run the &quot;testparm&quot; command after modifying this file to check for basic# syntax errors.##---------------##SAMBA selinuxç›¸å…³è®¾ç½®ï¼Œå¦‚æœä½ å¼€å¯äº†selinuxï¼Œè¯·æ³¨æ„ä¸‹é¢çš„è¯´æ˜###Security-Enhanced Linux (SELinux) Notes:## Turn the samba_domain_controller Boolean on to allow a Samba PDC to use the# useradd and groupadd family of binaries. Run the following command as the# root user to turn this Boolean on:# å¦‚æœä½ åœ¨åŸŸç¯å¢ƒä¸­ä½¿ç”¨sambaé‚£ä¹ˆè¯·è®¾ç½®ä¸‹é¢çš„boolå€¼# setsebool -P samba_domain_controller on## Turn the samba_enable_home_dirs Boolean on if you want to share home# directories via Samba. Run the following command as the root user to turn this# Boolean on:## å‡å¦‚å¸Œæœ›é€šè¿‡sambaå…±äº«ç”¨æˆ·å®¶ç›®å½•è¯·è®¾ç½®ä¸‹é¢çš„boolå€¼# setsebool -P samba_enable_home_dirs on## If you create a new directory, such as a new top-level directory, label it# with samba_share_t so that SELinux allows Samba to read and write to it. Do# not label system directories, such as /etc/ and /home/, with samba_share_t, as# such directories should already have an SELinux label.##åŠ å…¥ä½ æƒ³å°†ç›®å½•é€šè¿‡sambaå…±äº«ï¼Œè¯·ç¡®è®¤å…¶ç›®å½•æ ‡ç­¾ä¸ºsambe_share_t# Run the &quot;ls -ldZ /path/to/directory&quot; command to view the current SELinux# label for a given directory.## Set SELinux labels only on files and directories you have created. Use the# chcon command to temporarily change a label:# æ ‡ç­¾è®¾ç½®æ–¹æ³•# chcon -t samba_share_t /path/to/directory## Changes made via chcon are lost when the file system is relabeled or commands# such as restorecon are run.## Use the samba_export_all_ro or samba_export_all_rw Boolean to share system# directories. To share such directories and only allow read-only permissions:# å¯¹å…±äº«ç›®å½•çš„æƒé™çš„boolè®¾ç½®ï¼Œåªè¯»æˆ–è¯»å†™# setsebool -P samba_export_all_ro on# To share such directories and allow read and write permissions:# setsebool -P samba_export_all_rw on## To run scripts (preexec/root prexec/print command/...), copy them to the# /var/lib/samba/scripts/ directory so that SELinux will allow smbd to run them.# Note that if you move the scripts to /var/lib/samba/scripts/, they retain# their existing SELinux labels, which may be labels that SELinux does not allow# smbd to run. Copying the scripts will result in the correct SELinux labels.# Run the &quot;restorecon -R -v /var/lib/samba/scripts&quot; command as the root user to# apply the correct SELinux labels to these files.##--------------##======================= Global Settings =====================================#å…¨å±€è®¾ç½®ï¼Œå¯¹æ•´ä¸ªæœåŠ¡éƒ½ç”Ÿæ•ˆ[global]#ç½‘ç»œè®¾ç½®# ----------------------- Network-Related Options -------------------------## workgroup = the Windows NT domain name or workgroup name, for example, MYGROUP.## server string = the equivalent of the Windows NT Description field.## netbios name = used to specify a server name that is not tied to the hostname,# maximum is 15 characters.## interfaces = used to configure Samba to listen on multiple network interfaces.# If you have multiple interfaces, you can use the &quot;interfaces =&quot; option to# configure which of those interfaces Samba listens on. Never omit the localhost# interface (lo).## hosts allow = the hosts allowed to connect. This option can also be used on a# per-share basis.## hosts deny = the hosts not allowed to connect. This option can also be used on# a per-share basis.##å®šä¹‰è®¡ç®—æœºçš„å·¥ä½œç»„,å¦‚æœå¸Œæœ›å’Œwindowså…±äº«ï¼Œå¯ä»¥è®¾ç½®ä¸ºworkgroupï¼Œè¿™æ ·å°±å¯ä»¥åœ¨windowsçš„ç½‘ä¸Šé‚»å±…ä¸­æ‰¾åˆ°linuxè®¡ç®—æœº workgroup = MYGROUP#å¯¹sambaæœåŠ¡å™¨çš„æè¿°ä¿¡æ¯ server string = Samba Server Version %v#è®¾ç½®netbiosè®¡ç®—æœºåç§°; netbios name = MYSERVER#sambaä½¿ç”¨æœ¬æœºçš„é‚£å—ç½‘å¡; interfaces = lo eth0 192.168.12.2/24 192.168.13.2/24#å…è®¸é‚£ä¸ªç½‘æ®µè®¿é—®sambaæœåŠ¡å™¨å…±äº«; hosts allow = 127. 192.168.12. 192.168.13.##æ—¥å¿—é€‰é¡¹# --------------------------- Logging Options -----------------------------## log file = specify where log files are written to and how they are split.## max log size = specify the maximum size log files are allowed to reach. Log# files are rotated when they reach the size specified with &quot;max log size&quot;.# #sambaæ—¥å¿—æ–‡ä»¶è·¯å¾„ # log files split per-machine: log file = /var/log/samba/log.%m #æ—¥å¿—æ–‡ä»¶å¤§å°ï¼Œ0ä¸ºä¸é™åˆ¶ï¼Œæ³¨æ„ä¸å»ºè®®è¿™æ ·è®¾ç½® # maximum size of 50KB per log file, then rotate: max log size = 50#ç‹¬ç«‹æœåŠ¡é€‰é¡¹# ----------------------- Standalone Server Options ------------------------## security = the mode Samba runs in. This can be set to user, share# (deprecated), or server (deprecated).## passdb backend = the backend used to store user information in. New# installations should use either tdbsam or ldapsam. No additional configuration# is required for tdbsam. The &quot;smbpasswd&quot; utility is available for backwards# compatibility.##sambaå®‰å…¨çº§åˆ«#share: ä¸éœ€è¦è´¦å·å¯†ç ï¼Œå…¬å¼€å…±äº«#user: éœ€è¦æä¾›samè´¦å·å¯†ç æ‰èƒ½è®¿é—®å…±äº«ï¼Œç§å¯†å…±äº«#serverï¼šä¾é å…¶ä»–Windows NT/2000æˆ–Samba Serveræ¥éªŒè¯ç”¨æˆ·çš„è´¦å·å’Œå¯†ç ,æ˜¯ä¸€ç§ä»£ç†éªŒè¯ã€‚æ­¤ç§å®‰å…¨æ¨¡å¼ä¸‹,ç³»ç»Ÿç®¡ç†å‘˜å¯ä»¥æŠŠæ‰€æœ‰çš„Windowsç”¨æˆ·å’Œå£ä»¤é›†ä¸­åˆ°ä¸€ä¸ªNTç³»ç»Ÿä¸Š,&gt;ä½¿ç”¨Windows NTè¿›è¡ŒSambaè®¤è¯, è¿œç¨‹æœåŠ¡å™¨å¯ä»¥è‡ªåŠ¨è®¤è¯å…¨éƒ¨ç”¨æˆ·å’Œå£ä»¤,å¦‚æœè®¤è¯å¤±è´¥,Sambaå°†ä½¿ç”¨ç”¨æˆ·çº§å®‰å…¨æ¨¡å¼ä½œä¸ºæ›¿ä»£çš„æ–¹å¼ã€‚#domainï¼šåŸŸå®‰å…¨çº§åˆ«,ä½¿ç”¨ä¸»åŸŸæ§åˆ¶å™¨(PDC)æ¥å®Œæˆè®¤è¯ã€‚##ä¸€èˆ¬æƒ…å†µä¸‹æˆ‘ä»¬ä½¿ç”¨shareå’Œuserçš„æ¯”è¾ƒå¤šï¼Œé™¤éå…¬å¸æœ‰å®Œæ•´çš„åŸŸç¯å¢ƒ security = user#è¯¥æ–¹å¼åˆ™æ˜¯ä½¿ç”¨ä¸€ä¸ªæ•°æ®åº“æ–‡ä»¶æ¥å»ºç«‹ç”¨æˆ·æ•°æ®åº“ã€‚æ•°æ®åº“æ–‡ä»¶å«passdb.tdbï¼Œé»˜è®¤åœ¨/etc/sambaç›®å½•ä¸‹ã€‚passdb.tdb ç”¨æˆ·æ•°æ®åº“å¯ä»¥ä½¿ç”¨smbpasswd â€“aæ¥å»ºç«‹Sambaç”¨æˆ·ï¼Œä¸è¿‡è¦å»ºç«‹çš„Sambaç”¨æˆ·å¿…é¡»å…ˆæ˜¯ç³»ç»Ÿç”¨æˆ·ã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨pdbeditå‘½ä»¤æ¥å»ºç«‹Sambaè´¦æˆ·å¹¶ç”±å…¶pdbeditç®¡ç†ã€‚ passdb backend = tdbsam#åŸŸæˆå‘˜é€‰é¡¹# ----------------------- Domain Members Options ------------------------## security = must be set to domain or ads.## passdb backend = the backend used to store user information in. New# installations should use either tdbsam or ldapsam. No additional configuration# is required for tdbsam. The &quot;smbpasswd&quot; utility is available for backwards# compatibility.## realm = only use the realm option when the &quot;security = ads&quot; option is set.# The realm option specifies the Active Directory realm the host is a part of.## password server = only use this option when the &quot;security = server&quot;# option is set, or if you cannot use DNS to locate a Domain Controller. The# argument list can include My_PDC_Name, [My_BDC_Name], and [My_Next_BDC_Name]:## password server = My_PDC_Name [My_BDC_Name] [My_Next_BDC_Name]## Use &quot;password server = *&quot; to automatically locate Domain Controllers.#è®¾ç½®åŸŸå…±äº«; security = domain; passdb backend = tdbsam#å®šä¹‰åŸŸåç§°; realm = MY_REALM#åŸŸéªŒè¯æœåŠ¡å™¨; password server = #åŸŸæ§é€‰é¡¹# ----------------------- Domain Controller Options ------------------------## security = must be set to user for domain controllers.## passdb backend = the backend used to store user information in. New# installations should use either tdbsam or ldapsam. No additional configuration# is required for tdbsam. The &quot;smbpasswd&quot; utility is available for backwards# compatibility.## domain master = specifies Samba to be the Domain Master Browser, allowing# Samba to collate browse lists between subnets. Do not use the &quot;domain master&quot;# option if you already have a Windows NT domain controller performing this task.## domain logons = allows Samba to provide a network logon service for Windows# workstations.## logon script = specifies a script to run at login time on the client. These# scripts must be provided in a share named NETLOGON.## logon path = specifies (with a UNC path) where user profiles are stored.##; security = user; passdb backend = tdbsam; domain master = yes; domain logons = yes # the following login script name is determined by the machine name # (%m):; logon script = %m.bat # the following login script name is determined by the UNIX user used:; logon script = %u.bat; logon path = \\\\%L\\Profiles\\%u # use an empty path to disable profile support:; logon path = # various scripts can be used on a domain controller or a stand-alone # machine to add or delete corresponding UNIX accounts:; add user script = /usr/sbin/useradd &quot;%u&quot; -n -g users; add group script = /usr/sbin/groupadd &quot;%g&quot;; add machine script = /usr/sbin/useradd -n -c &quot;Workstation (%u)&quot; -M -d /nohome -s /bin/false &quot;%u&quot;; delete user script = /usr/sbin/userdel &quot;%u&quot;; delete user from group script = /usr/sbin/userdel &quot;%u&quot; &quot;%g&quot;; delete group script = /usr/sbin/groupdel &quot;%g&quot;#è¿™äº›è®¾ç½®é€‰é¡¹ä¸»è¦ç”¨äºSMBç½‘ç»œä¸­è¿›è¡Œæµè§ˆæ—¶ï¼Œè®¾ç½®sambaæœåŠ¡å™¨çš„è¡Œä¸ºã€‚ç¼ºçœæƒ…å†µä¸è®© sambaæœåŠ¡å™¨å‚åŠ broswserçš„æ¨ä¸¾è¿‡ç¨‹ï¼Œä¸ºäº†ä½¿å¾—sambaæœåŠ¡å™¨èƒ½æˆä¸ºbrowserï¼Œå°±éœ€è¦è®¾å®šlocal master =yesã€‚ç„¶åsambaæœåŠ¡å°±å¯ä»¥æ ¹æ®os levelè®¾ç½®çš„æƒé‡è¿›è¡Œæ¨ä¸¾ï¼Œç¼ºçœçš„os levelä¸º0ï¼Œè¿™ä¸ªæƒé‡ä¸ä¼šèµ¢å¾—æ¨ä¸¾ã€‚ä½†å¯ä»¥å–æ¶ˆæ³¨é‡Šï¼Œå°†os levelè®¾ç½®ä¸º33ï¼Œè¿™å°†åœ¨ä¸æ‰€æœ‰Windowsè®¡ç®—æœºï¼ˆåŒ…æ‹¬Windows NTï¼‰çš„æ¨ä¸¾ç«èµ›ä¸­è·å¾—èƒœåˆ©ï¼Œå› ä¸ºNT serverçš„æƒé‡ä¸º32ã€‚è®¾ç½®æ¯”33æ›´é«˜çš„æƒé‡ï¼Œåªæ˜¯åœ¨ä¸åŒçš„samba æœåŠ¡å™¨ä¹‹é—´è¿›è¡Œé€‰æ‹©æ—¶æ‰æœ‰æ„ä¹‰ã€‚## preferred master å¯ä»¥è®¾ç½®è‡ªå·±ä¼˜å…ˆæˆä¸ºæµè§ˆæœåŠ¡å™¨å€™é€‰äºº## ----------------------- Browser Control Options ----------------------------## local master = when set to no, Samba does not become the master browser on# your network. When set to yes, normal election rules apply.## os level = determines the precedence the server has in master browser# elections. The default value should be reasonable.## preferred master = when set to yes, Samba forces a local browser election at# start up (and gives itself a slightly higher chance of winning the election).#; local master = no; os level = 33; preferred master = yes###winsæœåŠ¡ï¼Œå¦‚æœç½‘ç»œä¸­é…ç½®äº†winsæœåŠ¡å™¨å¯ä»¥åœ¨æ­¤è®¾ç½®winsç›¸å…³é¡¹#----------------------------- Name Resolution -------------------------------## This section details the support for the Windows Internet Name Service (WINS).## Note: Samba can be either a WINS server or a WINS client, but not both.## wins support = when set to yes, the NMBD component of Samba enables its WINS# server.## wins server = tells the NMBD component of Samba to be a WINS client.## wins proxy = when set to yes, Samba answers name resolution queries on behalf# of a non WINS capable client. For this to work, there must be at least one# WINS server on the network. The default is no.## dns proxy = when set to yes, Samba attempts to resolve NetBIOS names via DNS# nslookups.#è®¾ç½®nmbè¿›ç¨‹æ”¯æŒwinsæœåŠ¡; wins support = yes#è®¾ç½®winsæœåŠ¡å™¨ip; wins server = w.x.y.z#è®¾ç½®winsä»£ç†IP; wins proxy = yes#è®¾ç½®SambaæœåŠ¡å™¨æ˜¯å¦åœ¨æ— æ³•è”ç³»WINSæœåŠ¡å™¨æ—¶é€šè¿‡DNSå»è§£æä¸»æœºçš„NetBIOSå; dns proxy = yes#è¯¥éƒ¨åˆ†åŒ…æ‹¬SambaæœåŠ¡å™¨æ‰“å°æœºç›¸å…³è®¾ç½®# --------------------------- Printing Options -----------------------------## The options in this section allow you to configure a non-default printing# system.## load printers = when set you yes, the list of printers is automatically# loaded, rather than setting them up individually.## cups options = allows you to pass options to the CUPS library. Setting this# option to raw, for example, allows you to use drivers on your Windows clients.## printcap name = used to specify an alternative printcap file.##æ˜¯å¦å¯ç”¨å…±äº«æ‰“å°æœº load printers = yes cups options = raw#æ‰“å°æœºé…ç½®æ–‡ä»¶; printcap name = /etc/printcap # obtain a list of printers automatically on UNIX System V systems:; printcap name = lpstat#æ‰“å°æœºçš„ç³»ç»Ÿç±»å‹,ç°åœ¨æ”¯æŒçš„æ‰“å°ç³»ç»Ÿæœ‰ï¼šbsd, sysv, plp, lprng, aix, hpux, qnx,cups; printing = cups#è¯¥éƒ¨åˆ†åŒ…æ‹¬SambaæœåŠ¡å™¨å¦‚ä½•ä¿ç•™ä»Windowså®¢æˆ·ç«¯å¤åˆ¶æˆ–ç§»åŠ¨åˆ°SambaæœåŠ¡å™¨å…±äº«ç›®å½•æ–‡ä»¶çš„Windowsæ–‡ä»¶å±æ€§çš„ç›¸å…³é…ç½®.# --------------------------- File System Options ---------------------------## The options in this section can be un-commented if the file system supports# extended attributes, and those attributes are enabled (usually via the# &quot;user_xattr&quot; mount option). These options allow the administrator to specify# that DOS attributes are stored in extended attributes and also make sure that# Samba does not change the permission bits.## Note: These options can be used on a per-share basis. Setting them globally# (in the [global] section) makes them the default for all shares.#å½“Windowså®¢æˆ·ç«¯å°†æ–‡ä»¶å¤åˆ¶æˆ–ç§»åŠ¨åˆ°SambaæœåŠ¡å™¨å…±äº«ç›®å½•æ—¶ï¼Œæ˜¯å¦ä¿ç•™æ–‡ä»¶åœ¨Windowsä¸­çš„å­˜æ¡£å±æ€§ã€‚é»˜è®¤noã€‚; map archive = no#å½“Windowså®¢æˆ·ç«¯å°†æ–‡ä»¶å¤åˆ¶æˆ–ç§»åŠ¨åˆ°SambaæœåŠ¡å™¨å…±äº«ç›®å½•æ—¶ï¼Œæ˜¯å¦ä¿ç•™æ–‡ä»¶åœ¨Windowsä¸­çš„éšè—å±æ€§ã€‚é»˜è®¤noã€‚; map hidden = no#å½“Windowså®¢æˆ·ç«¯å°†æ–‡ä»¶å¤åˆ¶æˆ–ç§»åŠ¨åˆ°SambaæœåŠ¡å™¨å…±äº«ç›®å½•æ—¶ï¼Œæ˜¯å¦ä¿ç•™æ–‡ä»¶åœ¨Windowsä¸­çš„åªè¯»å±æ€§ã€‚é»˜è®¤ä¸ºnoã€‚; map read only = no#å½“Windowså®¢æˆ·ç«¯å°†æ–‡ä»¶å¤åˆ¶æˆ–ç§»åŠ¨åˆ°SambaæœåŠ¡å™¨å…±äº«ç›®å½•æ—¶ï¼Œæ˜¯å¦ä¿ç•™æ–‡ä»¶åœ¨Windowsä¸­çš„ç³»ç»Ÿæ–‡ä»¶å±æ€§ã€‚é»˜è®¤ä¸ºnoã€‚; map system = no#å½“Windowså®¢æˆ·ç«¯å°†æ–‡ä»¶å¤åˆ¶æˆ–ç§»åŠ¨åˆ°SambaæœåŠ¡å™¨å…±äº«ç›®å½•æ—¶ï¼Œæ˜¯å¦ä¿ç•™æ–‡ä»¶åœ¨Windowsä¸­çš„ç›¸å…³å±æ€§ï¼ˆåªè¯»ã€ç³»ç»Ÿã€éšè—ã€å­˜æ¡£å±æ€§ï¼‰ã€‚é»˜è®¤ä¸ºyesã€‚; store dos attributes = yes#å…±äº«è®¾ç½®#============================ Share Definitions ==============================#ç”¨æˆ·å®¶ç›®å½•å…±äº«#å…±äº«åç§°[homes]#æè¿° comment = Home Directories#æ˜¯å¦æ”¯æŒæµè§ˆ browseable = no#æ˜¯å¦å…è®¸å†™å…¥ writable = yes#å…è®¸è®¿é—®è¯¥å…±äº«èµ„æºçš„smbç”¨æˆ·ï¼Œ@ç»„; valid users = %S; valid users = MYDOMAIN\\%S#æ‰“å°æœºå…±äº«[printers]#æè¿° comment = All Printers#è·¯å¾„ path = /var/spool/samba#æ˜¯å¦å¯æµè§ˆï¼Œnoç±»ä¼¼éšè—å…±äº« browseable = no#æ˜¯å¦æ”¯æŒguestè®¿é—®ï¼Œå’ŒpublicæŒ‡ä»¤ç±»ä¼¼ guest ok = no#æ˜¯å¦å¯å†™ writable = no#æ˜¯å¦å…è®¸æ‰“å° printable = yes# Un-comment the following and create the netlogon directory for Domain Logons:; [netlogon]; comment = Network Logon Service; path = /var/lib/samba/netlogon; guest ok = yes; writable = no; share modes = no# Un-comment the following to provide a specific roaming profile share.# The default is to use the user's home directory:; [Profiles]; path = /var/lib/samba/profiles; browseable = no; guest ok = yes# A publicly accessible directory that is read only, except for users in the# &quot;staff&quot; group (which have write permissions):; [public]; comment = Public Stuff; path = /home/samba; public = yes; writable = no; printable = no#å®šä¹‰å…è®¸å“ªäº›smbç”¨æˆ·å†™å…¥; write list = +staff 4.3 Sambaå…±äº«æ¡ˆä¾‹ï¼šåœ¨Windowsä¸Šè®¿é—®SambaæœåŠ¡å™¨ï¼Œå…±äº«ç›®å½•ä¸º/commonï¼ŒæŒ‡å®šç”¨cqm1ã€cqm2ç”¨æˆ·æ‰èƒ½è®¿é—®ï¼Œä¸”åªæœ‰cqm2æœ‰å†™æƒé™ã€‚ åˆ›å»ºSambaç”¨æˆ· 12345678910# smbpasswdç”¨æˆ·å‘½ä»¤# -a æ·»åŠ ç”¨æˆ· smbpasswd -a cqm# -x åˆ é™¤ç”¨æˆ· smbpasswd -x cqm# -d ç¦ç”¨å¸å· smbpasswd -d cqm# -e å–æ¶ˆç¦ç”¨ smbpasswd -e cqm# -n æ¸…é™¤å¯†ç  smbpasswd -a cqmuseradd -s /sbin/nologin cqm1useradd -s /sbin/nologin cqm2smbpasswd -a cqm1smbpasswd -a cqm2 åˆ›å»ºå…±äº«ç›®å½• 123mkdir /common# è®¾ç½®757æ˜¯ä¸ºäº†è®©cqm2æœ‰å†™æƒé™chmod 757 /common ä¿®æ”¹ä¸»é…æ–‡ä»¶ 1234567891011[global] workgroup = WORKGROUP ...[common] comment = samba share directory path = /common browseable = YES hosts allow = 10.0.0.0/8,192.168.88.0/24 valid users = cqm1,cqm2 writable = No write list = cqm2 åœ¨Windowsä¸­è¾“å…¥ \\\\192.168.88.132 è®¿é—® é¦–å…ˆæ˜¯cqm1ç”¨æˆ· å¯ä»¥çœ‹åˆ°cqm1ç”¨æˆ·æ²¡æœ‰å†™å…¥æƒé™ cqm2ç”¨æˆ· å¯ä»¥çœ‹åˆ°cqm2ç”¨æˆ·æœ‰åˆ›å»ºæ–‡ä»¶å¤¹çš„æƒé™ 4.4 LinuxæŒ‚è½½ åœ¨å®¢æˆ·ç«¯ä¸Šå®‰è£…samba-client 1yum -y install samba-client é€šè¿‡smbclientå‘½ä»¤è®¿é—® 1smbclient //192.168.88.132/common -U cqm2%toortoor é€šè¿‡mountå‘½ä»¤æŒ‚è½½ 1234mkdir /commonmount -o username=cqm2,password=toortoor -t cifs //192.168.88.132/common /commonmount//192.168.88.132/common on /common type cifs (rw,relatime,vers=default,cache=strict,username=cqm2,domain=LOCALHOST,uid=0,noforceuid,gid=0,noforcegid,addr=192.168.88.132,file_mode=0755,dir_mode=0755,soft,nounix,serverino,mapposix,rsize=1048576,wsize=1048576,echo_interval=60,actimeo=1) äº”ã€NFSæ–‡ä»¶æœåŠ¡5.1 NFSæœåŠ¡ä»‹ç»NFSå³ç½‘ç»œæ–‡ä»¶ç³»ç»Ÿï¼Œå®ƒå…è®¸ç½‘ç»œä¸­çš„è®¡ç®—æœºä¹‹é—´é€šè¿‡TCP/IPç½‘ç»œå…±äº«èµ„æºã€‚åœ¨NFSçš„åº”ç”¨ä¸­ï¼Œæœ¬åœ°NFSçš„å®¢æˆ·ç«¯åº”ç”¨å¯ä»¥é€æ˜åœ°è¯»å†™ä½äºè¿œç«¯NFSæœåŠ¡å™¨ä¸Šçš„æ–‡ä»¶ï¼Œå°±åƒè®¿é—®æœ¬åœ°æ–‡ä»¶ä¸€æ ·ã€‚ NFSåº”ç”¨åœºæ™¯ï¼š å…±äº«å­˜å‚¨æœåŠ¡å™¨ï¼šå›¾ç‰‡æœåŠ¡å™¨ã€è§†é¢‘æœåŠ¡å™¨ å®¶ç›®å½•æ¼«æ¸¸ï¼šåŸŸç”¨æˆ·å®¶ç›®å½•æœåŠ¡å™¨ æ–‡ä»¶æœåŠ¡å™¨ï¼šæ–‡ä»¶å­˜å‚¨æœåŠ¡å™¨ 5.2 NFSå®ç°å…±äº« å®‰è£…NFS 123yum -y install nfs-utilssystemctl start rpcbindsystemctl start nfs /etc/exportså…±äº«æ–‡ä»¶ 12345678910111213141516171819202122# å…±äº«æ ¼å¼# å…±äº«ç›®å½•ç»å¯¹è·¯å¾„ IPåœ°å€æˆ–ç½‘æ®µåœ°å€(æƒé™1,æƒé™2)/test 192.168.88.132(rw,sync)# æƒé™è¯´æ˜ro åªè¯»è®¿é—® rw è¯»å†™è®¿é—® sync æ‰€æœ‰æ•°æ®åœ¨è¯·æ±‚æ—¶å†™å…¥å…±äº« async NFSåœ¨å†™å…¥æ•°æ®å‰å¯ä»¥ç›¸åº”è¯·æ±‚ secure NFSé€šè¿‡1024ä»¥ä¸‹çš„å®‰å…¨TCP/IPç«¯å£å‘é€ insecure NFSé€šè¿‡1024ä»¥ä¸Šçš„ç«¯å£å‘é€ wdelay å¦‚æœå¤šä¸ªç”¨æˆ·è¦å†™å…¥NFSç›®å½•ï¼Œåˆ™å½’ç»„å†™å…¥ï¼ˆé»˜è®¤ï¼‰ no_wdelay å¦‚æœå¤šä¸ªç”¨æˆ·è¦å†™å…¥NFSç›®å½•ï¼Œåˆ™ç«‹å³å†™å…¥ï¼Œå½“ä½¿ç”¨asyncæ—¶ï¼Œæ— éœ€æ­¤è®¾ç½®ã€‚ hide åœ¨NFSå…±äº«ç›®å½•ä¸­ä¸å…±äº«å…¶å­ç›®å½• no_hide å…±äº«NFSç›®å½•çš„å­ç›®å½• subtree_check å¦‚æœå…±äº«/usr/binä¹‹ç±»çš„å­ç›®å½•æ—¶ï¼Œå¼ºåˆ¶NFSæ£€æŸ¥çˆ¶ç›®å½•çš„æƒé™ï¼ˆé»˜è®¤ï¼‰ no_subtree_check å’Œä¸Šé¢ç›¸å¯¹ï¼Œä¸æ£€æŸ¥çˆ¶ç›®å½•æƒé™ all_squash å…±äº«æ–‡ä»¶çš„UIDå’ŒGIDæ˜ å°„åŒ¿åç”¨æˆ·anonymousï¼Œé€‚åˆå…¬ç”¨ç›®å½•ã€‚ no_all_squash ä¿ç•™å…±äº«æ–‡ä»¶çš„UIDå’ŒGIDï¼ˆé»˜è®¤ï¼‰ root_squash rootç”¨æˆ·çš„æ‰€æœ‰è¯·æ±‚æ˜ å°„æˆå¦‚anonymousç”¨æˆ·ä¸€æ ·çš„æƒé™ï¼ˆé»˜è®¤ï¼‰ no_root_squash rootç”¨æˆ·å…·æœ‰æ ¹ç›®å½•çš„å®Œå…¨ç®¡ç†è®¿é—®æƒé™ anonuid=xxx æŒ‡å®šNFSæœåŠ¡å™¨/etc/passwdæ–‡ä»¶ä¸­åŒ¿åç”¨æˆ·çš„UID anongid=xxx æŒ‡å®šNFSæœåŠ¡å™¨/etc/passwdæ–‡ä»¶ä¸­åŒ¿åç”¨æˆ·çš„GID exportfså…±äº«ç®¡ç†å‘½ä»¤ 12345678910exportfså‘½ä»¤ï¼š-a æ‰“å¼€æˆ–å–æ¶ˆæ‰€æœ‰ç›®å½•å…±äº«ã€‚-o options,... æŒ‡å®šä¸€åˆ—å…±äº«é€‰é¡¹ï¼Œä¸ exports(5) ä¸­è®²åˆ°çš„ç±»ä¼¼ã€‚-i å¿½ç•¥ /etc/exports æ–‡ä»¶ï¼Œä»è€Œåªä½¿ç”¨é»˜è®¤çš„å’Œå‘½ä»¤è¡ŒæŒ‡å®šçš„é€‰é¡¹ã€‚-r é‡æ–°å…±äº«æ‰€æœ‰ç›®å½•ã€‚å®ƒä½¿/var/lib/nfs/xtabå’Œ/etc/exportsåŒæ­¥ã€‚å®ƒå°†/etc/exportsä¸­å·²åˆ é™¤çš„æ¡ç›®ä» /var/lib/nfs/xtabä¸­åˆ é™¤ï¼Œå°†å†…æ ¸å…±äº«è¡¨ä¸­ä»»ä½•ä¸å†æœ‰æ•ˆçš„æ¡ç›®ç§»é™¤ã€‚-u å–æ¶ˆä¸€ä¸ªæˆ–å¤šä¸ªç›®å½•çš„å…±äº«ã€‚-f åœ¨â€œæ–°â€æ¨¡å¼ä¸‹ï¼Œåˆ·æ–°å†…æ ¸å…±äº«è¡¨ä¹‹å¤–çš„ä»»ä½•ä¸œè¥¿ã€‚ ä»»ä½•æ´»åŠ¨çš„å®¢æˆ·ç¨‹åºå°†åœ¨å®ƒä»¬çš„ä¸‹æ¬¡è¯·æ±‚ä¸­å¾—åˆ°mountd æ·»åŠ çš„æ–°çš„å…±äº«æ¡ç›®ã€‚-v è¾“å‡ºè¯¦ç»†ä¿¡æ¯ã€‚å½“å…±äº«æˆ–è€…å–æ¶ˆå…±äº«æ—¶ï¼Œæ˜¾ç¤ºåœ¨åšä»€ä¹ˆã€‚ æ˜¾ç¤ºå½“å‰å…±äº«åˆ—è¡¨çš„æ—¶å€™ï¼ŒåŒæ—¶æ˜¾ç¤ºå…±äº«çš„é€‰é¡¹ã€‚ è®¾ç½®å…±äº« 12345678910# åˆ›å»ºè¢«å…±äº«ç›®å½•mkdir /test# è®¾ç½®exportsvim /etc/exports/test 192.168.88.0/24(rw,sync)# å…±äº«exportfs -r# æŸ¥çœ‹æ˜¯å¦å…±äº«exportfs -vshowmount -e 192.168.88.132 å®¢æˆ·ç«¯æŒ‚è½½ å®¢æˆ·ç«¯æŒ‚è½½æ˜¯ä½¿ç”¨nfsnobodyç”¨æˆ·è¿›è¡Œçš„ï¼Œå¦‚æœæ˜¯rootåˆ›å»ºçš„å…±äº«ç›®å½•ï¼Œä¸”å®¢æˆ·ç«¯æŒ‚è½½åè¦è¿›è¡Œè¯»å†™çš„è¯ï¼Œå¾—ç»™ç›®å½•757çš„æƒé™ã€‚ 1mount -t nfs 192.168.88.132:/test /test å…­ã€iSCSIæœåŠ¡6.1 iSCSIä»‹ç»iSCSIå³ç½‘ç»œå°å‹è®¡ç®—æœºç³»ç»Ÿæ¥å£ï¼Œåˆè¢«ç§°ä¸ºIPSANã€‚å®é™…å°±æ˜¯é€šè¿‡ç½‘ç»œæ¥å…±äº«è®¾å¤‡ã€‚ æ•°æ®å­˜å‚¨æŠ€æœ¯ï¼š DSAï¼ˆDirect Attached Storage ç›´æ¥é™„åŠ å­˜å‚¨ï¼‰ï¼šIDE SATA SAS SCSIï¼ˆæœ¬åœ°ç£ç›˜ï¼‰ NSAï¼ˆNetwork Attached Storage ç½‘ç»œé™„åŠ å­˜å‚¨ï¼‰ï¼šSamba NFSï¼ˆå…±äº«æ–‡ä»¶å¤¹ï¼‰ SANï¼ˆStorage Attached Network ç½‘ç»œé™„åŠ å­˜å‚¨ï¼‰ï¼šiSCSIï¼ˆå…±äº«è®¾å¤‡ï¼‰ 6.2 iSCSIæœåŠ¡éƒ¨ç½² å‡†å¤‡å¥½è¦è¢«æŒ‚è½½çš„ç£ç›˜ï¼Œè¿™é‡Œå…±äº«sdb1 å®‰è£…iSCSI 12yum -y install targetclisysetmctl start target é€šè¿‡targetcliå‘½ä»¤æ·»åŠ è®¾å¤‡å…±äº« 123456789101112131415161718192021222324# è¿›å…¥å‘½ä»¤è¡Œtargetclils...# backstores ä»£è¡¨åç«¯å­˜å‚¨,iscsié€šè¿‡ä½¿ç”¨æ–‡ä»¶ã€é€»è¾‘å·æˆ–ä»»ä½•ç±»å‹çš„ç£ç›˜ä½œä¸ºåº•å±‚å­˜å‚¨æ¥ä»¿çœŸå‘ˆç°ä¸ºç›®æ ‡çš„scsiè®¾å¤‡# block åç«¯å­˜å‚¨æ˜¯ä¸ªå—è®¾å¤‡# fileio åç«¯å­˜å‚¨æ˜¯ä¸€ä¸ªæ–‡ä»¶# pscsi ç‰©ç†scsiè®¾å¤‡# ramdisk åç«¯å­˜å‚¨æ˜¯å†…å­˜ä¸Šçš„ç©ºé—´ï¼Œåœ¨å†…å­˜ä¸Šåˆ›å»ºä¸€ä¸ªæŒ‡å®šå¤§å°çš„ramdiskè®¾å¤‡å¯ä»¥é€šè¿‡helpå‘½ä»¤æ¥æ‰“å°å¯ç”¨å‘½ä»¤# å°†è¦å…±äº«çš„è®¾å¤‡æ·»åŠ åˆ°backstoreså­˜å‚¨åº“ä¸­cd backstores/block/ creat block /dev/sdb1# è®¾ç½®IQNæ ‡è¯†# æ ¼å¼ï¼šiqn.å¹´-æœˆ.äºŒçº§åŸŸåå€’å†™:å…±äº«åcd ..iscsi/ create iqn.2021-04.com.cqm:storage# è®¾ç½®TPGç»„ä¸­å¯¹åº”çš„ä¸‰ä¸ªé—®é¢˜ è° ä»å“ªé‡Œ è®¿é—®ä»€ä¹ˆè®¾å¤‡cd iscsi/iqn.2021-04.com.cqm:storage/tpg1/acls/ create iqn.2021-04.com.cqm:clientluns/ create /backstores/block/blockexit 6.3 iSCSIå®¢æˆ·ç«¯æŒ‚è½½ å®‰è£…iSCSIå®¢æˆ·ç«¯ 1yum -y install iscsi-initiator-utils è®¾ç½®å®¢æˆ·ç«¯åç§° 123vim /etc/iscsi/initiatorname.iscsiInitiatorName=iqn.2021-04.com.cqm:clientsystemctl start iscsi å‘ç°å…±äº«è®¾å¤‡ 1iscsiadm --mode discoverydb --type sendtargets --portal 192.168.88.132:3260 --discover è¿æ¥è¿œç¨‹è®¾å¤‡ 1234iscsiadm --mode node --targetname iqn.2021-04.com.cqm:storage --portal 192.168.88.132:3260 --loginlsblk...sdb åˆ†åŒºæ ¼å¼åŒ– 1234fdisk /dev/sdb...mkfs.ext4 /dev/sdb1... æŒ‚è½½å…±äº«ç£ç›˜ 1234mkdir /root/sdb1vim /etc/fstab/dev/sdb1 /root/sdb1 ext4 _netdev 0 0mount -a 6.4 iSCSIå–æ¶ˆæŒ‚è½½ å®¢æˆ·ç«¯ 123iscsiadm --mode node --targetname iqn.2021-04.com.cqm:storage --portal 192.168.88.132:3260 --logoutrm -rf /var/lib/iscsi/nodes/iqn.2021-04.com.cqm\\:storage/rm -rf /var/lib/iscsi/send_targets/192.168.88.132,3260/ æœåŠ¡ç«¯ 1234567# å€’ç€åˆ targetcliiscsi/iqn.2021-04.com.cqm:storage/tpg1/portals/ delete 0.0.0.0 3260iscsi/iqn.2021-04.com.cqm:storage/tpg1/luns/ delete lun=0iscsi/iqn.2021-04.com.cqm:storage/tpg1/acls/ delete iqn.2021-04.com.cqm:clientiscsi/ delete iqn.2021-04.com.cqm:storagebackstores/block/ delete block ä¸ƒã€IPSANå¤šé“¾è·¯éƒ¨ç½²åœ¨ä¸Šè¾¹çš„ç¯å¢ƒä¸­çš„å…±äº«è®¾å¤‡æ˜¯é€šè¿‡å•é“¾è·¯å…±äº«çš„ï¼Œå¦‚æœè¿™æ¡é“¾è·¯å‡ºç°äº†æ•…éšœï¼Œé‚£ä¹ˆå°±ä¼šå‡ºç°è¿æ¥ä¸ä¸Šå…±äº«è®¾å¤‡çš„é—®é¢˜ï¼Œæ‰€ä»¥åœ¨ç”Ÿäº§ç¯å¢ƒä¸­éƒ½ä¼šé…ç½®å¤šé“¾è·¯è¿›è¡Œéƒ¨ç½²ã€‚ iSCSIæœåŠ¡ç«¯å’Œå®¢æˆ·ç«¯åˆ†åˆ«æ‹¥æœ‰ä¸¤å¼ ä¸åŒç½‘æ®µçš„ç½‘å¡ï¼Œå°±å¯ä»¥é…ç½®å¤šé“¾è·¯éƒ¨ç½²ã€‚ 7.1 éƒ¨ç½²å¤šé“¾è·¯ åœ¨æœåŠ¡ç«¯ä¸Šè®¾ç½®å…±äº«è®¾å¤‡ï¼Œå¹¶ç”¨ä¸¤ä¸ªIPè¿›è¡Œå…±äº« åœ¨å®¢æˆ·ç«¯å‘ç°å…±äº«è®¾å¤‡ 123456789vim /etc/iscsi/initiatorname.iscsiInitiatorName=iqn.2021-04.com.cqm:clientsystemctl start iscsiiscsiadm --mode discoverydb --type sendtargets --portal 192.168.88.132:3260 --discover 192.168.88.132:3260,1 iqn.2021-04.com.cqm:storage 192.168.99.130:3260,1 iqn.2021-04.com.cqm:storageiscsiadm --mode node --targetname iqn.2021-04.com.cqm:storage --portal 192.168.88.132:3260 --loginiscsiadm --mode node --targetname iqn.2021-04.com.cqm:storage --portal 192.168.99.130:3260 --login è¿™æ—¶å€™é€šè¿‡lsblkå‘½ä»¤å¯ä»¥çœ‹åˆ°å¤šäº†ä¸¤å—è®¾å¤‡ï¼Œä½†å…¶å®æ˜¯åŒä¸€ä¸ªè®¾å¤‡ä¸åŒå å®‰è£…å¤šè·¯å¾„è½¯ä»¶ 123yum -y install device-mapper-multipathcp /usr/share/doc/device-mapper-multipath-0.4.9/multipath.conf /etc/systemctl start multipathd å†ç”¨lsblkå‘½ä»¤æŸ¥çœ‹å¯å‘ç° é…ç½®å¤šè·¯å¾„è¿è¡Œæ¨¡å¼ 123456789101112131415161718192021222324252627282930multipath -ll# wwid:36001405ac25fe1abdfd4eecb1d0624b2mpatha (36001405ac25fe1abdfd4eecb1d0624b2) dm-2 LIO-ORG ,block...vim /etc/multipath.confmultipaths { multipath { wwid 36001405ac25fe1abdfd4eecb1d0624b2 # wwid alias cqm # èµ·å path_grouping_policy multibus # å¤šè·¯å¾„ç»„ç­–ç•¥ path_selector &quot;round-robin 0&quot; # è´Ÿè½½å‡è¡¡æ¨¡å¼ failback manual rr_weight priorities # æŒ‰ä¼˜å…ˆçº§è½®è¯¢ no_path_retry 5 # é‡è¯•æ—¶é—´5s } multipath { wwid 1DEC_____321816758474 alias red }}systemctl restart multipathdsystemctl restart iscsimultipath -llcqm (36001405ac25fe1abdfd4eecb1d0624b2) dm-2 LIO-ORG ,blocksize=1023M features='1 queue_if_no_path' hwhandler='0' wp=rw`-+- policy='round-robin 0' prio=1 status=active |- 5:0:0:0 sdb 8:16 active ready running `- 6:0:0:0 sdc 8:32 active ready running æŒ‚è½½ 12mkdir /root/testmount /dev/mapper/cqm1 /root/test 7.2 æµ‹è¯•å°†ä¸€å—ç½‘å¡æ–­æ‰ï¼Œçœ‹æ˜¯å¦è¿˜èƒ½ä½¿ç”¨iSCSIè®¾å¤‡ æ–­å¼€ç½‘å¡ens33 1ifdown ens33 ä¾æ—§å¯ä»¥åœ¨iSCSIè®¾å¤‡ä¸Šå†™å…¥æ•°æ®","link":"/2024/02/18/linux%E5%9F%BA%E7%A1%80%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/"},{"title":"Prometheus","text":"Prometheusæ˜¯ä¸€ä¸ªå¼€æºçš„äº‘åŸç”Ÿç›‘æ§ç³»ç»Ÿå’Œæ—¶é—´åºåˆ—æ•°æ®åº“ã€‚ ä¸€ã€Prometheusæ¦‚è¿°Prometheus ä½œä¸ºæ–°ä¸€ä»£çš„äº‘åŸç”Ÿç›‘æ§ç³»ç»Ÿï¼Œç›®å‰å·²ç»æœ‰è¶…è¿‡ 650+ä½è´¡çŒ®è€…å‚ä¸åˆ° Prometheus çš„ç ”å‘å·¥ä½œä¸Šï¼Œå¹¶ä¸”è¶…è¿‡ 120+é¡¹çš„ç¬¬ä¸‰æ–¹é›†æˆã€‚ 1.1 Prometheusçš„ä¼˜ç‚¹ æä¾›å¤šç»´åº¦æ•°æ®æ¨¡å‹å’Œçµæ´»çš„æŸ¥è¯¢æ–¹å¼ï¼Œé€šè¿‡å°†ç›‘æ§æŒ‡æ ‡å…³è”å¤šä¸ª tagï¼Œæ¥å°†ç›‘æ§æ•°æ®è¿›è¡Œä»»æ„ç»´åº¦çš„ç»„åˆï¼Œå¹¶ä¸”æä¾›ç®€å•çš„ PromQL æŸ¥è¯¢æ–¹å¼ï¼Œè¿˜æä¾› HTTP æŸ¥è¯¢æ¥å£ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿åœ°ç»“åˆ Grafana ç­‰ GUI ç»„ä»¶å±•ç¤ºæ•°æ®ã€‚ åœ¨ä¸ä¾èµ–å¤–éƒ¨å­˜å‚¨çš„æƒ…å†µä¸‹ï¼Œæ”¯æŒæœåŠ¡å™¨èŠ‚ç‚¹çš„æœ¬åœ°å­˜å‚¨ï¼Œé€šè¿‡ Prometheus è‡ªå¸¦çš„æ—¶åºæ•°æ®åº“ï¼Œå¯ä»¥å®Œæˆæ¯ç§’åƒä¸‡çº§çš„æ•°æ®å­˜å‚¨ï¼›ä¸ä»…å¦‚æ­¤ï¼Œåœ¨ä¿å­˜å¤§é‡å†å²æ•°æ®çš„åœºæ™¯ä¸­ï¼ŒPrometheus å¯ä»¥å¯¹æ¥ç¬¬ä¸‰æ–¹æ—¶åºæ•°æ®åº“å’Œ OpenTSDB ç­‰ã€‚ å®šä¹‰äº†å¼€æ”¾æŒ‡æ ‡æ•°æ®æ ‡å‡†ï¼Œä»¥åŸºäº HTTP çš„ Pull æ–¹å¼é‡‡é›†æ—¶åºæ•°æ®ï¼Œåªæœ‰å®ç°äº† Prometheus ç›‘æ§æ•°æ®æ‰å¯ä»¥è¢« Prometheus é‡‡é›†ã€æ±‡æ€»ã€å¹¶æ”¯æŒ Push æ–¹å¼å‘ä¸­é—´ç½‘å…³æ¨é€æ—¶åºåˆ—æ•°æ®ï¼Œèƒ½æ›´åŠ çµæ´»åœ°åº”å¯¹å¤šç§ç›‘æ§åœºæ™¯ã€‚ æ”¯æŒé€šè¿‡é™æ€æ–‡ä»¶é…ç½®å’ŒåŠ¨æ€å‘ç°æœºåˆ¶å‘ç°ç›‘æ§å¯¹è±¡ï¼Œè‡ªåŠ¨å®Œæˆæ•°æ®é‡‡é›†ã€‚ Prometheus ç›®å‰å·²ç»æ”¯æŒ Kubernetesã€etcdã€Consul ç­‰å¤šç§æœåŠ¡å‘ç°æœºåˆ¶ã€‚æ˜“äºç»´æŠ¤ï¼Œå¯ä»¥é€šè¿‡äºŒè¿›åˆ¶æ–‡ä»¶ç›´æ¥å¯åŠ¨ï¼Œå¹¶ä¸”æä¾›äº†å®¹å™¨åŒ–éƒ¨ç½²é•œåƒã€‚ æ”¯æŒæ•°æ®çš„åˆ†åŒºé‡‡æ ·å’Œè”é‚¦éƒ¨ç½²ï¼Œæ”¯æŒå¤§è§„æ¨¡é›†ç¾¤ç›‘æ§ã€‚ 1.2 PrometheusåŸºæœ¬ç»„ä»¶ Prometheus Serverï¼šæ˜¯ Prometheus ç»„ä»¶ä¸­çš„æ ¸å¿ƒéƒ¨åˆ†ï¼Œè´Ÿè´£å®ç°å¯¹ç›‘æ§æ•°æ®çš„è·å–ï¼Œå­˜å‚¨ä»¥åŠæŸ¥è¯¢ã€‚æ”¶é›†åˆ°çš„æ•°æ®ç»Ÿç§°ä¸ºmetricsã€‚ Push Gatewayï¼šå½“ç½‘ç»œéœ€æ±‚æ— æ³•ç›´æ¥æ»¡è¶³æ—¶ï¼Œå°±å¯ä»¥åˆ©ç”¨ Push Gateway æ¥è¿›è¡Œä¸­è½¬ã€‚å¯ä»¥é€šè¿‡ Push Gateway å°†å†…éƒ¨ç½‘ç»œçš„ç›‘æ§æ•°æ®ä¸»åŠ¨ Push åˆ° Gateway å½“ä¸­ã€‚è€Œ Prometheus Server åˆ™å¯ä»¥é‡‡ç”¨åŒæ · Pull çš„æ–¹å¼ä» Push Gateway ä¸­è·å–åˆ°ç›‘æ§æ•°æ®ã€‚ Exporterï¼šä¸»è¦ç”¨æ¥é‡‡é›†æ•°æ®ï¼Œå¹¶é€šè¿‡ HTTP æœåŠ¡çš„å½¢å¼æš´éœ²ç»™ Prometheus Serverï¼ŒPrometheus Server é€šè¿‡è®¿é—®è¯¥ Exporter æä¾›çš„æ¥å£ï¼Œå³å¯è·å–åˆ°éœ€è¦é‡‡é›†çš„ç›‘æ§æ•°æ®ã€‚ Alert managerï¼šç®¡ç†å‘Šè­¦ï¼Œä¸»è¦æ˜¯è´Ÿè´£å®ç°æŠ¥è­¦åŠŸèƒ½ã€‚ç°åœ¨grafanaä¹Ÿèƒ½å®ç°æŠ¥è­¦åŠŸèƒ½ï¼Œæ‰€ä»¥ä¹Ÿæ…¢æ…¢è¢«å–ä»£ã€‚ 1.3 Prometheusæ•°æ®ç±»å‹ Counterï¼ˆè®¡æ•°å™¨ç±»å‹ï¼‰ï¼šCounterç±»å‹çš„æŒ‡æ ‡çš„å·¥ä½œæ–¹å¼å’Œè®¡æ•°å™¨ä¸€æ ·ï¼Œåªå¢ä¸å‡ï¼ˆé™¤éç³»ç»Ÿå‘ç”Ÿäº†é‡ç½®ï¼‰ã€‚ Gaugeï¼ˆä»ªè¡¨ç›˜ç±»å‹ï¼‰ï¼šGaugeæ˜¯å¯å¢å¯å‡çš„æŒ‡æ ‡ç±»ï¼Œå¯ä»¥ç”¨äºååº”å½“å‰åº”ç”¨çš„çŠ¶æ€ã€‚ Histogramï¼ˆç›´æ–¹å›¾ç±»å‹ï¼‰ï¼šä¸»è¦ç”¨äºè¡¨ç¤ºä¸€æ®µæ—¶é—´èŒƒå›´å†…å¯¹æ•°æ®è¿›è¡Œé‡‡æ ·ï¼ˆé€šå¸¸æ˜¯è¯·æ±‚æŒç»­æ—¶é—´æˆ–å“åº”å¤§å°ï¼‰ï¼Œå¹¶èƒ½å¤Ÿå¯¹å…¶æŒ‡å®šåŒºé—´ä»¥åŠæ€»æ•°è¿›è¡Œç»Ÿè®¡ï¼Œé€šå¸¸å®ƒé‡‡é›†çš„æ•°æ®å±•ç¤ºä¸ºç›´æ–¹å›¾ã€‚ Summaryï¼ˆæ‘˜è¦ç±»å‹ï¼‰ï¼šä¸»è¦ç”¨äºè¡¨ç¤ºä¸€æ®µæ—¶é—´å†…æ•°æ®é‡‡æ ·ç»“æœï¼ˆé€šå¸¸æ˜¯è¯·æ±‚æŒç»­æ—¶é—´æˆ–å“åº”å¤§å°ï¼‰ã€‚ äºŒã€Prometheuså®‰è£…2.1 Prometheus serverå®‰è£… Prometheuså®‰è£…è¾ƒä¸ºç®€å•ï¼Œä¸‹è½½è§£å‹å³å¯ 123wget https://github.com/prometheus/prometheus/releases/download/v2.26.0-rc.0/prometheus-2.26.0-rc.0.linux-amd64.tar.gztar -xf prometheus-2.26.0-rc.0.linux-amd64.tar.gzmv prometheus-2.26.0-rc.0.linux-amd64 prometheus prometheus.ymlé…ç½®æ–‡ä»¶ 12345678910111213141516171819202122232425# å…¨å±€é…ç½®global: scrape_interval: 15s # è®¾ç½®æŠ“å–é—´éš”ï¼Œé»˜è®¤ä¸º1åˆ†é’Ÿ evaluation_interval: 15s # ä¼°ç®—è§„åˆ™çš„é»˜è®¤å‘¨æœŸï¼Œæ¯15ç§’è®¡ç®—ä¸€æ¬¡è§„åˆ™ï¼Œé»˜è®¤1åˆ†é’Ÿ # scrape_timeout # é»˜è®¤æŠ“å–è¶…æ—¶ï¼Œé»˜è®¤ä¸º10s# æŠ¥è­¦é…ç½®alerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093# è§„åˆ™æ–‡ä»¶åˆ—è¡¨ï¼Œä½¿ç”¨'evaluation_interval' å‚æ•°å»æŠ“å–rule_files: # - &quot;first_rules.yml&quot; # - &quot;second_rules.yml&quot;# æŠ“å–é…ç½®åˆ—è¡¨scrape_configs: # ä»»åŠ¡åç§° - job_name: 'prometheus' # è¦è¢«ç›‘æ§çš„å®¢æˆ·ç«¯ static_configs: - targets: ['localhost:9090'] åˆ›å»ºPrometheusçš„ç”¨æˆ·åŠæ•°æ®å­˜å‚¨ç›®å½• 1234groupadd prometheususeradd -g prometheus -s /sbin/nologin prometheusmkdir /root/prometheus/datachown -R prometheus:prometheus /root/prometheus Prometheusçš„å¯åŠ¨å¾ˆç®€å•ï¼Œåªéœ€è¦ç›´æ¥å¯åŠ¨è§£å‹ç›®å½•çš„äºŒè¿›åˆ¶æ–‡ä»¶Prometheuså³å¯ï¼Œä½†æ˜¯ä¸ºäº†æ›´åŠ æ–¹ä¾¿å¯¹Prometheusè¿›è¡Œç®¡ç†ï¼Œè¿™é‡Œç¼–å†™è„šæœ¬æˆ–è€…ä½¿ç”¨screenå·¥å…·æ¥è¿›è¡Œå¯åŠ¨ 123456789vim /root/prometheus/start.sh#!/bin/bashprometheus_dir=/root/prometheus${prometheus_dir}/prometheus --config.file=${prometheus_dir}/prometheus.yml --storage.tsdb.path=${prometheus_dir}/data --storage.tsdb.retention.time=24h --web.enable-lifecycle --storage.tsdb.no-lockfile# --config.file:æŒ‡å®šé…ç½®æ–‡ä»¶è·¯å¾„# --storage.tsdb.path:æŒ‡å®štsdbè·¯å¾„# --storage.tsdb.retention.time:æŒ‡å®šæ•°æ®å­˜å‚¨æ—¶é—´# --web.enable-lifecycle:ç±»ä¼¼nginxçš„reloadåŠŸèƒ½# --storage.tsdb.no-lockfile:å¦‚æœç”¨k8sçš„deploymentç®¡ç†éœ€åŠ æ­¤é¡¹ å¯åŠ¨Prometheusåè®¿é—® 12# nohupè‹±æ–‡å…¨ç§°no hang upï¼ˆä¸æŒ‚èµ·ï¼‰ï¼Œç”¨äºåœ¨ç³»ç»Ÿåå°ä¸æŒ‚æ–­åœ°è¿è¡Œå‘½ä»¤ï¼Œé€€å‡ºç»ˆç«¯ä¸ä¼šå½±å“ç¨‹åºçš„è¿è¡Œã€‚nohup sh start.sh 2&gt;&amp;1 &gt; prometheus.log ç”¨screenå·¥å…·è¿›è¡Œå¯åŠ¨ 123456789101112yum -y install screen# è¿›å…¥åå°screen# è¿è¡Œè„šæœ¬/root/prometheus/prometheus --config.file=/root/prometheus/prometheus.yml --storage.tsdb.path=/root/prometheus/data --storage.tsdb.retention.time=24h --web.enable-lifecycle --storage.tsdb.no-lockfile# è¾“å…¥CTRL + A + Dæ’¤å›å‰å°# æŸ¥çœ‹åå°è¿è¡Œçš„è„šæœ¬screen -ls# è¿”å›åå°screen -r åå°id# åˆ é™¤åå°screen -S åå°id -X quit 2.2 node exporterå®‰è£…åœ¨Prometheusæ¶æ„ä¸­ï¼Œexporteræ˜¯è´Ÿè´£æ”¶é›†æ•°æ®å¹¶å°†ä¿¡æ¯æ±‡æŠ¥ç»™Prometheus Serverçš„ç»„ä»¶ã€‚å®˜æ–¹æä¾›äº†node_exporterå†…ç½®äº†å¯¹ä¸»æœºç³»ç»Ÿçš„åŸºç¡€ç›‘æ§ã€‚ ä¸‹è½½node exporter 123wget https://github.com/prometheus/node_exporter/releases/download/v1.1.2/node_exporter-1.1.2.linux-amd64.tar.gztar -xf node_exporter-1.1.2.linux-amd64.tar.gzmv node_exporter-1.1.2.linux-amd64.tar.gz node_exporter åœ¨prometheus.ymlä¸­æ·»åŠ è¢«ç›‘æ§ä¸»æœº 12static_configs: - targets: ['localhost:9090','localhost:9100'] åå°å¯åŠ¨exporterå’Œé‡å¯prometheus 12screen./root/node_exporter/node_exporter é€šè¿‡curlå‘½ä»¤è·å–æ”¶é›†åˆ°çš„æ•°æ®key 12curl http://localhost:9100/metrics... ç”¨å…¶ä¸­çš„ä¸€ä¸ªkeyåœ¨Prometheusæµ‹è¯•æ˜¯å¦è¢«ç›‘æ§ ä¸‰ã€Prometheuså‘½ä»¤è¡Œçš„ä½¿ç”¨3.1 è®¡ç®—cpuä½¿ç”¨ç‡ é€šè¿‡ä¸Šå›¾å¯ä»¥çŸ¥é“ï¼Œlinuxçš„cpuä½¿ç”¨æ˜¯åˆ†ä¸ºå¾ˆå¤šç§çŠ¶æ€çš„ï¼Œä¾‹å¦‚ç”¨æˆ·æ€userï¼Œç©ºé—²æ€idleã€‚ è¦è®¡ç®—cpuçš„ä½¿ç”¨ç‡æœ‰ä¸¤ç§ç²—ç•¥çš„å…¬å¼ï¼š é™¤å»idleçŠ¶æ€çš„æ‰€æœ‰cpuçŠ¶æ€æ—¶é—´ä¹‹å’Œ / cpuæ—¶é—´æ€»å’Œ 100% - ï¼ˆidleçŠ¶æ€ / cpuæ—¶é—´æ€»å’Œï¼‰ ä½†è¿™ä¸¤ç§æ–¹å¼éƒ½å­˜åœ¨ä¸¤ä¸ªé—®é¢˜ï¼š å¦‚ä½•è®¡ç®—æŸä¸€æ—¶é—´æ®µçš„cpuä½¿ç”¨ç‡ï¼Ÿä¾‹å¦‚ç²¾ç¡®åˆ°æ¯ä¸€åˆ†é’Ÿã€‚ å®é™…å·¥ä½œä¸­cpuå¤§å¤šæ•°éƒ½æ˜¯å¤šæ ¸çš„ï¼Œnode exporteræˆªå–åˆ°çš„æ•°æ®ç²¾ç¡®åˆ°äº†æ¯ä¸ªæ ¸ï¼Œå¦‚ä½•ç›‘æ§æ‰€æœ‰æ ¸åŠ èµ·æ¥çš„æ•°æ®ï¼Ÿ Prometheusæä¾›äº†è®¸å¤šçš„å‡½æ•°ï¼Œå…¶ä¸­ increase å’Œ sum å°±å¾ˆå¥½çš„è§£å†³äº†ä»¥ä¸Šä¸¤ä¸ªé—®é¢˜ã€‚ æå–cpuçš„keyï¼Œå³node_cpu_seconds_total æŠŠidleç©ºé—²æ—¶é—´å’Œæ€»æ—¶é—´è¿‡æ»¤å‡ºæ¥ï¼Œåœ¨Prometheusä¸­ä½¿ç”¨{}è¿›è¡Œè¿‡æ»¤ 1node_cpu_seconds_total{mode='idle'} ä½¿ç”¨increaseå‡½æ•°å–ä¸€åˆ†é’Ÿå†…çš„å¢é‡ 1increase(node_cpu_seconds_total{mode='idle'}[1m]) ä½¿ç”¨sumå‡½æ•°å°†æ¯ä¸ªæ ¸çš„æ•°æ•´åˆèµ·æ¥ 1sum(increase(node_cpu_seconds_total{mode='idle'}[1m])) åˆ°è¿™é‡Œåˆå‡ºç°ä¸€ä¸ªé—®é¢˜ï¼Œsumå‡½æ•°ä¼šå°†æ‰€æœ‰æ•°æ®æ•´åˆèµ·æ¥ï¼Œä¸å…‰å°†ä¸€å°æœºå™¨çš„æ‰€æœ‰cpuåŠ åˆ°ä¸€èµ·ï¼Œä¹Ÿå°†æ‰€æœ‰æœºå™¨çš„cpuéƒ½åŠ åˆ°äº†ä¸€èµ·ï¼Œæœ€ç»ˆæ˜¾ç¤ºçš„æ˜¯é›†ç¾¤cpuçš„æ€»å¹³å‡å€¼ï¼Œby(instance)å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ 1sum(increase(node_cpu_seconds_total{mode='idle'}[1m])) by(instance) è¿™æ ·å°±å¾—åˆ°äº†ç©ºé—²æ—¶cpuçš„æ•°æ®äº†ï¼Œç”¨ä¸Šè¾¹ç¬¬ä¸€ä¸ªå…¬å¼å³å¯å¾—åˆ°å•å°ä¸»æœºcpuåœ¨ä¸€åˆ†é’Ÿå†…çš„ä½¿ç”¨ç‡ã€‚ 1(1 - ((sum(increase(node_cpu_seconds_total{mode='idle'}[1m])) by(instance)) / (sum(increase(node_cpu_seconds_total[1m])) by(instance)))) * 100 3.2 è®¡ç®—å†…å­˜ä½¿ç”¨ç‡å†…å­˜ä½¿ç”¨ç‡å…¬å¼ä¸º = (available / total) * 100 1(node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100 3.3 rateå‡½æ•°rateå‡½æ•°æ˜¯ä¸“é—¨æ­é…counterç±»å‹æ•°æ®ä½¿ç”¨çš„å‡½æ•°ï¼ŒåŠŸèƒ½æ˜¯æŒ‰ç…§è®¾ç½®çš„ä¸€ä¸ªæ—¶é—´æ®µï¼Œå–counteråœ¨è¿™ä¸ªæ—¶é—´æ®µä¸­å¹³å‡æ¯ç§’çš„å¢é‡ã€‚ ä¸¾ä¸ªæ —å­ï¼Œå‡è®¾æˆ‘ä»¬è¦å–ens33è¿™ä¸ªç½‘å¡åœ¨ä¸€åˆ†é’Ÿå†…å­—èŠ‚çš„æ¥å—æ•°é‡ï¼Œå‡å¦‚ä¸€åˆ†é’Ÿå†…æ¥æ”¶åˆ°çš„æ˜¯1000bytesï¼Œé‚£ä¹ˆå¹³å‡æ¯ç§’æ¥æ”¶åˆ°å°±æ˜¯1000bytes / 1m * 60s â‰ˆ 16bytes/sã€‚ 1rate(node_network_receive_bytes_total{device='ens33'}[1m]) å¦‚æœæ˜¯äº”åˆ†é’Ÿçš„è¯å³ä¸º5000bytes / 5m * 60s â‰ˆ 16bytes/sï¼Œç»“æœæ˜¯ä¸€æ ·çš„ï¼Œä½†æ›²çº¿å›¾å°±ä¸ä¸€æ ·äº†ï¼Œä¸Šå›¾ä¸ºä¸€åˆ†é’Ÿï¼Œä¸‹å›¾ä¸ºäº”åˆ†é’Ÿï¼Œå› ä¸ºäº”åˆ†é’Ÿçš„å¯†åº¦è¦æ›´åº•ï¼Œæ‰€ä»¥å¯ä»¥çœ‹åˆ°äº”åˆ†é’Ÿçš„æ›²çº¿å›¾æ›´åŠ å¹³ç¼“ã€‚ rateå’Œincreaseçš„æ¦‚å¿µæœ‰äº›ç±»ä¼¼ï¼Œä½†rateå–çš„æ˜¯ä¸€æ®µæ—¶é—´å¢é‡çš„å¹³å‡æ¯ç§’æ•°é‡ï¼Œincreaseå–çš„æ˜¯ä¸€æ®µæ—¶é—´å¢é‡çš„æ€»é‡ï¼Œå³ï¼š rate(1m)ï¼šæ€»é‡ / 60s increase(1m)ï¼šæ€»é‡ 3.4 sumå‡½æ•°sumå‡½æ•°å°±æ˜¯å°†æ”¶åˆ°çš„æ•°æ®å…¨éƒ¨è¿›è¡Œæ•´åˆã€‚ å‡å¦‚ä¸€ä¸ªé›†ç¾¤é‡Œæœ‰20å°æœåŠ¡å™¨ï¼Œåˆ†åˆ«ä¸º5å°webæœåŠ¡å™¨ï¼Œ10å°dbæœåŠ¡å™¨ï¼Œè¿˜æœ‰5å°å…¶ä»–æœåŠ¡çš„æœåŠ¡å™¨ï¼Œè¿™æ—¶å€™sumå°±å¯ä»¥åˆ†ä¸ºä¸‰æ¡æ›²çº¿æ¥ä»£è¡¨ä¸åŒåŠŸèƒ½æœåŠ¡å™¨çš„æ€»å’Œæ•°æ®ã€‚ 3.5 topkå‡½æ•°topkå‡½æ•°çš„ä½œç”¨å°±æ˜¯å–å‰å‡ ä½çš„æœ€é«˜å€¼ã€‚ 3.6 countå‡½æ•°countå‡½æ•°çš„ä½œç”¨æ˜¯æŠŠç¬¦åˆæ¡ä»¶çš„æ•°å€¼è¿›è¡Œæ•´åˆã€‚ å‡å¦‚æˆ‘ä»¬è¦æŸ¥çœ‹é›†ç¾¤ä¸­cpuä½¿ç”¨ç‡è¶…è¿‡80%çš„ä¸»æœºæ•°é‡çš„è¯ 1count((1 - ((sum(increase(node_cpu_seconds_total{mode='idle'}[1m])) by(instance)) / (sum(increase(node_cpu_seconds_total[1m])) by(instance)))) * 100 &gt; 80) å››ã€Push gatewayPush gatewayå®é™…ä¸Šå°±æ˜¯ä¸€ç§è¢«åŠ¨æ¨é€æ•°æ®çš„æ–¹å¼ï¼Œä¸exporterä¸»åŠ¨è·å–ä¸åŒã€‚ 4.1 Push gatewayå®‰è£… ä¸‹è½½å®‰è£…Push gateway 123wget https://github.com/prometheus/pushgateway/releases/download/v1.4.0/pushgateway-1.4.0.linux-amd64.tar.gztar -xf pushgateway-1.4.0.linux-amd64.tar.gzmv pushgateway-1.4.0.linux-amd64 pushgateway åå°è¿è¡ŒPush gateway 12screen./root/pushgateway/pushgateway åœ¨prometheus.ymlä¸­åŠ ä¸Š 123- job_name: 'pushgateway' static_configs: - targets: ['localhost:9091'] 4.2 è‡ªå®šä¹‰ç¼–å†™è„šæœ¬ç”±äºPush gatewayè‡ªå·±æœ¬èº«æ˜¯æ²¡æœ‰ä»»ä½•æŠ“å–æ•°æ®çš„åŠŸèƒ½çš„ï¼Œæ‰€ä»¥ç”¨æˆ·éœ€è¦è‡ªè¡Œç¼–å†™è„šæœ¬æ¥æŠ“å–æ•°æ®ã€‚ ä¸¾ä¸ªä¾‹å­ï¼šç¼–å†™è„šæœ¬æŠ“å– TCP waiting_connection çš„æ•°é‡ ç¼–å†™è‡ªå®šä¹‰è„šæœ¬ 123456789101112131415161718192021222324252627#!/bin/bash# è·å–ç›‘æ§ä¸»æœºåinstance_name=`hostname -f | cut -d'.' -f1`# å¦‚æœä¸»æœºåä¸ºlocalhostï¼Œåˆ™é€€å‡ºif [ $instance_name == &quot;localhost&quot; ]then echo &quot;ä¸èƒ½ç›‘æ§ä¸»æœºåä¸ºlocalhostçš„ä¸»æœº&quot; exit 1fi#---# è·å–TCP CONNECTEDæ•°é‡# æŠ“å–TCP CONNECTEDæ•°é‡ï¼Œå®šä¹‰ä¸ºä¸€ä¸ªæ–°keylable_tcp_connected=&quot;count_netstat_connected_connections&quot;count_netstat_connected_connections=`netstat -an | grep 'CONNECTED' | wc -l`# ä¸Šä¼ è‡³pushgatewayecho &quot;$lable_tcp_connected $count_netstat_connected_connections&quot; | curl --data-binary @- http://localhost:9091/metrics/job/pushgateway/instance/$instance_name#---# è¯¥è„šæœ¬æ˜¯é€šè¿‡postçš„æ–¹å¼å°†keyæ¨é€ç»™pushgateway# http://localhost:9091 å³æ¨é€ç»™å“ªå°pushgatewayä¸»æœº# job/pushgateway å³æ¨é€ç»™prometheus.ymlä¸­å®šä¹‰çš„jobä¸ºpushgatewayçš„ä¸»æœº# instance/$instance_name æ¨é€åæ˜¾ç¤ºçš„ä¸»æœºå å› ä¸ºè„šæœ¬éƒ½æ˜¯è¿è¡Œä¸€æ¬¡åå°±ç»“æŸäº†ï¼Œå¯ä»¥é…åˆcrontabåå¤è¿è¡Œ 12345crontab -e# æ¯åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡è„šæœ¬* * * * * sh /root/pushgateway/node_exporter_shell.sh# æ¯10sæ‰§è¡Œä¸€æ¬¡è„šæœ¬* * * * * sh /root/pushgateway/node_exporter_shell.sh 4.3 ç¼–å†™æŠ“å–pingä¸¢åŒ…å’Œå»¶è¿Ÿæ—¶é—´æ•°æ®åœ¨node_exporter_shell.shä¸­åŠ å…¥ 123456789101112131415161718192021#---# è·å–pingæŸç½‘ç«™ä¸¢åŒ…ç‡å’Œå»¶è¿Ÿæ—¶é—´site_address=&quot;www.baidu.com&quot;# è·å–ä¸¢åŒ…ç‡å’Œå»¶è¿Ÿæ—¶é—´ï¼Œå®šä¹‰ä¸ºä¸¤ä¸ªæ–°keylable_ping_packet_loss=&quot;ping_packet_loss&quot;ping_packet_loss_test=`ping -c3 $site_address | awk 'NR==7{print $6}'`# å­—ç¬¦ä¸²æˆªå–ï¼Œ%?ä¸ºå»é™¤æœ€åä¸€ä¸ªå­—ç¬¦ping_packet_loss=`echo ${ping_packet_loss_test%?}`lable_ping_time=&quot;ping_time&quot;ping_time_test=`ping -c3 $site_address | awk 'NR==7{print $10}'`# å­—ç¬¦ä¸²æˆªå–ï¼Œ%??ä¸ºå»é™¤æœ€åä¸¤ä¸ªå­—ç¬¦ping_time=`echo ${ping_time_test%??}`# ä¸Šä¼ è‡³push_ping_timegatewayecho &quot;$lable_ping_packet_loss $ping_packet_loss&quot; | curl --data-binary @- http://localhost:9091/metrics/job/pushgateway/instance/$instance_nameecho &quot;$lable_ping_time $ping_time&quot; | curl --data-binary @- http://localhost:9091/metrics/job/pushgateway/instance/$instance_name#--- äº”ã€Grafanaçš„ä½¿ç”¨Grafanaæ˜¯ä¸€æ¬¾ç”¨Goè¯­è¨€å¼€å‘çš„å¼€æºæ•°æ®å¯è§†åŒ–å·¥å…·ï¼Œå¯ä»¥åšæ•°æ®ç›‘æ§å’Œæ•°æ®ç»Ÿè®¡ï¼Œå¸¦æœ‰å‘Šè­¦åŠŸèƒ½ã€‚ 5.1 Grafanaå®‰è£…1234wget https://dl.grafana.com/oss/release/grafana-7.5.1-1.x86_64.rpmyum -y install grafana-7.5.1-1.x86_64.rpmsystemctl start grafana-serversystemctl enable grafana-server 5.2 è®¾ç½®æ•°æ®æº Grafana -&gt; Configuration -&gt; Date Sources -&gt; Prometheus New dashboard æ·»åŠ ä¸€ä¸ªç›‘æ§å’ŒCPUå†…å­˜ä½¿ç”¨ç‡çš„ä»ªè¡¨ç›˜ 5.3 jsonå¤‡ä»½å’Œè¿˜åŸ å¤‡ä»½ï¼šdashboard -&gt; Settings -&gt; JSON Modelï¼Œå°†é‡Œé¢å†…å®¹ä¿å­˜ä¸ºjsonæ–‡ä»¶ æ¢å¤ï¼šCreate -&gt; import 5.4 Grafanaå®ç°æŠ¥è­¦åŠŸèƒ½ é…ç½®Grafanaæ–‡ä»¶ 123456789101112131415# å®‰è£…ä¾èµ–å’Œå›¾å½¢æ˜¾ç¤ºæ’ä»¶yum -y install libatk-bridge* libXss* libgtk*grafana-cli plugins install grafana-image-renderer# ä¿®æ”¹é…ç½®vim /etc/grafana/grafana.inienabled = truehost = smtp.163.com:25# å‘é€æŠ¥è­¦é‚®ä»¶çš„é‚®ç®±user = chenqiming13@163.com# æˆæƒç password = QXQALYMTRYRWIOOSskip_verify = truefrom_address = chenqiming13@163.comfrom_name = Grafanasystemctl restart grafana-server åˆ›å»ºæŠ¥è­¦è§„åˆ™ é’ˆå¯¹å…·ä½“ç›‘æ§é¡¹ï¼Œè®¾ç½®å‘é€é‚®ä»¶é˜ˆå€¼ç­‰ï¼Œè¿™é‡Œè®¾ç½®ä¸ºå‘ç°è¶…è¿‡é˜ˆå€¼èµ·5åˆ†é’Ÿåè§¦å‘æŠ¥è­¦ ![Grafanaå®ç°æŠ¥è­¦åŠŸèƒ½ä¸ƒ](Grafanaå®ç°æŠ¥è­¦åŠŸèƒ½ä¸ƒ.png å…­ã€Prometheus + Grafanaå®é™…æ¡ˆä¾‹6.1 predict_linearå‡½æ•°å®ç°ç¡¬ç›˜ç›‘æ§ç¡¬ç›˜ä½¿ç”¨ç‡å…¬å¼ä¸ºï¼šï¼ˆï¼ˆæ€»å®¹é‡ - å‰©ä½™å®¹é‡ï¼‰/ æ€»å®¹é‡ï¼‰* 100ï¼Œåœ¨Prometheusä¸­è¡¨ç¤ºä¸º 1((node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes) * 100 é€šè¿‡df -må¯ä»¥çœ‹å‡ºè®¡ç®—å‡ºæ¥çš„å€¼æ˜¯æ­£ç¡®çš„ Prometheusæä¾›äº†ä¸€ä¸ªpredict_linearå‡½æ•°å¯ä»¥é¢„è®¡å¤šé•¿æ—¶é—´ç£ç›˜çˆ†æ»¡ï¼Œä¾‹å¦‚å½“å‰è¿™1ä¸ªå°æ—¶çš„ç£ç›˜å¯ç”¨ç‡æ€¥å‰§ä¸‹é™ï¼Œè¿™ç§æƒ…å†µå¯èƒ½å¯¼è‡´ç£ç›˜å¾ˆå¿«è¢«å†™æ»¡ï¼Œè¿™æ—¶å¯ä»¥ä½¿ç”¨è¯¥å‡½æ•°ï¼Œç”¨å½“å‰1å°æ—¶çš„æ•°æ®å»é¢„æµ‹æœªæ¥å‡ ä¸ªå°æ—¶çš„çŠ¶æ€ï¼Œå®ç°æå‰æŠ¥è­¦ã€‚ 12# è¯¥å¼å­è¡¨ç¤ºç”¨å½“å‰1å°æ—¶çš„å€¼æ¥é¢„æµ‹æœªæ¥4å°æ—¶åå¦‚æœæ ¹ç›®å½•ä¸‹å®¹é‡å°äº0åˆ™è§¦å‘æŠ¥è­¦predict_linear(node_filesystem_free_bytes {mountpoint =&quot;/&quot;}[1h], 4*3600) &lt; 0 åœ¨Grafanaæ·»åŠ ç›‘æ§ç¡¬ç›˜ä½¿ç”¨ç‡å’Œé¢„æµ‹ç¡¬ç›˜ä½¿ç”¨ç‡çš„ä»ªè¡¨ç›˜ 6.2 ç›‘æ§ç¡¬ç›˜IOå…¬å¼ä¸ºï¼šï¼ˆè¯»å–æ—¶é—´ / å†™å…¥æ—¶é—´ï¼‰/ 1024 / 1024ï¼Œç”¨rateå‡½æ•°å–ä¸€åˆ†é’Ÿå†…è¯»å’Œå†™çš„å­—èŠ‚å¢é•¿ç‡æ¥è®¡ç®—ï¼Œç”¨Prometheusè¡¨ç¤ºä¸º 1((rate(node_disk_read_bytes_total[1m]) + rate(node_disk_written_bytes_total[1m])) / 1024 / 1024) &gt; 0 6.3 ç›‘æ§TCP_WAITçŠ¶æ€çš„æ•°é‡åœ¨è¢«ç›‘æ§ä¸»æœºä¸Šç¼–å†™ç›‘æ§è„šæœ¬ 12345678910111213141516171819202122#!/bin/bash# è·å–ç›‘æ§ä¸»æœºåinstance_name=`hostname -f | cut -d'.' -f1`# å¦‚æœä¸»æœºåä¸ºlocalhostï¼Œåˆ™é€€å‡ºif [ $instance_name == &quot;localhost&quot; ]then echo &quot;ä¸èƒ½ç›‘æ§ä¸»æœºåä¸ºlocalhostçš„ä¸»æœº&quot; exit 1fi#---# è·å–TCP WAITæ•°é‡# æŠ“å–TCP WAITæ•°é‡ï¼Œå®šä¹‰ä¸ºä¸€ä¸ªæ–°keylable_tcp_wait=&quot;count_netstat_wait_connections&quot;count_netstat_wait_connections=`netstat -an | grep 'WAIT' | wc -l`# ä¸Šä¼ è‡³pushgatewayecho &quot;$lable_tcp_wait $count_netstat_wait_connections&quot; | curl --data-binary @- http://localhost:9091/metrics/job/pushgateway/instance/$instance_name#--- 6.4 ç›‘æ§æ–‡ä»¶æè¿°ç¬¦ä½¿ç”¨ç‡åœ¨linuxä¸­ï¼Œæ¯å½“è¿›ç¨‹æ‰“å¼€ä¸€ä¸ªæ–‡ä»¶æ—¶ï¼Œç³»ç»Ÿå°±ä¼šä¸ºå…¶åˆ†é…ä¸€ä¸ªå”¯ä¸€çš„æ•´å‹æ–‡ä»¶æè¿°ç¬¦ï¼Œç”¨æ¥æ ‡è¯†è¿™ä¸ªæ–‡ä»¶ï¼Œæ¯ä¸ªè¿›ç¨‹é»˜è®¤æ‰“å¼€çš„æ–‡ä»¶æè¿°ç¬¦æœ‰ä¸‰ä¸ªï¼Œåˆ†åˆ«ä¸ºæ ‡å‡†è¾“å…¥ã€æ ‡å‡†è¾“å‡ºã€æ ‡å‡†é”™è¯¯ï¼Œå³stdinã€stoutã€steerï¼Œç”¨æ–‡ä»¶æè¿°ç¬¦æ¥è¡¨ç¤ºä¸º0ã€1ã€2ã€‚ ç”¨å‘½ä»¤å¯ä»¥æŸ¥çœ‹ç›®å‰ç³»ç»Ÿçš„æœ€å¤§æ–‡ä»¶æè¿°ç¬¦é™åˆ¶ï¼Œä¸€èˆ¬é»˜è®¤è®¾ç½®æ˜¯1024ã€‚ 1ulimit -n æ–‡ä»¶æè¿°ç¬¦ä½¿ç”¨ç‡å…¬å¼ä¸ºï¼šï¼ˆå·²åˆ†é…çš„æ–‡ä»¶æè¿°ç¬¦æ•°é‡ / æœ€å¤§æ–‡ä»¶æè¿°ç¬¦æ•°é‡ï¼‰* 100ï¼Œåœ¨Prometheusä¸­åˆ™è¡¨ç¤ºä¸º 1(node_filefd_allocated / node_filefd_maximum) * 100 6.5 ç½‘ç»œå»¶è¿Ÿå’Œä¸¢åŒ…ç‡ç›‘æ§å‰é¢æˆ‘ä»¬é‡‡ç”¨çš„éƒ½æ˜¯ç®€å•çš„ping + ipåœ°å€æ¥è¿›è¡Œæµ‹è¯•ï¼Œå®é™…ä¸Šè¿™æ ·æµ‹è¯•å‘å‡ºå»çš„icmpæ•°æ®åŒ…æ˜¯éå¸¸å°çš„ï¼Œåªé€‚åˆç”¨æ¥æµ‹è¯•ç½‘ç»œæ˜¯å¦è¿é€šï¼Œå› æ­¤ç”¨ä»¥ä¸‹å‘½ä»¤æ¥è¿›è¡Œä¼˜åŒ–ï¼š 12345ping -q ipåœ°å€ -s 500 -W 1000 -c 100-q:ä¸æ˜¾ç¤ºæŒ‡ä»¤æ‰§è¡Œè¿‡ç¨‹ï¼Œå¼€å¤´å’Œç»“å°¾çš„ç›¸å…³ä¿¡æ¯é™¤å¤–ã€‚-s:è®¾ç½®æ•°æ®åŒ…çš„å¤§å°ã€‚-W:åœ¨ç­‰å¾… timeout ç§’åå¼€å§‹æ‰§è¡Œã€‚-c:è®¾ç½®å®Œæˆè¦æ±‚å›åº”çš„æ¬¡æ•°ã€‚ 6.6 ä½¿ç”¨Pagedutyå®ç°æŠ¥è­¦Pagerdutyæ˜¯ä¸€å¥—ä»˜è´¹ç›‘æ§æŠ¥è­¦ç³»ç»Ÿï¼Œç»å¸¸ä½œä¸ºSRE/è¿ç»´äººå‘˜çš„ç›‘æ§æŠ¥è­¦å·¥å…·ï¼Œå¯ä»¥å’Œå¸‚é¢ä¸Šå¸¸è§çš„ç›‘æ§å·¥å…·ç›´æ¥æ•´åˆã€‚ åˆ›å»ºæ–°service åœ¨Grafanaæ–°å»ºæŠ¥è­¦æ¸ é“ï¼Œå¹¶åœ¨ä»ªè¡¨ç›˜ä¸­è®¾ç½®ä¸ºPagedutyæŠ¥è­¦ è®¾ç½®æŠ¥è­¦ä¿¡æ¯ æŸ¥çœ‹æ˜¯å¦æ”¶åˆ°æŠ¥è­¦ å½“é—®é¢˜è§£å†³å¯ä»¥ç‚¹å‡»å·²è§£å†³","link":"/2024/02/18/prometheus/"},{"title":"Web","text":"ä¸€ã€Apache1.1 Apacheä»‹ç»Apache HTTP Serverï¼ˆç®€ç§°Apacheï¼‰æ˜¯Apacheè½¯ä»¶åŸºé‡‘ä¼šçš„ä¸€ä¸ªå¼€æ”¾æºç çš„ç½‘é¡µæœåŠ¡å™¨ï¼Œæ˜¯ä¸–ç•Œä½¿ç”¨æ’åç¬¬ä¸€çš„WebæœåŠ¡å™¨è½¯ä»¶ã€‚å®ƒå¯ä»¥è¿è¡Œåœ¨å‡ ä¹æ‰€æœ‰å¹¿æ³›ä½¿ç”¨çš„è®¡ç®—æœºå¹³å°ä¸Šï¼Œç”±äºå…¶è·¨å¹³å°å’Œå®‰å…¨æ€§è¢«å¹¿æ³›ä½¿ç”¨ï¼Œæ˜¯æœ€æµè¡Œçš„WebæœåŠ¡å™¨ç«¯è½¯ä»¶ä¹‹ä¸€ã€‚å®ƒå¿«é€Ÿã€å¯é å¹¶ä¸”å¯é€šè¿‡ç®€å•çš„APIæ‰©å……ï¼Œå°†Perl/Pythonç­‰è§£é‡Šå™¨ç¼–è¯‘åˆ°æœåŠ¡å™¨ä¸­ã€‚ Apache HTTPæœåŠ¡å™¨æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–çš„æœåŠ¡å™¨ï¼ŒæºäºNCSAhttpdæœåŠ¡å™¨ï¼Œç»è¿‡å¤šæ¬¡ä¿®æ”¹ï¼Œæˆä¸ºä¸–ç•Œä½¿ç”¨æ’åç¬¬ä¸€çš„WebæœåŠ¡å™¨è½¯ä»¶ã€‚ Apacheå®˜æ–¹æ–‡æ¡£ï¼šhttp://httpd.apache.org/docs/ 1.2 é€šè¿‡è„šæœ¬æºç å®‰è£…Apache ç¼–å†™å®‰è£…è„šæœ¬ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189useradd -s /sbin/nologin -r wwwvim apache-install.sh#!/bin/bashapr_version=1.7.0apr_iconv_version=1.2.2apr_util_version=1.6.1apache_version=2.4.46#æ£€æŸ¥function check(){ #æ£€æŸ¥æ˜¯å¦ä¸ºrootç”¨æˆ· if [ $USER != 'root' ] then echo -e &quot;\\e[1;31m error:need to be root so that \\e[0m&quot; exit 1 fi #æ£€æŸ¥æ˜¯å¦å®‰è£…äº†wget if [ `rpm -qa | grep wget | wc -l` -lt 1 ] then echo -e &quot;\\e[1;31m error:not found wget \\e[0m&quot; exit 1 fi}#å®‰è£…å‰å‡†å¤‡function install_pre(){ #å®‰è£…ä¾èµ– if [ ! `yum -y install zlib-devel pcre-devel libxml2 expat-devel &amp;&gt; /dev/null` ] then echo -e &quot;\\e[1;31m error:yum install dependency package failed \\e[0m&quot; exit 1 fi #ä¸‹è½½apr cd /usr/local if [ ! `wget https://downloads.apache.org/apr/apr-${apr_version}.tar.bz2 &amp;&gt; /dev/null` ] then tar -xf apr-${apr_version}.tar.bz2 if [ ! -d apr-${apr_version} ] then echo -e &quot;\\e[1;31m error:not found apr-${apr_version} \\e[0m&quot; exit 1 else cd apr-${apr_version} fi else echo -e &quot;\\e[1;31m error:Failed to download apr-${apr_version}.tar.bz2 \\e[0m&quot; exit 1 fi #å®‰è£…apr echo &quot;apr configure...&quot; ./configure --prefix=/usr/local/apr &amp;&gt; /dev/null if [ `echo $?` -eq 0 ] then echo &quot;apr make &amp;&amp; make install...&quot; make &amp;&amp; make install &amp;&gt; /dev/null if [ `echo $?` -eq 0 ] then echo -e &quot;\\e[1;32m apr installed successfully \\e[0m&quot; else echo -e &quot;\\e[1;31m apr installed failed \\e[0m&quot; exit 1 fi else echo -e &quot;\\e[1;31m error:apr configure failed \\e[0m&quot; exit 1 fi #ä¸‹è½½apr-iconv cd /usr/local if [ ! `wget https://www.apache.org/dist/apr/apr-iconv-${apr_iconv_version}.tar.bz2 &amp;&gt; /dev/null` ] then tar -xf apr-iconv-${apr_iconv_version}.tar.bz2 if [ ! -d apr-iconv-${apr_iconv_version} ] then echo -e &quot;\\e[1;31m error:not found apr-iconv-${apr_iconv_version} \\e[0m&quot; exit 1 else cd apr-iconv-${apr_iconv_version} fi else echo -e &quot;\\e[1;31m error:Failed to download apr-iconv-${apr_iconv_version}.tar.bz2 \\e[0m&quot; exit 1 fi #å®‰è£…apr-iconv echo &quot;apr-iconv configure...&quot; ./configure --prefix=/usr/local/apr-iconv --with-apr=/usr/local/apr &amp;&gt; /dev/null if [ `echo $?` -eq 0 ] then echo &quot;apr-iconv make &amp;&amp; make install...&quot; make &amp;&amp; make install &amp;&gt; /dev/null if [ `echo $?` -eq 0 ] then echo -e &quot;\\e[1;32m apr-iconv installed successfully \\e[0m&quot; else echo -e &quot;\\e[1;31m apr-iconv installed failed \\e[0m&quot; exit 1 fi else echo -e &quot;\\e[1;31m error:apr-iconv configure failed \\e[0m&quot; exit 1 fi #ä¸‹è½½apr-util cd /usr/local if [ ! `wget https://www.apache.org/dist/apr/apr-util-${apr_util_version}.tar.bz2 &amp;&gt; /dev/null` ] then tar -xf apr-util-${apr_util_version}.tar.bz2 if [ ! -d apr-util-${apr_util_version} ] then echo -e &quot;\\e[1;31m error:not found apr-util-${apr_util_version} \\e[0m&quot; exit 1 else cd apr-util-${apr_util_version} fi else echo -e &quot;\\e[1;31m error:Failed to download apr-util-${apr_util_version}.tar.bz2 \\e[0m&quot; exit 1 fi #å®‰è£…apr-util echo &quot;apr-util configure...&quot; ./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr/ &amp;&gt; /dev/null if [ `echo $?` -eq 0 ] then echo &quot;apr-util make &amp;&amp; make install...&quot; make &amp;&amp; make install &amp;&gt; /dev/null if [ `echo $?` -eq 0 ] then echo -e &quot;\\e[1;32m apr-util installed successfully \\e[0m&quot; else echo -e &quot;\\e[1;31m apr-util installed failed \\e[0m&quot; exit 1 fi else echo -e &quot;\\e[1;31m error:apr-util configure failed \\e[0m&quot; exit 1 fi}#ä¸‹è½½å®‰è£…Apachefunction apache_install(){ #ä¸‹è½½Apache cd /usr/local if [ ! `wget https://downloads.apache.org/httpd/httpd-${apache_version}.tar.gz &amp;&gt; /dev/null` ] then tar -xf httpd-${apache_version}.tar.gz if [ ! -d httpd-${apache_version} ] then echo -e &quot;\\e[1;31m error:not found httpd-${apache_version} \\e[0m&quot; exit 1 else cd httpd-${apache_version} fi else echo -e &quot;\\e[1;31m error:Failed to download httpd-${apache_version} \\e[0m&quot; exit 1 fi #å®‰è£…Apache echo &quot;Apache configure...&quot; ./configure --prefix=/usr/local/apache --enable-mpms-shared=all --with-mpm=event --with-apr=/usr/local/apr --with-apr-util=/usr/local/apr-util --enable-so --enable-remoteip --enable-proxy --enable-proxy-fcgi --enable-proxy-uwsgi --enable-deflate=shared --enable-expires=shared --enable-rewrite=shared --enable-cache --enable-file-cache --enable-mem-cache --enable-disk-cache --enable-static-support --enable-static-ab --disable-userdir --enable-nonportable-atomics --disable-ipv6 --with-sendfile &amp;&gt; /dev/null if [ `echo $?` -eq 0 ] then echo &quot;Apache make &amp;&amp; make install...&quot; make &amp;&amp; make install &amp;&gt; /dev/null if [ `echo $?` -eq 0 ] then echo -e &quot;\\e[1;32m Apache installed sucessfully \\e[0m&quot; else echo -e &quot;\\e[1;31m Apache installed failed \\e[0m&quot; exit 1 fi else echo -e &quot;\\e[1;31m Apache configure failed \\e[0m&quot; exit 1 fi}checkinstall_preapache_install ç¼–å†™å¯åŠ¨è„šæœ¬ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#!/bin/bashapache_doc=/usr/local/apache/binapache_pid=/usr/local/apache/logs/httpd.pidfunction apache_start(){ apache_num=`ps -ef | grep httpd | wc -l` if [ $apache_num -gt 1 ] &amp;&amp; [ -f $apache_pid ] then echo -e &quot;Apache [\\e[1;32m running \\e[0m]&quot; exit 1 elif [ $apache_num -eq 1 ] &amp;&amp; [ -f $apache_pid ] then killall httpd fi cd /usr/local/apache/bin;./apachectl echo -e &quot;start Apache [\\e[1;32m OK \\e[0m]&quot;}function apache_stop(){ apache_num=`ps -ef | grep httpd | wc -l` if [ $apache_num -eq 1 ] then echo -e &quot;Apache [\\e[1;31m stopping \\e[0m]&quot; else killall httpd echo -e &quot;stop Apache [\\e[1;32m OK \\e[0m]&quot; fi}function apache_restart(){ cd /usr/local/apache/bin;./apachectl restart echo -e &quot;restart Apache [\\e[1;32m OK \\e[0m]&quot;}function apache_status(){ apache_num=`ps -ef | grep httpd | wc -l` if [ $apache_num -gt 1 ] &amp;&amp; [ -f $nginx_pid ] then echo -e &quot;Apache [\\e[1;32m running \\e[0m]&quot; else echo -e &quot;Apache [\\e[1;31m stopping \\e[0m]&quot; fi}function apache_reload(){ apache_num=`ps -ef | grep httpd | wc -l` if [ $apache_num -gt 1 ] &amp;&amp; [ -f $nginx_pid ] then cd /usr/local/apache/bin;./apachectl graceful echo -e &quot;reload Apache [\\e[1;32m OK \\e[0m]&quot; else echo -e &quot;Apache [\\e[1;31m stopping \\e[0m]&quot; fi}case $1 instart) apache_start;;stop) apache_stop;;restart) apache_restart;;status) apache_status;;reload) apache_reloadesac 1.3 å¤šå¤„ç†æ¨¡å—MPMApache HTTP æœåŠ¡å™¨è¢«è®¾è®¡ä¸ºä¸€ä¸ªåŠŸèƒ½å¼ºå¤§ï¼Œå¹¶ä¸”çµæ´»çš„ web æœåŠ¡å™¨ï¼Œ å¯ä»¥åœ¨å¾ˆå¤šå¹³å°ä¸ç¯å¢ƒä¸­å·¥ä½œã€‚ä¸åŒå¹³å°å’Œä¸åŒçš„ç¯å¢ƒå¾€å¾€éœ€è¦ä¸åŒ çš„ç‰¹æ€§ï¼Œæˆ–å¯èƒ½ä»¥ä¸åŒçš„æ–¹å¼å®ç°ç›¸åŒçš„ç‰¹æ€§æœ€æœ‰æ•ˆç‡ã€‚Apache é€šè¿‡æ¨¡å—åŒ–çš„è®¾è®¡æ¥é€‚åº”å„ç§ç¯å¢ƒã€‚è¿™ç§è®¾è®¡å…è®¸ç½‘ç«™ç®¡ç†å‘˜é€šè¿‡åœ¨ ç¼–è¯‘æ—¶æˆ–è¿è¡Œæ—¶ï¼Œé€‰æ‹©å“ªäº›æ¨¡å—å°†ä¼šåŠ è½½åœ¨æœåŠ¡å™¨ä¸­ï¼Œæ¥é€‰æ‹©æœåŠ¡å™¨ç‰¹æ€§ã€‚ å®é™…ä¸Šå°±æ˜¯ç”¨æ¥æ¥å—è¯·æ±‚å’Œå¤„ç†è¯·æ±‚çš„ã€‚ Apacheçš„ä¸‰ç§å·¥ä½œæ–¹å¼ï¼š Prefork MPMï¼šä½¿ç”¨å¤šä¸ªè¿›ç¨‹ï¼Œæ¯ä¸ªè¿›ç¨‹åªæœ‰ä¸€ä¸ªçº¿ç¨‹ï¼Œæ¯ä¸ªè¿›ç¨‹å†æŸä¸ªç¡®å®šçš„æ—¶é—´åªèƒ½ç»´æŒä¸€ä¸ªè¿æ¥ï¼Œæœ‰ç‚¹æ˜¯ç¨³å®šï¼Œç¼ºç‚¹æ˜¯å†…å­˜æ¶ˆè€—è¿‡é«˜ã€‚ ![Prefork MPM](Prefork MPM.png) Worker MPMï¼šä½¿ç”¨å¤šä¸ªè¿›ç¨‹ï¼Œæ¯ä¸ªè¿›ç¨‹æœ‰å¤šä¸ªçº¿ç¨‹ï¼Œæ¯ä¸ªçº¿ç¨‹åœ¨æŸä¸ªç¡®å®šçš„æ—¶é—´åªèƒ½ç»´æŒä¸€ä¸ªè¿æ¥ï¼Œå†…å­˜å ç”¨æ¯”è¾ƒå°ï¼Œæ˜¯ä¸ªå¤§å¹¶å‘ã€é«˜æµé‡çš„åœºæ™¯ï¼Œç¼ºç‚¹æ˜¯ä¸€ä¸ªçº¿ç¨‹å´©æºƒï¼Œæ•´ä¸ªè¿›ç¨‹å°±ä¼šè¿åŒå…¶ä»»ä½•çº¿ç¨‹ä¸€èµ·æŒ‚æ‰ã€‚ ![Worker MPM](Worker MPM.png) Event MPMï¼šä½¿ç”¨å¤šè¿›ç¨‹å¤šçº¿ç¨‹+epollçš„æ¨¡å¼ã€‚ ![Event MPM](Event MPM.png) 1.4 è™šæ‹Ÿä¸»æœºé»˜è®¤æƒ…å†µä¸‹ï¼Œä¸€ä¸ªwebæœåŠ¡å™¨åªèƒ½å‘å¸ƒä¸€ä¸ªé»˜è®¤ç½‘ç«™ï¼Œä¹Ÿå°±æ˜¯åªèƒ½å‘å¸ƒä¸€ä¸ªwebç«™ç‚¹ï¼Œå¯¹äºå¤§ç½‘ç«™æ¥è¯´è¿˜å¥½ï¼Œä½†å¯¹äºè®¿é—®é‡è¾ƒå°‘çš„å°ç½‘ç«™é‚£å°±æ˜¾å¾—æœ‰ç‚¹æµªè´¹äº†ã€‚ è€Œè™šæ‹Ÿä¸»æœºå°±å¯ä»¥å®ç°åœ¨ä¸€ä¸ªwebæœåŠ¡å™¨ä¸Šå‘å¸ƒå¤šä¸ªç«™ç‚¹ï¼Œåˆ†ä¸ºåŸºäºIPåœ°å€ã€åŸŸåå’Œç«¯å£ä¸‰ç§ã€‚ Apacheçš„è™šæ‹Ÿä¸»æœºå’Œé»˜è®¤ç½‘ç«™ä¸èƒ½å¤ŸåŒæ—¶å­˜åœ¨ï¼Œå¦‚æœè®¾ç½®äº†è™šæ‹Ÿä¸»æœºé‚£ä¹ˆé»˜è®¤ç½‘ç«™ä¹Ÿå°±å¤±æ•ˆäº†ï¼Œéœ€è¦åœ¨ç”¨è™šæ‹Ÿä¸»æœºå‘å¸ƒé»˜è®¤ç«™ç‚¹æ‰å¯è§£å†³ã€‚ åŸºäºIPï¼šåŸºäºIPçš„è™šæ‹Ÿä¸»æœºéœ€è¦è€—è´¹å¤§é‡çš„IPåœ°å€ï¼Œåªé€‚åˆIPåœ°å€å……è¶³çš„ç¯å¢ƒã€‚ åŸºäºç«¯å£ï¼šéœ€è¦è€—è´¹è¾ƒå¤šçš„ç«¯å£ï¼Œé€‚åˆç§ç½‘ç¯å¢ƒã€‚ åŸºäºåŸŸåï¼šéœ€è¦è€—è´¹è¾ƒå¤šçš„åŸŸåï¼Œé€‚åˆå…¬ç½‘ç¯å¢ƒã€‚ 1.4.1 åŸºäºIPçš„è™šæ‹Ÿä¸»æœº åœ¨ä¸»é…æ–‡ä»¶ä¸­è°ƒç”¨è™šæ‹Ÿä¸»æœºæ–‡ä»¶ 123vim /usr/local/apache/conf/httpd.conf# Virtual hostsInclude conf/extra/httpd-vhosts.conf ä¿®æ”¹è™šæ‹Ÿä¸»æœºæ–‡ä»¶ 123456789101112131415161718192021# æ·»åŠ ä¸€ä¸ªé€»è¾‘ç½‘å¡ï¼Œé‡å¯å³å¤±æ•ˆifconfig eth0:1 192.168.88.100/24 upvim /usr/local/apache/conf/extra/httpd-vhosts.conf&lt;VirtualHost 49.232.160.75:80&gt; # ç®¡ç†å‘˜é‚®ç®± # ServerAdmin webmaster@dummy-host.example.com # webç›®å½• DocumentRoot &quot;/usr/local/apache/htdocs/web1&quot; # åŸŸå # ServerName dummy-host.example.com # ç»™åŸŸåèµ·åˆ«åï¼Œèµ·åˆ°é‡å®šå‘ä½œç”¨ # ServerAlias www.dummy-host.example.com # é”™è¯¯æ—¥å­ # ErrorLog &quot;logs/dummy-host.example.com-error_log&quot; # è®¿é—®æ—¥å¿— # CustomLog &quot;logs/dummy-host.example.com-access_log&quot; common&lt;/VirtualHost&gt;&lt;VirtualHost 192.168.88.100:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web2&quot;&lt;/VirtualHost&gt; åˆ›å»ºç«™ç‚¹ç›®å½•å’Œæ–‡ä»¶ 1234mkdir /usr/local/apache/htdocs/web{1..2}echo 'this is web1' &gt; /usr/local/apache/htdocs/web1/index.htmlecho 'this is web2' &gt; /usr/local/apache/htdocs/web2/index.html./apache start æµ‹è¯• 1.4.2 åŸºäºç«¯å£çš„è™šæ‹Ÿä¸»æœº ä¿®æ”¹è™šæ‹Ÿä¸»æœºæ–‡ä»¶ 12345678&lt;VirtualHost *:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web1&quot;&lt;/VirtualHost&gt;Listen 81&lt;VirtualHost *:81&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web2&quot;&lt;/VirtualHost&gt; æµ‹è¯• 1.4.3 åŸºäºåŸŸåçš„è™šæ‹Ÿä¸»æœº ä¿®æ”¹è™šæ‹Ÿä¸»æœºæ–‡ä»¶ 123456789&lt;VirtualHost *:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web1&quot; ServerName www.cqm1.com&lt;/VirtualHost&gt;&lt;VirtualHost *:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web2&quot; ServerName www.cqm2.com&lt;/VirtualHost&gt; æµ‹è¯• 1.5 LAMPLAMPï¼šLinux + Apache + Mysql + PHP ä½œç”¨å°±æ˜¯æ„å»ºä¸€ä¸ªPHPä¸šåŠ¡ç¯å¢ƒï¼Œç”¨æ¥å‘å¸ƒPHPç½‘ç«™ã€‚ 1.5.1 Mysqlé€šè¿‡è„šæœ¬æºç å®‰è£… ç¼–å†™å®‰è£…è„šæœ¬ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208#!/bin/bashmysql_version=5.7.35install_dir=/optdata_dir=/datawget_url=&quot;https://mirrors.tuna.tsinghua.edu.cn/mysql/downloads/MySQL-5.7/mysql-${mysql_version}-linux-glibc2.12-x86_64.tar.gz&quot;function loginfo(){ if [[ $? -eq 0 ]];then echo -e &quot;\\033[32m[INFO][$(date +&quot;%F %T&quot;)] $1 succeed! \\033[0m&quot; else echo -e &quot;\\033[31m[ERROR][$(date +&quot;%F %T&quot;)] $1 failed! \\033[0m&quot; fi}function mysql_install(){ echo -e &quot;\\033[32mBegin install mysql V${mysql_version} ...\\033[0m&quot; # å®‰è£…ä¾èµ– sudo yum -y install libaio &gt;/dev/null 2&gt;&amp;1 loginfo &quot;libaio install&quot; # ä¸‹è½½mysql echo -e &quot;\\033[32mBegin download mysql V${mysql_version} ...\\033[0m&quot; curl -O $wget_url &gt;/dev/null 2&gt;&amp;1 mv ./mysql-${mysql_version}-linux-glibc2.12-x86_64.tar.gz $install_dir loginfo &quot;mysql software download&quot; # è§£å‹ç¼©mysql sudo tar -xf $install_dir/mysql-${mysql_version}-linux-glibc2.12-x86_64.tar.gz -C $install_dir loginfo &quot;mysql software decompression&quot; # åˆ›å»ºé…ç½®æ–‡ä»¶ç›®å½•å’Œæ•°æ®ç›®å½• if [[ -d $install_dir/mysql ]];then rm -rf $install_dir/mysql fi sudo ln -s $install_dir/mysql-${mysql_version}-linux-glibc2.12-x86_64 $install_dir/mysql loginfo &quot;create mysql config dir soft link&quot; if [[ -d $data_dir/mysql ]];then rm -rf $data_dir/mysql fi sudo mkdir -p $data_dir/mysql loginfo &quot;create mysql data dir&quot; # ä¿®æ”¹å¯åŠ¨è„šæœ¬ sudo sed -i &quot;46s#basedir=#basedir=${install_dir}/mysql#&quot; ${install_dir}/mysql/support-files/mysql.server sudo sed -i &quot;47s#datadir=#datadir=${data_dir}/mysql#&quot; ${install_dir}/mysql/support-files/mysql.server sudo cp ${install_dir}/mysql/support-files/mysql.server /etc/init.d/mysqld sudo chmod 755 /etc/init.d/mysqld # åˆ›å»ºç”¨æˆ·ç»„åŠç”¨æˆ· if ! grep -q '^mysql:' /etc/group then sudo groupadd mysql loginfo &quot;create user mysql&quot; fi if ! grep -q '^mysql:' /etc/passwd then sudo useradd -r -g mysql -s /bin/false mysql loginfo &quot;create group mysql&quot; fi # æˆæƒ sudo chown -R mysql:mysql $install_dir/mysql sudo chown -R mysql:mysql $data_dir/mysql # ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶åˆ›å»ºè½¯è¿æ¥ if [ ! -f /usr/bin/mysql ] then sudo ln -s /opt/mysql/bin/mysql /usr/bin/ fi # åˆ›å»ºé…ç½®æ–‡ä»¶ if [ -f /etc/my.cnf ] then sudo rm -f /etc/my.cnf fi sudo bash -c &quot;cat &gt;&gt; /etc/my.cnf&quot; &lt;&lt;EOF[mysqld]datadir = /data/mysqlbasedir = /opt/mysql#tmpdir = /data/mysql/tmp_mysqlport = 3306socket = /data/mysql/mysql.sockpid-file = /data/mysql/mysql.pidmax_connections = 8000max_connect_errors = 100000max_user_connections = 3000check_proxy_users = onmysql_native_password_proxy_users = onlocal_infile = OFFsymbolic-links = FALSEgroup_concat_max_len = 4294967295max_join_size = 18446744073709551615max_execution_time = 20000lock_wait_timeout = 60autocommit = 1lower_case_table_names = 1thread_cache_size = 64disabled_storage_engines = &quot;MyISAM,FEDERATED&quot;character_set_server = utf8mb4character-set-client-handshake = FALSEcollation_server = utf8mb4_general_ciinit_connect = 'SET NAMES utf8mb4'transaction-isolation = &quot;READ-COMMITTED&quot;skip_name_resolve = ONexplicit_defaults_for_timestamp = ONlog_timestamps = SYSTEMlocal_infile = OFFevent_scheduler = OFFquery_cache_type = OFFquery_cache_size = 0sql_mode = NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ZERO_DATE,NO_ZERO_IN_DATE,ERROR_FOR_DIVISION_BY_ZEROlog_error = /data/mysql/mysql.errslow_query_log = ONslow_query_log_file = /data/mysql/slow.loglong_query_time = 1general_log = OFFgeneral_log_file = /data/mysql/general.logexpire_logs_days = 99log-bin = /data/mysql/mysql-binlog-bin-index = /data/mysql/mysql-bin.indexmax_binlog_size = 500Mbinlog_format = mixedbinlog_rows_query_log_events = ONbinlog_cache_size = 128kbinlog_stmt_cache_size = 128klog-bin-trust-function-creators = 1max_binlog_cache_size = 2Gmax_binlog_stmt_cache_size = 2Grelay_log = /data/mysql/relayrelay_log_index = /data/mysql/relay.indexmax_relay_log_size = 500Mrelay_log_purge = ONrelay_log_recovery = ONserver_id = 1read_buffer_size = 1Mread_rnd_buffer_size = 2Msort_buffer_size = 64Mjoin_buffer_size = 64Mtmp_table_size = 64Mmax_allowed_packet = 128Mmax_heap_table_size = 64Mconnect_timeout = 43200wait_timeout = 43200back_log = 512interactive_timeout = 300net_read_timeout = 30net_write_timeout = 30skip_external_locking = ONkey_buffer_size = 16Mbulk_insert_buffer_size = 16Mconcurrent_insert = ALWAYSopen_files_limit = 65000table_open_cache = 16000table_definition_cache = 16000default_storage_engine = InnoDBdefault_tmp_storage_engine = InnoDBinternal_tmp_disk_storage_engine = InnoDB[client]socket = /data/mysql/mysql.sockdefault_character_set = utf8mb4[mysql]default_character_set = utf8mb4[ndatad default]TransactionDeadLockDetectionTimeOut = 20000EOF sudo chown -R mysql:mysql /etc/my.cnf loginfo &quot;configure my.cnf&quot; # åˆ›å»ºSSLè¯ä¹¦ # sudo mkdir -p ${install_dir}/mysql/ca-pem/ # sudo ${install_dir}/mysql/bin/mysql_ssl_rsa_setup -d ${install_dir}/mysql/ca-pem/ --uid=mysql # sudo chown -R mysql:mysql ${install_dir}/mysql/ca-pem/ # sudo bash -c &quot;cat &gt;&gt; ${data_dir}/mysql/init_file.sql&quot; &lt;&lt;EOF# set global sql_safe_updates=0;# set global sql_select_limit=50000;# EOF # sudo chown -R mysql:mysql ${data_dir}/mysql/init_file.sql # sudo chown -R mysql:mysql /etc/init.d/mysqld # åˆå§‹åŒ– ${install_dir}/mysql/bin/mysqld --initialize --user=mysql --basedir=${DEPLOY_PATH}/mysql --datadir=/data/mysql loginfo &quot;initialize mysql&quot; # å®¢æˆ·ç«¯ç¯å¢ƒå˜é‡ echo &quot;export PATH=\\$PATH:${install_dir}/mysql/bin&quot; | sudo tee /etc/profile.d/mysql.sh source /etc/profile.d/mysql.sh loginfo &quot;configure envirement&quot; # è·å–åˆå§‹å¯†ç  mysql_init_passwd=$(grep 'A temporary password is generated' ${data_dir}/mysql/mysql.err | awk '{print $NF}') # å¯åŠ¨æœåŠ¡ chkconfig --add mysqld sudo systemctl start mysqld loginfo &quot;start mysqld&quot; # ä¿®æ”¹å¯†ç  mysql --connect-expired-password -uroot -p${mysql_init_passwd} -e 'alter user user() identified by &quot;toortoor&quot;;' &gt;/dev/null 2&gt;&amp;1 loginfo &quot;edit mysql root password&quot;}mysql_install 1.5.2 PHPé€šè¿‡è„šæœ¬æºç å®‰è£… ç¼–å†™å®‰è£…è„šæœ¬ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176#!/bin/bashcmake_version=3.22.0libzip_version=1.8.0php_version=7.4.16#æ£€æŸ¥function check(){ #æ£€æŸ¥æ˜¯å¦ä¸ºrootç”¨æˆ· if [ $USER != &quot;root&quot; ] then echo -e &quot;\\e[1;31m error:need to be root so that \\e[0m&quot; exit 1 fi #æ£€æŸ¥æ˜¯å¦å®‰è£…äº†wget if [ `rpm -qa | grep wget | wc -l` -lt 1 ] then echo -e &quot;\\e[1;31m error:not found wget \\e[0m&quot; exit 1 fi}#å®‰è£…å‰å‡†å¤‡function pre(){ #å®‰è£…ä¾èµ–åŒ… if [ ! `yum -y install gcc-c++ libxml2 libxml2-devel openssl openssl-devel bzip2 bzip2-devel libcurl libcurl-devel libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel gmp gmp-devel libmcrypt libmcrypt-devel readline readline-devel libxslt libxslt-devel gd net-snmp-* sqlite-devel oniguruma-devel &amp;&gt; /dev/null` ] then echo -e &quot;\\e[1;31m error:yum install dependency package failed \\e[0m&quot; exit 1 fi #ä¸‹è½½æœ€æ–°ç‰ˆcmake cd /usr/local if [ ! `wget https://github.com/Kitware/CMake/releases/download/v${cmake_version}/cmake-${cmake_version}.tar.gz &amp;&gt; /dev/null` ] then tar -xf cmake-${cmake_version}.tar.gz if [ ! -d cmake-${cmake_version} ] then echo -e &quot;\\e[1;31m error:no found cmake-${cmake_version} \\e[0m&quot; exit 1 else cd cmake-${cmake_version} fi else echo -e &quot;\\e[1;31m error:Failed to download cmake-${cmake_version} \\e[0m&quot; exit 1 fi #å®‰è£…cmake echo &quot;cmake configure...&quot; ./configure &amp;&gt; /dev/null if [ `echo $?` -eq 0 ] then echo &quot;cmake make &amp;&amp; make install...&quot; make &amp;&amp; make install &amp;&gt; /dev/null if [ `echo $?` -eq 0 ] then echo -e &quot;\\e[1;32m cmake installed sucessfully \\e[0m&quot; else echo -e &quot;\\e[1;31m cmake installed failed \\e[0m&quot; exit 1 fi else echo -e &quot;\\e[1;31m error:cmake configure failed \\e[0m&quot; exit 1 fi #ä¸‹è½½libzip1.1ä»¥ä¸Šç‰ˆæœ¬ cd /usr/local if [ ! `wget --no-check-certificate https://libzip.org/download/libzip-${libzip_version}.tar.gz &amp;&gt; /dev/null` ] then echo &quot;tar libzip...&quot; tar -xf libzip-${libzip_version}.tar.gz if [ ! -d libzip-${libzip_version} ] then echo -e &quot;\\e[1;31m error:not found libzip-${libzip_version} \\e[0m&quot; exit 1 else cd libzip-${libzip_version} fi else echo -e &quot;\\e[1;31m error:Failed to download libzip-${libzip_version}.tar.gz \\e[0m&quot; exit 1 fi #å®‰è£…libzip mkdir build;cd build echo &quot;cmake libzip...&quot; cmake .. &amp;&gt; /dev/null if [ `echo $?` -eq 0 ] then echo &quot;make &amp;&amp; make install libzip...&quot; make &amp;&amp; make install &amp;&gt; /dev/null if [ `echo $?` -eq 0 ] then echo -e &quot;\\e[1;32m libzip install sucessfully \\e[0m&quot; echo -e '/usr/local/lib64\\n/usr/local/lib\\n/usr/lib\\n/usr/lib64'&gt;&gt; /etc/ld.so.conf ldconfig -v &amp;&gt; /dev/null else echo -e &quot;\\e[1;31m error:libzip install failed \\e[0m&quot; exit 1 fi else echo -e &quot;\\e[1;31m error:lipzip cmake failed \\e[0m&quot; exit 1 fi}function php_install(){ #ä¸‹è½½php cd /usr/local if [ ! `wget https://www.php.net/distributions/php-${php_version}.tar.bz2 &amp;&gt; /dev/null` ] then echo &quot;tar php...&quot; tar -xf php-${php_version}.tar.bz2 if [ ! -d php-${php_version} ] then echo -e &quot;\\e[1;31m error:not found php-${php_version} \\e[0m&quot; exit 1 else cd php-${php_version} fi else echo -e &quot;\\e[1;31m error:Failed to download php-${php_version}.tar.bz2 \\e[0m&quot; exit 1 fi #å®‰è£…php echo &quot;configure php...&quot; #è¦phpä»¥apacheæ¨¡å—è¿è¡Œéœ€åŠ ä¸Š--with-apxs2=/usr/localapache/bin/apxså‚æ•° ./configure --prefix=/usr/local/php --with-config-file-path=/usr/local/php/etc --with-mysqli=mysqlnd --enable-pdo --with-pdo-mysql=mysqlnd --with-iconv-dir=/usr/local/ --enable-fpm --with-fpm-user=www --with-fpm-group=www --with-pcre-regex --with-zlib --with-bz2 --enable-calendar --disable-phar --with-curl --enable-dba --with-libxml-dir --enable-ftp --with-gd --with-jpeg-dir --with-png-dir --with-zlib-dir --with-freetype-dir --enable-gd-jis-conv --with-mhash --enable-mbstring --enable-opcache=yes --enable-pcntl --enable-xml --disable-rpath --enable-shmop --enable-sockets --enable-zip --enable-bcmath --with-snmp --disable-ipv6 --with-gettext --disable-rpath --disable-debug --enable-embedded-mysqli --with-mysql-sock=/var/lib/mysql/ &amp;&gt; /dev/null if [ `echo $?` -eq 0 ] then echo &quot;make &amp;&amp; make install php...&quot; make &amp;&amp; make install &amp;&gt; /dev/null if [ `echo $?` -eq 0 ] then echo -e &quot;\\e[1;32m php install sucessfully \\e[0m&quot; else echo -e &quot;\\e[1;31m php install failed \\e[0m&quot; exit 1 fi else echo -e &quot;\\e[1;31m configure php failed \\e[0m&quot; exit 1 fi}function php_set(){ if [ ! -f /usr/local/php-${php_version}/sapi/fpm/php-fpm.service ] then echo -e &quot;\\e[1;31m No found php-fpm.service \\e[0m&quot; exit 1 else cp /usr/local/php-${php_version}/sapi/fpm/php-fpm.service /etc/systemd/system if [ `echo $?` -ne 0 ] then echo -e &quot;\\e[1;31m Copy php-fpm.service failed \\e[0m&quot; exit 1 else sed -i '/PrivateTmp=true/a\\ProtectSystem=false' /etc/systemd/system/php-fpm.service systemctl daemon-reload echo -e &quot;\\e[1;32m php set sucessfully \\e[0m&quot; fi fi}checkprephp_installphp_set é…ç½®PHP 123456789101112131415161718192021222324cd /usr/local/php/etccp php-fpm.conf.default php-fpm.confcp php-fpm.d/www.conf.default php-fpm.d/www.confegrep -v '^;|^$' php-fpm.conf[global]pid = run/php-fpm.piderror_log = log/php-fpm.logdaemonize = yesinclude=/usr/local/php/etc/php-fpm.d/*.confegrep -v '^;|^$' php-fpm.d/www.conf[www]user = wwwgroup = wwwlisten = 127.0.0.1:9000listen.owner = wwwlisten.group = wwwlisten.mode = 0660pm = dynamicpm.max_children = 5pm.start_servers = 2pm.min_spare_servers = 1pm.max_spare_servers = 3 å¯åŠ¨ 1systemctl start php-fpm 1.5.3 PHPä½œä¸ºApacheæ¨¡å—è¿è¡Œ åœ¨apacheä¸»é…ç½®æ–‡ä»¶ä¸­è°ƒç”¨å­é…ç½®æ–‡ä»¶ 12vim /usr/local/apache/conf/httpd.confinclude conf/extra/php.conf é…ç½®å­é…ç½®æ–‡ä»¶ 123vim /usr/local/apache/conf/extra/php.conLoadModule php7_module modules/libphp7.soAddType application/x-httpd-php .php é…ç½®è™šæ‹Ÿä¸»æœº 1234vim /usr/local/apache/conf/extra/httpd-vhosts.conf&lt;VirtualHost *:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web&quot;&lt;/VirtualHost&gt; å†™webç›®å½• 12345echo 'this is cqm web' &gt; /usr/local/apache/htdocs/web/index.htmlvim /usr/local/apache/htdocs/web/phpinfo.php&lt;?phpphpinfo()?&gt; æµ‹è¯• 1.5.4 PHPä½œä¸ºç‹¬ç«‹æœåŠ¡è¿è¡ŒPHPä½œä¸ºç‹¬ç«‹æœåŠ¡è¿è¡Œæœ‰ä¸¤ç§æ¨¡å¼ï¼š TCP socketæ¨¡å¼ UNIX socketæ¨¡å¼ TCP socketæ¨¡å¼ ä¿®æ”¹www.confæ–‡ä»¶ 12vim /usr/local/php/etc/php-fpm.d/www.conflisten = 127.0.0.1:9000 é…ç½®è™šæ‹Ÿä¸»æœºæ–‡ä»¶ 123456789101112131415161718vim /usr/local/apache/conf/extra/httpd-vhosts.conf&lt;VirtualHost *:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web&quot;&lt;/VirtualHost&gt;&lt;Directory &quot;/usr/local/apache/htdocs/web&quot;&gt; Options Indexes FollowSymLinks AllowOverride None Require all granted&lt;/Directory&gt;&lt;IfModule dir_module&gt; DirectoryIndex index.php index.html&lt;/IfModule&gt;&lt;FilesMatch \\.php$&gt; SetHandler &quot;proxy:fcgi://127.0.0.1:9000&quot;&lt;/FilesMatch&gt; åœ¨apacheä¸»é…æ–‡ä»¶æ·»åŠ å…³è” 12vim /usr/local/apache/conf/httpd.confinclude conf/extra/php-fpm.conf é…ç½®å­é…æ–‡ä»¶ 1234vim /usr/local/apache/conf/php-fpm.conf# è½½å…¥éœ€è¦çš„æ¨¡å—LoadModule proxy_module modules/mod_proxy.soLoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so UNIX socketæ¨¡å¼ ä¿®æ”¹www.confæ–‡ä»¶ 12vim /usr/local/php/etc/php-fpm.d/www.conflisten = /usr/local/php/etc/php-fpm.socket é…ç½®è™šæ‹Ÿä¸»æœº 123&lt;FilesMatch \\.php$&gt; SetHandler &quot;proxy:unix:/usr/local/php/etc/php-fpm.socket|fcgi://localhost/&quot;&lt;/FilesMatch&gt; 1.6 Apacheå¸¸ç”¨æ¨¡å—1.6.1 é•¿è¿æ¥HTTPé‡‡ç”¨TCPè¿›è¡Œä¼ è¾“ï¼Œæ˜¯é¢å‘è¿æ¥çš„åè®®ï¼Œæ¯å®Œæˆä¸€æ¬¡è¯·æ±‚å°±è¦ç»å†ä»¥ä¸‹è¿‡ç¨‹ï¼š ä¸‰æ¬¡æ¡æ‰‹ å‘èµ·è¯·æ±‚ å“åº”è¯·æ±‚ å››æ¬¡æŒ¥æ‰‹ é‚£ä¹ˆNä¸ªè¯·æ±‚å°±è¦å»ºç«‹Næ¬¡è¿æ¥ï¼Œå¦‚æœå¸Œæœ›ç”¨æˆ·èƒ½å¤Ÿæ›´å¿«çš„æ‹¿åˆ°æ•°æ®ï¼ŒæœåŠ¡å™¨çš„å‹åŠ›é™åˆ°æœ€ä½ï¼Œé‚£ä¹ˆé é•¿è¿æ¥å°±å¯ä»¥è§£å†³ã€‚ é•¿è¿æ¥å®é™…ä¸Šå°±æ˜¯ä¼˜åŒ–äº†TCPè¿æ¥ã€‚ Apacheé»˜è®¤å¼€å¯äº†é•¿è¿æ¥ï¼ŒæŒç»­æ—¶é—´ä¸º5ç§’ï¼Œåœ¨httpd-default.confä¸­å¯ä»¥å®šä¹‰ã€‚ 1234567vim /usr/local/apache/conf/extra/httpd-default.conf# å¼€å¯é•¿è¿æ¥KeepAlive On# é™åˆ¶æ¯ä¸ªè¿æ¥å…è®¸çš„è¯·æ±‚æ•°MaxKeepAliveRequests 500# é•¿è¿æ¥æ—¶é—´KeepAliveTimeout 5 1.6.2 é™æ€ç¼“å­˜ç”¨æˆ·æ¯æ¬¡è®¿é—®ç½‘ç«™éƒ½ä¼šå°†é¡µé¢ä¸­çš„æ‰€æœ‰å…ƒç´ éƒ½è¯·æ±‚ä¸€éï¼Œå…¨éƒ¨ä¸‹è½½åé€šè¿‡æµè§ˆå™¨æ¸²æŸ“ï¼Œå±•ç¤ºåˆ°æµè§ˆå™¨ä¸­ã€‚ä½†æ˜¯ï¼Œç½‘ç«™ä¸­çš„æŸäº›å…ƒç´ æˆ‘ä»¬ä¸€èˆ¬éƒ½æ˜¯å›ºå®šä¸å˜çš„ï¼Œæ¯”å¦‚logoã€æ¡†æ¶æ–‡ä»¶ç­‰ã€‚ç”¨æˆ·æ¯æ¬¡è®¿é—®éƒ½éœ€è¦åŠ è½½è¿™äº›å…ƒç´ ã€‚è¿™æ ·åšå¥½å¤„æ˜¯ä¿è¯äº†æ•°æ®çš„æ–°é²œï¼Œå¯æ˜¯è¿™äº›æ•°æ®ä¸æ˜¯å¸¸å˜åŒ–çš„ï¼Œå¾ˆä¹…æ‰å˜åŒ–ä¸€æ¬¡ã€‚æ¯æ¬¡éƒ½è¯·æ±‚ã€ä¸‹è½½æµªè´¹äº†ç”¨æˆ·æ—¶é—´å’Œå…¬å¸å¸¦å®½ã€‚ æ‰€ä»¥æˆ‘ä»¬é€šè¿‡é™æ€ç¼“å­˜çš„æ–¹å¼ï¼Œå°†è¿™äº›ä¸å¸¸å˜åŒ–çš„æ•°æ®ç¼“å­˜åˆ°ç”¨æˆ·æœ¬åœ°ç£ç›˜ï¼Œç”¨æˆ·ä»¥åå†è®¿é—®è¿™äº›è¯·æ±‚ï¼Œç›´æ¥ä»æœ¬åœ°ç£ç›˜æ‰“å¼€åŠ è½½ï¼Œè¿™æ ·çš„å¥½å¤„æ˜¯åŠ è½½é€Ÿåº¦å¿«ï¼Œä¸”èŠ‚çº¦å…¬å¸å¸¦å®½åŠæˆæœ¬ã€‚ åœ¨apacheä¸»é…æ–‡ä»¶ä¸­åŠ è½½ç¼“å­˜æ¨¡å— 12vim /usr/local/apache/conf/httpd.confLoadModule expires_module modules/mod_expires.so ä¿®æ”¹è™šæ‹Ÿä¸»æœºæ–‡ä»¶è°ƒç”¨æ¨¡å— 1234567891011121314151617181920vim /usr/local/apache/conf/extra/httpd-vhosts.conf&lt;VirtualHost *:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web&quot; &lt;IfMoudle expires_module&gt; #å¼€å¯ç¼“å­˜ ExpiresActive on #é’ˆå¯¹ä¸åŒç±»å‹å…ƒç´ è®¾ç½®ç¼“å­˜æ—¶é—´ ExpiresByType image/gif &quot;access plus 1 days&quot; ExpiresByType image/jpeg &quot;access plus 24 hours&quot; ExpiresByType image/png &quot;access plus 24 hours&quot; #now ç›¸å½“äº access ExpiresByType text/css &quot;now plus 2 hour&quot; ExpiresByType application/x-javascript &quot;now plus 2 hours&quot; ExpiresByType application/x-shockwave-flash &quot;now plus 2 hoursâ€ #å…¶ä»–æ•°æ®ä¸ç¼“å­˜ ExpiresDefault &quot;now plus 0 min&quot; &lt;/IfModule&gt; &lt;/VirtualHost&gt; 1.6.3 æ•°æ®å‹ç¼©æ•°æ®ä»æœåŠ¡å™¨ä¼ è¾“åˆ°å®¢æˆ·ç«¯ï¼Œéœ€è¦ä¼ è¾“æ—¶é—´ï¼Œæ–‡ä»¶è¶Šå¤§ä¼ è¾“æ—¶é—´å°±è¶Šé•¿ï¼Œä¸ºäº†å‡å°‘ä¼ è¾“æ—¶é—´ï¼Œæˆ‘ä»¬ä¸€èˆ¬æŠŠæ•°æ®å‹ç¼©ååœ¨ä¼ ç»™å®¢æˆ·ç«¯ã€‚ apacheæ”¯æŒä¸¤ç§æ¨¡å¼çš„å‹ç¼©ï¼š default gzip ä¸¤è€…çš„åŒºåˆ«ï¼š mod_deflate å‹ç¼©é€Ÿåº¦å¿«ã€‚ mod_gzip çš„å‹ç¼©æ¯”ç•¥é«˜ã€‚ ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œmod_gzip ä¼šæ¯” mod_deflate å¤šå‡º 4%~6ï¼… çš„å‹ç¼©é‡ã€‚ mod_gzip å¯¹æœåŠ¡å™¨CPUçš„å ç”¨è¦é«˜ä¸€äº›ï¼Œæ‰€ä»¥ mod_deflate æ˜¯ä¸“é—¨ä¸ºç¡®ä¿æœåŠ¡å™¨çš„æ€§èƒ½è€Œä½¿ç”¨çš„ä¸€ä¸ªå‹ç¼©æ¨¡å—ï¼Œåªéœ€è¾ƒå°‘çš„èµ„æºæ¥è¿›è¡Œå‹ç¼©ã€‚ åœ¨apacheä¸»é…æ–‡ä»¶ä¸­åŠ è½½å‹ç¼©æ¨¡å— 12vim /usr/local/apache/conf/httpd.confLoadModule deflate_module modules/mod_deflate.so ä¿®æ”¹è™šæ‹Ÿä¸»æœºæ–‡ä»¶è°ƒç”¨æ¨¡å— 12345678910111213141516171819vim /usr/local/apache/conf/extra/httpd-vhosts.conf&lt;VirtualHost *:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web&quot; &lt;IfMoudle deflate_module&gt; #å‹ç¼©ç­‰çº§1-9ï¼Œæ•°å­—è¶Šå¤§å‹ç¼©èƒ½åŠ›è¶Šå¥½ï¼Œç›¸åº”åœ°ä¹Ÿè¶Šè€—CPUæ€§èƒ½ DeflateCompressionLevel 4 #å‹ç¼©ç±»å‹ï¼Œhtmlã€xmlã€phpã€cssã€js AddOutputFilterByType DEFLATE text/html text/plain text/xml application/x-javascript application/x-httpd-php AddOutputFilter DEFLATE js css #æµè§ˆå™¨åŒ¹é…ä¸ºIE1-6çš„ä¸å‹ç¼© BrowserMatch \\bMSIE\\s[1-6] dont-vary #è®¾ç½®ä¸å‹ç¼©çš„æ–‡ä»¶ SetEnvIfNoCase Request_URI .(?:gif|jpe?g|png)$ no-gzip dont-vary SetEnvIfNoCase Request_URI .(?:exe|t?gz|zip|bz2|sit|rar)$ no-gzip dont-vary SetEnvIfNoCase Request_URI .(?:pdf|doc)$ no-gzip dont-vary &lt;/IfModule&gt; &lt;/VirtualHost&gt; 1.6.4 é™é€Ÿç½‘ç«™é™¤äº†èƒ½å…±äº«é¡µé¢ç»™ç”¨æˆ·å¤–ï¼Œè¿˜èƒ½ä½œä¸ºä¸‹è½½æœåŠ¡å™¨å­˜åœ¨ã€‚ä½†æ˜¯ä½œä¸ºä¸‹è½½æœåŠ¡å™¨æ—¶ï¼Œæˆ‘ä»¬åº”è¯¥è€ƒè™‘æœåŠ¡å™¨çš„å¸¦å®½å’ŒIOçš„æ€§èƒ½ï¼Œé˜²æ­¢éƒ¨åˆ†é‚ªæ¶åˆ†å­ä¼šé€šè¿‡å¤§é‡ä¸‹è½½çš„æ–¹å¼æ¥æ”»å‡»ä½ çš„å¸¦å®½å’ŒæœåŠ¡å™¨IOæ€§èƒ½ã€‚ é—®é¢˜ï¼š å‡å¦‚ä½ çš„æœåŠ¡å™¨è¢«é‚ªæ¶åˆ†å­é€šè¿‡ä¸‹è½½çš„æ–¹å¼æŠŠå¸¦å®½å æ»¡äº†ï¼Œé‚£ä¹ˆä½ æˆ–å…¶ä»–ç”¨æˆ·åœ¨è®¿é—®çš„æ—¶å€™å°±ä¼šé€ æˆè®¿é—®æ…¢æˆ–è€…æ ¹æœ¬æ— æ³•è®¿é—®ã€‚ å‡å¦‚ä½ çš„æœåŠ¡å™¨è¢«é‚ªæ¶åˆ†å­é€šè¿‡ä¸‹è½½çš„æ–¹å¼æŠŠæœåŠ¡å™¨IOå æ»¡äº†ï¼Œé‚£ä¹ˆä½ çš„æœåŠ¡å™¨å°†ä¼šæ— æ³•å¤„ç†ç”¨æˆ·è¯·æ±‚æˆ–å®•æœºã€‚ ä»¥ä¸Šé—®é¢˜å¯ä»¥é€šè¿‡é™é€Ÿæ¥è§£å†³ï¼Œapacheè‡ªå¸¦äº†åŸºäºå®½å¸¦é™é€Ÿçš„æ¨¡å—ï¼š ratelimit_moduleï¼šåªèƒ½å¯¹è¿æ¥ä¸‹è½½é€Ÿåº¦åšé™åˆ¶ï¼Œä¸”æ˜¯å•çº¿ç¨‹çš„ä¸‹è½½ï¼Œè¿…é›·ç­‰ä¸‹è½½å·¥å…·ä½¿ç”¨çš„æ˜¯å¤šçº¿ç¨‹ä¸‹è½½ã€‚ mod_limitipconnï¼šé™åˆ¶æ¯ IP çš„è¿æ¥æ•°ï¼Œéœ€è¦é¢å¤–å®‰è£…è¯¥æ¨¡å—ã€‚ ratelimit_moduleæ¨¡å— åœ¨apacheä¸»é…æ–‡ä»¶ä¸­åŠ è½½å‹ç¼©æ¨¡å— 12vim /usr/local/apache/conf/httpd.confLoadModule ratelimit_module modules/mod_ratelimit.so ä¿®æ”¹è™šæ‹Ÿä¸»æœºæ–‡ä»¶è°ƒç”¨æ¨¡å— 123456789101112vim /usr/local/apache/conf/extra/httpd-vhosts.conf&lt;VirtualHost *:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web&quot;&lt;/VirtualHost&gt;# Locationç›¸å¯¹è·¯å¾„ï¼š/usr/local/apache/htdocs/...# Directoryç»å¯¹è·¯å¾„ï¼š...&lt;Location /download&gt; SetOutputFiler RATE_LIMIT #é™é€Ÿ100k SetEnv rate-limit 100&lt;/Location&gt; mod_limitipconnæ¨¡å— ä¸‹è½½å®‰è£…æ¨¡å— 123456wget http://dominia.org/djao/limit/mod_limitipconn-0.24.tar.bz2tar -xf mod_limitipconn-0.24.tar.bz2cd mod_limitipconn-0.24vim Makefile apxs = &quot;/usr/local/apache/bin/apxs&quot;make &amp;&amp; make install åœ¨apacheä¸»é…æ–‡ä»¶å¯ç”¨æ¨¡å— 12vim /usr/local/apache/conf/httpd.confLoadModule limitipconn_module modules/mod_limitipconn.so ä¿®æ”¹è™šæ‹Ÿä¸»æœºæ–‡ä»¶è°ƒç”¨æ¨¡å— 123456789&lt;Location /download&gt; SetOutputFiler RATE_LIMIT #é™é€Ÿ100k SetEnv rate-limit 100 #é™åˆ¶çº¿ç¨‹æ•° MaxConnPerIP 3 #å¯¹index.htmlæ–‡ä»¶ä¸ä½œé™åˆ¶ NoIPLimit index.html&lt;/Location&gt; 1.6.5 è®¿é—®æ§åˆ¶åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œç½‘ç«™åˆ†ä¸ºå…¬ç«™å’Œç§ç«™ï¼Œå…¬ç«™å…è®¸æ‰€æœ‰äººè®¿é—®ï¼Œä½†ç§ç«™å°±åªå…è®¸å†…éƒ¨äººå‘˜è®¿é—®ï¼ŒRequireå°±å¯ä»¥å®ç°è®¿é—®æ§åˆ¶çš„åŠŸèƒ½ã€‚ å®¹å™¨ï¼š RequireAnyï¼šä¸€ä¸ªç¬¦åˆå³å¯é€šè¿‡ RequireAllï¼šæ‰€æœ‰ç¬¦åˆæ‰å¯é€šè¿‡ Requirenoneï¼šæ‰€æœ‰éƒ½ä¸ç¬¦åˆæ‰å¯é€šè¿‡ æ™®é€šçš„è®¿é—®æ§åˆ¶ ä¿®æ”¹è™šæ‹Ÿä¸»æœºæ–‡ä»¶ 1234567891011121314vim /usr/local/apache/conf/extra/httpd-vhosts.conf&lt;VirtualHost *:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web&quot;&lt;/VirtualHost&gt;&lt;Directory &quot;/usr/local/apache/htdocs/web/test&quot;&gt; AllowOverride None # æ‹’ç»æ‰€æœ‰äººè®¿é—® Require all denied # å…è®¸è¯¥åœ°å€æ®µçš„ç”¨æˆ·è®¿é—® Require ip 192.168.88 # å…è®¸è¯¥ä¸»æœºè®¿é—® Require host www.cqm.com&lt;/Directory&gt; ç”¨æˆ·ç™»å½•éªŒè¯è®¿é—®æ§åˆ¶ ä¿®æ”¹è™šæ‹Ÿä¸»æœºæ–‡ä»¶ 123456789101112131415161718192021vim /usr/local/apache/conf/extra/httpd-vhosts.conf&lt;VirtualHost *:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web&quot;&lt;/VirtualHost&gt;&lt;Directory &quot;/usr/local/apache/htdocs/web/test&quot;&gt; # å®šä¹‰æç¤ºä¿¡æ¯ï¼Œç”¨æˆ·è®¿é—®æ—¶æç¤ºä¿¡æ¯ä¼šå‡ºç°åœ¨è®¤è¯çš„å¯¹è¯æ¡†ä¸­ AuthName &quot;Private&quot; # å®šä¹‰è®¤è¯ç±»å‹ï¼Œåœ¨HTTP1.0ä¸­ï¼Œåªæœ‰ä¸€ç§è®¤è¯ç±»å‹ï¼šbasicã€‚åœ¨HTTP1.1ä¸­æœ‰å‡ ç§è®¤è¯ç±»å‹ï¼Œå¦‚ï¼šMD5 AuthType Basic # å®šä¹‰åŒ…å«ç”¨æˆ·åå’Œå¯†ç çš„æ–‡æœ¬æ–‡ä»¶ï¼Œæ¯è¡Œä¸€å¯¹ AuthUserFile &quot;/usr/local/apache/user.dbm&quot; # é…åˆå®¹å™¨ä½¿ç”¨ï¼Œåªæœ‰æ¡ä»¶å…¨éƒ¨ç¬¦åˆæ‰èƒ½é€šè¿‡ &lt;RequireAll&gt; Require not ip 192.168.88 # require user user1 user2 (åªæœ‰ç”¨æˆ·user1å’Œuser2å¯ä»¥è®¿é—®) # requires groups group1 (åªæœ‰group1ä¸­çš„æˆå‘˜å¯ä»¥è®¿é—®) # require valid-user (åœ¨AuthUserFileæŒ‡å®šçš„æ–‡ä»¶ä¸­çš„æ‰€æœ‰ç”¨æˆ·éƒ½å¯ä»¥è®¿é—®) Require valid-user &lt;/RequireAll&gt;&lt;/Directory&gt; ç”Ÿæˆç”¨æˆ·æ–‡ä»¶ 123# ç”Ÿæˆcqmç”¨æˆ·/usr/local/apache/bin/htpasswd -cm /usr/local/apache/user.dbm cqm... 1.6.6 URLé‡å†™Apacheé€šè¿‡mod_rewriteæ¨¡å—å¯ä»¥å®ç°URLé‡å†™çš„åŠŸèƒ½ï¼ŒURLé‡å†™å…¶å®å°±æ˜¯æ”¹å†™ç”¨æˆ·æµè§ˆå™¨ä¸­çš„URLåœ°å€ã€‚ åœ¨ä¸»é…æ–‡ä»¶å¼€å¯æ¨¡å— 12vim /usr/local/apache/conf/httpd.confLoadModule rewrite_module modules/mod_rewrite.so ä¿®æ”¹è™šæ‹Ÿä¸»æœºæ–‡ä»¶ 123456789101112131415161718192021222324vim /usr/local/apache/conf/extra/httpd-vhosts.conf&lt;VirtualHost *:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web&quot; # å¼€å¯URLé‡å†™åŠŸèƒ½ RewriteEngine on # é‡å†™è§„åˆ™ï¼Œè·³è½¬åˆ°ç™¾åº¦ RewriteRule &quot;^/$&quot; &quot;http://www.baidu.com&quot; [NC,L] # åŒ¹é…æ¡ä»¶ï¼Œæ ¹æ®è¯·æ±‚å¤´è¿›è¡ŒåŒ¹é… RewriteCond &quot;%{HTTP_USER_AGENT}&quot; &quot;chrome&quot; [NC,OR] RewriteCond &quot;%{HTTP_USER_AGENT}&quot; &quot;curl&quot; # é‡å†™è§„åˆ™ï¼Œå’ŒåŒ¹é…åˆ°çš„æ¡ä»¶é…åˆä½¿ç”¨ï¼Œè¯·æ±‚å¤´åŒ¹é…åˆ°chromeæˆ–curlåˆ™è¿”å›403çŠ¶æ€ç  RewriteRule &quot;^/$&quot; - [F]&lt;/VirtualHost&gt;RewreteRule [flag] éƒ¨åˆ†æ ‡è®°è§„åˆ™R:å¼ºåˆ¶å¤–éƒ¨é‡å®šå‘F:ç¦ç”¨URLï¼Œè¿”å›403HTTPçŠ¶æ€ç G:å¼ºåˆ¶URLä¸ºGONEï¼Œè¿”å›410HTTPçŠ¶æ€ç P:å¼ºåˆ¶ä½¿ç”¨ä»£ç†è½¬å‘L:è¡¨æ˜å½“å‰è§„åˆ™æ˜¯æœ€åä¸€æ¡è§„åˆ™ï¼Œåœæ­¢åˆ†æä»¥åè§„åˆ™çš„é‡å†™N:é‡æ–°ä»ç¬¬ä¸€æ¡è§„åˆ™å¼€å§‹è¿è¡Œé‡å†™è¿‡ç¨‹C:ä¸ä¸‹ä¸€æ¡è§„åˆ™å…³è”NS:åªç”¨äºä¸æ˜¯å†…éƒ¨å­è¯·æ±‚NC:ä¸åŒºåˆ†å¤§å°å†™ é€šè¿‡URLé‡å†™å®ç°åˆ†æµåŠŸèƒ½ 123456789vim /usr/local/apache/conf/extra/httpd-vhosts.conf&lt;VirtualHost *:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web&quot; RewriteEngine on RewriteCond &quot;%{HTTP_USER_AGENT}&quot; &quot;(chrome|curl)&quot; [NC,OR] RewriteRule &quot;^/$&quot; &quot;http://pc.cqm.com&quot; [NC] RewriteCond &quot;%{HTTP_USER_AGENT}&quot; &quot;(iPhone|Blackberry|Android|ipad)&quot; [NC] RewriteRule &quot;^/$&quot; &quot;http://phone.cqm.com&quot; [NC]&lt;/VirtualHost&gt; 1.6.7 å‹åŠ›æµ‹è¯•Apacheå‹åŠ›æµ‹è¯•ä½¿ç”¨abå‘½ä»¤ 123456789101112131415161718ab-A:æŒ‡å®šè¿æ¥æœåŠ¡å™¨çš„åŸºæœ¬çš„è®¤è¯å‡­æ®-c:æŒ‡å®šä¸€æ¬¡å‘æœåŠ¡å™¨å‘å‡ºè¯·æ±‚æ•°-C:æ·»åŠ cookie-g:å°†æµ‹è¯•ç»“æœè¾“å‡ºä¸ºâ€œgnuolotâ€æ–‡ä»¶-h:æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯-H:ä¸ºè¯·æ±‚è¿½åŠ ä¸€ä¸ªé¢å¤–çš„å¤´-i:ä½¿ç”¨â€œheadâ€è¯·æ±‚æ–¹å¼-k:æ¿€æ´»HTTPä¸­çš„â€œkeepAliveâ€ç‰¹æ€§-n:æŒ‡å®šæµ‹è¯•ä¼šè¯ä½¿ç”¨çš„è¯·æ±‚æ•°-p:æŒ‡å®šåŒ…å«æ•°æ®çš„æ–‡ä»¶-q:ä¸æ˜¾ç¤ºè¿›åº¦ç™¾åˆ†æ¯”-T:ä½¿ç”¨POSTæ•°æ®æ—¶ï¼Œè®¾ç½®å†…å®¹ç±»å‹å¤´-v:è®¾ç½®è¯¦ç»†æ¨¡å¼ç­‰çº§-w:ä»¥HTMLè¡¨æ ¼æ–¹å¼æ‰“å°ç»“æœ-x:ä»¥è¡¨æ ¼æ–¹å¼è¾“å‡ºæ—¶ï¼Œè®¾ç½®è¡¨æ ¼çš„å±æ€§-X:ä½¿ç”¨æŒ‡å®šçš„ä»£ç†æœåŠ¡å™¨å‘é€è¯·æ±‚-y:ä»¥è¡¨æ ¼æ–¹å¼è¾“å‡ºæ—¶ï¼Œè®¾ç½®è¡¨æ ¼å±æ€§ 123/usr/local/apache/bin/ab -n 10000 -c 200 http:...# å¹¶å‘æ•°per second... äºŒã€Nginx2.1 Nginxä»‹ç»Nginxæ˜¯ä¸€æ¬¾æ˜¯ç”±ä¿„ç½—æ–¯çš„ç¨‹åºè®¾è®¡å¸ˆIgor Sysoevæ‰€å¼€å‘é«˜æ€§èƒ½çš„ Webå’Œ åå‘ä»£ç†æœåŠ¡å™¨ï¼Œä¹Ÿæ˜¯ä¸€ä¸ª IMAP/POP3/SMTP ä»£ç†æœåŠ¡å™¨ã€‚å’Œapacheä¸€æ ·ï¼Œéƒ½æ˜¯webæœåŠ¡å™¨è½¯ä»¶ï¼Œå› ä¸ºå…¶æ€§èƒ½ä¼˜å¼‚ï¼Œæ‰€ä»¥è¢«å¹¿å¤§è¿ç»´å–œæ¬¢ã€‚åˆå› ä¸ºnginxæ˜¯ä¸€ä¸ªè½»é‡çº§çš„webæœåŠ¡å™¨ï¼Œç›¸æ¯”apacheæ¥è¯´èµ„æºæ¶ˆè€—æ›´ä½ã€‚ Nginxä¸­æ–‡æ–‡æ¡£ï¼šhttps://www.nginx.cn/doc/index.html 2.2 é€šè¿‡è„šæœ¬æºç å®‰è£…Nginx ç¼–å†™å®‰è£…è„šæœ¬ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576vim nginx-install.sh#!/bin/bashnginx_version=1.21.3#æ£€æµ‹function check(){ #æ£€æµ‹æ˜¯å¦ä¸ºroot if [ $USER != &quot;root&quot; ] then echo -e &quot;\\e[1;31m error:need to be root so that \\e[0m&quot; exit 1 fi #æ£€æµ‹wgetæ˜¯å¦å®‰è£… if [ ! -e /usr/bin/wget ] then echo -e &quot;\\e[1;31m error:not found command /usr/bin/wget \\e[0m&quot; exit 1 fi}#å®‰è£…å‰å‡†å¤‡function install_pre(){ # å®‰è£…ä¾èµ– #0:stdinæ ‡å‡†è¾“å…¥ 1:stdoutæ ‡å‡†è¾“å‡º 2:stderré”™è¯¯è¾“å‡º if [ ! `yum -y install gcc-* pcre-devel zlib-devel &amp;&gt; /dev/null` ] then echo -e &quot;\\e[1;31m error:yum install dependency package failed \\e[0m&quot; exit 1 fi #ä¸‹è½½æºç åŒ… cd /usr/local/ if [ ! `wget http://nginx.org/download/nginx-${nginx_version}.tar.gz &amp;&gt; /dev/null` ] then tar -xf nginx-${nginx_version}.tar.gz if [ ! -d nginx-${nginx_version} ] then echo -e &quot;\\e[1;31m error:not found nginx-${nginx_version} \\e[0m&quot; exit 1 fi else echo -e &quot;\\e[1;31m error:wget file nginx-${nginx_version}.tar.gz failed \\e[0m&quot; exit 1 fi}#å®‰è£…function install_nginx(){ cd /usr/local/nginx-${nginx_version} echo &quot;nginx configure...&quot; ./configure --prefix=/usr/local/nginx &amp;&gt; /dev/null if [ `echo $?` -eq 0 ] then echo &quot;nginx make...&quot; make &amp;&amp; make install &amp;&gt; /dev/null if [ `echo $?` -eq 0 ] then echo -e &quot;\\e[1;32m nginx install success \\e[0m&quot; else echo -e &quot;\\e[1;31m error:nginx install fail \\e[0m&quot; exit 1 fi else echo -e &quot;\\e[1;31m error:nginx configure fail \\e[0m&quot; exit 1 fi}checkinstall_preinstall_nginx ç¼–å†™å¯åŠ¨è„šæœ¬ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889#!/bin/bash#Source function libiaryif [ -f /etc/init.d/functions ]then . /etc/init.d/functionselse echo &quot;Not found file /etc/init.d/functions&quot; exitfinginxd=/usr/local/nginx/sbin/nginxnginx_pid=/usr/local/nginx/logs/nginx.pidfunction nginx_start(){ nginx_num=`ps -ef | grep nginx | wc -l` if [ $nginx_num -gt 1 ] &amp;&amp; [ -f $nginx_pid ] then echo -e &quot;nginx [\\e[1;32m running \\e[0m]&quot; exit 1 elif [ $nginx_num -eq 1 ] &amp;&amp; [ -f $nginx_pid ] then killall nginx fi $nginxd}function nginx_stop(){ nginx_num=`ps -ef | grep nginx | wc -l` if [ $nginx_num -eq 1 ] then echo -e &quot;nginx [\\e[1;31m stopping \\e[0m]&quot; exit 1 elif [ $nginx_num -gt 1 ] then killall nginx fi}function nginx_status(){ nginx_num=`ps -ef | grep nginx | wc -l` if [ $nginx_num -gt 1 ] &amp;&amp; [ -f $nginx_pid ] then echo -e &quot;nginx [\\e[1;32m running \\e[0m]&quot; else echo -e &quot;nginx [\\e[1;31m stopping \\e[0m]&quot; fi}function nginx_restart(){ nginx_stop nginx_start}function nginx_reload(){ nginx_num=`ps -ef | grep nginx | wc -l` if [ $nginx_num -gt 1 ] &amp;&amp; [ -f $nginx_pid ] then $nginxd -s reload else echo -e &quot;nginx [\\e[1;31m stopping \\e[0m]&quot; fi}case $1 instart) nginx_start echo -e &quot;nginx start [\\e[1;32m OK \\e[0m]&quot;;;stop) nginx_stop echo -e &quot;nginx stop [\\e[1;32m OK \\e[0m]&quot;;;status) nginx_status;;restart) nginx_restart echo -e &quot;nginx restart [\\e[1;32m OK \\e[0m]&quot;;;reload) nginx_reload echo -e &quot;nginx reload [\\e[1;32m OK \\e[0m]&quot;esac 2.3 Nginxçš„Serverå—å½“Nginxé…ç½®æ–‡ä»¶åªæœ‰ä¸€ä¸ªServerå—æ—¶ï¼Œé‚£ä¹ˆè¯¥Serverå—å°±è¢«Nginxè®¤ä¸ºæ˜¯é»˜è®¤ç½‘ç«™ï¼Œæ‰€æœ‰å‘ç»™Nginxçš„è¯·æ±‚éƒ½ä¼šä¼ ç»™è¯¥Serverå—ã€‚ 123456789101112131415161718192021222324252627server { # ç›‘å¬80ç«¯å£ listen 80; # åŸŸå server_name localhost; # å­—ç¬¦é›† charset koi8-r; # è®¿é—®æ—¥å¿—è·¯å¾„ access_log logs/host.access.log main; # webæ ¹è·¯å¾„ # /ä»£è¡¨ç›¸å¯¹è·¯åŠ²ï¼Œè¿™é‡Œä»£è¡¨/usr/local/nginx location / { # æ ¹ç›®å½•è·¯å¾„ï¼Œè¿™é‡Œä»£è¡¨/usr/local/nginx/html root html; # ç´¢å¼•é¡µ index index.html index.htm; } # 404çŠ¶æ€ç  error_page 404 /404.html; location = /404.html{ root html; } # 50xçŠ¶æ€ç  error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } 2.4 Nginxçš„è®¿é—®æ§åˆ¶ ç¼–å†™ä¸»é…æ–‡ä»¶ 12345678910111213location / { root html; index index.html index.htm; # å…è®¸192.168.88.0/24çš„ç”¨æˆ·è®¿é—® allow 192.168.88.0/24; # æ‹’ç»æ‰€æœ‰ deny all; # åŸºäºå®¢æˆ·ç«¯IPåšè¿‡æ»¤ï¼Œç¬¦åˆæ¡ä»¶çš„å…è®¸è®¿é—®ï¼Œä¸ç¬¦åˆçš„è¿”å›404 # è¿™é‡Œä¸ºä¸æ˜¯192.168.88çš„å°±è¿”å›404 if ( $remote_addr !~ &quot;192.168.88&quot; ){ return 404; }} 2.5 Nginxçš„ç”¨æˆ·éªŒè¯ ç¼–å†™ä¸»é…æ–‡ä»¶ 12345678location / { root html; index index.html index.htm; # æ¬¢è¿è¯ auth_basic &quot;welcome to cqm's web&quot;; # å­˜æ”¾ç”¨æˆ·æ–‡ä»¶ auth_basic_user_file /usr/local/nginx/htpasswd;} ç”Ÿæˆç”¨æˆ·æ–‡ä»¶ 1/usr/local/apache/bin/htpasswd -cm /usr/local/nginx/htpasswd cqm 2.6 Nginxå‚æ•°1234567891011# nginxä¸­çš„log_formatå¯ä»¥ç”¨æ¥è‡ªå®šä¹‰æ—¥å¿—æ ¼å¼# log_formatå˜é‡ï¼š$remote_addr:è®°å½•è®¿é—®ç½‘ç«™çš„å®¢æˆ·ç«¯åœ°å€$remote_user:è¿œç¨‹å®¢æˆ·ç«¯ç”¨æˆ·å$time_local:è®°å½•è®¿é—®æ—¶é—´ä¸æ—¶åŒº$request:ç”¨æˆ·çš„httpè¯·æ±‚èµ·å§‹è¡Œä¿¡æ¯$status:httpçŠ¶æ€ç ï¼Œè®°å½•è¯·æ±‚è¿”å›çš„çŠ¶æ€ç ï¼Œä¾‹å¦‚ï¼š200ã€301ã€404ç­‰$body_bytes_sent:æœåŠ¡å™¨å‘é€ç»™å®¢æˆ·ç«¯çš„å“åº”bodyå­—èŠ‚æ•°$http_referer:è®°å½•æ­¤æ¬¡è¯·æ±‚æ˜¯ä»å“ªä¸ªè¿æ¥è®¿é—®è¿‡æ¥çš„ï¼Œå¯ä»¥æ ¹æ®è¯¥å‚æ•°è¿›è¡Œé˜²ç›—é“¾è®¾ç½®ã€‚$http_user_agent:è®°å½•å®¢æˆ·ç«¯è®¿é—®ä¿¡æ¯ï¼Œä¾‹å¦‚ï¼šæµè§ˆå™¨ã€æ‰‹æœºå®¢æˆ·ç«¯ç­‰$http_x_forwarded_for:å½“å‰ç«¯æœ‰ä»£ç†æœåŠ¡å™¨æ—¶ï¼Œè®¾ç½®webèŠ‚ç‚¹è®°å½•å®¢æˆ·ç«¯åœ°å€çš„é…ç½®ï¼Œæ­¤å‚æ•°ç”Ÿæ•ˆçš„å‰ææ˜¯ä»£ç†æœåŠ¡å™¨ä¹Ÿè¦è¿›è¡Œç›¸å…³çš„x_forwarded_forè®¾ç½® 2.7 Nginxé˜²ç›—é“¾ç›—é“¾ç”¨å¤§ç™½è¯è®²å°±æ˜¯æŠ“å–åˆ«äººç½‘ç«™çš„èµ„æºï¼ŒåŠ ä»¥åˆ©ç”¨ï¼Œä»¥è‡³äºè¢«æŠ“å–èµ„æºçš„ç½‘ç«™æ¶ˆè€—äº†å¸¦å®½ï¼Œè€Œæ”¶ç›Šçš„æ˜¯æŠ“å–èµ„æºçš„äººã€‚ è€Œåç›—é“¾å°±å¯ä»¥é˜²æ­¢åˆ«äººæŠ“å–è‡ªèº«ç½‘ç«™çš„èµ„æºã€‚ ç¼–å†™ä¸»é…æ–‡ä»¶ 1234567location / { # é™¤äº†www.cqm.comä¹‹å¤–ï¼Œéƒ½è¿”å›403 valid_referers none blocked www.cqm.com; if ($invalid_referer){ return 403; }} 2.8 Nginxè™šæ‹Ÿä¸»æœºNginxçš„è™šæ‹Ÿä¸»æœºæ˜¯é€šè¿‡serverå—æ¥å®ç°çš„ã€‚ 2.8.1 åŸºäºIPçš„è™šæ‹Ÿä¸»æœº ä¿®æ”¹ä¸»é…æ–‡ä»¶ 12vim /usr/local/nginx/conf/nginx.confinclude /usr/local/nginx/conf/conf.d/nginx_vhosts.conf; ä¿®æ”¹è™šæ‹Ÿä¸»æœºæ–‡ä»¶ 12345678910111213141516vim /usr/local/nginx/conf/conf.d/nginx_vhosts.confserver { listen 192.168.88.100; location / { root html/web1; index index.html index.htm index.php; }}server { listen 192.168.88.101; location / { root html/web2; index index.html index.htm index.php; }} å…¶å®ƒé…ç½® 12345# æ·»åŠ ä¸€ä¸ªé€»è¾‘ç½‘å¡ï¼Œé‡å¯å³å¤±æ•ˆifconfig eth0:1 192.168.88.100/24 upmkdir /usr/local/nginx/html/web{1..2}echo 'this is web1' &gt; /usr/local/nginx/html/web1/index.htmlecho 'this is web2' &gt; /usr/local/nginx/html/web2/index.html æµ‹è¯• 1234curl http://192.168.88.100/this is web1curl http://192.168.88.101/this is web2 2.8.2 åŸºäºç«¯å£çš„è™šæ‹Ÿä¸»æœº ä¿®æ”¹è™šæ‹Ÿä¸»æœºæ–‡ä»¶ 12345678910111213141516vim /usr/local/nginx/conf/conf.d/nginx_vhosts.confserver { listen 80; location / { root html/web1; index index.html index.htm index.php; }}server { listen 81; location / { root html/web2; index index.html index.htm index.php; }} 2.8.3 åŸºäºåŸŸåçš„è™šæ‹Ÿä¸»æœº123456789101112131415161718vim /usr/local/nginx/conf/conf.d/nginx_vhosts.confserver { listen 80; server_name www.cqm1.com; location / { root html/web1; index index.html index.htm index.php; }}server { listen 80; server_name www.cqm2.com; location / { root html/web2; index index.html index.htm index.php; }} 2.9 Nginxåå‘ä»£ç†ä»£ç†æœ€å¸¸è§çš„ä½¿ç”¨æ–¹å¼å°±æ˜¯ç¿»å¢™ï¼Œèƒ½å¤Ÿå®ç°è®©å›½å†…çš„ç”¨æˆ·è®¿é—®å›½å¤–çš„ç½‘ç«™ã€‚ åŸç†ï¼š ç”¨æˆ·è®²è¯·æ±‚å‘ç»™ä»£ç†æœåŠ¡å™¨ ä»£ç†æœåŠ¡å™¨ä»£æ›¿ç”¨æˆ·å»è·å–æ•°æ® ä»£ç†æœåŠ¡å™¨å°†æ•°æ®å‘é€ç»™ç”¨æˆ· æ­£å¸¸æ²¡æœ‰ä»£ç†çš„ä¸Šç½‘ ä½¿ç”¨ä»£ç†æœåŠ¡å™¨çš„ä¸Šç½‘ = ä»£ç†æœåŠ¡å™¨åˆåˆ†ä¸ºä¸¤ç§ï¼šæ­£å‘ä»£ç†ã€åå‘ä»£ç† æ­£å‘ä»£ç†ï¼šä»£ç†ç”¨æˆ·å‘æœåŠ¡å™¨è·å–èµ„æº åå‘ä»£ç†ï¼šä»£ç†æœåŠ¡å™¨å»ç®¡ç†ç½‘ç»œèµ„æºï¼Œç”¨æˆ·æœ‰è¯·æ±‚æ‰¾åå‘ä»£ç†å°±å¯ä»¥äº† ç¼–å†™åå‘ä»£ç†æœåŠ¡å™¨ä¸»é…æ–‡ä»¶ 123456vim /usr/local/nginx/conf/nginx.conflocation / { index index.html index.htm index.php; # è®¿é—®ä»£ç†æœåŠ¡å™¨å°±ä¼šè·³è½¬åˆ°http://192.168.88.100 proxy_pass http://192.168.88.100;} åå‘ä»£ç†å…¶å®ƒé…ç½® 1234567891011121314151617181920212223proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;client_max_body_size 10m; #å…è®¸å®¢æˆ·ç«¯è¯·æ±‚çš„æœ€å¤§å•æ–‡ä»¶å­—èŠ‚æ•°client_body_buffer_size 128k; #ç¼“å†²åŒºä»£ç†ç¼“å†²ç”¨æˆ·ç«¯è¯·æ±‚çš„æœ€å¤§å­—èŠ‚æ•°ï¼Œproxy_connect_timeout 90; #nginxè·Ÿåç«¯æœåŠ¡å™¨è¿æ¥è¶…æ—¶æ—¶é—´(ä»£ç†è¿æ¥è¶…æ—¶)proxy_send_timeout 90; #åç«¯æœåŠ¡å™¨æ•°æ®å›ä¼ æ—¶é—´(ä»£ç†å‘é€è¶…æ—¶)proxy_read_timeout 90; #è¿æ¥æˆåŠŸåï¼Œåç«¯æœåŠ¡å™¨å“åº”æ—¶é—´(ä»£ç†æ¥æ”¶è¶…æ—¶)proxy_buffer_size 4k; #è®¾ç½®ä»£ç†æœåŠ¡å™¨ï¼ˆnginxï¼‰ä¿å­˜ç”¨æˆ·å¤´ä¿¡æ¯çš„ç¼“å†²åŒºå¤§å°proxy_buffers 4 32k; #proxy_buffersç¼“å†²åŒºï¼Œç½‘é¡µå¹³å‡åœ¨32kä»¥ä¸‹çš„è¯ï¼Œè¿™æ ·è®¾ç½®proxy_busy_buffers_size 64k; #é«˜è´Ÿè·ä¸‹ç¼“å†²å¤§å°ï¼ˆproxy_buffers*2ï¼‰proxy_temp_file_write_size 64k; #è®¾å®šç¼“å­˜æ–‡ä»¶å¤¹å¤§å°ï¼Œå¤§äºè¿™ä¸ªå€¼ï¼Œå°†ä»upstreamæœåŠ¡å™¨ä¼  2.10 Nginxä¸‹è½½é™é€Ÿé™é€Ÿæ–¹æ³•ä¸»è¦åˆ†ä¸ºï¼š ä¸‹è½½é€Ÿåº¦é™åˆ¶ å•ä½æ—¶é—´å†…è¯·æ±‚æ•°é™åˆ¶ åŸºäºå®¢æˆ·ç«¯çš„å¹¶å‘æ•°é™åˆ¶ Nginxå®˜æ–¹æä¾›çš„é™åˆ¶IPè¿æ¥å’Œå¹¶å‘çš„æ¨¡å—æœ‰ä¸¤ä¸ªï¼š limit_req_zoneï¼šç”¨æ¥é™åˆ¶å•ä½æ—¶é—´å†…çš„è¯·æ±‚æ•°ï¼Œå³é€Ÿç‡é™åˆ¶ï¼Œé‡‡ç”¨çš„æ¼æ¡¶ç®—æ³• limit_req_connï¼šæ¥é™åˆ¶åŒä¸€æ—¶é—´è¿æ¥æ•°ï¼Œå³å¹¶å‘é™åˆ¶ å•ä½æ—¶é—´å†…è¯·æ±‚æ•°é™åˆ¶ ä¿®æ”¹ä¸»é…æ–‡ä»¶ 12345678910111213# åœ¨httpå¿«ä¸‹è°ƒç”¨æ¨¡å—# $binary_remote_addr:åŸºäºipåœ°å€åšé™åˆ¶# zone:åˆ›å»ºç¼“å­˜åŸŸå’Œç¼“å­˜å¤§å°# rate:è®¾ç½®è®¿é—®é¢‘æ•°limit_req_zone $binary_remote_addr zone=cqm:10m rate=1r/s;# serverå—location /test { ... # è°ƒç”¨æ¨¡å— # å½“è¯·æ±‚æ•°è¶…è¿‡5æ¬¡æ—¶ï¼Œå°±æ‹’ç»è®¿é—®ï¼Œå¹¶è¿”å›503çŠ¶æ€ç  limit_req zone=cqm burst=5 nodelay;} é™åˆ¶å¹¶å‘è¿æ¥æ•° ä¿®æ”¹ä¸»é…æ–‡ä»¶ 1234567891011# åœ¨httpå¿«ä¸‹è°ƒç”¨æ¨¡å—# $binary_remote_addr:åŸºäºipåœ°å€åšé™åˆ¶# zone:åˆ›å»ºç¼“å­˜åŸŸå’Œç¼“å­˜å¤§å°limit_req_conn $binary_remote_addr zone=cqm:10m;# serverå—location /test { ... # é™åˆ¶åŒä¸€æ—¶é—´å†…ä¸‹è½½æ•°ä¸º1ä¸ª limit_conn cqm 1;} é™åˆ¶ä¸‹è½½é€Ÿåº¦ ä¿®æ”¹ä¸»é…æ–‡ä»¶ 12345location /test { ... # é™åˆ¶ä¸‹è½½é€Ÿåº¦ä¸º1k limit_rate 1k;} 2.11 Nginxçš„URLé‡å†™rewriteçš„ä¸»è¦åŠŸèƒ½æ˜¯å®ç°URLåœ°å€çš„é‡å®šå‘ã€‚Nginxçš„rewriteåŠŸèƒ½éœ€è¦PCREè½¯ä»¶çš„æ”¯æŒï¼Œå³é€šè¿‡perlå…¼å®¹æ­£åˆ™è¡¨è¾¾å¼è¯­å¥è¿›è¡Œè§„åˆ™åŒ¹é…çš„ã€‚é»˜è®¤å‚æ•°ç¼–è¯‘nginxå°±ä¼šæ”¯æŒrewriteçš„æ¨¡å—ï¼Œä½†æ˜¯ä¹Ÿå¿…é¡»è¦PCREçš„æ”¯æŒã€‚ URLæ¨¡æ¿è¯­å—ï¼š setï¼šè®¾ç½®å˜é‡ ifï¼šåˆ¤æ–­ returnï¼šè¿”å›å€¼æˆ–URL breakï¼šç»ˆæ­¢ rewriteï¼šé‡å®šå‘URL ä¾‹ä¸€ï¼šæ ¹æ®ä¸åŒåŸŸåè·³è½¬åˆ°ä¸»åŸŸåçš„ä¸åŒç›®å½•ä¸‹ åˆ›å»ºæµ‹è¯•ç›®å½• 1234mkdir /usr/local/nginx/html/{cn,jp,us}echo 'this is China' &gt; /usr/local/nginx/html/cn/index.htmlecho 'this is Japan' &gt; /usr/local/nginx/html/jp/index.htmlecho 'this is America' &gt; /usr/local/nginx/html/us/index.html ä¿®æ”¹hostsæ–‡ä»¶ï¼Œä»¥ä¾¿è§£æ 12345vim /etc/hosts192.168.88.100 www.cqm.com192.168.88.100 www.cqm.com.cn192.168.88.100 www.cqm.com.jp192.168.88.100 www.cqm.com.us ä¿®æ”¹ä¸»é…æ–‡ä»¶ 1include /usr/local/nginx/conf/conf.d/rewrite.conf ä¿®æ”¹é‡å®šå‘æ–‡ä»¶ 1234567891011121314151617181920212223242526272829vim /usr/local/nginx/conf/conf.d/rewrite.conf# è®¾ç½®é‡å®šå‘serverserver { listen 80; server_name www.cqm.com.cn www.cqm.com.jp www.cqm.com.us; location / { # æ¨¡ç³ŠåŒ¹é…åˆ°cnçš„è¯ï¼Œå°±è·³è½¬åˆ°http://www.cqm.com/cnä¸‹ if ($http_host ~ (cn)$){ set $nation cn; rewrite ^/$ http://www.cqm.com/$nation; } if ($http_host ~ (jp)$){ set $nation jp; rewrite ^/$ http://www.cqm.com/$nation; } if ($http_host ~ (us)$){ set $nation us; rewrite ^/$ http://www.cqm.com/$nation; } }}server { listen 80; server_name www.cqm.com; location / { root html; index index.html; }} æµ‹è¯• 1234567curl -L http://www.cqm.com.cnthis is Chinacurl -L http://www.cqm.com.jpthis is Japancurl -L http://www.cqm.com.usthis is America-L:è‡ªåŠ¨è·å–é‡å®šå‘ ä¾‹äºŒï¼šretuenä»¥åŠbreakçš„ç®€å•å®ç”¨ ä¿®æ”¹é‡å®šå‘æ–‡ä»¶ 12345678910111213141516171819vim /usr/local/nginx/conf/conf.d/rewrite.confserver { listen 80; server_name www.cqm.com; location / { root html; index index.html; # æ¨¡ç³ŠåŒ¹é… ~ # ç²¾ç¡®åŒ¹é… = # ä¸åŒ¹é… !~ # å¦‚æœåŒ¹é…è¯·æ±‚å¤´ä¸æ˜¯chromeçš„è¯ï¼Œå°±è¿”å›403 if ($http_user_agent !~ 'chrome'){ return 403; # breakæ”¾åœ¨returnä¸Šé¢çš„è¯å°±ä¸ä¼šæ‰§è¡Œreturnæ“ä½œ # break; # return http://www.baidu.com; } }} flag flagæ˜¯æ”¾åœ¨rewriteé‡å®šå‘çš„URLåè¾¹çš„ï¼Œæ ¼å¼ä¸ºï¼šrewrite URL flag flagçš„é€‰é¡¹æœ‰ï¼š lastï¼šæœ¬æ¡è§„åˆ™åŒ¹é…å®Œæˆåç»§ç»­æ‰§è¡Œåˆ°æœ€åã€‚ breakï¼šæœ¬æ¡è§„åˆ™åŒ¹é…å®Œæˆå³ç»ˆæ­¢ã€‚ redirectï¼šè¿”å›302ä¸´æ—¶é‡å®šå‘ã€‚ permanentï¼šè¿”å›301æ°¸ä¹…é‡å®šå‘ã€‚ redirectå’Œpermanentçš„åŒºåˆ«ï¼šè®¾ç½®permanentçš„è¯ï¼Œæ–°ç½‘å€å°±ä¼šå®Œå…¨ç»§æ‰¿æ—§ç½‘å€ï¼Œæ—§ç½‘å€çš„æ’åç­‰å®Œå…¨æ¸…é›¶ï¼Œå¦‚æœä¸æ˜¯æš‚æ—¶è¿ç§»çš„æƒ…å†µä¸‹éƒ½å»ºè®®ä½¿ç”¨permanentï¼›è®¾ç½®redirectçš„è¯ï¼Œæ–°ç½‘å€å¯¹æ—§ç½‘å€æ²¡æœ‰å½±å“ï¼Œä¸”æ–°ç½‘å€ä¹Ÿä¸ä¼šæœ‰æ’åã€‚ 2.12 Nginxä¼˜åŒ–2.12.1 å¤§å¹¶å‘Nginxçš„å·¥ä½œæ¨¡å¼ï¼šä¸»è¿›ç¨‹ + å·¥ä½œè¿›ç¨‹ å‡å¦‚NginxæœåŠ¡å™¨æœ‰4ä¸ªCPU è®¾ç½®ä¸»é…æ–‡ä»¶æ¥å®ç°é«˜å¹¶å‘ 12345678vim /usr/local/nginx/conf/nginx.confworker_processes 4;# æŒ‡å®šè¿è¡Œçš„æ ¸çš„ç¼–å·ï¼Œé‡‡ç”¨æ©ç çš„æ–¹å¼è®¾ç½®ç¼–å·worker_cpu_affinity 0001 0010 0100 1000;events { # å•ä¸ªå·¥ä½œè¿›ç¨‹ç»´æŠ¤çš„è¯·æ±‚é˜Ÿåˆ—é•¿åº¦ï¼Œæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ worker_connections 1024;} 2.12.2 é•¿è¿æ¥ ä¿®æ”¹ä¸»é…æ–‡ä»¶ 1234567vim /usr/local/nginx/conf/nginx.conf# keepalive_timeoutç”¨æ¥è®¾ç½®é•¿è¿æ¥ï¼Œ0ä»£è¡¨å…³é—­keepalive_timeout 0;# è®¾ç½®é•¿è¿æ¥æ—¶é—´100s#keepalive_timeout 100;# è®¾ç½®æ¯ç§’å¯ä»¥æ¥å—çš„è¯·æ±‚æ•°#keepalive_requests 8192; 2.12.3 å‹ç¼©Nginxæ˜¯é‡‡ç”¨gzipè¿›è¡Œå‹ç¼©ã€‚ ä¿®æ”¹ä¸»é…æ–‡ä»¶ 1234567891011121314151617181920212223242526272829303132vim /usr/local/nginx/conf/nginx.conf# å¼€å¯ç¼“å­˜gzip on;# Nginxåšä¸ºåå‘ä»£ç†çš„æ—¶å€™å¯ç”¨# off:å…³é—­æ‰€æœ‰çš„ä»£ç†ç»“æœæ•°æ®å‹ç¼©# expired:å¦‚æœheaderä¸­åŒ…å«â€Expiresâ€å¤´ä¿¡æ¯ï¼Œå¯ç”¨å‹ç¼©# no-cache:å¦‚æœheaderä¸­åŒ…å«â€Cache-Control:no-cacheâ€å¤´ä¿¡æ¯ï¼Œå¯ç”¨å‹ç¼©# no-store:å¦‚æœheaderä¸­åŒ…å«â€Cache-Control:no-storeâ€å¤´ä¿¡æ¯ï¼Œå¯ç”¨å‹ç¼©# private:å¦‚æœheaderä¸­åŒ…å«â€Cache-Control:privateâ€å¤´ä¿¡æ¯ï¼Œå¯ç”¨å‹ç¼©# no_last_modified:å¯ç”¨å‹ç¼©ï¼Œå¦‚æœheaderä¸­åŒ…å«â€Last_Modifiedâ€å¤´ä¿¡æ¯ï¼Œå¯ç”¨å‹ç¼©# no_etag:å¯ç”¨å‹ç¼©ï¼Œå¦‚æœheaderä¸­åŒ…å«â€œETagâ€å¤´ä¿¡æ¯ï¼Œå¯ç”¨å‹ç¼©# auth:å¯ç”¨å‹ç¼©ï¼Œå¦‚æœheaderä¸­åŒ…å«â€œAuthorizationâ€å¤´ä¿¡æ¯ï¼Œå¯ç”¨å‹ç¼©# any:æ— æ¡ä»¶å‹ç¼©æ‰€æœ‰ç»“æœæ•°æ®gzip_proxied any;# å¯ç”¨gzipå‹ç¼©çš„æœ€å°æ–‡ä»¶ï¼Œå°äºè®¾ç½®å€¼çš„æ–‡ä»¶å°†ä¸ä¼šå‹ç¼©gzip_min_length 1k;# è®¾ç½®å‹ç¼©æ‰€éœ€è¦çš„ç¼“å†²åŒºå¤§å°# 32 4Kè¡¨ç¤ºæŒ‰ç…§å†…å­˜é¡µï¼ˆone memory pageï¼‰å¤§å°ä»¥4Kä¸ºå•ä½ï¼ˆå³ä¸€ä¸ªç³»ç»Ÿä¸­å†…å­˜é¡µä¸º4Kï¼‰ï¼Œç”³è¯·32å€çš„å†…å­˜ç©ºé—´# å»ºè®®æ­¤é¡¹ä¸è®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼gzip_buffers 32 4k;# è®¾ç½®gzipå‹ç¼©çº§åˆ«ï¼Œçº§åˆ«è¶Šåº•å‹ç¼©é€Ÿåº¦è¶Šå¿«æ–‡ä»¶å‹ç¼©æ¯”è¶Šå°ï¼Œåä¹‹é€Ÿåº¦è¶Šæ…¢æ–‡ä»¶å‹ç¼©æ¯”è¶Šå¤§gzip_comp_level 1;# ç”¨äºè¯†åˆ«httpåè®®çš„ç‰ˆæœ¬ï¼Œæ—©æœŸçš„æµè§ˆå™¨ä¸æ”¯æŒgzipå‹ç¼©ï¼Œç”¨æˆ·ä¼šçœ‹åˆ°ä¹±ç ï¼Œæ‰€ä»¥ä¸ºäº†æ”¯æŒå‰æœŸç‰ˆæœ¬åŠ äº†æ­¤é€‰é¡¹ã€‚é»˜è®¤åœ¨http/1.0çš„åè®®ä¸‹ä¸å¼€å¯gzipå‹ç¼©gzip_http_version 1.1;# è®¾ç½®éœ€è¦å‹ç¼©çš„MIMEç±»å‹,å¦‚æœä¸åœ¨è®¾ç½®ç±»å‹èŒƒå›´å†…çš„è¯·æ±‚ä¸è¿›è¡Œå‹ç¼©gzip_types text/plain application/javascript application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png application/vnd.ms-fontobject font/ttf font/opentype font/x-woff image/svg+xml; 2.12.4 é™æ€ç¼“å­˜å°†éƒ¨åˆ†æ•°æ®ç¼“å­˜åœ¨ç”¨æˆ·æœ¬åœ°ç£ç›˜ï¼Œç”¨æˆ·åŠ è½½æ—¶ï¼Œå¦‚æœæœ¬åœ°å’ŒæœåŠ¡å™¨çš„æ•°æ®ä¸€è‡´ï¼Œåˆ™ä»æœ¬åœ°åŠ è½½ã€‚æå‡ç”¨æˆ·è®¿é—®é€Ÿåº¦ï¼Œæå‡ä½“éªŒåº¦ã€‚èŠ‚çœå…¬å¸å¸¦å®½æˆæœ¬ã€‚ ä¿®æ”¹ä¸»é…æ–‡ä»¶ 12345# æ¨¡ç³ŠåŒ¹é…ä»¥pngæˆ–gifç»“å°¾çš„æ–‡ä»¶location ~* \\.(png|gif)$ { # ç¼“å­˜æ—¶é—´ä¸º1å°æ—¶ expires 1h;} ä¸‰ã€Tomcat3.1 Tomcatä»‹ç»Tomcat æœåŠ¡å™¨æ˜¯ä¸€ä¸ªå…è´¹çš„å¼€æ”¾æºä»£ç çš„ Web åº”ç”¨æœåŠ¡å™¨ï¼Œå±äºè½»é‡çº§åº”ç”¨æœåŠ¡å™¨ï¼Œåœ¨ä¸­å°å‹ç³»ç»Ÿå’Œå¹¶å‘è®¿é—®ç”¨æˆ·ä¸æ˜¯å¾ˆå¤šçš„åœºåˆä¸‹è¢«æ™®éä½¿ç”¨ï¼Œæ˜¯å¼€å‘å’Œè°ƒè¯• JSP ç¨‹åºçš„é¦–é€‰ã€‚ å®é™…ä¸Š Tomcat æ˜¯ Apache æœåŠ¡å™¨çš„æ‰©å±•ï¼Œä½†è¿è¡Œæ—¶å®ƒæ˜¯ç‹¬ç«‹è¿è¡Œçš„ï¼Œæ‰€ä»¥å½“ä½ è¿è¡Œ tomcat æ—¶ï¼Œå®ƒå®é™…ä¸Šä½œä¸ºä¸€ä¸ªä¸ Apache ç‹¬ç«‹çš„è¿›ç¨‹å•ç‹¬è¿è¡Œçš„ã€‚ Tomcat å®˜æ–¹æ–‡æ¡£ï¼šhttps://tomcat.apache.org/ 3.2 Tomcatå®‰è£… å®‰è£…jdkå’Œtomcat 123456yum -y install java-1.8.0-openjdk*wget https://downloads.apache.org/tomcat/tomcat-9/v9.0.43/bin/apache-tomcat-9.0.43.tar.gztar -xf apache-tomcat-9.0.43.tar.gzmkdir /root/tomcatmv apache-tomcat-9.0.43.tar.gz/* /root/tomcat./root/tomcat/bin/startup.sh","link":"/2024/02/18/web/"},{"title":"ä½¿ç”¨ Istio å®ç°åº”ç”¨è¿ç§»","text":"èƒŒæ™¯ï¼šå½“å‰ç¯å¢ƒä¸­æœ‰ Cluster A å’Œ Cluster Bï¼Œå„è‡ªéƒ¨ç½²äº†ç›¸åŒçš„åº”ç”¨ï¼Œä¸”è¯¥åº”ç”¨æœ‰ä¸¤ä¸ªåŸŸåç”¨äºå¤„ç†ä¸åŒçš„è¯·æ±‚ã€‚ç›®å‰ï¼Œè¿™ä¸¤ä¸ªåŸŸåçš„è¯·æ±‚éƒ½ç”± Cluster A ä¸­çš„åº”ç”¨å¤„ç†ã€‚ä¸ºè¿›è¡Œåº”ç”¨è¿ç§»ï¼Œç°å¸Œæœ›å°†åŸŸå A çš„è¯·æ±‚ç»§ç»­ç”± Cluster A å¤„ç†ï¼Œè€ŒåŸŸå B çš„è¯·æ±‚åˆ™åˆ‡æ¢è‡³ç”± Cluster B ä¸­çš„åº”ç”¨æ¥å¤„ç†ã€‚ ç”±äºç›®å‰çš„æµé‡å¤„ç†éƒ½æ˜¯ç”± Istio è´Ÿè´£ï¼Œæ‰€ä»¥å¯ä»¥é€šè¿‡ ServiceEntry æ¥å®ç°æ­¤éœ€æ±‚ã€‚ åˆ›å»ºä¸€ä¸ª ServiceEntryï¼š å°† b.nginx.com çš„æµé‡è½¬å‘åˆ° Cluster B çš„ Istio Ingress Gatewayï¼Œç„¶åå†é€šè¿‡ Cluster B çš„ VirtualService å°†æµé‡è½¬å‘åˆ° Cluster B ä¸­çš„åº”ç”¨ã€‚ 1234567891011121314151617181920apiVersion: networking.istio.io/v1beta1kind: ServiceEntrymetadata: name: external-nginx namespace: defaultspec: addresses: {} endpoints: # æ­¤å¤„ä¸º Cluster B çš„ Istio Ingress Gateway çš„åœ°å€å’Œç«¯å£ - address: 172.16.0.104 ports: http: 80 hosts: - b.nginx.com location: MESH_EXTERNAL ports: - name: http number: 80 protocol: HTTP resolution: DNS ä¿®æ”¹åŸæœ‰çš„ VirtualService ä¸­å¤„ç†åŸŸå B æµé‡çš„éƒ¨ä»½ï¼š 12345678910111213141516171819202122232425262728293031apiVersion: networking.istio.io/v1beta1kind: VirtualServicemetadata: name: nginx-virtualservice namespace: defaultspec: gateways: - http-gateway.istio-system.svc.cluster.local hosts: - a.nginx.com - b.nginx.com http: - match: - headers: host: exact: a.nginx.com route: - destination: host: nginx.default.svc.cluster.local port: number: 80 - match: - headers: host: exact: b.nginx.com route: - destination: # æ­¤å¤„åŸæœ¬ä¸º nginx.default.svc.cluster.localï¼Œå¦‚æœè¦åšè¿ç§»å°†å…¶ä¿®æ”¹ä¸º b.nginx.com å³å¯ host: b.nginx.com port: number: 80 å°è¯•è¯·æ±‚æŸ¥çœ‹æ•ˆæœï¼š","link":"/2024/11/11/%E4%BD%BF%E7%94%A8-Istio-%E5%AE%9E%E7%8E%B0%E5%BA%94%E7%94%A8%E8%BF%81%E7%A7%BB/"},{"title":"ä½¿ç”¨ä»£ç†è·å–é•œåƒ","text":"ç”±äºå›½å†…ç½‘ç»œå—é™ï¼Œå»åˆ° Docker Hub ç­‰è·å–é•œåƒéƒ½ä¼šéå¸¸ç¼“æ…¢ï¼ˆç”šè‡³å¤±è´¥ï¼‰ï¼Œå¦‚æœæœ‰æ¢¯å­ï¼Œå¯ä»¥é€šè¿‡ä»£ç†è·å–ï¼Œæ­¤å¤„ä½¿ç”¨ Clash ä½œä¸ºä»£ç†ç»„ä»¶ã€‚ Docker é…ç½®ä»£ç†åœ¨èŠ‚ç‚¹ä¸Šå‡†å¤‡ Clash é…ç½®æ–‡ä»¶ï¼š 12# å°†æ¢¯å­çš„ .yaml é…ç½®æ–‡ä»¶æ”¾åœ¨æ­¤å¤„mkdir /root/clash å¯åŠ¨ Clash å®¹å™¨ï¼š 1docker run -d --restart=unless-stopped --name clash -v /root/clash/xxx.yaml:/root/.config/clash/config.yaml:ro -p 9090:9090 -p 7890:7890 -p 7891:7891 harbor.warnerchen.com/dreamacro/clash:v1.18.0 éªŒè¯æ˜¯å¦å¯ç”¨ï¼š 1curl -x http://localhost:7890 https://www.google.com -I åˆ›å»º systemd é…ç½®æ–‡ä»¶ï¼š 123456cat &lt;&lt;EOF &gt; /etc/systemd/system/docker.service.d/http-proxy.conf[Service]Environment=&quot;HTTP_PROXY=http://127.0.0.1:7890&quot;Environment=&quot;HTTPS_PROXY=http://127.0.0.1:7890&quot;Environment=&quot;NO_PROXY=localhost,127.0.0.0/8,harbor.warnerchen.com,registry.rancher.com,registry.rancher.cn,registry.cn-hangzhou.aliyuncs.com&quot;EOF é‡å¯ Dockerï¼š 123systemctl daemon-reloadsystemctl show --property Environment dockersystemctl restart docker éªŒè¯æ˜¯å¦å¯ç”¨ï¼š 1docker pull nginx:mainline","link":"/2025/02/24/%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%90%86%E8%8E%B7%E5%8F%96%E9%95%9C%E5%83%8F/"},{"title":"SUSE Observability ä½¿ç”¨éšè®°","text":"SUSE Observabilityï¼ˆå‰èº«ä¸º StackStateï¼‰å¯ç”¨äºè§‚å¯Ÿ Kubernetes é›†ç¾¤åŠå…¶å·¥ä½œè´Ÿè½½ã€‚ SUSE Observability ä¸»è¦åˆ†ä¸º Server å’Œ Agent ä¸¤ä¸ªéƒ¨åˆ†ï¼ŒServer è´Ÿè´£å­˜å‚¨å’Œå±•ç¤ºæ•°æ®ï¼ŒAgent è´Ÿè´£é‡‡é›†æ•°æ®å¹¶å‘é€ç»™ Serverã€‚ Server çš„ç»„ä»¶æœ‰ï¼š Topology (StackGraph) Metrics (VictoriaMetrics) Traces (ClickHouse) Logs (ElasticSearch) éƒ¨ç½² SUSE ObservabilityåŸºäº Rancher Prime çš„ SUSE Observability éƒ¨ç½²æ–‡æ¡£ helm template çš„å‘½ä»¤ä¼šç”Ÿæˆä¸¤ä¸ª values æ–‡ä»¶ï¼ŒbaseConfig_values.yaml é…ç½® license ç­‰ä¿¡æ¯ï¼Œsizing_values.yaml é…ç½®é›†ç¾¤è§„æ¨¡ç­‰ä¿¡æ¯ï¼š 1234567891011helm repo add suse-observability https://charts.rancher.com/server-charts/prime/suse-observabilityhelm repo updatekubectl create namespace suse-observabilityexport VALUES_DIR=.helm template \\ --set license='xxx' \\ --set baseUrl='https://suse-observability.warnerchen.com' \\ --set sizing.profile='trial' \\ suse-observability-values \\ suse-observability/suse-observability-values --output-dir $VALUES_DIR å®‰è£…å‰ï¼Œåˆ›å»º ingress_values.yamlã€ingress_otel_values.yaml ä¸­æ·»åŠ  Ingress é…ç½®ï¼š 12345678910111213cat &lt;&lt;EOF &gt; $VALUES_DIR/suse-observability-values/templates/ingress_values.yamlingress: enabled: true annotations: nginx.ingress.kubernetes.io/proxy-body-size: &quot;50m&quot; hosts: - host: suse-observability.warnerchen.com tls: # æ­¤å¤„è¯ä¹¦åªèƒ½ä½¿ç”¨æƒå¨è¯ä¹¦ - secretName: tls-secret hosts: - suse-observability.warnerchen.comEOF 12345678910111213141516171819202122232425262728293031323334cat &lt;&lt;EOF &gt; $VALUES_DIR/suse-observability-values/templates/ingress_otel_values.yamlopentelemetry-collector: ingress: enabled: true annotations: nginx.ingress.kubernetes.io/proxy-body-size: &quot;50m&quot; nginx.ingress.kubernetes.io/backend-protocol: GRPC cert-manager.io/cluster-issuer: suse-observability-otlp-selfsigned-cluster-issuer hosts: - host: suse-observability-otlp.warnerchen.com paths: - path: / pathType: Prefix port: 4317 tls: - hosts: - suse-observability-otlp.warnerchen.com secretName: suse-observability-otlp-tls-secret additionalIngresses: - name: otlp-http annotations: nginx.ingress.kubernetes.io/proxy-body-size: &quot;50m&quot; cert-manager.io/cluster-issuer: suse-observability-otlp-selfsigned-cluster-issuer hosts: - host: suse-observability-otlp-http.warnerchen.com paths: - path: / pathType: Prefix port: 4318 tls: - hosts: - suse-observability-otlp-http.warnerchen.com secretName: suse-observability-otlp-tls-secretEOF é€šè¿‡ Cert Manager åˆ›å»ºè‡ªç­¾åè¯ä¹¦ç»™ Otlp Ingress ä½¿ç”¨ï¼š 1234567891011121314151617181920212223242526272829cat &lt;&lt;EOF | kubectl apply -f -apiVersion: cert-manager.io/v1kind: ClusterIssuermetadata: name: suse-observability-otlp-selfsigned-cluster-issuerspec: selfSigned: {}---apiVersion: cert-manager.io/v1kind: Certificatemetadata: name: suse-observability-otlp-tls namespace: suse-observabilityspec: secretName: suse-observability-otlp-tls-secret issuerRef: name: suse-observability-otlp-selfsigned-cluster-issuer kind: ClusterIssuer commonName: suse-observability-otlp.warnerchen.com dnsNames: - suse-observability-otlp.warnerchen.com - suse-observability-otlp-http.warnerchen.com duration: 8760h renewBefore: 720h privateKey: algorithm: RSA size: 2048EOF æ‰§è¡Œå®‰è£…ï¼š 12345678helm upgrade \\ --install \\ --namespace suse-observability \\ --values $VALUES_DIR/suse-observability-values/templates/baseConfig_values.yaml \\ --values $VALUES_DIR/suse-observability-values/templates/sizing_values.yaml \\ --values $VALUES_DIR/suse-observability-values/templates/ingress_values.yaml \\ --values $VALUES_DIR/suse-observability-values/templates/ingress_otel_values.yaml \\ suse-observability suse-observability/suse-observability ç­‰å¾…æ‰€æœ‰ Pod è¿è¡Œå®Œæ¯•ï¼š é€šè¿‡ Service suse-observability-router / Ingress è®¿é—® SUSE Observability UIï¼š éƒ¨ç½² SUSE Observability Agentè¢«ç›‘æ§é›†ç¾¤éœ€è¦éƒ¨ç½² Agent æ‰èƒ½å¤Ÿè¿›è¡Œç›‘æ§ã€‚ åœ¨ StackPacks é€‰æ‹© Kubernetesï¼Œç„¶åå¡«å…¥é›†ç¾¤åç§°ï¼š ç‚¹å‡» Install åï¼Œä¼šæä¾›å®‰è£…å‘½ä»¤ï¼š åœ¨è¢«ç›‘æ§é›†ç¾¤æ‰§è¡Œå®‰è£…ï¼š 123456789helm upgrade --install \\--namespace suse-observability \\--create-namespace \\--set-string 'stackstate.apiKey'='xxx' \\--set-string 'stackstate.cluster.name'='test' \\--set-string 'stackstate.url'='https://suse-observability.warnerchen.com/receiver/stsAgent' \\--set-string 'global.skipSslValidation'='true' \\--set-string 'global.imageRegistry'='harbor.warnerchen.com' \\suse-observability-agent suse-observability/suse-observability-agent ç­‰å¾…æ‰€æœ‰ Pod æ­£å¸¸è¿è¡Œï¼š æ”¶é›† Logs/Metrics/Events æ•°æ®éƒ¨ç½² SUSE Observability Agent åå³å¯æŸ¥çœ‹ç›¸å…³æ•°æ®ã€‚ Pod çš„æŒ‡æ ‡ï¼š Pod çš„è¯¦ç»†ç›‘æ§ä¿¡æ¯ï¼š Pod çš„äº‹ä»¶ï¼š Pod çš„æ—¥å¿—ï¼š æ”¶é›† Traces æ•°æ®é€šè¿‡ Helm Chart éƒ¨ç½² OpenTelemetry Collectoræ”¶é›†è¢«ç›‘æ§é›†ç¾¤çš„ Traces æ•°æ®ï¼Œè¿˜éœ€è¦éƒ¨ç½² OpenTelemetry Collectorã€‚ å‡†å¤‡ values.yamlï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110cat &lt;&lt;EOF &gt; otel-collector.yamlextraEnvsFrom: - secretRef: name: open-telemetry-collectormode: deploymentimage: repository: &quot;harbor.warnerchen.com/otel/opentelemetry-collector-k8s&quot;ports: metrics: enabled: truepresets: kubernetesAttributes: enabled: true extractAllPodLabels: trueconfig: extensions: bearertokenauth: scheme: SUSEObservability # ä¿®æ”¹ä¸ºå®é™…çš„ API Key token: &quot;xxx&quot; exporters: otlp/stackstate: auth: authenticator: bearertokenauth # ä¿®æ”¹ä¸ºå®é™…çš„ SUSE O11y Server é›†ç¾¤çš„ otlp ingress host endpoint: suse-observability-otlp.warnerchen.com:443 tls: insecure_skip_verify: true otlphttp/stackstate: auth: authenticator: bearertokenauth # ä¿®æ”¹ä¸ºå®é™…çš„ SUSE O11y Server é›†ç¾¤çš„ otlp http ingress host endpoint: https://suse-observability-otlp-http.warnerchen.com tls: insecure_skip_verify: true processors: tail_sampling: decision_wait: 10s policies: - name: rate-limited-composite type: composite composite: max_total_spans_per_second: 500 policy_order: [errors, slow-traces, rest] composite_sub_policy: - name: errors type: status_code status_code: status_codes: [ ERROR ] - name: slow-traces type: latency latency: threshold_ms: 1000 - name: rest type: always_sample rate_allocation: - policy: errors percent: 33 - policy: slow-traces percent: 33 - policy: rest percent: 34 resource: attributes: - key: k8s.cluster.name action: upsert # ä¿®æ”¹ä¸ºå®é™…çš„é›†ç¾¤åç§° value: test - key: service.instance.id from_attribute: k8s.pod.uid action: insert filter/dropMissingK8sAttributes: error_mode: ignore traces: span: - resource.attributes[&quot;k8s.node.name&quot;] == nil - resource.attributes[&quot;k8s.pod.uid&quot;] == nil - resource.attributes[&quot;k8s.namespace.name&quot;] == nil - resource.attributes[&quot;k8s.pod.name&quot;] == nil connectors: spanmetrics: metrics_expiration: 5m namespace: otel_span routing/traces: error_mode: ignore table: - statement: route() pipelines: [traces/sampling, traces/spanmetrics] service: extensions: - health_check - bearertokenauth pipelines: traces: receivers: [otlp] processors: [filter/dropMissingK8sAttributes, memory_limiter, resource] exporters: [routing/traces] traces/spanmetrics: receivers: [routing/traces] processors: [] exporters: [spanmetrics] traces/sampling: receivers: [routing/traces] processors: [tail_sampling, batch] exporters: [debug, otlp/stackstate] metrics: receivers: [otlp, spanmetrics, prometheus] processors: [memory_limiter, resource, batch] exporters: [debug, otlp/stackstate]EOF éƒ¨ç½² OpenTelemetry Collectorï¼š 12345678910111213kubectl create ns open-telemetrykubectl create secret generic open-telemetry-collector \\ --namespace open-telemetry \\ --from-literal=API_KEY='xxx'helm repo add open-telemetry https://open-telemetry.github.io/opentelemetry-helm-chartshelm repo updatehelm upgrade --install opentelemetry-collector open-telemetry/opentelemetry-collector \\ --values otel-collector.yaml \\ --namespace open-telemetry æ”¶é›† Java åº”ç”¨ Traces æ•°æ®æ­¤å¤„ä½¿ç”¨ Automatic instrumentation çš„æ–¹å¼ï¼Œä¸º Spring Boot æ³¨å…¥ OpenTelemetry Java Agentï¼Œå…¶åŸç†å°±æ˜¯åœ¨ Java å¯åŠ¨å‘½ä»¤ä¸­è°ƒç”¨ OpenTelemetry çš„ Java Agentï¼Œç„¶åé€šè¿‡ OpenTelemetry Collector å‘é€æ•°æ®åˆ° SUSE Observabilityã€‚ DEMO ä»“åº“åœ°å€ï¼šhttps://github.com/warnerchen/otel-spring-boot-demo.git éƒ¨ç½²åæ•ˆæœå¦‚ä¸‹ï¼š ä¹Ÿä¼šæ”¶é›† Java åº”ç”¨çš„ Metrics æ•°æ®ï¼š Rancher å¯¹æ¥SUSE Observabilityåœ¨ Rancher å¯¹æ¥ SUSE Observabilityï¼ŒURL éœ€è¦ä½¿ç”¨æœ‰æ•ˆè¯ä¹¦ï¼ˆéè‡ªç­¾åè¯ä¹¦ï¼‰ã€‚ åœ¨ SUSE Observability -&gt; CLI é¡µé¢ï¼Œè·å– CLI å·¥å…·å®‰è£…å‘½ä»¤ï¼š é€šè¿‡ CLI å·¥å…·è·å– Service Tokenï¼Œåç»­ç”¨äº Rancher å¯¹æ¥ SUSE Observabilityï¼š 12curl -o- https://dl.stackstate.com/stackstate-cli/install.sh | STS_URL=&quot;https://suse-observability.warnerchen.com&quot; STS_API_TOKEN=&quot;xxx&quot; bashsts service-token create --name suse-observability-extension --roles stackstate-k8s-troubleshooter åœ¨ Rancher Extensions ä¸­å®‰è£… Observabilityï¼š","link":"/2025/03/03/SUSE-Observability-%E4%BD%BF%E7%94%A8%E9%9A%8F%E8%AE%B0/"},{"title":"å…«è‚¡æ–‡éšè®°å½•","text":"ä¸€ã€ç½‘ç»œæ–¹é¢1.1 OSIä¸ƒå±‚ä½“ç³»æ¨¡å‹å’ŒTCP/IPå››å±‚ä½“ç³»æ¨¡å‹ OSIä¸ƒå±‚ï¼š ç‰©ç†å±‚ æ•°æ®é“¾è·¯å±‚ ç½‘ç»œå±‚ ä¼ è¾“å±‚ ä¼šè¯å±‚ è¡¨ç¤ºå±‚ åº”ç”¨å±‚ TCP/IPå››å±‚ï¼š ç½‘ç»œæ¥å£å±‚ ç½‘é™…å±‚IP ä¼ è¾“å±‚ åº”ç”¨å±‚ åŸºæœ¬äº”å±‚ä½“ç³»æ¨¡å‹ï¼š ç‰©ç†å±‚ï¼šIEEE802.3 æ•°æ®é“¾è·¯å±‚ï¼šPPPã€Ethernet ç½‘ç»œå±‚ï¼šARPã€RARPã€IPã€ICMPã€RIPã€OSPFã€BGP ä¼ è¾“å±‚ï¼šTCPã€UDP åº”ç”¨å±‚ï¼šHTTPã€DNSã€FTPã€TELNETã€SMTPã€NFSã€SNMP 1.2 ç‰©ç†å±‚1.3 æ•°æ®é“¾è·¯å±‚1.3.1 PPPPPPåè®®å³ç‚¹å¯¹ç‚¹åè®®ï¼Œå±äºæ•°æ®é“¾è·¯å±‚åè®®ï¼Œä¸€èˆ¬ç”¨äºå¹¿åŸŸç½‘ã€‚PPPåè®®é¦–å…ˆä¼šå»ºç«‹ç‰©ç†é“¾è·¯ï¼Œå½“ç‰©ç†é“¾è·¯å»ºç«‹æˆåŠŸï¼Œå°±é€šè¿‡é“¾è·¯æ§åˆ¶åè®®LCPæ¥å»ºç«‹æ•°æ®é“¾è·¯è¿æ¥ï¼Œæ¥ç€ç½‘ç»œæ§åˆ¶åè®®NCPå°±ä¼šåå•†è¯¥é“¾è·¯ä¸Šæ‰€ä¼ è¾“çš„æ•°æ®åŒ…æ ¼å¼å’Œç±»å‹ï¼Œä»è€Œå»ºç«‹ä¸åŒçš„ç½‘ç»œå±‚åè®®ã€‚ 1.3.2 CSMA/CDCSMA/CDåè®®å³è½½æ³¢ç›‘å¬å¤šç‚¹æ¥å…¥/ç¢°æ’æ£€æµ‹åè®®ï¼Œå±äºæ•°æ®é“¾è·¯å±‚åè®®ã€‚å·¥ä½œåŸç†æ˜¯å‘é€æ•°æ®ä¹‹å‰ä¼šå…ˆä¾¦å¬ä¿¡é“æ˜¯å¦ç©ºé—²ï¼Œå¦‚æœç©ºé—²å°±å‘é€æ•°æ®ï¼Œå¦‚æœå¿™ç¢Œå°±ç­‰å¾…ä¸€æ®µæ—¶é—´å†å‘é€ï¼Œå³è½½æ³¢ç›‘å¬ï¼›å½“ä¸Šä¸€æ®µä¿¡æ¯å‘é€å®Œåï¼Œå‘ç”Ÿäº†ä¸¤ä¸ªæˆ–ä¸¤ä¸ªä»¥ä¸Šçš„èŠ‚ç‚¹åŒæ—¶å‘é€æ•°æ®ï¼Œé‚£å°±åˆ¤å®šä¸ºå†²çªï¼Œä¼šç«‹å³åœæ­¢å‘é€ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´å†å‘é€æ•°æ®ï¼Œå³ç¢°æ’æ£€æµ‹ã€‚èŠ‚ç‚¹åœ¨å‘é€è¿‡ç¨‹ä¸­ä¹Ÿä¼šç›‘å¬ä¿¡é“ã€‚æ‰€ä»¥CSMA/CDçš„å·¥ä½œåŸç†å¯ä»¥æ¦‚æ‹¬ä¸ºï¼šå…ˆå¬åå‘ã€è¾¹å‘è¾¹å¬ã€å†²çªåœå‘ã€éšæœºå»¶è¿Ÿåé‡å‘ã€‚ 1.3.2 åˆ’åˆ†vlanæœ‰ä½•ç”¨vlan å³è™šæ‹Ÿå±€åŸŸç½‘ï¼Œå°±æ˜¯æŠŠä¸€ä¸ªå¤§çš„å±€åŸŸç½‘ï¼Œåˆ’åˆ†ä¸ºå¤šä¸ªç›¸äº’éš”ç¦»çš„å°å±€åŸŸç½‘ï¼Œç”¨äºåˆ’åˆ†æ•°æ®é“¾è·¯å±‚ï¼Œå¯ä»¥å®ç°éš”ç¦»å¹¿æ’­åŸŸï¼Œé¿å…æ¯ä¸ªèŠ‚ç‚¹æ”¶åˆ°å¤ªå¤šæ— ç”¨çš„å¹¿æ’­åŒ…ï¼Œå‡å°èŠ‚ç‚¹æ€§èƒ½å’Œç½‘ç»œå®½å¸¦çš„æ¶ˆè€—ï¼ŒåŒæ—¶å¯ä»¥éš”ç¦»å¸¸è§çš„æ”»å‡»ï¼Œå¦‚ arp æ”»å‡»ï¼Œå—åˆ°æ”»å‡»çš„å½±å“èŒƒå›´ä»…é™äºè¯¥ vlanã€‚ 1.4 ç½‘ç»œå±‚1.4.1 ARPåœ°å€è§£æåè®®ARPï¼Œæ˜¯æ ¹æ®IPåœ°å€æ¥è·å–ç‰©ç†åœ°å€çš„åè®®ï¼Œå·¥ä½œåœ¨æ•°æ®é“¾è·¯å±‚ï¼Œæºä¸»æœºå‘é€ä¿¡æ¯æ—¶ä¼šå°†ç›®æ ‡åœ°å€ä¸»æœºçš„IPåœ°å€é€šè¿‡å¹¿æ’­çš„å½¢å¼å‘é€åˆ°å±€åŸŸç½‘å†…çš„æ‰€æœ‰ä¸»æœºä¸Šï¼Œç›®æ ‡åœ°å€ä¸»æœºæ”¶åˆ°å¹¿æ’­åå°±ä¼šå°†è‡ªå·±çš„MACåœ°å€å‘é€ç»™æºä¸»æœºï¼Œè¿™æ ·æºä¸»æœºå°±ä¼šå°†ç›®æ ‡åœ°å€ä¸»æœºçš„IPåœ°å€å’ŒMACåœ°å€ä¿å­˜åœ¨ARPç¼“å­˜ä¸­ï¼Œä»è€ŒèŠ‚çº¦ç½‘ç»œèµ„æºã€‚ 1.4.2 RIPRIPæ˜¯é‡‡ç”¨è·ç¦»å‘é‡çš„è·¯ç”±é€‰æ‹©åè®®ï¼Œå±äºå†…éƒ¨ç½‘å…³åè®®ï¼Œä½¿ç”¨ â€œè·³æ•°â€ æ¥è¡¡é‡åˆ°è¾¾ç›®æ ‡åœ°å€çš„è·¯ç”±è·ç¦»ã€‚è·ç¦»çš„å–å€¼ä¸º0 - 16ï¼Œ16å³ä¸ºä¸å¯è¾¾ã€‚RIPåè®®ä»…å’Œç›¸é‚»è·¯ç”±å™¨äº¤æ¢ä¿¡æ¯ï¼Œäº¤æ¢çš„ä¿¡æ¯æ˜¯è‡ªå·±çš„è·¯ç”±è¡¨ï¼Œæ¯30ç§’å°±ä¼šäº¤æ¢ä¸€æ¬¡ï¼Œå¦‚æœè¶…è¿‡180ç§’æ²¡æ”¶åˆ°ç›¸é‚»è·¯ç”±å™¨å‘é€è¿‡æ¥çš„ä¿¡æ¯ï¼Œåˆ™è§†ä¸ºä¸å¯è¾¾ã€‚ 1.4.3 OSPFOSPFå³å¼€æ”¾æœ€çŸ­è·¯å¾„ä¼˜å…ˆï¼Œå±äºå†…éƒ¨ç½‘å…³åè®®ï¼Œæ˜¯é‡‡ç”¨æ´ªæ³›æ³•å‘è‡ªæ²»ç³»ç»Ÿå†…çš„æ‰€æœ‰è·¯ç”±å™¨å‘é€ä¿¡æ¯ï¼Œæ¯ä¸€ä¸ªç›¸é‚»è·¯ç”±å™¨ä¼šå°†æ­¤æ¶ˆæ¯å†æ¬¡å‘é€ç»™ç›¸é‚»çš„è·¯ç”±å™¨ï¼Œäº¤æ¢çš„ä¿¡æ¯æ˜¯ä¸æœ¬è·¯ç”±å™¨ç›¸é‚»çš„æ‰€æœ‰è·¯ç”±å™¨çš„é“¾è·¯çŠ¶æ€ï¼Œé“¾è·¯çŠ¶æ€å¯ä»¥æ˜¯è´¹ç”¨ã€è·ç¦»ã€æ—¶å»¶ã€å¸¦å®½ç­‰ï¼Œåªæœ‰å½“é“¾è·¯çŠ¶æ€å‘ç”Ÿå˜åŒ–æ—¶ï¼Œè·¯ç”±å™¨æ‰ä¼šå‘æ‰€æœ‰è·¯ç”±å™¨é‡‡ç”¨æ´ªæ³›æ³•å‘é€æ¶ˆæ¯ã€‚ OSPFå·¥ä½œçŠ¶æ€ï¼š å‘ç°é‚»å±…ï¼šé€šè¿‡å‘é€helloåŒ…æ¥å‘ç°é‚»å±… å»ºç«‹é‚»å±…å…³ç³»ï¼šé€‰ä¸¾DR/BDRæ¥å»ºç«‹å…³ç³»ï¼Œå…¶å®ƒè·¯ç”±ä»…ä¸DRå’ŒBDRå»ºç«‹å…³ç³»ï¼ŒDRæŒ‚äº†è¿˜æœ‰BDRåœ¨æ‰€ä»¥ä¸æ€•é“¾è·¯å‘ç”Ÿæ–­è”çš„çŠ¶å†µ æ›´æ–°é“¾è·¯çŠ¶æ€ï¼šæ¯ä¸ªè·¯ç”±å»éƒ½æœ‰ä¸ªLSDBï¼ˆé“¾è·¯çŠ¶æ€æ•°æ®åº“ï¼‰ï¼Œé‡Œé¢å­˜æ”¾LSAï¼ˆé“¾è·¯çŠ¶æ€å…¬å‘Šï¼‰ï¼Œå¦‚æœç½‘ç»œçŠ¶æ€æ²¡å‘ç”Ÿå˜åŒ–ï¼Œå°±æ¯éš”30åˆ†é’Ÿä¸é‚»å±…æ›´æ–°é“¾è·¯çŠ¶æ€ä¿¡æ¯ï¼Œå¦‚æœå‘ç”Ÿå˜åŒ–åˆ™è‡ªåŠ¨æ›´æ–°é“¾è·¯çŠ¶æ€ä¿¡æ¯ è·¯ç”±è®¡ç®—ï¼šæ ¹æ®LSDBä¸­çš„LSAè®¡ç®—æœ€ä¼˜è·¯å¾„ OSPFçš„äº”ç§åŒ…ç±»å‹ï¼š å‘ç°é‚»å±…ï¼šé€šè¿‡å‘é€helloåŒ…æ¥å‘ç°é‚»å±…ï¼Œä»¥åŠç”¨æ¥é€‰ä¸¾DR/BDR æ•°æ®åº“æè¿°ï¼šç”¨åœ¨LSDBäº¤æ¢è¿‡ç¨‹ä¸­ï¼Œç¡®ç«‹ä¸»/ä»å…³ç³»ï¼Œäº¤æ¢LSAåŒ…å¤´ï¼Œä»¥åŠç¡®å®šé¦–ä¸ªåºåˆ—å· é“¾è·¯çŠ¶æ€è¯·æ±‚ï¼šè¯·æ±‚LSDBäº¤æ¢è¿‡ç¨‹ä¸­æœ¬è·¯ç”±å™¨æ²¡æœ‰çš„LSA é“¾è·¯çŠ¶æ€æ›´æ–°ï¼šé€šè¿‡æ³›æ´ªæ³•æ›´æ–°LSA é“¾è·¯çŠ¶æ€ç¡®è®¤ï¼šå¯¹æ”¶åˆ°çš„é“¾è·¯çŠ¶æ€æ›´æ–°è¿›è¡Œç¡®è®¤ï¼Œ å¦‚æœå‘é€ç¡®è®¤çš„è·¯ç”±å™¨çš„çŠ¶æ€æ˜¯DRæˆ–è€…BDRï¼Œç¡®è®¤æ•°æ®åŒ…å‘é€åˆ°OSPFçš„ç»„æ’­åœ°å€224.0.0.5ï¼Œå¦‚æœä¸æ˜¯ï¼Œåˆ™ç»„æ’­åœ°å€224.0.0.6 OSPFåŒºåŸŸï¼š åŒä¸€åŒºåŸŸå†…çš„è·¯ç”±å™¨æ‰ä¼šå»ºç«‹å…³ç³»ï¼Œäº¤æ¢LSAï¼Œæ”¶æ•›åï¼ŒåŒä¸€åŒºåŸŸå†…çš„è·¯ç”±å™¨éƒ½æ‹¥æœ‰ç›¸åŒçš„LSDBã€‚ å¦‚æœæœ‰å¤šä¸ªåŒºåŸŸï¼Œé‚£ä¹ˆæ¯ä¸ªåŒºåŸŸéƒ½ä¼šé€‰æ‹©ä¸€ä¸ªæ€§èƒ½è¾ƒå¥½çš„è·¯ç”±å™¨æ¥ä½œä¸ºABRï¼ˆåŒºåŸŸè¾¹ç•Œè·¯ç”±å™¨ï¼‰ï¼Œä¸åŒåŒºåŸŸå†…çš„è·¯ç”±å™¨è¿›è¡Œé€šä¿¡ç›´æ¥é€šè¿‡è¿™ä¸ªABRè½¬å‘è·¯ç”±ã€‚ æ¯ä¸ªåŒºåŸŸéƒ½æœ‰ä¸€ä¸ªåŒºåŸŸIDï¼Œä¸º32ä½äºŒè¿›åˆ¶æ•°ï¼Œå¯ä»¥è¡¨è¾¾ä¸ºä¸€ä¸ªåè¿›åˆ¶æ•°ï¼Œä¹Ÿå¯ä»¥è¡¨è¾¾ä¸ºä¸€ä¸ªç‚¹åˆ†åè¿›åˆ¶æ•°å­—ï¼Œä¾‹å¦‚åŒºåŸŸ0ç­‰ä»·äº0.0.0.0ï¼ŒåŒºåŸŸ1ç­‰ä»·äº0.0.0.1 éª¨å¹²åŒºåŸŸä¸ºåŒºåŸŸ0 ééª¨å¹²åŒºåŸŸé—´è¿›è¡Œé€šä¿¡éƒ½è¦é€šè¿‡éª¨å¹²åŒºåŸŸ0è¿›è¡Œè½¬å‘ å¦‚æœç½‘ç»œä¸­æœ‰ä¸åŒçš„OSPFåŒºåŸŸï¼Œé‚£ä¹ˆæœ‰ä¸ªåŒºåŸŸè‚¯å®šæ˜¯åŒºåŸŸ0 1.4.4 BGPBGPå³è¾¹ç•Œç½‘å…³åè®®ï¼Œå±äºå¤–éƒ¨ç½‘å…³åè®®ï¼Œæ˜¯ä¸åŒè‡ªæ²»ç³»ç»ŸASä½¿ç”¨çš„åè®®ï¼Œæ¯ä¸ªè‡ªæ²»ç³»ç»Ÿéƒ½è¦æœ‰ä¸€ä¸ªBGPå‘è¨€äººï¼Œç”¨æ¥äº¤æ¢ä¿¡æ¯ï¼Œäº¤æ¢çš„ä¿¡æ¯æ˜¯ç½‘ç»œå¯è¾¾æ€§çš„ä¿¡æ¯ï¼Œå³è¦åˆ°è¾¾æŸä¸€ç½‘ç»œæ‰€ç»è¿‡çš„ä¸€ç³»åˆ—è‡ªæ²»ç³»ç»Ÿï¼Œä¸”åªæœ‰åœ¨ä¿¡æ¯å‘ç”Ÿå˜åŒ–æ—¶æ‰ä¼šè¿›è¡Œä¿¡æ¯äº¤æ¢ã€‚ 1.4.5 PINGPINGå®é™…å°±æ˜¯å‘é€ä¸€ä¸ªICMPå›é€è¯·æ±‚æŠ¥æ–‡ç»™ç›®çš„ä¸»æœºï¼Œå¹¶ç­‰å¾…å›é€çš„ICMPå“åº”ã€‚å®é™…å°±æ˜¯åˆ©ç”¨äº†IPåœ°å€çš„å”¯ä¸€æ€§ï¼Œç»™ç›®æ ‡ä¸»æœºçš„IPåœ°å€å‘é€ä¸€ä¸ªICMPæ•°æ®åŒ…ï¼Œå†è¦æ±‚å¯¹æ–¹è¿”å›ä¸€ä¸ªåŒç­‰å¤§å°çš„æ•°æ®åŒ…æ¥ç¡®å®šä¸¤å°ä¸»æœºæ˜¯å¦ç›¸äº’è¿é€šï¼Œä»¥åŠæ—¶å»¶æ˜¯å¤šå°‘ã€‚ 1.4.6 TracerouteTracerouteæ˜¯é€šè¿‡TTLå’ŒICMPæŠ¥æ–‡æ¥ç¡®å®šä»ä¸€ä¸ªä¸»æœºåˆ°ç½‘ç»œä¸Šå…¶ä»–ä¸»æœºçš„è·¯ç”±ã€‚é¦–å…ˆä¼šå‘é€ä¸€ä¸ªTTLä¸º1çš„æ•°æ®åŒ…åˆ°ç›®çš„ä¸»æœºï¼Œç»è¿‡ä¸€ä¸ªè·¯ç”±å™¨TTLå°±å‡1ï¼Œæ­¤æ—¶TTLä¸º0æ•°æ®åŒ…å°±ä¼šè¢«ä¸¢å¼ƒï¼Œè·¯ç”±å™¨ä¼šå›é€ä¸€ä¸ªICMPè¶…æ—¶æŠ¥æ–‡ç»™æºä¸»æœºï¼Œæºä¸»æœºæ”¶åˆ°è¶…æ—¶æŠ¥æ–‡åï¼Œå°±ä¼šå°†TTLçš„å€¼åŠ 1ï¼Œå†å‘é€æ•°æ®åŒ…åˆ°ç›®çš„ä¸»æœºï¼Œä¸æ–­é‡å¤ä»¥ä¸Šçš„è¿‡ç¨‹ç›´åˆ°æ•°æ®åŒ…åˆ°è¾¾ç›®çš„ä¸»æœºï¼Œç›®çš„ä¸»æœºæ”¶åˆ°æ•°æ®åŒ…åå°±ä¼šä¼šé€ä¸€ä¸ªICMPå“åº”æŠ¥æ–‡ã€‚ 1.4.7 åˆ’åˆ†å­ç½‘æœ‰ä½•ç”¨IP æ˜¯ä»¥ç½‘ç»œå·å’Œä¸»æœºå·æ„æˆçš„ï¼Œåªæœ‰åœ¨åŒä¸€ä¸ªç½‘ç»œå·ä¸‹çš„ä¸»æœºæ‰èƒ½å¤Ÿç›¸äº’é€šä¿¡ï¼Œä¸åŒç½‘ç»œå·çš„ä¸»æœºè¦é€šä¿¡å°±è¦é€šè¿‡ç½‘å…³æ¥å®ç°ï¼Œä½†åªé€šè¿‡ç½‘ç»œå·æ¥åˆ’åˆ†å¹¶ä¸çµæ´»ï¼Œè€Œå­ç½‘å°±æ˜¯å°†ä¸€ä¸ªç½‘ç»œåˆ’åˆ†ä¸ºæ›´å¤šä¸ªå°çš„ç½‘ç»œï¼Œè¿™äº›å°çš„ç½‘ç»œå°±æ˜¯å­ç½‘ï¼Œæ¯ä¸€ä¸ªå­ç½‘éƒ½æœ‰ç›¸åº”çš„å­ç½‘æ©ç ï¼Œå­ç½‘æ©ç å°±æ˜¯ç”¨æ¥åˆ¤æ–­å¤šä¸ª IP æ˜¯å¦åœ¨åŒä¸€å­ç½‘ä¸­çš„ã€‚ 1.5 ä¼ è¾“å±‚1.5.1 TCPä¸UDP TCPä¸UDPçš„åŒºåˆ«ï¼š TCPå³ä¼ è¾“æ§åˆ¶åè®®ï¼Œæ˜¯ä¸€ç§é¢å‘è¿æ¥çš„ã€å¯é çš„ã€åŸºäºå­—èŠ‚æµçš„ä¼ è¾“å±‚åè®®ï¼ŒTCPçš„è¿æ¥æ˜¯ç‚¹å¯¹ç‚¹è¿æ¥ï¼Œæ‰€ä»¥ä¼ è¾“çš„æ•°æ®æ˜¯æ— å·®é”™ã€ä¸ä¸¢å¤±ã€ä¸é‡å¤ã€æŒ‰éœ€åˆ°è¾¾çš„ï¼Œä½†é¦–éƒ¨å¼€é”€è¾ƒå¤§ï¼Œæœ‰20å­—èŠ‚ã€‚ UDPå³ç”¨æˆ·æ•°æ®æŠ¥åè®®ï¼Œæ˜¯ä¸€ç§é¢å‘æ— è¿æ¥çš„ã€å°½æœ€å¤§åŠªåŠ›äº¤ä»˜çš„ã€åŸºäºæŠ¥æ–‡çš„ä¼ è¾“å±‚åè®®ï¼ŒUDPçš„è¿æ¥å¯ä»¥æ˜¯ä¸€å¯¹ä¸€ã€ä¸€å¯¹å¤šã€å¤šå¯¹ä¸€å’Œå¤šå¯¹å¤šçš„ï¼Œä¼ è¾“çš„æ•°æ®å¾ˆå¯èƒ½ä¼šä¸¢å¤±ï¼Œä½†é¦–éƒ¨å¼€é”€å°ï¼Œåªæœ‰8å­—èŠ‚ã€‚ TCPçš„æµé‡æ§åˆ¶ï¼š æ‰€è°“æµé‡æ§åˆ¶å°±æ˜¯è®©å¯¹æ–¹å‘é€é€Ÿç‡ä¸è¦è¿‡å¿«ï¼Œè®©æ¥æ”¶æ–¹æ¥å¾—åŠæ¥æ”¶ã€‚ æ»‘åŠ¨çª—å£æœºåˆ¶ï¼šæ»‘åŠ¨çª—å£æœºåˆ¶çš„åŸºæœ¬åŸç†å°±æ˜¯åœ¨ä»»æ„æ—¶åˆ»ï¼Œå‘é€æ–¹éƒ½ç»´æŒäº†ä¸€ä¸ªè¿ç»­çš„å…è®¸å‘é€çš„å¸§çš„åºå·ï¼Œç§°ä¸ºå‘é€çª—å£ï¼›åŒæ—¶ï¼Œæ¥æ”¶æ–¹ä¹Ÿç»´æŒäº†ä¸€ä¸ªè¿ç»­çš„å…è®¸æ¥æ”¶çš„å¸§çš„åºå·ï¼Œç§°ä¸ºæ¥æ”¶çª—å£ã€‚å‘é€çª—å£å’Œæ¥æ”¶çª—å£çš„åºå·çš„ä¸Šä¸‹ç•Œä¸ä¸€å®šè¦ä¸€æ ·ï¼Œç”šè‡³å¤§å°ä¹Ÿå¯ä»¥ä¸åŒã€‚ä¸åŒçš„æ»‘åŠ¨çª—å£åè®®çª—å£å¤§å°ä¸€èˆ¬ä¸åŒã€‚ TCPçš„æ‹¥å¡æ§åˆ¶ï¼ˆåŠ æ³•å¢å¤§ä¹˜æ³•å‡å°ç®—æ³• AIMDï¼‰ï¼š æ‹¥å¡æ§åˆ¶çš„ç›®çš„æ˜¯é˜²æ­¢è¿‡å¤šçš„æ•°æ®æ³¨å…¥åˆ°ç½‘ç»œä¸­ã€‚ æ…¢å¼€å§‹ï¼šä¸è¦ä¸€å¼€å§‹å°±å‘é€å¤§é‡çš„æ•°æ®ï¼Œå…ˆæ¢æµ‹ä¸€ä¸‹ç½‘ç»œçš„æ‹¥å¡ç¨‹åº¦ï¼Œä¹Ÿå°±æ˜¯è¯´ç”±å°åˆ°å¤§é€æ¸å¢åŠ æ‹¥å¡çª—å£çš„å¤§å°ã€‚ æ‹¥å¡é¿å…ï¼šè®©æ‹¥å¡çª—å£å€¼cwndç¼“æ…¢åœ°å¢å¤§ï¼Œå³æ¯ç»è¿‡ä¸€ä¸ªå¾€è¿”æ—¶é—´RTTå°±æŠŠå‘é€æ–¹çš„æ‹¥å¡æ§åˆ¶çª—å£åŠ ä¸€ã€‚ å¿«é‡ä¼ ï¼šå‘é€æ–¹åªè¦æ”¶åˆ°ä¸‰ä¸ªé‡å¤ç¡®è®¤å°±ç«‹å³é‡ä¼ å¯¹æ–¹å°šæœªæ”¶åˆ°çš„æŠ¥æ–‡æ®µï¼Œä¸å¿…ç»§ç»­ç­‰å¾…è®¾ç½®çš„é‡ä¼ è®¡æ—¶å™¨æ—¶é—´åˆ°æœŸã€‚ å¿«æ¢å¤ï¼šå¿«æ¢å¤å’Œå¿«é‡ä¼ æ˜¯é…åˆä½¿ç”¨çš„ï¼Œæ‰§è¡Œå¿«æ¢å¤ä¼šå°†æ‹¥å¡çª—å£å€¼è®¾ä¸ºæ…¢å¼€å§‹é—¨é™å€¼çš„ä¸€åŠï¼Œç„¶åæ‰§è¡Œæ‹¥å¡é¿å…ã€‚ æµé‡æ§åˆ¶å’Œæ‹¥å¡æ§åˆ¶çš„åŒºåˆ«ï¼š æµé‡æ§åˆ¶æ˜¯ç«¯åˆ°ç«¯çš„é—®é¢˜ï¼Œå°±æ˜¯è¦æ§åˆ¶ä½å‘é€ç«¯çš„å‘é€é€Ÿç‡ï¼Œä»¥ä¾¿æ¥æ”¶ç«¯æ¥å¾—åŠæ¥æ”¶ã€‚ æ‹¥å¡æ§åˆ¶æ˜¯ä¸€ä¸ªå…¨å±€æ€§çš„è¿‡ç¨‹ï¼Œç›®çš„æ˜¯é˜²æ­¢è¿‡å¤šçš„æ•°æ®æ³¨å…¥åˆ°ç½‘ç»œä¸­ã€‚ TCPçš„ä¸‰æ¬¡æ¡æ‰‹å’Œå››æ¬¡æŒ¥æ‰‹ ä¸‰æ¬¡æ¡æ‰‹ï¼šä¸‰æ¬¡æ¡æ‰‹å°±æ˜¯è®¡ç®—æœºç½‘ç»œä¸­å®¢æˆ·ç«¯å’ŒæœåŠ¡ç«¯é€šä¿¡å‰è¿›è¡Œè¿æ¥çš„ä¸€ä¸ªè¿‡ç¨‹ï¼Œå®¢æˆ·ç«¯ä¼šå…ˆç»™æœåŠ¡ç«¯å‘å‡ºä¸€ä¸ªè¯·æ±‚SYNï¼ˆseq=xï¼‰ï¼ŒæœåŠ¡ç«¯æ”¶åˆ°è¯·æ±‚ä¸”èƒ½å¤Ÿè¿›è¡Œè¿æ¥å°±ä¼šç»™å®¢æˆ·ç«¯å‘é€ä¸€ä¸ªè¯·æ±‚SYNå’Œç¡®è®¤ACKï¼ˆack=x+1ï¼Œseq=yï¼‰ï¼Œå®¢æˆ·ç«¯æ”¶åˆ°äº†æœåŠ¡ç«¯çš„å“åº”å°±ä¼šç»™æœåŠ¡ç«¯å†æ¬¡å‘é€ä¸€ä¸ªè¯·æ±‚SYNå’Œç¡®è®¤ACKï¼ˆack=y+1ï¼Œseq=x+1ï¼‰ï¼Œå°±å®Œæˆäº†ä¸‰æ¬¡æ¡æ‰‹ã€‚ å››æ¬¡æŒ¥æ‰‹ï¼šå®¢æˆ·ç«¯è·å¾—äº†éœ€è¦çš„èµ„æºä¹‹åï¼Œå°±ä¼šç»™æœåŠ¡ç«¯å‘é€ä¸­æ­¢FINå’Œç¡®è®¤ACKï¼ˆfin=1ï¼Œack=zï¼Œseq=xï¼‰ï¼ŒæœåŠ¡ç«¯æ”¶åˆ°å°±ä¼šå›å¤ä¸€ä¸ªACKï¼ˆack=x+1ï¼Œseq=zï¼‰ï¼Œå…³é—­è¿æ¥æ¥ç€ç»™å®¢æˆ·ç«¯å‘é€ä¸€ä¸ªä¸­æ­¢FINï¼ˆfin=1ï¼Œack=xï¼Œseq=yï¼‰ï¼Œå®¢æˆ·ç«¯æ”¶åˆ°åå°±ä¼šç»™æœåŠ¡ç«¯å‘é€ä¸€ä¸ªç¡®è®¤ACKï¼ˆack=yï¼Œseq=xï¼‰ï¼Œä¾¿å®Œæˆäº†å››æ¬¡æŒ¥æ‰‹ã€‚ TIME_WAIT çŠ¶æ€äº§ç”Ÿçš„åŸå› ï¼š ä¸ºå®ç°TCPå…¨åŒå·¥è¿æ¥çš„å¯é é‡Šæ”¾ ä¸ºä½¿æ—§çš„æ•°æ®åŒ…åœ¨ç½‘ç»œå› è¿‡æœŸè€Œæ¶ˆå¤± å¤§é‡ TIME_WAIT çŠ¶æ€æ‰€å¸¦æ¥çš„å±å®³ï¼š å¦‚æœç³»ç»Ÿä¸­æœ‰å¾ˆå¤š socket å¤„äº TIME_WAIT çŠ¶æ€ï¼Œå½“éœ€è¦åˆ›å»ºæ–°çš„ socket è¿æ¥çš„æ—¶å€™å¯èƒ½ä¼šå—åˆ°å½±å“ï¼Œå¦‚æœå®¢æˆ·ç«¯çš„å¹¶å‘é‡æŒç»­å¾ˆé«˜ï¼Œæ­¤æ—¶éƒ¨åˆ†å®¢æˆ·ç«¯å°±ä¼šæ˜¾ç¤ºè¿æ¥ä¸ä¸Šã€‚ ä¸ºä»€ä¹ˆä¼šé‡‡ç”¨ä¸‰æ¬¡æ¡æ‰‹ï¼ŒäºŒæ¬¡æ¡æ‰‹å¯ä»¥å—ï¼Ÿç¬¬ä¸‰æ¬¡æ¡æ‰‹å¤±è´¥äº†æ€ä¹ˆåŠï¼Ÿ é‡‡ç”¨ä¸‰æ¬¡æ¡æ‰‹æ˜¯ä¸ºäº†é˜²æ­¢å¤±æ•ˆçš„è¿æ¥è¯·æ±‚æŠ¥æ–‡æ®µå†æ¬¡ä¼ åˆ°æœåŠ¡å™¨ï¼Œå› è€Œäº§ç”Ÿé”™è¯¯ã€‚å¦‚æœç”±äºç½‘ç»œä¸ç¨³å®šï¼Œè™½ç„¶å®¢æˆ·ç«¯ä»¥å‰å‘é€çš„è¿æ¥è¯·æ±‚ä»¥åˆ°è¾¾æœåŠ¡æ–¹ï¼Œä½†æœåŠ¡æ–¹çš„åŒæ„è¿æ¥çš„åº”ç­”æœªèƒ½åˆ°è¾¾å®¢æˆ·ç«¯ã€‚åˆ™å®¢æˆ·æ–¹è¦é‡æ–°å‘é€è¿æ¥è¯·æ±‚ï¼Œè‹¥é‡‡ç”¨äºŒæ¬¡æ¡æ‰‹ï¼ŒæœåŠ¡æ–¹æ”¶åˆ°å®¢æœç«¯é‡ä¼ çš„è¯·æ±‚è¿æ¥åï¼Œä¼šä»¥ä¸ºæ˜¯æ–°çš„è¯·æ±‚ï¼Œå°±ä¼šå‘é€åŒæ„è¿æ¥æŠ¥æ–‡ï¼Œå¹¶æ–°å¼€è¿›ç¨‹æä¾›æœåŠ¡ï¼Œè¿™æ ·ä¼šé€ æˆæœåŠ¡æ–¹èµ„æºçš„æ— è°“æµªè´¹ã€‚å¦‚æœç¬¬ä¸‰æ¬¡æ¡æ‰‹å¤±è´¥ï¼ŒæœåŠ¡ç«¯ä¸ä¼šé‡æ–°å‘é€ACKæŠ¥æ–‡ï¼Œè€Œæ˜¯å‘é€RSTï¼ˆå¤ä½ï¼‰æŠ¥æ–‡ï¼Œè¿›å…¥CLOSEDçŠ¶æ€ï¼Œé˜²æ­¢SYNæ³›æ´ªæ”»å‡»ã€‚ ä¸ºä»€ä¹ˆæ–­å¼€è¿æ¥è¦å››æ¬¡æŒ¥æ‰‹ï¼Ÿ å› ä¸ºTCPè¿æ¥æ˜¯å…¨åŒå·¥çš„ç½‘ç»œåè®®ï¼Œå…è®¸åŒæ—¶é€šä¿¡çš„åŒæ–¹åŒæ—¶è¿›è¡Œæ•°æ®çš„æ”¶å‘ï¼ŒåŒæ ·ä¹Ÿå…è®¸æ”¶å‘ä¸¤ä¸ªæ–¹å‘çš„è¿æ¥è¢«ç‹¬ç«‹å…³é—­ï¼Œä»¥é¿å…clientæ•°æ®å‘é€å®Œæ¯•ï¼Œå‘serverå‘é€FINå…³é—­è¿æ¥ï¼Œè€Œserverè¿˜æœ‰å‘é€åˆ°clientçš„æ•°æ®æ²¡æœ‰å‘é€å®Œæ¯•çš„æƒ…å†µã€‚æ‰€ä»¥å…³é—­TCPè¿æ¥éœ€è¦è¿›è¡Œå››æ¬¡æ¡æ‰‹ï¼Œæ¯æ¬¡å…³é—­ä¸€ä¸ªæ–¹å‘ä¸Šçš„è¿æ¥éœ€è¦FINå’ŒACKä¸¤æ¬¡æ¡æ‰‹ã€‚ TCPè¿æ¥æ•°è¿‡é«˜æ€ä¹ˆåŠï¼Ÿ é¦–å…ˆå¯ä»¥é€šè¿‡ netstat å‘½ä»¤æŸ¥çœ‹å½“å‰çš„TCPè¿æ¥å“ªç§çŠ¶æ€æ¯”è¾ƒå¤šï¼Œå¦‚æœå­˜åœ¨å¤§é‡çš„ TIME_WAITï¼Œåˆ™å¯ä»¥é€šè¿‡ä¿®æ”¹å†…æ ¸å‚æ•°è§£å†³ï¼Œä¿®æ”¹ /etc/sysctl.conf æ–‡ä»¶ï¼Œæ·»åŠ æ§åˆ¶ TIME_WAIT æ•°é‡çš„å‚æ•°ï¼Œä¸€èˆ¬è®¾ç½®ä¸º30å·¦å³ï¼Œç„¶åå†æ‰§è¡Œ /sbin/sysctl -p å‘½ä»¤è®©å‚æ•°ç”Ÿæ•ˆã€‚ äº§ç”Ÿå¤§é‡TIME_WAITçš„åŸå› æœ‰å“ªäº›ï¼Ÿ TIME_WAITçŠ¶æ€æ˜¯æŒ‡TCPè¿æ¥åœ¨å…³é—­åç­‰å¾…ä¸€æ®µæ—¶é—´çš„çŠ¶æ€ã€‚è¿™ä¸ªçŠ¶æ€çš„å­˜åœ¨æ˜¯ä¸ºäº†ç¡®ä¿ç½‘ç»œä¸­æ‰€æœ‰ä¼ è¾“çš„æ•°æ®éƒ½è¢«æ­£ç¡®æ¥æ”¶å’Œå¤„ç†ã€‚äº§ç”Ÿå¤§é‡TIME_WAITçŠ¶æ€çš„åŸå› å¯ä»¥æœ‰ä»¥ä¸‹å‡ ç§ï¼š ä¸»åŠ¨å…³é—­è¿æ¥çš„ä¸€æ–¹åœ¨å…³é—­è¿æ¥åï¼Œå¯èƒ½éœ€è¦åœ¨TIME_WAITçŠ¶æ€ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œä»¥ç¡®ä¿è¿œç¨‹ä¸»æœºç¡®è®¤è¿æ¥å…³é—­ã€‚è¿™æ˜¯TCPåè®®çš„ä¸€éƒ¨åˆ†ï¼Œå¯ä»¥é˜²æ­¢å·²å…³é—­çš„è¿æ¥çš„æ•°æ®åŒ…åœ¨ç½‘ç»œä¸­è¢«è¯¯è§£ä¸ºæ–°è¿æ¥çš„æ•°æ®åŒ…ã€‚å¦‚æœæœ‰å¤§é‡çš„ä¸»åŠ¨å…³é—­è¿æ¥çš„æ“ä½œï¼Œé‚£ä¹ˆå°±ä¼šå¯¼è‡´å¤§é‡çš„TIME_WAITçŠ¶æ€çš„äº§ç”Ÿã€‚ ç½‘ç»œä¸­å­˜åœ¨ä¸¢åŒ…æˆ–å»¶è¿Ÿè¾ƒå¤§çš„æƒ…å†µï¼Œè¿™ä¼šå¯¼è‡´TCPåè®®æ— æ³•åŠæ—¶æ¥æ”¶åˆ°è¿œç¨‹ä¸»æœºçš„è¿æ¥å…³é—­ç¡®è®¤ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¸»åŠ¨å…³é—­è¿æ¥çš„ä¸€æ–¹å¯èƒ½ä¼šåœ¨TIME_WAITçŠ¶æ€ç­‰å¾…æ›´é•¿çš„æ—¶é—´ï¼Œä»¥ç¡®ä¿ç¡®è®¤æ”¶åˆ°ã€‚ è¿æ¥é¢‘ç¹åœ°å»ºç«‹å’Œå…³é—­ã€‚å¦‚æœä¸€ä¸ªåº”ç”¨ç¨‹åºé¢‘ç¹åœ°å»ºç«‹å’Œå…³é—­è¿æ¥ï¼Œå°±ä¼šå¯¼è‡´å¤§é‡çš„TIME_WAITçŠ¶æ€çš„äº§ç”Ÿã€‚è¿™å¯èƒ½æ˜¯ç”±äºåº”ç”¨ç¨‹åºè®¾è®¡ä¸å½“ï¼Œæˆ–è€…å­˜åœ¨æŸäº›é”™è¯¯å¯¼è‡´è¿æ¥é¢‘ç¹æ–­å¼€ã€‚ æ“ä½œç³»ç»Ÿèµ„æºé™åˆ¶ã€‚æ“ä½œç³»ç»Ÿå¯¹äºTIME_WAITçŠ¶æ€çš„å¤„ç†æ˜¯æœ‰é™åˆ¶çš„ï¼Œé€šå¸¸ä¼šé™åˆ¶åŒæ—¶å­˜åœ¨çš„TIME_WAITçŠ¶æ€çš„æ•°é‡ã€‚å¦‚æœæ“ä½œç³»ç»Ÿèµ„æºä¸è¶³ï¼Œå°±å¯èƒ½å¯¼è‡´TIME_WAITçŠ¶æ€çš„ç§¯ç´¯ã€‚ 1.6 åº”ç”¨å±‚1.6.1 HTTPå’ŒHTTPS HTTPå¸¸è§çŠ¶æ€ç ï¼š 1å¼€å¤´ï¼šä»£è¡¨è¯·æ±‚æˆåŠŸã€‚ 200ï¼šè¿™æ˜¯æœ€å¸¸è§çš„çŠ¶æ€ç ï¼Œè¡¨ç¤ºæœåŠ¡ç«¯å·²ç»æ¥å—åˆ°å®¢æˆ·ç«¯çš„è¯·æ±‚ï¼Œä¹Ÿç»™å®¢æˆ·ç«¯è¿”å›äº†ç»“æœã€‚ 202ï¼šè¡¨ç¤ºæœåŠ¡ç«¯å·²ç»æ¥å—äº†è¯·æ±‚ï¼Œä½†è¿˜æœªå¤„ç†ã€‚ 301ï¼šæ°¸ä¹…é‡å®šå‘ï¼Œè¡¨ç¤ºè¯·æ±‚çš„èµ„æºå·²ç»è¢«åˆ†é…åˆ°æ–°çš„URLã€‚ 302ï¼šä¸´æ—¶é‡å®šå‘ã€‚ 400ï¼šè¯·æ±‚æŠ¥æ–‡æœ‰è¯¯ã€‚ 403ï¼šæœåŠ¡å™¨æ‹’ç»æ­¤æ¬¡è®¿é—®ï¼Œä¸€èˆ¬æ˜¯æƒé™é—®é¢˜ã€‚ 404ï¼šè®¿é—®å¤±è´¥ã€‚ 500ï¼šæœåŠ¡å™¨æ‰§è¡Œè¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯ã€‚ 503ï¼šæœåŠ¡å™¨å¤„äºè¶…è´Ÿè½½æˆ–åœæœºç»´æŠ¤ï¼Œæ— æ³•å¤„ç†è¯·æ±‚ã€‚ HTTPçš„é•¿è¿æ¥å’ŒçŸ­è¿æ¥ï¼š HTTP/1.0é»˜è®¤ä½¿ç”¨çŸ­é“¾æ¥ï¼Œæ˜¯ä¸€ç§éæµæ°´çº¿å·¥ä½œæ–¹å¼ï¼Œä¹Ÿå°±æ˜¯è¯´å®¢æˆ·ç«¯å‘æœåŠ¡ç«¯æ¯è¿›è¡Œä¸€æ¬¡è¯·æ±‚ï¼Œå°±å»ºç«‹ä¸€æ¬¡è¿æ¥ï¼Œæ”¶åˆ°å“åº”å°±æ–­å¼€è¿æ¥ã€‚ HTTP/1.1é»˜è®¤ä½¿ç”¨é•¿è¿æ¥ï¼Œæ˜¯ä¸€ç§æµæ°´çº¿å·¥ä½œæ–¹å¼ï¼Œä¹Ÿå°±æ˜¯è¯´å®¢æˆ·ç«¯å’ŒæœåŠ¡ç«¯å»ºç«‹è¿æ¥ï¼Œåœ¨å®¢æˆ·ç«¯æ”¶åˆ°å“åº”åå¹¶ä¸ä¼šæ–­å¼€è¿æ¥ï¼Œè€Œæ˜¯ç­‰è®¾å®šçš„æ—¶é—´æ¥æ–­å¼€è¿æ¥ã€‚ HTTP/1.0å’ŒHTTP/1.1çš„åŒºåˆ«ï¼š é•¿è¿æ¥ èŠ‚çº¦å®½å¸¦ HOSTåŸŸ HTTP/1.1å’ŒHTTP/2.0çš„åŒºåˆ«ï¼š å¤šè·¯å¤ç”¨ äºŒè¿›åˆ¶åˆ†å¸§ é¦–éƒ¨å‹ç¼© æœåŠ¡å™¨æ¨é€ GET å’Œ POST çš„åŒºåˆ«ï¼š GET è·å–æ•°æ®ï¼ŒPOST ä¼ é€æ•°æ® å¯¹äº GET æ–¹å¼çš„è¯·æ±‚ï¼Œæµè§ˆå™¨ä¼šæŠŠ http header å’Œ data ä¸€å¹¶å‘é€å‡ºå»ï¼ŒæœåŠ¡å™¨å“åº”200ï¼›è€Œå¯¹äºPOSTï¼Œæµè§ˆå™¨å…ˆå‘é€headerï¼ŒæœåŠ¡å™¨å“åº”100ï¼Œæµè§ˆå™¨å†å‘é€ dataï¼ŒæœåŠ¡å™¨å“åº”200ã€‚ HTTP å’Œ HTTPS çš„åŒºåˆ«ï¼š HTTP å³è¶…æ–‡æœ¬ä¼ è¾“åè®®ï¼Œé€šè¿‡ TCP 80 ç«¯å£è¿›è¡Œä¼ è¾“ï¼Œè€Œ HTTPS æ˜¯HTTP + SSL åè®®æ„å»ºçš„å¯è¿›è¡ŒåŠ å¯†ä¼ è¾“ã€èº«ä»½è®¤è¯çš„ç½‘ç»œåè®®ï¼Œæ¯” HTTP æ›´åŠ å®‰å…¨ï¼Œé€šè¿‡ TCP 443 ç«¯å£è¿›è¡Œä¼ è¾“ã€‚ HTTPS éœ€è¦åˆ° CA ç”³è¯·è¯ä¹¦ï¼Œä¸€èˆ¬å…è´¹è¯ä¹¦è¾ƒå°‘ï¼Œå› æ­¤éœ€è¦ä¸€å®šè´¹ç”¨ã€‚ HTTP ä¿¡æ¯æ˜¯æ˜æ–‡ä¼ è¾“ï¼ŒHTTPS æ˜¯å…·æœ‰å®‰å…¨æ€§çš„ SSL åŠ å¯†ä¼ è¾“åè®®ã€‚ HTTPS åŠ å¯†è¿‡ç¨‹ï¼š æœåŠ¡å™¨ç”Ÿæˆä¸€å¯¹å…¬é’¥Aï¼Œå¯†é’¥B æµè§ˆå™¨å‘æœåŠ¡å™¨å‘èµ·è¯·æ±‚çš„è¯ï¼Œå°±å‘é€å…¬é’¥Aç»™æµè§ˆå™¨ æµè§ˆå™¨æ‹¿åˆ°å…¬é’¥Aåï¼Œéšæœºç”Ÿæˆå¯†é’¥Cï¼Œé€šè¿‡å…¬é’¥Aè¿›è¡ŒåŠ å¯†å¹¶ä¼ è¾“ç»™æœåŠ¡å™¨ æœåŠ¡å™¨æ‹¿åˆ°åï¼Œé€šè¿‡å¯†é’¥Bè§£å¯†è·å¾—å¯†é’¥Cï¼Œè¿™æ—¶å€™ä¸¤è¾¹éƒ½æŒæœ‰å¯†é’¥Cï¼Œå°±å¯ä»¥è¿›è¡Œå¯¹ç§°åŠ è§£å¯† 1.6.2 DNSDNS å³åŸŸåç³»ç»Ÿï¼Œåœ¨äº’è”ç½‘ä¸­ä¸ºåŸŸåå’ŒIPåœ°å€è¿›è¡Œç›¸äº’æ˜ å°„çš„ä¸€ä¸ªåˆ†å¸ƒå¼æ•°æ®åº“ï¼Œé‡‡ç”¨UDPåè®®ï¼Œä½¿ç”¨UDP53ç«¯å£è¿›è¡Œä¼ è¾“ã€‚ DNS ä¸­ï¼Œä¸»æœºå‘æœ¬åœ°åŸŸåæœåŠ¡å™¨çš„æŸ¥è¯¢ä¸€èˆ¬éƒ½æ˜¯é‡‡ç”¨é€’å½’æŸ¥è¯¢ï¼Œå¦‚æœä¸»æœºæ‰€è¯¢é—®çš„æœ¬åœ°åŸŸåæœåŠ¡å™¨ä¸çŸ¥é“è¢«æŸ¥è¯¢åŸŸåçš„IPåœ°å€æ—¶ï¼Œé‚£ä¹ˆæœ¬åœ°åŸŸåæœåŠ¡å™¨å°±ä¼šä»¥DNSå®¢æˆ·çš„èº«ä»½å‘å…¶å®ƒåŸŸåæœåŠ¡å™¨å‘é€æŸ¥è¯¢è¯·æ±‚ï¼Œå°±æ˜¯ä»£æ›¿ä¸»æœºç»§ç»­æŸ¥è¯¢ï¼›æœ¬åœ°åŸŸåæœåŠ¡å™¨å‘æ ¹åŸŸåæœåŠ¡å™¨çš„æŸ¥è¯¢é€šå¸¸æ˜¯é‡‡ç”¨è¿­ä»£æŸ¥è¯¢ï¼Œå½“æ ¹åŸŸåæœåŠ¡å™¨æ”¶åˆ°æœ¬åœ°åŸŸåæœåŠ¡å™¨å‘å‡ºçš„è¿­ä»£æŸ¥è¯¢è¯·æ±‚æŠ¥æ–‡æ—¶ï¼Œè¦ä¹ˆç»™å‡ºæ‰€è¦æŸ¥è¯¢çš„IPåœ°å€ï¼Œè¦ä¹ˆå‘Šè¯‰æœ¬åœ°åŸŸåæœåŠ¡å™¨ä¸‹ä¸€æ­¥åº”å½“å‘å“ªä¸€ä¸ªåŸŸåæœåŠ¡å™¨è¿›è¡ŒæŸ¥è¯¢ï¼Œç„¶åè®©æœ¬åœ°åŸŸåæœåŠ¡å™¨è¿›è¡Œåç»­çš„æŸ¥è¯¢ï¼ŒæŸ¥è¯¢åˆ°ç»“æœå°±ä¼šå›é€ç»™æºä¸»æœºã€‚ 1.6.3 DHCPDHCP å³åŠ¨æ€ä¸»æœºé…ç½®åè®®ï¼Œæ˜¯ç”¨ä¸å±€åŸŸç½‘çš„åè®®ï¼Œé‡‡ç”¨UDPè¿›è¡Œä¼ è¾“ï¼ŒæœåŠ¡ç«¯é‡‡ç”¨67ç«¯å£ï¼Œå®¢æˆ·ç«¯é‡‡ç”¨68ç«¯å£ã€‚ å®¢æˆ·ç«¯ä¼šä»¥å¹¿æ’­çš„å½¢å¼å‘é€ DHCP å‘ç°æŠ¥æ–‡ DHCP æœåŠ¡ç«¯æ”¶åˆ°ä¹‹åå°±ä¼šå‘é€ offer æŠ¥æ–‡ï¼Œå®¢æˆ·ç«¯åªèƒ½æ¥æ”¶ä¸€ä¸ª offer æŠ¥æ–‡ï¼Œé€šå¸¸åªæ¥æ”¶ç¬¬ä¸€ä¸ª å®¢æˆ·ç«¯å—åˆ° offer æŠ¥æ–‡ä¹‹åä¼šå‘é€ä¸€ä¸ªè¯·æ±‚æŠ¥æ–‡ï¼Œå­—æ®µä¸­åŒ…å«é€‰ä¸­çš„ DHCP åœ°å€å’Œ IP åœ°å€ DHCP æœåŠ¡ç«¯æ”¶åˆ°åä¼šåˆ¤æ–­å­—æ®µæ˜¯å¦ç›¸åŒï¼Œç›¸åŒå°±ä¼šç»™å‡ºä¸€ä¸ªç¡®è®¤æŠ¥æ–‡ï¼Œå¹¶æºå¸¦ IP åœ°å€å’Œç§ŸæœŸä¿¡æ¯ å®¢æˆ·ç«¯æ”¶åˆ°ç¡®è®¤æŠ¥æ–‡åå°±ä¼šæ£€æŸ¥æ˜¯å¦å¯ç”¨ï¼Œå¦‚æœä¸å¯ç”¨å°±ä¼šå‘é€ä¸€ä¸ªæŠ¥æ–‡é€šçŸ¥ DHCP æœåŠ¡ç«¯è¯¥åœ°å€ä¸å¯ç”¨ äºŒã€Linuxæ–¹é¢2.1 å‘½ä»¤ åŸºæœ¬å‘½ä»¤ï¼š æŸ¥çœ‹ç¡¬ä»¶ä¿¡æ¯ï¼šifconfigã€freeã€fdisk æŸ¥çœ‹ç³»ç»Ÿæ€§èƒ½ä¿¡æ¯ï¼štopã€psã€iostatã€lsofã€netstatã€dfã€mountã€umount ç³»ç»Ÿå®‰å…¨ç›¸å…³ï¼šchmodã€chownã€chgrpã€passwdã€suã€sudo ä¸‰å‰‘å®¢ï¼šgrepã€sedã€awk å…¶å®ƒï¼šlsã€llã€cdã€pwdã€rpmã€yumã€firewall-cmdã€dateã€clearã€echoã€rmã€touchã€mkdirã€mvã€cpã€findã€uniqã€sort 2.2 vim vimçš„ä¸‰ç§æ¨¡å¼ï¼š æ™®é€šæ¨¡å¼ï¼švim + æ–‡ä»¶åå³å¯è¿›å…¥æ™®é€šæ¨¡å¼ æ’å…¥æ¨¡å¼ï¼šæ™®é€šæ¨¡å¼ä¸‹è¾“å…¥iã€aã€oå³å¯è¿›å…¥æ’å…¥æ¨¡å¼ å‘½ä»¤æ¨¡å¼ï¼šè¾“å…¥ï¼šå³å¯è¿›å…¥å‘½ä»¤æ¨¡å¼ï¼Œè¾“å…¥Escé€€å‡ºå‘½ä»¤æ¨¡å¼ 2.3 Linuxè¿›ç¨‹ Linuxç³»ç»Ÿè¿›ç¨‹å¯ä»¥åˆ†ä¸ºï¼š äº¤äº’è¿›ç¨‹ï¼šç”±ä¸€ä¸ªshellç»ˆç«¯å¯åŠ¨çš„è¿›ç¨‹ï¼Œåœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œéœ€è¦ä¸ç”¨æˆ·è¿›è¡Œäº¤äº’æ“ä½œï¼Œå¯ä»¥è¿è¡Œäºå‰å°ï¼Œä¹Ÿå¯ä»¥è¿è¡Œåœ¨åå°ã€‚ æ‰¹å¤„ç†è¿›ç¨‹ï¼šè¯¥è¿›ç¨‹æ˜¯ä¸€ä¸ªè¿›ç¨‹é›†åˆï¼Œè´Ÿè´£æŒ‰é¡ºåºå¯åŠ¨å…¶ä»–çš„è¿›ç¨‹ã€‚ å®ˆæŠ¤è¿›ç¨‹ï¼šå®ˆæŠ¤è¿›ç¨‹æ˜¯ä¸€ç›´è¿è¡Œçš„ä¸€ç§è¿›ç¨‹ï¼Œç»å¸¸åœ¨Linuxç³»ç»Ÿå¯åŠ¨æ—¶å¯åŠ¨ï¼Œåœ¨ç³»ç»Ÿå…³é—­æ—¶ç»ˆæ­¢ã€‚ 2.4 run levelLinuxåœ¨å®Œæˆæ ¸å†…å¼•å¯¼ä»¥åï¼Œå°±å¼€å§‹è¿è¡Œinitç¨‹åºï¼ŒåŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªè¿è¡Œçº§ï¼š 0 ç³»ç»ŸåœæœºçŠ¶æ€ï¼Œç³»ç»Ÿé»˜è®¤è¿è¡Œçº§åˆ«ä¸èƒ½è®¾ä¸º0ï¼Œå¦åˆ™ä¸èƒ½æ­£å¸¸å¯åŠ¨ 1 å•ç”¨æˆ·å·¥ä½œçŠ¶æ€ï¼Œrootæƒé™ï¼Œç”¨äºç³»ç»Ÿç»´æŠ¤ï¼Œç¦æ­¢è¿œç¨‹ç™»é™† 2 å¤šç”¨æˆ·çŠ¶æ€(æ²¡æœ‰NFS) 3 å®Œå…¨çš„å¤šç”¨æˆ·çŠ¶æ€(æœ‰NFS)ï¼Œç™»é™†åè¿›å…¥æ§åˆ¶å°å‘½ä»¤è¡Œæ¨¡å¼ 4 ç³»ç»Ÿæœªä½¿ç”¨ï¼Œä¿ç•™ 5 ä»£è¡¨å›¾å½¢GUIæ¨¡å¼ 6 ç³»ç»Ÿæ­£å¸¸å…³é—­å¹¶é‡å¯ï¼Œé»˜è®¤è¿è¡Œçº§åˆ«ä¸èƒ½è®¾ä¸º6ï¼Œå¦åˆ™ä¸èƒ½æ­£å¸¸å¯åŠ¨ 2.5 æ ‡å‡†è¾“å…¥è¾“å‡ºå’Œé”™è¯¯è¾“å‡ºé‡å®šå‘ 0 ä»£è¡¨æ ‡å‡†è¾“å…¥ï¼Œå³stdinï¼ˆstandard inputï¼‰ 1 ä»£è¡¨æ ‡å‡†è¾“å‡ºï¼Œå³stdoutï¼ˆstandard outputï¼‰ 2 ä»£è¡¨æ ‡å‡†é”™è¯¯è¾“å‡ºï¼Œå³stderrï¼ˆstandard errorï¼‰ 2.6 Linuxç³»ç»Ÿå¯åŠ¨è¿‡ç¨‹ å†…æ ¸çš„å¼•å¯¼ï¼šå½“è®¡ç®—æœºæ‰“å¼€ç”µæºåï¼Œé¦–å…ˆæ˜¯BIOSå¼€æœºè‡ªæ£€ï¼ŒæŒ‰ç…§BIOSä¸­è®¾ç½®çš„å¯åŠ¨è®¾å¤‡ï¼ˆé€šå¸¸æ˜¯ç¡¬ç›˜ï¼‰æ¥å¯åŠ¨ã€‚æ“ä½œç³»ç»Ÿæ¥ç®¡ç¡¬ä»¶ä»¥åï¼Œé¦–å…ˆè¯»å…¥ /boot ç›®å½•ä¸‹çš„å†…æ ¸æ–‡ä»¶ã€‚ è¿è¡Œinitï¼šinit è¿›ç¨‹æ˜¯ç³»ç»Ÿæ‰€æœ‰è¿›ç¨‹çš„èµ·ç‚¹ï¼Œé¦–å…ˆæ˜¯éœ€è¦è¯»å–é…ç½®æ–‡ä»¶ /etc/inittabã€‚å¯åŠ¨æ—¶æ ¹æ®â€è¿è¡Œçº§åˆ«â€ï¼Œç¡®å®šè¦è¿è¡Œå“ªäº›ç¨‹åºã€‚ ç³»ç»Ÿåˆå§‹åŒ–ï¼šæ¿€æ´»äº¤æ¢åˆ†åŒºï¼Œæ£€æŸ¥ç£ç›˜ï¼ŒåŠ è½½ç¡¬ä»¶æ¨¡å—ä»¥åŠå…¶å®ƒä¸€äº›éœ€è¦ä¼˜å…ˆæ‰§è¡Œä»»åŠ¡ã€‚ å»ºç«‹ç»ˆç«¯ï¼šåŸºæœ¬ç³»ç»Ÿç¯å¢ƒå·²ç»è®¾ç½®å¥½äº†ï¼Œå„ç§å®ˆæŠ¤è¿›ç¨‹ä¹Ÿå·²ç»å¯åŠ¨äº†ï¼Œinitæ¥ä¸‹æ¥ä¼šæ‰“å¼€6ä¸ªç»ˆç«¯ï¼Œä»¥ä¾¿ç”¨æˆ·ç™»å½•ç³»ç»Ÿï¼ŒåŒæ—¶å®ƒä¼šæ˜¾ç¤ºä¸€ä¸ªæ–‡æœ¬ç™»å½•ç•Œé¢ï¼Œåœ¨è¿™ä¸ªç™»å½•ç•Œé¢ä¸­ä¼šæç¤ºç”¨æˆ·è¾“å…¥ç”¨æˆ·åã€‚ ç”¨æˆ·ç™»é™†ç³»ç»Ÿï¼šå‘½ä»¤è¡Œç™»å½•ã€sshç™»å½•ã€å›¾å½¢ç•Œé¢ç™»å½•ã€‚ 2.7 iptables iptables çš„å·¥ä½œè¿‡ç¨‹ï¼šé‡‡ç”¨æ•°æ®åŒ…è¿‡æ»¤æœºåˆ¶å·¥ä½œï¼Œå½“é˜²ç«å¢™å—åˆ°æ•°æ®åŒ…æ—¶ï¼Œiptables æ˜¯ä¸€å±‚ä¸€å±‚è¿›è¡Œè¿‡æ»¤çš„ï¼Œè§„åˆ™é¡ºåºä»ä¸Šåˆ°ä¸‹ï¼Œä»å‰åˆ°åè¿›è¡Œè¿‡æ»¤ï¼Œå³åŒ¹é…äº†ä¸Šé¢çš„è§„åˆ™ï¼Œé‚£ä¹ˆå°±ä¸ä¼šåŒ¹é…ä¸‹é¢çš„è§„åˆ™äº†ï¼Œå¦‚æœæ‰€æœ‰è§„åˆ™éƒ½ä¸èƒ½åŒ¹é…ï¼Œå°±ä½¿ç”¨é»˜è®¤è§„åˆ™ã€‚ å››è¡¨ï¼ˆtablesï¼‰ï¼š filterï¼šè¿›è¡ŒåŒ…è¿‡æ»¤å¤„ç† natï¼šå¯¹æ•°æ®åœ°å€ä¿¡æ¯å’Œæ•°æ®åŒ…ç«¯å£ä¿¡æ¯è¿›è¡Œè½¬æ¢ mangleï¼šå¯¹æ•°æ®åŒ…ä¿¡æ¯è¿›è¡Œæ ‡è®° rawï¼šå°†æ•°æ®åŒ…ä¸€äº›æ ‡è®°ä¿¡æ¯è¿›è¡Œæ‹†è§£ äº”é“¾ï¼ˆchainsï¼‰ï¼š inputï¼šè¿‡æ»¤è¿›å…¥ä¸»æœºçš„æ•°æ®åŒ… forwardï¼šå¤„ç†ç»è¿‡ä¸»æœºçš„æ•°æ®åŒ…ï¼Œä¸ nat è¡¨æœ‰å…³ outputï¼šå¤„ç†ä»ä¸»æœºå‘å‡ºçš„æ•°æ®åŒ… preroutingï¼šæ•°æ®åŒ…åˆ°è¾¾é˜²ç«å¢™æ—¶è¿›è¡Œåˆ†è·¯ç”±åˆ¤æ–­ä¹‹å‰æ‰§è¡Œçš„è§„åˆ™ï¼Œæ”¹å˜æ•°æ®åŒ…çš„ç›®çš„åœ°å€ã€ç›®çš„ç«¯å£ postroutingï¼šæ•°æ®åŒ…ç¦»å¼€é˜²ç«å¢™æ—¶è¿›è¡Œåˆ†è·¯ç”±åˆ¤æ–­ä¹‹å‰æ‰§è¡Œçš„è§„åˆ™ï¼Œæ”¹å˜æ•°æ®åŒ…çš„ç›®çš„åœ°å€ã€ç›®çš„ç«¯å£ ä¸‰ã€å…¶å®ƒ3.1 Nginxå’ŒApache nginxå’Œapacheçš„åŒºåˆ«ï¼š nginxå’Œapacheéƒ½æ˜¯webæœåŠ¡å™¨ï¼Œä½†ä¸¤è€…é€‚åº”çš„åœºæ™¯ä¸åŒï¼Œä¹Ÿå°±æ˜¯ä¸¤è€…ä¸“æ³¨äºè§£å†³ä¸åŒçš„é—®é¢˜ã€‚ nginxï¼šé«˜å¹¶å‘å¤„ç†èƒ½åŠ›å¼ºï¼Œæ“…é•¿å¤„ç†é™æ€è¯·æ±‚ã€åå‘ä»£ç†ã€è´Ÿè½½å‡è¡¡ï¼›åŠ¨æ€è¯·æ±‚å¤„ç†èƒ½åŠ›ä¸å¼ºã€‚ apacheï¼šç¨³å®šã€å¯¹åŠ¨æ€è¯·æ±‚å¤„ç†å¼ºï¼Œrewriteèƒ½åŠ›æ¯”nginxå¼ºï¼Œæ¨¡å—å¤šï¼Œbugç›¸å¯¹è¾ƒå°‘ï¼›ä½†ä¸æ“…é•¿é«˜å¹¶å‘å¤„ç†ï¼Œè€—è´¹çš„èµ„æºè¾ƒå¤šã€‚ 3.2 æ­£å‘ä»£ç†å’Œåå‘ä»£ç† æ­£å‘ä»£ç†ï¼šæ­£å‘ä»£ç†æ˜¯ä¸€ä¸ªä½äºå®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨ä¹‹é—´çš„ä»£ç†æœåŠ¡å™¨ã€‚ä¸ºäº†ä»æœåŠ¡å™¨å–å¾—å†…å®¹ï¼Œå®¢æˆ·ç«¯å‘ä»£ç†æœåŠ¡å™¨å‘é€ä¸€ä¸ªè¯·æ±‚ï¼Œå¹¶ä¸”æŒ‡å®šç›®æ ‡æœåŠ¡å™¨ï¼Œä¹‹åä»£ç†æœåŠ¡å™¨å‘ç›®æ ‡æœåŠ¡å™¨è½¬å‘å¹¶ä¸”å°†è·å¾—çš„å†…å®¹è¿”å›ç»™å®¢æˆ·ç«¯ã€‚æ­£å‘ä»£ç†çš„æƒ…å†µä¸‹å®¢æˆ·ç«¯å¿…é¡»è¦è¿›è¡Œä¸€äº›ç‰¹åˆ«çš„è®¾ç½®æ‰èƒ½ä½¿ç”¨ã€‚ åå‘ä»£ç†ï¼šåå‘ä»£ç†æ­£ç›¸åï¼Œå¯¹äºå®¢æˆ·ç«¯æ¥è¯´ï¼Œä»£ç†æœåŠ¡å™¨å°±åƒæ˜¯ç›®æ ‡æœåŠ¡å™¨ï¼Œå®¢æˆ·ç«¯ä¸éœ€è¦åšç‰¹åˆ«çš„è®¾ç½®ã€‚å®¢æˆ·ç«¯å‘åå‘ä»£ç†æœåŠ¡å™¨å‘é€è¯·æ±‚ï¼Œåå‘ä»£ç†æœåŠ¡å™¨ä¼šè‡ªè¡Œåˆ¤æ–­ï¼Œå°†è¯·æ±‚è½¬å‘ç»™å†…éƒ¨çš„ç›®æ ‡æœåŠ¡å™¨ï¼Œå¹¶å°†å“åº”å›é€ç»™å®¢æˆ·ç«¯ï¼Œä½¿å¾—è¿™äº›å“åº”æ˜¯å®ƒè‡ªå·±çš„ä¸€æ ·ã€‚ æ­£å‘ä»£ç†å’Œåå‘ä»£ç†çš„åŒºåˆ«ï¼šæ­£å‘ä»£ç†éœ€è¦å®¢æˆ·ç«¯ä¸»åŠ¨è®¾ç½®ä»£ç†æœåŠ¡å™¨ipæˆ–è€…åŸŸåè¿›è¡Œè®¿é—®ï¼Œç”±è®¾ç½®çš„æœåŠ¡å™¨å»è·å–è®¿é—®å†…å®¹å¹¶è¿”å›ï¼›è€Œåå‘ä»£ç†ä¸éœ€è¦åšä»»ä½•è®¾ç½®ï¼Œç›´æ¥è®¿é—®æœåŠ¡å™¨çœŸå®ipæˆ–åŸŸåï¼Œä½†æ˜¯æœåŠ¡å™¨å†…éƒ¨ä¼šè‡ªåŠ¨æ ¹æ®è®¿é—®å†…å®¹è¿›è¡Œè·³è½¬åŠå†…å®¹è¿”å›ï¼Œå®¢æˆ·ç«¯ä¸çŸ¥é“å®ƒæœ€ç»ˆè®¿é—®çš„æ˜¯å“ªäº›æœºå™¨ã€‚ 3.3 è™šæ‹ŸåŒ–å’Œå®¹å™¨ è™šæ‹ŸåŒ–ï¼šé€šè¿‡æ¨¡æ‹Ÿè®¡ç®—æœºçš„ç¡¬ä»¶ï¼Œæ¥å®ç°åœ¨åŒä¸€å°è®¡ç®—æœºä¸ŠåŒæ—¶è¿è¡Œä¸åŒçš„æ“ä½œç³»ç»Ÿçš„æŠ€æœ¯ï¼Œå¸¸ç”¨çš„vmwareã€openstackã€kvméƒ½æ˜¯ä½¿ç”¨çš„è™šæ‹ŸåŒ–æŠ€æœ¯ã€‚ å®¹å™¨ï¼šå®¹å™¨å°±æ˜¯åœ¨éš”ç¦»ç¯å¢ƒè¿è¡Œçš„ä¸€ä¸ªè¿›ç¨‹ï¼Œå¦‚æœè¿›ç¨‹åœæ­¢ï¼Œå®¹å™¨å°±ä¼šé”€æ¯ã€‚éš”ç¦»çš„ç¯å¢ƒæ‹¥æœ‰è‡ªå·±çš„ç³»ç»Ÿæ–‡ä»¶ï¼ŒIPåœ°å€ï¼Œä¸»æœºåç­‰ è™šæ‹ŸåŒ–å’Œå®¹å™¨çš„åŒºåˆ«ï¼šè™šæ‹ŸåŒ–éœ€è¦ç¡¬ä»¶æ”¯æŒï¼Œéœ€è¦æ¨¡æ‹Ÿç¡¬ä»¶ï¼Œå¯ä»¥è¿è¡Œä¸åŒçš„æ“ä½œç³»ç»Ÿï¼Œå¯åŠ¨éœ€è¦èµ°å¼€æœºå¯åŠ¨æµç¨‹(åˆ†é’Ÿçº§)ï¼›å®¹å™¨å…±ç”¨å®¿ä¸»æœºå†…æ ¸ï¼Œç¬¬ä¸€ä¸ªè¿›ç¨‹ç›´æ¥å¯åŠ¨æœåŠ¡(nginxï¼Œmysqlç­‰)ï¼Œå¼€æœºç§’çº§ï¼Œè½»é‡ï¼ŒæŸè€—å°‘ã€‚ 3.4 CDN CDNå³å†…å®¹åˆ†å‘ç½‘ç»œï¼ŒåŸç†å°±æ˜¯é‡‡ç”¨å„ç§ç¼“å­˜æœåŠ¡å™¨ï¼Œå°†è¿™äº›ç¼“å­˜æœåŠ¡å™¨éƒ¨ç½²åˆ°ç”¨æˆ·è®¿é—®ç›¸å¯¹é›†ä¸­çš„åœ°åŒºï¼Œç”¨æˆ·è®¿é—®ç½‘ç«™æ—¶ï¼Œåˆ©ç”¨å…¨å±€è´Ÿè½½æŠ€æœ¯å°†ç”¨æˆ·çš„è®¿é—®æŒ‡å‘è·ç¦»æœ€è¿‘çš„å·¥ä½œæ­£å¸¸çš„ç¼“å­˜æœåŠ¡å™¨ä¸Šï¼Œç”±ç¼“å­˜æœåŠ¡å™¨ç›´æ¥å“åº”ç”¨æˆ·è¯·æ±‚ï¼Œä»è€Œæé«˜ç”¨æˆ·ä½“éªŒã€‚ CDNåŠŸèƒ½ï¼š èŠ‚çœéª¨å¹²ç½‘å¸¦å®½ï¼Œå‡å°‘å¸¦å®½éœ€æ±‚é‡ã€‚ æä¾›æœåŠ¡å™¨ç«¯åŠ é€Ÿï¼Œè§£å†³ç”±äºç”¨æˆ·è®¿é—®é‡å¤§é€ æˆçš„æœåŠ¡å™¨è¿‡è½½é—®é¢˜ã€‚ æœåŠ¡å•†èƒ½ä½¿ç”¨Web CacheæŠ€æœ¯åœ¨æœ¬åœ°ç¼“å­˜ç”¨æˆ·è®¿é—®è¿‡çš„Webé¡µé¢å’Œå¯¹è±¡ï¼Œå®ç°ç›¸åŒå¯¹è±¡çš„è®¿é—®æ— é¡»å ç”¨ä¸»å¹²çš„å‡ºå£å¸¦å®½ï¼Œå¹¶æé«˜ç”¨æˆ·è®¿é—®å› ç‰¹ç½‘é¡µé¢çš„ç›¸åº”æ—¶é—´çš„éœ€æ±‚ã€‚ èƒ½å…‹æœç½‘ç«™åˆ†å¸ƒä¸å‡çš„é—®é¢˜ï¼Œå¹¶ä¸”èƒ½é™ä½ç½‘ç«™è‡ªèº«å»ºè®¾å’Œç»´æŠ¤æˆæœ¬ã€‚ é™ä½â€œé€šä¿¡é£æš´â€çš„å½±å“ï¼Œæé«˜ç½‘ç»œè®¿é—®çš„ç¨³å®šæ€§ã€‚ 3.5 C/Så’ŒB/S C/Så’ŒB/Sçš„åŒºåˆ«ï¼š C/Så³Client/Serverï¼ˆå®¢æˆ·ç«¯/æœåŠ¡å™¨ï¼‰æ¶æ„ï¼Œæ˜¯ä¸€ä¸ªå…¸å‹çš„ä¸¤å±‚æ¶æ„ã€‚é€šè¿‡å°†ä»»åŠ¡åˆç†åˆ†é…åˆ°å®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨ï¼Œé™ä½äº†ç³»ç»Ÿçš„é€šè®¯å¼€é”€ï¼Œéœ€è¦å®‰è£…å®¢æˆ·ç«¯æ‰å¯è¿›è¡Œç®¡ç†æ“ä½œã€‚ B/Så³å³Brower/Serverï¼ˆæµè§ˆå™¨/æœåŠ¡å™¨ï¼‰æ¶æ„ï¼Œç»Ÿä¸€äº†å®¢æˆ·ç«¯ï¼Œæ— éœ€ç‰¹æ®Šå®‰è£…ï¼Œæ‹¥æœ‰Webæµè§ˆå™¨å³å¯ï¼›å®ƒå°†ç³»ç»ŸåŠŸèƒ½å®ç°çš„æ ¸å¿ƒéƒ¨åˆ†é›†ä¸­åˆ°æœåŠ¡å™¨ä¸Šï¼Œç®€åŒ–äº†ç³»ç»Ÿçš„å¼€å‘ã€ç»´æŠ¤å’Œä½¿ç”¨ã€‚ 3.6 è¾“å…¥ä¸€ä¸ªç½‘å€åå‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ DNSè§£æï¼Œä¼šæ ¹æ®è¾“å…¥çš„URLæŸ¥æ‰¾å¯¹åº”çš„IP é¦–å…ˆæŸ¥æ‰¾æœ¬åœ°æµè§ˆå™¨ç¼“å­˜ï¼Œæµè§ˆå™¨ä¼šä¿å­˜è¿‘æœŸè®¿é—®è¿‡çš„ä¸€äº›åœ°å€çš„DNSä¿¡æ¯ã€‚ å¦‚æœæµè§ˆå™¨ç¼“å­˜æ²¡æœ‰ï¼Œä¼šå°è¯•è°ƒç”¨ç³»ç»Ÿç¼“å­˜å’Œ host æ–‡ä»¶æŸ¥æ‰¾DNSä¿¡æ¯ã€‚ å¦‚æœç³»ç»Ÿç¼“å­˜æ²¡æœ‰ï¼Œå°±ä¼šå‘é€è¯·æ±‚åˆ°è·¯ç”±å™¨ä¸Šï¼ŒæŸ¥æ‰¾è·¯ç”±å™¨ç¼“å­˜ä¸­çš„DNSä¿¡æ¯ã€‚ å¦‚æœè·¯ç”±å™¨æ²¡æœ‰ï¼Œå°±ä¼šå‘é€è¯·æ±‚åˆ°æœ¬åœ°åŸŸåæœåŠ¡å™¨ï¼ŒæŸ¥æ‰¾æ–¹å¼ä¸ºé€’å½’æŸ¥æ‰¾ã€‚ å¦‚æœæœ¬åœ°åŸŸåæœåŠ¡å™¨æ²¡æœ‰ï¼Œå°±ä¼šå‘æ ¹åŸŸåæœåŠ¡å™¨æŸ¥æ‰¾ï¼ŒæŸ¥æ‰¾æ–¹å¼ä¸ºè¿­ä»£æŸ¥æ‰¾ã€‚ æœ€åå°±æ˜¯æµè§ˆå™¨å¾—åˆ°äº†å¯¹åº”çš„IPï¼Œæˆ–è€…æ²¡æœ‰ï¼Œå³è¿™ä¸ªURLä¸å­˜åœ¨ã€‚ TCPè¿æ¥ï¼Œæµè§ˆå™¨å‘ç›®æ ‡æœåŠ¡å™¨è¿›è¡ŒTCPä¸‰æ¬¡æ¡æ‰‹è¿æ¥ æµè§ˆå™¨å‘é€HTTPè¯·æ±‚ æœåŠ¡å™¨å“åº”HTTPè¯·æ±‚ æµè§ˆå™¨æ”¶åˆ°å“åº”åï¼Œè§£ææ¸²æŸ“é¡µé¢ å…³é—­TCPè¿æ¥ 3.7 è¿›ç¨‹å’Œçº¿ç¨‹çš„åŒºåˆ« è¿›ç¨‹ï¼šè¿›ç¨‹æ˜¯æ“ä½œç³»ç»Ÿèµ„æºåˆ†é…çš„æœ€å°å•ä½ï¼Œæ¯ä¸ªè¿›ç¨‹éƒ½æœ‰ç‹¬ç«‹çš„ä»£ç å’Œæ•°æ®ç©ºé—´ï¼ˆè¿›ç¨‹ä¸Šä¸‹æ–‡ï¼‰ï¼Œè¿›ç¨‹é—´çš„åˆ‡æ¢ä¼šæœ‰è¾ƒå¤§çš„å¼€é”€ï¼Œä¸€ä¸ªè¿›ç¨‹åŒ…å«1â€“nä¸ªçº¿ç¨‹ã€‚ çº¿ç¨‹ï¼šçº¿ç¨‹æ˜¯ CPU ç‹¬ç«‹è°ƒåº¦çš„æœ€å°å•ä½ï¼ŒåŒä¸€ç±»çº¿ç¨‹å…±äº«ä»£ç å’Œæ•°æ®ç©ºé—´ï¼Œæ¯ä¸ªçº¿ç¨‹æœ‰ç‹¬ç«‹çš„è¿è¡Œæ ˆå’Œç¨‹åºè®¡æ•°å™¨(PC)ï¼Œçº¿ç¨‹åˆ‡æ¢å¼€é”€å°ã€‚ çº¿ç¨‹å’Œè¿›ç¨‹çš„ç”Ÿå‘½å‘¨æœŸï¼šæ–°å»ºã€å°±ç»ªã€è¿è¡Œã€é˜»å¡ã€æ­»äº¡ã€‚ 3.8 è½¯è¿æ¥å’Œç¡¬é“¾æ¥çš„åŒºåˆ« è½¯è¿æ¥ï¼š ç±»ä¼¼äºå¿«æ·æ–¹å¼ å¯ä»¥è·¨æ–‡ä»¶ç³»ç»Ÿ å¯ä»¥å¯¹ä¸€ä¸ªä¸å­˜åœ¨çš„æ–‡ä»¶åè¿›è¡Œé“¾æ¥ï¼Œç¡¬é“¾æ¥å¿…é¡»è¦æœ‰æºæ–‡ä»¶ å¯ä»¥å¯¹ç›®å½•è¿›è¡Œé“¾æ¥ ç¡¬è¿æ¥ï¼š ä»¥æ–‡ä»¶å‰¯æœ¬çš„å½¢å¼å­˜åœ¨ï¼Œä½†ä¸å ç”¨å®é™…ç©ºé—´ ä¸å…è®¸ç»™ç›®å½•åˆ›å»ºç¡¬é“¾æ¥ åªæœ‰åœ¨åŒä¸€ä¸ªæ–‡ä»¶ç³»ç»Ÿä¸­æ‰èƒ½åˆ›å»º åˆ é™¤å…¶ä¸­ä¸€ä¸ªç¡¬é“¾æ¥æ–‡ä»¶å¹¶ä¸å½±å“å…¶ä»–æœ‰ç›¸åŒ inode å·çš„æ–‡ä»¶ 3.9 Dos å’Œ DDos Dos å³æ‹’ç»æœåŠ¡ï¼Œå°±æ˜¯å‘ç›®æ ‡æœåŠ¡å™¨å‘é€å¤§é‡çš„è™šæ‹Ÿ ip è¯·æ±‚ï¼Œè¢«æ”»å‡»çš„æœåŠ¡å™¨åœ¨æ”¶åˆ°è¯·æ±‚åè¿”å›ç¡®è®¤ä¿¡æ¯ï¼Œç­‰å¾…æ”»å‡»è€…ç¡®è®¤ï¼Œä½†ç”±äºè¯·æ±‚çš„æ˜¯è™šæ‹Ÿ ipï¼ŒæœåŠ¡å™¨æ”¶ä¸åˆ°å›å¤ï¼Œé‚£ä¹ˆåœ¨ä¸€æ®µæ—¶é—´å†…æœåŠ¡å™¨ä¼šå¤„äºç­‰å¾…çš„çŠ¶æ€ï¼Œåˆ†é…ç»™è™šæ‹Ÿ ip è¯·æ±‚çš„èµ„æºä¹Ÿæ²¡æœ‰é‡Šæ”¾ï¼Œæ”»å‡»è€…ç­‰å¾…ä¸€æ®µæ—¶é—´ä¼šå› è¿æ¥è¶…æ—¶è€Œæ–­å¼€ï¼Œæ¥ç€å†å‘é€å¤§é‡æ–°çš„è¯·æ±‚ï¼Œä¸æ–­æ¶ˆè€—æœåŠ¡å™¨èµ„æºï¼Œæœ€ç»ˆå¯¼è‡´ç˜«ç—ªã€‚ DDos å³åˆ†å¸ƒå¼æ‹’ç»æœåŠ¡ï¼ŒDos æ”»å‡»æ˜¯å•æœºä¸å•æœºä¹‹é—´çš„æ”»å‡»æ¨¡å¼ï¼Œè€Œ DDos æ˜¯åˆ©ç”¨ä¸€æ‰¹åƒµå°¸ä¸»æœºå‘æœåŠ¡å™¨åŒæ—¶å‘é€æ”»å‡»çš„æ¨¡å¼ã€‚ 3.10 å››å±‚è´Ÿè½½å‡è¡¡å’Œä¸ƒå±‚è´Ÿè½½å‡è¡¡ å››å±‚è´Ÿè½½å‡è¡¡ï¼šä¸»è¦æ˜¯é€šè¿‡ç½‘ç»œå±‚å’Œä¼ è¾“å±‚çš„æµé‡æ¥å®ç°åŸºäº IP åŠ ç«¯å£çš„è´Ÿè½½å‡è¡¡ ä¸ƒå±‚è´Ÿè½½å‡è¡¡ï¼šæ˜¯åŸºäºåº”ç”¨å±‚çš„è´Ÿè½½å‡è¡¡ï¼Œæ”¯æŒå„ç§åº”ç”¨å±‚åè®® 3.11 cookie session token cookieï¼šç”±æœåŠ¡å™¨ç”Ÿæˆï¼Œå­˜å‚¨åœ¨æµè§ˆå™¨ä¸­ï¼Œç”¨äºä¿å­˜å®¢æˆ·ç™»å½•ç­‰ä¿¡æ¯ sessionï¼šç”±æœåŠ¡å™¨ç»™æµè§ˆå™¨ç”Ÿæˆçš„èº«ä»½æ ‡è¯†ï¼Œç”¨äºåŒºåˆ†ä¸åŒå®¢æˆ·ç«¯ tokenï¼šç”±æœåŠ¡å™¨äº§ç”Ÿï¼Œå¦‚æœå®¢æˆ·ç«¯é€šè¿‡ç”¨æˆ·åå’Œå¯†ç è¯·æ±‚è®¤è¯ä¸”è®¤è¯æˆåŠŸï¼Œé‚£ä¹ˆæœåŠ¡ç«¯å°±ä¼šå‘é€ä¸€ä¸ª token ç»™å›å®¢æˆ·ç«¯ï¼Œå®¢æˆ·ç«¯æ¯æ¬¡è¯·æ±‚éƒ½å¯ä»¥å¸¦ä¸Š token æ¥è¯æ˜è‡ªå·±çš„åˆæ³•åœ°ä½ 3.12 CPUä¸Šä¸‹æ–‡Linux æ˜¯ä¸€ä¸ªæ”¯æŒå¤šä»»åŠ¡çš„æ“ä½œç³»ç»Ÿï¼Œæ”¯æŒè¿œå¤§äº CPU æ•°é‡çš„ä»»åŠ¡åŒæ—¶è¿è¡Œï¼Œå…¶å®è¿™äº›ä»»åŠ¡ä¸æ˜¯çœŸæ­£åœ¨åŒæ—¶è¿è¡Œï¼Œè€Œæ˜¯ç³»ç»Ÿåœ¨å¾ˆçŸ­æ—¶é—´å†…ï¼Œå°† CPU è½®æµåˆ†é…ç»™å®ƒä»¬ï¼Œé€Ÿåº¦æå¿«é€ æˆäº†åƒæ˜¯åœ¨åŒæ—¶è¿è¡Œçš„é”™è§‰ã€‚è€Œæ¯ä¸ªä»»åŠ¡åœ¨è¿è¡Œå‰ï¼ŒCPU éƒ½éœ€è¦çŸ¥é“ä»»åŠ¡ä»å“ªé‡ŒåŠ è½½ã€ä»å“ªé‡Œè¿è¡Œï¼Œä¹Ÿå°±æ˜¯éœ€è¦ç³»ç»Ÿä¸ºå®ƒä»¬è®¾ç½®å¥½ CPU å¯„å­˜å™¨å’Œç¨‹åºè®¡æ•°å™¨ã€‚ CPU å¯„å­˜å™¨ï¼šæ˜¯ CPU å†…ç½®çš„å®¹é‡å¾ˆå°ä½†é€Ÿåº¦æå¿«çš„å†…å­˜ã€‚ ç¨‹åºè®¡æ•°å™¨ï¼šç”¨æ¥å­˜å‚¨ CPU æ­£åœ¨æ‰§è¡Œçš„æŒ‡ä»¤ä½ç½®ï¼Œæˆ–è€…å³å°†æ‰§è¡Œçš„ä¸‹ä¸€æ¡æŒ‡ä»¤ä½ç½®ã€‚ CPU å¯„å­˜å™¨å’Œç¨‹åºè®¡æ•°å™¨éƒ½æ˜¯ CPU åœ¨è¿è¡Œä»»ä½•ä»»åŠ¡å‰ï¼Œå¿…é¡»ä¾èµ–çš„ç¯å¢ƒï¼Œå°±è¢«ç§°ä¸º CPU ä¸Šä¸‹æ–‡ã€‚ CPU ä¸Šä¸‹æ–‡åˆ‡æ¢å°±æ˜¯æŒ‡æŠŠå…ˆå‰ä¸€ä¸ªä»»åŠ¡çš„ CPU ä¸Šä¸‹æ–‡ï¼ˆCPU å¯„å­˜å™¨å’Œç¨‹åºè®¡æ•°å™¨çš„ä½ç½®ï¼‰ä¿å­˜èµ·æ¥ï¼Œå†åŠ è½½æ–°ä»»åŠ¡çš„ä¸Šä¸‹æ–‡åˆ°è¿™äº›å¯„å­˜å™¨å’Œè®¡æ•°å™¨ï¼Œæœ€åå†è·³è½¬åˆ°ç¨‹åºè®¡æ•°å™¨æ‰€æŒ‡çš„æ–°ä½ç½®ï¼Œè¿è¡Œæ–°ä»»åŠ¡ã€‚è€Œä¿å­˜ä¸‹æ¥çš„ä¸Šä¸‹æ–‡ï¼Œä¼šå­˜å‚¨åœ¨ç³»ç»Ÿå†…æ ¸ä¸­ï¼Œå¹¶åœ¨ä»»åŠ¡é‡æ–°è°ƒåº¦æ‰§è¡Œæ—¶å†åŠ è½½è¿›æ¥ï¼Œè¿™æ ·å°±èƒ½ä¿è¯ä»»åŠ¡åŸæ¥çš„çŠ¶æ€ä¸å—å½±å“ï¼Œè®©ä»»åŠ¡çœ‹èµ·æ¥åƒæ˜¯è¿ç»­è¿è¡Œã€‚ è¿›ç¨‹ä¸Šä¸‹æ–‡åˆ‡æ¢ è¿›ç¨‹çš„è¿è¡Œç©ºé—´åˆ†ä¸ºå†…æ ¸ç©ºé—´å’Œç”¨æˆ·ç©ºé—´ï¼Œåˆ†åˆ«å¯¹åº” CPU ç‰¹æƒç­‰çº§çš„ Ring0 å’Œ Ring3ã€‚ å†…æ ¸ç©ºé—´ï¼ˆRing0ï¼‰å…·æœ‰æœ€é«˜æƒé™ï¼Œå¯ä»¥ç›´æ¥è®¿é—®æ‰€æœ‰èµ„æºï¼›ç”¨æˆ·ç©ºé—´ï¼ˆRing3ï¼‰åªèƒ½è®¿é—®å—é™èµ„æºï¼Œä¸èƒ½ç›´æ¥è®¿é—®ç³»ç»Ÿèµ„æºï¼Œå¿…é¡»é€šè¿‡ç³»ç»Ÿè°ƒç”¨é™·å…¥åˆ°å†…æ ¸æ‰å¯ä»¥ä½¿ç”¨ã€‚ æ‰€ä»¥è¯´è¿›ç¨‹å¯ä»¥åœ¨å†…æ ¸ç©ºé—´å’Œç”¨æˆ·ç©ºé—´è¿è¡Œï¼Œåœ¨å‰è€…è¿è¡Œè¢«ç§°ä¸ºå†…æ ¸æ€ï¼Œåè€…è¢«ç§°ä¸ºç”¨æˆ·æ€ã€‚ä»ç”¨æˆ·æ€åˆ°ç³»ç»Ÿæ€çš„è½¬å˜ï¼Œå°±éœ€è¦é€šè¿‡ç³»ç»Ÿè°ƒç”¨ï¼Œæ¯”å¦‚æŸ¥çœ‹æ–‡ä»¶å†…å®¹å°±è¦ä¾æ¬¡è°ƒç”¨ open()ã€read()ã€close()ã€‚åœ¨è¿™æœŸé—´å°±å‘ç”Ÿäº†ä¸Šä¸‹æ–‡åˆ‡æ¢ï¼ŒCPU å¯„å­˜å™¨é‡ŒåŸæ¥çš„ç”¨æˆ·æ€çš„æŒ‡ä»¤ä½ç½®éœ€å­˜èµ·æ¥ï¼Œç„¶åæ›´è¡Œä¸ºå†…æ ¸æ€æŒ‡ä»¤çš„æ–°ä½ç½®ï¼Œæœ€åè·³è½¬åˆ°å†…æ ¸æ€è¿è¡Œä»»åŠ¡ã€‚ç³»ç»Ÿè°ƒç”¨ç»“æŸåï¼ŒCPU å¯„å­˜å™¨éœ€è¦æ¢å¤åˆ°åŸæ¥ç”¨æˆ·æ€çš„æŒ‡ä»¤ä½ç½®ï¼Œæ‰€ä»¥ä¸€æ¬¡ç³»ç»Ÿè°ƒç”¨æ˜¯å‘ç”Ÿäº†ä¸¤æ¬¡ä¸Šä¸‹æ–‡åˆ‡æ¢ã€‚ä½†ç³»ç»Ÿè°ƒç”¨åˆå’Œè¿›ç¨‹ä¸Šä¸‹æ–‡åˆ‡æ¢ä¸å¤ªä¸€æ ·ï¼Œè¿›ç¨‹ä¸Šä¸‹æ–‡åˆ‡æ¢æ—¶ä¸€ä¸ªè¿›ç¨‹åˆ‡æ¢åˆ°å¦ä¸€ä¸ªè¿›ç¨‹è¿è¡Œï¼Œç³»ç»Ÿè°ƒç”¨æ˜¯åœ¨é€šè¿‡ä¸€ä¸ªè¿›ç¨‹ä¸Šè¿è¡Œçš„ï¼Œåè€…å¸¸è¢«ç§°ä¸ºç‰¹æƒæ¨¡å¼åˆ‡æ¢ã€‚ 3.13 Raid0 Raid1 Raid5 Raid6 Raid0ï¼šæœ€å°‘éœ€è¦ä¸€å—ç£ç›˜ï¼ŒåŸç†æ˜¯å°†å¤šä¸ªç£ç›˜ç»„æˆä¸€ä¸ªå¤§çš„ç£ç›˜ï¼Œè¯»å†™æ€§èƒ½å’Œå­˜å‚¨å®¹é‡éƒ½ä»¥ç£ç›˜æ•°é‡å€æ•°å¢åŠ ï¼Œæ•°æ®åœ¨å†™å…¥å‰éƒ½ä¼šè¿›è¡Œåˆ†ç‰‡çš„æ“ä½œï¼Œå­˜å…¥ä¸åŒçš„ç£ç›˜ä¸­ï¼Œè¯»å†™é€Ÿåº¦æ˜¯æ‰€æœ‰Raidç±»å‹ä¸­æœ€å¿«çš„ï¼Œå®¹é‡ä¹Ÿæ˜¯æœ€å¤§çš„ï¼Œä½†ä¹Ÿæ˜¯æœ€ä¸å®‰å…¨çš„ï¼Œå› ä¸ºåªè¦ä¸€å—ç£ç›˜åäº†æ•°æ®å°±ä¼šä¸¢å¤±ï¼Œä¸”æ— æ³•æ¢å¤ã€‚ Raid1ï¼šæœ€å°‘éœ€è¦ä¸¤å—ç£ç›˜ï¼Œç›¸å½“äºä¸€ä¸ªæ•°æ®å­˜åˆ°å¤šä¸ªç£ç›˜ä¸­ï¼Œåªè¦å‰©ä¸‹æœ€å°‘ä¸€å—ç£ç›˜æ•°æ®å°±ä¸ä¼šä¸¢å¤±ï¼Œæ˜¯æœ€å®‰å…¨çš„ï¼Œä½†ä¹Ÿæ˜¯æ€§èƒ½æœ€ä½çš„ï¼Œå°½ç®¡æœ‰100ä¸ª10Gçš„ç£ç›˜ç»„æˆRaid1ï¼Œå®¹é‡ä¹Ÿæ˜¯10Gï¼Œä¸”è¯»å†™é€Ÿåº¦å’Œä¸€å—ç£ç›˜æ—¶ä¸€æ ·ã€‚ Raid5ï¼šæœ€å°‘éœ€è¦ä¸‰å—ç£ç›˜ï¼Œæ¯å—ç£ç›˜1/3çš„ç©ºé—´ç”¨æ¥å­˜æ ¡éªŒä¿¡æ¯ï¼Œ2/3çš„ç©ºé—´ç”¨æ¥å­˜æ•°æ®ï¼Œä¸‰å—ç£ç›˜ç»„æˆRaid5çš„è¯å…è®¸åæ‰ä¸€å—ç£ç›˜ï¼Œå› ä¸ºå‰©ä¸‹ä¸¤å—ç£ç›˜ä¼šé€šè¿‡æ ¡éªŒä¿¡æ¯æ¥æ¢å¤æ•°æ®ï¼Œè¯»å†™é€Ÿåº¦å’Œå®‰å…¨æ€§æ˜¯å±äºæŠ˜ä¸­çš„ã€‚ Raid6ï¼šæœ€å°‘éœ€è¦å››å—ç£ç›˜ï¼Œæ¯”Raid5å¤šäº†ä¸€ä¸ªæ ¡éªŒä½ï¼Œæ‰€ä»¥å®‰å…¨æ€§æœ‰æ›´å¤§çš„æå‡ï¼Œå››å—ç£ç›˜ç»„æˆçš„Raid6å…è®¸åæ‰ä¸¤å—ç£ç›˜ï¼Œä½†ç›¸æ¯”åŸŸRaid5å†™çš„æ€§èƒ½å˜å¾—æ›´å·®ã€‚","link":"/2024/03/31/%E5%85%AB%E8%82%A1%E6%96%87%E9%9A%8F%E8%AE%B0%E5%BD%95/"},{"title":"Zookeeper","text":"ZooKeeper æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼çš„ï¼Œå¼€æ”¾æºç çš„åˆ†å¸ƒå¼åº”ç”¨ç¨‹åºåè°ƒæœåŠ¡ï¼Œæ˜¯ Hadoop å’Œ Hbase çš„é‡è¦ç»„ä»¶ã€‚å®ƒæ˜¯ä¸€ä¸ªä¸ºåˆ†å¸ƒå¼åº”ç”¨æä¾›ä¸€è‡´æ€§æœåŠ¡çš„è½¯ä»¶ï¼Œæä¾›çš„åŠŸèƒ½åŒ…æ‹¬ï¼šé…ç½®ç»´æŠ¤ã€åŸŸåæœåŠ¡ã€åˆ†å¸ƒå¼åŒæ­¥ã€ç»„æœåŠ¡ç­‰ã€‚ ä¸€ã€ZookeeperåŸºç¡€1.1 ä½¿ç”¨åœºæ™¯ åˆ†å¸ƒå¼åè°ƒç»„ä»¶ï¼šé€šè¿‡ watch æœºåˆ¶å¯ä»¥åè°ƒå¥½èŠ‚ç‚¹ä¹‹é—´çš„æ•°æ®ä¸€è‡´æ€§ åˆ†å¸ƒå¼é”ï¼šé€šè¿‡åˆ†å¸ƒå¼é”å¯ä»¥åšåˆ°å¼ºä¸€è‡´æ€§ æ— çŠ¶æ€åŒ–å®ç° è´Ÿè½½å‡è¡¡ æ•°æ®å‘å¸ƒ/è®¢é˜… å‘½åæœåŠ¡ 1.2 éƒ¨ç½²docker-compose.yaml 123456789101112version: '3.8'services: zookeeper: container_name: zk01 image: zookeeper:3.7.0 restart: always hostname: zk01 ports: - 2181:2181 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=zk01:2888:3888;2181 zoo.cfg 1234567891011121314151617181920dataDir=/datadataLogDir=/datalog# åŸºæœ¬æ—¶é—´é…ç½®ï¼ˆæ¯«ç§’ï¼‰tickTime=2000# åˆå§‹åŒ–è¿æ¥åˆ°leaderçš„æœ€å¤§æ—¶é•¿ï¼Œå•ä½ä¸ºå€æ•°ï¼Œå³åˆå§‹åŒ–æ—¶é—´ä¸ºtickTime * initLimitinitLimit=5# followerä¸leaderæ•°æ®åŒæ­¥çš„æœ€å¤§æ—¶é•¿syncLimit=2# ä¿å­˜æ•°æ®çš„å¿«ç…§æ•°é‡autopurge.snapRetainCount=3# è‡ªåŠ¨è§¦å‘æ¸…é™¤ä»»åŠ¡æ—¶é—´é—´éš”ï¼Œä»¥å°æ—¶ä¸ºå•ä½ï¼Œé»˜è®¤ä¸º0ï¼Œè¡¨ä¸æ¸…é™¤autopurge.purgeInterval=0# å®¢æˆ·ç«¯ä¸zkçš„æœ€å¤§å¹¶å‘è¿æ¥æ•°maxClientCnxns=60# å¼€å¯standaloneEnabledæ¨¡å¼ï¼Œå³ç‹¬ç«‹éƒ¨ç½²standaloneEnabled=true# å¼€å¯adminServeradmin.enableServer=true# 2181æ˜¯ä¸ºå®¢æˆ·ç«¯æä¾›çš„ç«¯å£server.1=zk01:2888:3888;2181 1.3 åŸºæœ¬å‘½ä»¤ å¯åŠ¨|å…³é—­|æŸ¥çœ‹çŠ¶æ€ 1zkServer.sh start|stop|status è¿›å…¥ zk 1zkCli.sh æŸ¥çœ‹å†…éƒ¨æ•°æ®ç»“æ„ 1ls [path] äºŒã€å†…éƒ¨æ•°æ®ç»“æ„2.1 æ˜¯å¦‚ä½•å­˜å‚¨æ•°æ®çš„Zookeeper ä¸­çš„æ•°æ®æ˜¯ä¿å­˜åœ¨èŠ‚ç‚¹ä¸Šçš„ï¼Œå³ znodeï¼Œå¤šä¸ª znode å°±æ„æˆä¸€ä¸ªæ ‘çš„ç»“æ„ã€‚ å¦‚å›¾ï¼Œa å’Œ b å°±æ˜¯ Zookeeper çš„ znodeï¼Œåˆ›å»º znode æ–¹å¼å¦‚ä¸‹ 12345create /[znode_name]# åˆ›å»ºèŠ‚ç‚¹å¹¶åˆ›å»ºä¸€ä¸ªæ•°æ®create /[znode_name] [data_name]# è·å–æ•°æ®get [znode_name] 2.2 znodeç»“æ„Zookeeper ä¸­çš„ zonodeï¼ŒåŒ…å«ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š dataï¼šä¿å­˜æ•°æ® aclï¼šæƒé™ cï¼šåˆ›å»ºæƒé™ wï¼šå†™æƒé™ rï¼šè¯»æƒé™ dï¼šåˆ é™¤æƒé™ aï¼šadmin ç®¡ç†è€…æƒé™ statï¼šæè¿°å½“å‰ znode çš„å…ƒæ•°æ® childï¼šå½“å‰èŠ‚ç‚¹çš„å­èŠ‚ç‚¹ 12345678910111213# æŸ¥çœ‹znodeè¯¦ç»†ä¿¡æ¯get -s /[znode_name]cZxid:åˆ›å»ºèŠ‚ç‚¹çš„äº‹åŠ¡IDctime:åˆ›å»ºèŠ‚ç‚¹æ—¶é—´mZxid:ä¿®æ”¹èŠ‚ç‚¹çš„äº‹åŠ¡IDmtime:ä¿®æ”¹èŠ‚ç‚¹æ—¶é—´pZxid:æ·»åŠ å’Œåˆ é™¤å­èŠ‚ç‚¹çš„äº‹åŠ¡IDcversion:å½“å‰èŠ‚ç‚¹çš„å­èŠ‚ç‚¹ç‰ˆæœ¬å·ï¼Œåˆå§‹å€¼ä¸º-1ï¼Œæ¯å¯¹è¯¥èŠ‚ç‚¹çš„å­èŠ‚ç‚¹è¿›è¡Œæ“ä½œï¼Œè¿™ä¸ªcversionéƒ½ä¼šè‡ªåŠ¨å¢åŠ dataVersion:æ•°æ®ç‰ˆæœ¬åˆè¯†ç‰ˆæœ¬ä¸º0ï¼Œæ¯å¯¹è¯¥èŠ‚ç‚¹çš„æ•°æ®è¿›è¡Œæ“ä½œï¼Œè¿™ä¸ªdataVersionéƒ½ä¼šè‡ªåŠ¨å¢åŠ aclVersion:æƒé™ç‰ˆæœ¬ephemeralOwne:å¦‚æœå½“å‰èŠ‚ç‚¹æ˜¯ä¸´æ—¶èŠ‚ç‚¹ï¼Œè¯¥å€¼æ˜¯å½“å‰èŠ‚ç‚¹çš„session idï¼Œå¦‚æœä¸æ˜¯ä¸´æ—¶èŠ‚ç‚¹åˆ™ä¸º0dataLength:æ•°æ®é•¿åº¦numChildren:è¯¥èŠ‚ç‚¹çš„å­èŠ‚ç‚¹ä¸ªæ•° 2.3 znodeç±»å‹ æŒä¹…èŠ‚ç‚¹ï¼šåœ¨ä¼šè¯ç»“æŸåä»ä¼šå­˜åœ¨ æŒä¹…åºå·èŠ‚ç‚¹ï¼šæ ¹æ®å…ˆåé¡ºåºï¼Œä¼šåœ¨ç»“ç‚¹ä¹‹åå¸¦ä¸Šä¸€ä¸ªæ•°å€¼ï¼Œé€‚ç”¨äºåˆ†å¸ƒå¼é”çš„åœºæ™¯ï¼ˆå•è°ƒé€’å¢ï¼‰ ä¸´æ—¶èŠ‚ç‚¹ï¼šä¼šè¯ç»“æŸåä¼šè‡ªåŠ¨åˆ é™¤ï¼Œé€‚ç”¨äºæ³¨å†Œä¸æœåŠ¡å‘ç°çš„åœºæ™¯ ä¸´æ—¶åºå·èŠ‚ç‚¹ï¼šè·ŸæŒä¹…åºå·èŠ‚ç‚¹ç›¸åŒï¼Œé€‚ç”¨äºåˆ†å¸ƒå¼é”çš„åœºæ™¯ å®¹å™¨èŠ‚ç‚¹ï¼šå½“å®¹å™¨èŠ‚ç‚¹ä¸­æ²¡æœ‰ä»»ä½•å­èŠ‚ç‚¹æ—¶ï¼Œè¯¥å®¹å™¨èŠ‚ç‚¹ä¼šè¢«å®šæœŸåˆ é™¤ï¼ˆ60sï¼‰ TTL èŠ‚ç‚¹ï¼šå¯ä»¥æŒ‡å®šèŠ‚ç‚¹çš„åˆ°æœŸæ—¶é—´ æŒä¹…åºå·èŠ‚ç‚¹åˆ›å»º 1create -s /[znode_name] ä¸´æ—¶èŠ‚ç‚¹åˆ›å»º 1create -e /[znode_name] ä¸´æ—¶åºå·èŠ‚ç‚¹åˆ›å»º 1create -e -s /[znode_name] å®¹å™¨èŠ‚ç‚¹åˆ›å»º 1create -c /[znode_name] TTL èŠ‚ç‚¹åˆ›å»º 12# é€šè¿‡ç³»ç»Ÿé…ç½®å¼€å¯zookeeper.extendedTypesEnabled=true æŒä¹…èŠ‚ç‚¹ æŒä¹…èŠ‚ç‚¹åœ¨åˆ›å»ºåæœåŠ¡ç«¯ä¼šå‘é€ä¸€ä¸ª session idï¼Œå¹¶ä¸€ç›´ä¿ç•™ç€ã€‚ ä¸´æ—¶èŠ‚ç‚¹ ä¸´æ—¶èŠ‚ç‚¹åœ¨åˆ›å»ºæ—¶åæœåŠ¡å™¨ä¹Ÿä¼šå‘é€ä¸€ä¸ª session idï¼Œåœ¨ä¼šè¯æŒç»­çš„è¿‡ç¨‹ä¸­å®¢æˆ·ç«¯ä¼šä¸æ–­å‘æœåŠ¡ç«¯ç»­çº¦ session id çš„æ—¶é—´ï¼Œå½“å®¢æˆ·ç«¯æ²¡æœ‰ç»§ç»­ç»­çº¦ï¼Œè€ŒæœåŠ¡ç«¯å†…éƒ¨çš„è®¡æ—¶å™¨åˆ°æœŸæ—¶ï¼Œå°±ä¼šå°†è¯¥ session id æ‰€å¯¹åº”çš„ znode å…¨éƒ¨åˆ é™¤ã€‚ 2.4 æŒä¹…åŒ–æœºåˆ¶Zookeeper çš„æ•°æ®æ˜¯è¿è¡Œåœ¨å†…å­˜ä¸­çš„ï¼Œæ‰€ä»¥æä¾›äº†ä¸¤ç§æŒä¹…åŒ–æœºåˆ¶ï¼š äº‹åŠ¡æ—¥å¿—ï¼šZookeeper å°†æ‰§è¡Œè¿‡çš„å‘½ä»¤ä»¥æ—¥å¿—çš„å½¢å¼å­˜å‚¨åœ¨ dataLogDir / dataDir ä¸­ï¼Œç±»ä¼¼äº redis çš„ AOF æ•°æ®å¿«ç…§ï¼šåœ¨ä¸€å®šæ—¶é—´é—´éš”å†…åšä¸€æ¬¡æ•°æ®å¿«ç…§ï¼Œå­˜å‚¨åœ¨å¿«ç…§æ–‡ä»¶ä¸­ï¼ˆsnapshotï¼‰ï¼Œç±»ä¼¼äº redis çš„RDB Zookeeper é€šè¿‡è¿™ä¸¤ç§æŒä¹…åŒ–æœºåˆ¶ï¼Œåœ¨æ¢å¤æ•°æ®æ—¶å…ˆå°†å¿«ç…§æ–‡ä»¶ä¸­çš„æ•°æ®æ¢å¤åˆ°å†…å­˜ä¸­ï¼Œå†ç”¨æ—¥å¿—æ–‡ä»¶ä¸­çš„æ•°æ®åšå¢é‡æ¢å¤ï¼Œå¯ä»¥å®ç°é«˜æ•ˆçš„æŒä¹…åŒ–ã€‚ ä¸‰ã€zkCliçš„ä½¿ç”¨ é€’å½’æŸ¥è¯¢ 1ls -R /[znode_name] åˆ é™¤èŠ‚ç‚¹ 1deleteall /[znode_name] ä¹è§‚é”åˆ é™¤ 1delete -v [version] /[znode_name] ç»™å½“å‰ä¼šè¯æ³¨å†Œç”¨æˆ·ï¼Œå¹¶åˆ›å»ºèŠ‚ç‚¹èµ‹äºˆè¯¥ç”¨æˆ·æƒé™ 12addauth digest [user]:[password]create /[znode_name] auth:[user]:[password]:[privileges] å››ã€åˆ†å¸ƒå¼é”åœ¨åˆ†å¸ƒå¼çš„ç¯å¢ƒä¸‹ï¼Œå¦‚æœåœ¨ä¸€ä¸ªèŠ‚ç‚¹å»ä¸Šäº†ä¸ªé”ï¼Œå½“è¯·æ±‚è¢«è´Ÿè½½å‡è¡¡åˆ†é…åˆ°äº†å…¶å®ƒèŠ‚ç‚¹ï¼Œé‚£ä¹ˆé”å°±æ— æ³•å½¢æˆäº’æ–¥ï¼Œæ‰€ä»¥èŠ‚ç‚¹ä¹‹é—´ä½¿ç”¨ Zookeeperï¼Œåšä¸€ä¸ªåè°ƒä¸­å¿ƒï¼Œå°†é”ä¸Šä¼ åˆ° Zookeeperï¼Œå…¶å®ƒèŠ‚ç‚¹è¦ç”¨åˆ°å°±å» Zookeeper æ‹¿è¿™ä¸ªé”ï¼Œè¿™å°±æ˜¯åˆ†å¸ƒå¼é”ã€‚ Zookeeper é”çš„åˆ†ç±»ï¼š è¯»é”ï¼šå¤§å®¶éƒ½å¯ä»¥è¯»ï¼Œå‰ææ˜¯ä¹‹å‰æ²¡æœ‰å†™é”ã€‚ï¼ˆè¯»é”æ¯”å–»æˆçº¦ä¼šï¼Œå¤§å®¶éƒ½æœ‰æœºä¼šå’Œå¥³ç¥çº¦ä¼šï¼Œçº¦ä¼šå‰ææ˜¯å¥³ç¥æ²¡ç»“å©šï¼‰ å†™é”ï¼šåªæœ‰å†™é”æ‰èƒ½å†™ï¼Œå‰ææ˜¯ä¸èƒ½æœ‰ä»»ä½•é”ã€‚ï¼ˆå†™é”æ¯”å–»æˆç»“å©šï¼Œç»“å©šååªæœ‰è€å…¬èƒ½å’Œå¥³ç¥çº¦ä¼šï¼Œç»“å©šå‰ææ˜¯å¥³ç¥å’Œå…¶ä»–äººçš„å…³ç³»æ–­å¹²å‡€äº†ï¼‰ 4.1 ä¸Šè¯»é” åˆ›å»ºä¸€ä¸ªä¸´æ—¶åºå·èŠ‚ç‚¹ï¼ŒèŠ‚ç‚¹æ•°æ®æ˜¯ readï¼Œè¡¨ç¤ºä¸ºè¯»é” è·å–å½“å‰ Zookeeper ä¸­åºå·æ¯”è‡ªå·±å°çš„æ‰€æœ‰èŠ‚ç‚¹ åˆ¤æ–­æœ€å°èŠ‚ç‚¹æ˜¯å¦ä¸ºè¯»é”ï¼š å¦‚æœæ˜¯è¯»é”ï¼šåˆ™ä¸Šé”å¤±è´¥ï¼Œå› ä¸ºå¦‚æœæœ€å°èŠ‚ç‚¹æ˜¯è¯»é”ï¼Œé‚£ä¹ˆåé¢å°±ä¸å¯èƒ½æœ‰å†™é”ï¼Œæ¥ç€ä¸ºæœ€å°èŠ‚ç‚¹è®¾ç½®ç›‘å¬ï¼ŒZookeeper çš„ watch æœºåˆ¶ä¼šåœ¨æœ€å°èŠ‚ç‚¹å‘ç”Ÿå˜åŒ–æ—¶é€šçŸ¥å½“å‰èŠ‚ç‚¹ï¼Œå†è¿›è¡Œåé¢çš„æ­¥éª¤ï¼Œè¢«ç§°ä¸ºé˜»å¡ç­‰å¾… å¦‚æœä¸æ˜¯è¯»é”ï¼šåˆ™ä¸Šé”æˆåŠŸ 4.2 ä¸Šå†™é” åˆ›å»ºä¸€ä¸ªä¸´æ—¶åºå·èŠ‚ç‚¹ï¼ŒèŠ‚ç‚¹æ•°æ®æ˜¯ writeï¼Œè¡¨ç¤ºä¸ºå†™é” è·å– Zookeeper ä¸­çš„æ‰€æœ‰èŠ‚ç‚¹ åˆ¤æ–­è‡ªå·±æ˜¯å¦ä¸ºæœ€å°èŠ‚ç‚¹ï¼š å¦‚æœæ˜¯ï¼šä¸Šé”æˆåŠŸ å¦‚æœä¸æ˜¯ï¼šè¯´æ˜å‰é¢è¿˜æœ‰é”ï¼Œæ‰€ä»¥ä¸Šé”å¤±è´¥ï¼Œæ¥ç€ç›‘å¬æœ€å°èŠ‚ç‚¹ï¼Œå¦‚æœæœ€å°èŠ‚ç‚¹å‘ç”Ÿå˜åŒ–ï¼Œåˆ™é‡æ–°è¿›è¡Œç¬¬äºŒæ­¥ ç¾Šç¾¤æ•ˆåº” å‡è®¾æœ‰ä¸€ç™¾ä¸ªè¯·æ±‚éƒ½æ˜¯è¦å»å†™é”ï¼Œé‚£ä¹ˆå°±ä¼šæœ‰ä¸€ç™¾ä¸ªè¯·æ±‚å»ç›‘å¬æœ€å°èŠ‚ç‚¹ï¼Œé‚£ä¹ˆ Zookeeper çš„å‹åŠ›å°±ä¼šéå¸¸å¤§ï¼Œè§£å†³æ–¹æ³•æ˜¯å°†è¿™ä¸€ç™¾ä¸ªè¯·æ±‚æŒ‰è¯·æ±‚é¡ºåºæ’åˆ—ï¼Œåä¸€ä¸ªè¯·æ±‚å»ç›‘å¬å‰ä¸€ä¸ªè¯·æ±‚å³å¯ï¼Œå®ç°é“¾å¼ç›‘å¬ã€‚ 4.3 watchæœºåˆ¶Zookeeper çš„ watch å¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªè§¦å‘å™¨ï¼Œå½“ç›‘æ§çš„ znode å‘ç”Ÿæ”¹å˜ï¼Œå°±ä¼šè§¦å‘ znode ä¸Šæ³¨å†Œçš„å¯¹åº”äº‹ä»¶ï¼Œè¯·æ±‚ watch çš„å®¢æˆ·ç«¯å°±ä¼šæ¥æ”¶åˆ°å¼‚æ­¥é€šçŸ¥ã€‚ zkCli.sh ä¸­ä½¿ç”¨ watch 1234567create /test# ä¸€æ¬¡æ€§ç›‘å¬ï¼Œç›‘å¬èŠ‚ç‚¹å†…å®¹get -w /test# ç›‘å¬ç›®å½•ï¼Œä½†æ‰€ç›‘å¬èŠ‚ç‚¹ä¸‹åˆ›å»ºå’Œåˆ é™¤å­èŠ‚ç‚¹ä¸ä¼šè§¦å‘ç›‘å¬ls -w /test# ä¸ä¸Šé¢ç›¸å¯¹ï¼Œéƒ½ä¼šè§¦å‘ç›‘å¬ls -R -w /test äº”ã€é›†ç¾¤éƒ¨ç½²Zookeeper çš„é›†ç¾¤è§’è‰²æœ‰ä¸‰ä¸ªï¼š Leaderï¼šå¤„ç†é›†ç¾¤æ‰€æœ‰äº‹åŠ¡çš„è¯·æ±‚ï¼Œé›†ç¾¤åªæœ‰ä¸€ä¸ª Leader Followerï¼šåªå¤„ç†è¯»è¯·æ±‚ï¼Œå‚ä¸ Leader é€‰ä¸¾ Observerï¼šåªå¤„ç†è¯»è¯·æ±‚ï¼Œæå‡é›†ç¾¤çš„æ€§èƒ½ï¼Œä½†ä¸èƒ½å‚ä¸ Leader é€‰ä¸¾ docker-compose.yaml 1234567891011121314151617181920212223242526272829303132333435363738version: '3.8'services: zk01: container_name: zk01 image: zookeeper:3.7.0 restart: always hostname: zk01 ports: - 2181:2181 environment: ZOO_MY_ID: 1 # 2888:ç”¨äºé›†ç¾¤å†…zkä¹‹é—´çš„é€šä¿¡ # 3888:ç”¨äºé€‰ä¸¾æŠ•ç¥¨ # 2181:å®¢æˆ·ç«¯ä½¿ç”¨ # è¦åˆ›å»ºobserveråˆ™åœ¨2181ç«¯å£ååŠ :observer ZOO_SERVERS: server.1=zk01:2888:3888;2181 server.2=zk02:2888:3888;2181 server.3=zk03:2888:3888;2181 zk02: container_name: zk02 image: zookeeper:3.7.0 restart: always hostname: zk02 ports: - 2182:2181 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zk01:2888:3888;2181 server.2=zk02:2888:3888;2181 server.3=zk03:2888:3888;2181 zk03: container_name: zk03 image: zookeeper:3.7.0 restart: always hostname: zk03 ports: - 2183:2181 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zk01:2888:3888;2181 server.2=zk02:2888:3888;2181 server.3=zk03:2888:3888;2181 é€šè¿‡å‘½ä»¤æŸ¥çœ‹èŠ‚ç‚¹è§’è‰² 12zkServer.sh statusMode: leader è¿æ¥é›†ç¾¤ 1zkCli.sh -server zk01:2181,zk02:2181,zk03:2181 5.1 ZABåè®®ZABï¼ˆZookeeper Atomic Broadcastï¼‰å³ Zookeeper åŸå­å¹¿æ’­åè®®ï¼Œé€šè¿‡è¿™ä¸ªåè®®è§£å†³äº†é›†ç¾¤æ•°æ®ä¸€è‡´æ€§å’Œå´©æºƒæ¢å¤çš„é—®é¢˜ã€‚ ZAB åè®®ä¸­èŠ‚ç‚¹çš„å››ç§çŠ¶æ€ Lookingï¼šé€‰ä¸¾çŠ¶æ€ Following Leading Observing åˆå§‹åŒ–é›†ç¾¤æ—¶ leader çš„é€‰ä¸¾ å½“é›†ç¾¤ä¸­ä¸¤å°èŠ‚ç‚¹å¯åŠ¨æ—¶ï¼Œå°±ä¼šå¼€å§‹ leader çš„é€‰ä¸¾ï¼Œé€‰ç¥¨çš„æ ¼å¼ä¸º (myid,zXid) ç¬¬ä¸€è½®æŠ•ç¥¨æ—¶ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä¼šç”Ÿæˆè‡ªå·±çš„é€‰ç¥¨ï¼Œå³è‡ªå·±çš„ (myid,zXid)ï¼Œç„¶åå°†é€‰ç¥¨ç»™åˆ°å¯¹æ–¹ï¼Œè¿™æ—¶å€™æ¯ä¸ªèŠ‚ç‚¹å°±ä¼šæœ‰ä¸¤å¼ é€‰ç¥¨ï¼Œå³è‡ªå·±çš„å’Œå¯¹æ–¹èŠ‚ç‚¹çš„ æ¥ç€å°±ä¼šæ¯”è¾ƒä¸¤å¼ é€‰ç¥¨çš„ zXidï¼Œå¦‚æœéƒ½ç›¸åŒå°±å¯¹æ¯” myidï¼Œå°†å¤§çš„ä¸€ç¥¨æŠ•åˆ°æŠ•ç¥¨ç®±ä¸­ ç¬¬äºŒè½®æŠ•ç¥¨æ—¶ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä¼šå°†ä¸Šä¸€è½®æŠ•å‡ºå»çš„é€‰ç¥¨ç»™åˆ°å…¶å®ƒèŠ‚ç‚¹ï¼Œç„¶åå†å¯¹æ¯” (myid,zXid)ï¼Œå°†å¤§çš„ä¸€ç¥¨æŠ•å‡ºå»ï¼Œå°±èƒ½å¤Ÿé€‰å‡º leader åæ¥æ–°å¯åŠ¨çš„èŠ‚ç‚¹ä¼šå‘ç°å·²ç»æœ‰ leaderäº†ï¼Œå°±ä¸ç”¨åšé€‰ä¸¾çš„è¿‡ç¨‹äº† å¯ä»¥çœ‹å‡ºåˆå§‹åŒ–é›†ç¾¤æ—¶ï¼Œleader çš„é€‰ä¸¾ä¸»è¦çœ‹ myid å´©æºƒæ¢å¤æ—¶çš„ leader é€‰ä¸¾ åœ¨ leader ç¡®å®šäº†ä¹‹åï¼Œleader ä¼šå‘¨æœŸæ€§åœ°å‘ follower å‘é€å¿ƒè·³åŒ…ï¼Œå½“ follower æ²¡æœ‰æ”¶åˆ° leader å‘é€è¿‡æ¥çš„å¿ƒè·³åŒ…ï¼Œå°±ä¼šè¿›å…¥é€‰ä¸¾è¿‡ç¨‹ï¼Œè¿™æ—¶å€™é›†ç¾¤ä¸èƒ½å¯¹å¤–æä¾›æœåŠ¡ã€‚ å½“ leader æŒ‚äº†ä¹‹åï¼Œfollower çš„çŠ¶æ€ä¼šå˜æˆ looking æ¥ç€å°±è¿›è¡Œé€‰ä¸¾æŠ•ç¥¨ï¼Œè¿‡ç¨‹å’Œåˆå§‹åŒ–é›†ç¾¤æ—¶ä¸€æ · 5.2 ä¸»ä»åŒæ­¥åŸç† 5.3 NIOå’ŒBIONIO ç”¨äºè¢«å®¢æˆ·ç«¯è¿æ¥çš„ 2181 ç«¯å£ï¼Œä½¿ç”¨çš„å°±æ˜¯ NIO çš„è¿æ¥æ¨¡å¼ï¼›å®¢æˆ·ç«¯å¼€å¯ watch æ—¶ï¼Œä½¿ç”¨çš„ä¹Ÿæ˜¯ NIOã€‚ BIO é›†ç¾¤åœ¨è¿›è¡Œé€‰ä¸¾æ—¶ï¼Œå¤šä¸ªèŠ‚ç‚¹ä¹‹é—´çš„é€šä¿¡ç«¯å£ï¼Œä½¿ç”¨çš„æ˜¯ BIO çš„è¿æ¥æ¨¡å¼ã€‚","link":"/2024/02/18/zookeeper/"},{"title":"å…³é—­ NeuVector çš„ nvprotect æœºåˆ¶","text":"NeuVector æœ‰ä¸€ä¸ªåä¸º nvprotect çš„å†…éƒ¨ä¿æŠ¤æœºåˆ¶ï¼Œç”¨äºé™åˆ¶ç”¨æˆ·å¯¹ NeuVector pod çš„è®¿é—®æƒé™ã€‚ ä¾‹å¦‚ shã€ls ç­‰å‘½ä»¤æ˜¯æ— æ³•ä½¿ç”¨çš„ï¼š å¦‚æœéœ€è¦å…³é—­ï¼Œå¯ä»¥é€šè¿‡æ¥å£è¿›è¡Œå…³é—­ï¼Œæ­¤å¤„æä¾›è„šæœ¬ï¼Œæ”¯æŒå…³é—­ Controllerã€Scannerã€Enforcer çš„ nvprotectã€‚ ä½¿ç”¨æ–¹æ³•ï¼š 12345678910git clone https://github.com/warnerchen/disable-nvprotect.gitcd disable-nvprotectchmod +x script.sh# å…³é—­ nvprotect# å…³é—­ enforcer å³å¯åŒæ—¶å…³é—­ scanner çš„ nvprotect./script.sh off (controller|enforcer)# å¼€å¯ nvprotect./script.sh on (controller|enforcer)","link":"/2025/02/05/%E5%85%B3%E9%97%AD-NeuVector-%E7%9A%84-nvprotect-%E6%9C%BA%E5%88%B6/"},{"title":"å®¹å™¨ç½‘ç»œå®ç°","text":"å®¹å™¨çš„ç½‘ç»œæ˜¯åŸºäº linux çš„ç½‘ç»œå‘½åç©ºé—´(networke namespace)å’Œè™šæ‹Ÿç½‘ç»œè®¾å¤‡(veth pair)å®ç°çš„ã€‚","link":"/2024/03/18/%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E5%AE%9E%E7%8E%B0/"},{"title":"å¿«é€Ÿå®‰è£…containerdå’Œnerdctl","text":"è®°å½•èŠ‚ç‚¹å®‰è£… Containerd å’Œ Nerdctl æ­¥éª¤ã€‚ 1234567891011121314151617181920212223242526272829303132333435# Download# ç‰ˆæœ¬çµæ´»å˜åŠ¨export CONTAINERD_VERSION=1.7.13export CNI_PLUGIN_VERSION=v1.4.0export RUNC_VERSION=v1.1.11export NERDCTL_VERSION=1.7.4wget &quot;https://github.com/containerd/containerd/releases/download/v$CONTAINERD_VERSION/containerd-v$CONTAINERD_VERSION-linux-amd64.tar.gz&quot;wget &quot;https://github.com/containernetworking/plugins/releases/download/$CNI_PLUGIN_VERSION/cni-plugins-linux-amd64-$CNI_PLUGIN_VERSION.tgz&quot;wget &quot;https://github.com/opencontainers/runc/releases/download/$RUNC_VERSION/runc.amd64&quot;wget &quot;https://github.com/containerd/nerdctl/releases/download/v$NERDCTL_VERSION/nerdctl-$NERDCTL_VERSION-linux-amd64.tar.gz&quot;# Installtar -Czvxf /usr/local/bin containerd-$CONTAINERD_VERSION-linux-amd64.tar.gzmv /usr/local/bin/bin/* /usr/local/bin/ &amp;&amp; rm -rf /usr/local/bin/binmkdir -p /opt/cni/bin &amp;&amp; tar Czvxf /opt/cni/bin cni-plugins-linux-amd64-$CNI_PLUGIN_VERSION.tgzchmod 755 runc.amd64 &amp;&amp; mv runc.amd64 /usr/local/bin/runctar Czvxf /usr/local/bin nerdctl-$NERDCTL_VERSION-linux-amd64.tar.gz # Configmkdir /etc/containerdcontainerd config default &gt; /etc/containerd/config.tomlvim /etc/containerd/config.toml[plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors] [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors.&quot;k8s.gcr.io&quot;] endpoint = [&quot;https://k8s-gcr.m.daocloud.io&quot;]...# Enable# cp https://github.com/containerd/containerd/blob/v$CONTAINERD_VERSION/containerd.service to /etc/systemd/system/containerd.servicesystemctl daemon-reloadsystemctl enable containerd --now # Testnerdctl info","link":"/2024/02/29/%E5%BF%AB%E9%80%9F%E5%AE%89%E8%A3%85containerd%E5%92%8Cnerdctl/"},{"title":"èŠ‚ç‚¹æ ¹ç›®å½•è¢«æ‰“æ»¡å¯¼è‡´çš„ETCDæ†¨æ‰¹ä¿®å¤è®°å½•","text":"èƒŒæ™¯äº‹æƒ…å‘ç”Ÿåœ¨ UAT ç¯å¢ƒçš„å…¶ä¸­ä¸€å° Controller èŠ‚ç‚¹ï¼ŒèŠ‚ç‚¹æ ¹ç›®å½•è¢«æ‰“æ»¡ï¼ŒåŒæ—¶ etcd æ•°æ®æ²¡æœ‰è½ç›˜åˆ°ç‹¬ç«‹çš„ç£ç›˜ä¸­ï¼Œå¯¼è‡´ etcd æ†¨æ‰¹ï¼ŒèŠ‚ç‚¹å‡ºç° notready ä¿®å¤è¿‡ç¨‹å‚è€ƒäº†å„ç§ç½‘ç»œèµ„æ–™ï¼Œæœ€ç»ˆå½¢æˆå¦‚ä¸‹ä¿®å¤æ‰‹æ®µ: ç§»é™¤ statis pod yamlï¼Œä»è€Œåœæ­¢åæ‰çš„ etcd pod é€šè¿‡ etcdctl member remove ç§»é™¤åæ‰çš„ etcd å®ä¾‹ å¤‡ä»½æ•°æ®ç›®å½•å¹¶ç§»é™¤ é€šè¿‡ etcdctl member add æ·»åŠ æ–°å®ä¾‹ï¼Œè®°å½• etcdctl è¾“å‡ºçš„é…ç½®ä¿¡æ¯ é€šè¿‡è£¸èµ·å®¹å™¨çš„æ–¹å¼ï¼Œå¯åŠ¨ etcd å®¹å™¨ï¼Œå¯åŠ¨éœ€è¦ç”¨åˆ°çš„å‚æ•°ï¼Œå‚è€ƒ statis pod yaml å’Œç¬¬ 4 æ­¥è¾“å‡ºçš„é…ç½®ä¿¡æ¯ å¯åŠ¨åä¼šä¸ leader è¿›è¡Œæ•°æ®çš„åŒæ­¥ï¼Œå¯ä»¥é€šè¿‡ etcdctl endpoint status -w table æŸ¥çœ‹çŠ¶æ€ å¦‚æœåŒæ­¥æˆåŠŸåˆ™å¯ä»¥åœæ­¢ etcd å®¹å™¨ï¼Œå°† statis pod yaml æ”¾å›å¯¹åº”çš„ç›®å½•ä¸­ï¼Œé›†ç¾¤ä¿®å¤ å…·ä½“çš„æ“ä½œå‘½ä»¤: 12345678910111213141516171819202122232425262728293031323334353637383940# stop issue etcd podmv /etc/kubernetes/manifests/etcd.yaml .# init etcdctl command envsexport endpoints=&quot;https://10.82.69.10:2379,https://10.82.69.11:2379,https://10.82.69.12:2379,https://10.82.69.19:2379,https://10.66.10.83:2379&quot;export cacert=&quot;/etc/kubernetes/pki/etcd/ca.crt&quot;export cert=&quot;/etc/kubernetes/pki/etcd/peer.crt&quot;export key=&quot;/etc/kubernetes/pki/etcd/peer.key&quot;# sample: e member list -w table alias e=&quot;etcdctl --endpoints $endpoints --cacert $cacert --cert $cert --key $key&quot;# or use this oneeval $(kubectl get nodes -owide|grep -E &quot;etcd|control-plane&quot; |awk '{printf &quot;https://&quot;$6&quot;:2379,&quot;}'|awk '{gsub(&quot;,$&quot;,&quot;&quot;);print &quot;export ETCDCTL_ENDPOINTS=\\&quot;&quot;$1&quot;\\&quot;&quot;}') &amp;&amp; export ETCDCTL_CACERT=/etc/kubernetes/ssl/etcd/ca.crt &amp;&amp; export ETCDCTL_CERT=/etc/kubernetes/ssl/etcd/peer.crt &amp;&amp; export ETCDCTL_KEY=/etc/kubernetes/ssl/etcd/peer.key# remove issue etcd memberetcdctl member remove $issue_etcd_id# delete etcd datarm -rf /var/lib/etcd/*# member addetcdctl member add wcn-gduvm-mwdcm1 --peer-urls=https://10.82.69.10:2380# start a temporary etcd pod to restorenerdctl run -d --name restore_etcd \\ -v /etc/kubernetes/ssl/etcd:/etc/kubernetes/ssl/etcd \\ -v /var/lib/etcd:/var/lib/etcd \\ --network=host \\ -e ETCD_NAME=&quot;wcn-gduvm-mwdcm1&quot; \\ -e ETCD_INITIAL_CLUSTER=&quot;wcn-gduvm-mwdcm2=https://10.82.69.11:2380,wcn-gduvm-mwdcm1=https://10.82.69.10:2380,wcn-gduvm-mwdcm3=https://10.82.69.12:2380&quot; \\ -e ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://10.82.69.10:2380&quot; \\ -e ETCD_INITIAL_CLUSTER_STATE=&quot;existing&quot; \\ --entrypoint=etcd 10.82.49.238/quay.io/coreos/etcd:v3.5.6 --advertise-client-urls=https://10.82.69.10:2379 --auto-compaction-retention=8 --cert-file=/etc/kubernetes/ssl/etcd/server.crt --client-cert-auth=true --data-dir=/var/lib/etcd --election-timeout=5000 --experimental-initial-corrupt-check=true --experimental-watch-progress-notify-interval=5s --heartbeat-interval=250 --key-file=/etc/kubernetes/ssl/etcd/server.key --listen-client-urls=https://127.0.0.1:2379,https://10.82.69.10:2379 --listen-metrics-urls=http://127.0.0.1:2381 --listen-peer-urls=https://10.82.69.10:2380 --metrics=basic --peer-cert-file=/etc/kubernetes/ssl/etcd/peer.crt --peer-client-cert-auth=true --peer-key-file=/etc/kubernetes/ssl/etcd/peer.key --peer-trusted-ca-file=/etc/kubernetes/ssl/etcd/ca.crt --snapshot-count=10000 --trusted-ca-file=/etc/kubernetes/ssl/etcd/ca.crt# wait for the etcd pod running, if use kubectl and etcdctl to see that both node and member are restored, we can stop itnerdctl stop restore_etcd# start etcd podmv ./etcd.yaml /etc/kubernetes/manifests/etcd.yaml","link":"/2024/06/29/%E8%8A%82%E7%82%B9%E6%A0%B9%E7%9B%AE%E5%BD%95%E8%A2%AB%E6%89%93%E6%BB%A1%E5%AF%BC%E8%87%B4%E7%9A%84ETCD%E6%86%A8%E6%89%B9%E4%BF%AE%E5%A4%8D%E8%AE%B0%E5%BD%95/"},{"title":"Redis","text":"ä¸€ã€ç®€ä»‹REmote DIctionary Serverï¼ˆRedisï¼‰æ˜¯ä¸€ä¸ªç”± Salvatore Sanfilippo å†™çš„ key-value å­˜å‚¨ç³»ç»Ÿï¼Œæ˜¯è·¨å¹³å°çš„éå…³ç³»å‹æ•°æ®åº“ã€‚ Redis å°±æ˜¯ä¸€æ¬¾ NoSQLï¼Œè€Œ NoSQL å°±æ˜¯æŒ‡éå…³ç³»å‹æ•°æ®åº“ï¼Œä¸»è¦åˆ†ä¸ºå››ç§ï¼š é”®å€¼å‹ï¼šRedis æ–‡æ¡£å‹ï¼šElasticSearchã€Mongdb é¢å‘åˆ—ï¼šHbase å›¾å½¢åŒ–ï¼šNeo4j äºŒã€RedisåŸºç¡€2.1 Rediså®‰è£… é€šè¿‡ docker-compose å®‰è£… redis 12345678910version: '3.8'services: redis: image: daocloud.io/library/redis:5.0.9 restart: always container_name: redis environment: - TZ=Asia/Shanghai ports: - 6379:6379 è¿›å…¥å®¹å™¨å†…éƒ¨æµ‹è¯• redis 123456# è¿æ¥redisredis-cli# setæ–°å»ºé”®å€¼å¯¹set key value# getè·å–é”®å€¼get key 2.2 Rediså¸¸ç”¨å‘½ä»¤redis çš„æ•°æ®å­˜å‚¨ç»“æ„æœ‰ä»¥ä¸‹å‡ ç§ï¼š key-stringï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼šä¸€ä¸ª key å¯¹åº”ä¸€ä¸ªå€¼ key-hashï¼ˆå“ˆå¸Œï¼‰ï¼šä¸€ä¸ª key å¯¹åº”ä¸€ä¸ª map key-listï¼ˆåˆ—è¡¨ï¼‰ï¼šä¸€ä¸ª key å¯¹åº”ä¸€ä¸ªåˆ—è¡¨ key-setï¼ˆé›†åˆï¼‰ï¼šä¸€ä¸ª key å¯¹åº”ä¸€ä¸ªé›†åˆ key-zsetï¼ˆæœ‰åºé›†åˆï¼‰ï¼šä¸€ä¸ª key å¯¹åº”ä¸€ä¸ªæœ‰åºçš„é›†åˆ 2.2.1 stringå¸¸ç”¨å‘½ä»¤ è®¾ç½®å€¼ 1set key value å–å€¼ 1get key æ‰¹é‡æ“ä½œ 12mset key1 value1 key2 value2 ...mget key1 key2 ... è‡ªå¢ 1incr key è‡ªå‡ 1decr key è‡ªå¢è‡ªå‡æŒ‡å®šæ•°é‡ 12incrby key numberdecrby key number è®¾ç½®å€¼çš„åŒæ—¶æŒ‡å®šç”Ÿå­˜æ—¶é—´ 1setex key seconds value è®¾ç½®å€¼ï¼Œå¦‚æœå½“å‰ key ä¸å­˜åœ¨å¦‚åŒ setï¼Œå¦‚æœå­˜åœ¨åˆ™è¯´æ˜éƒ½ä¸åš 1setex key value åœ¨ key å¯¹åº”çš„ value åè¿½åŠ å†…å®¹ 1append key value æŸ¥çœ‹ value å­—ç¬¦ä¸²é•¿åº¦ 1strlen key 2.2.2 hashå¸¸ç”¨å‘½ä»¤ å­˜å‚¨æ•°æ® 1hset key field value è·å–æ•°æ® 1hget key field æ‰¹é‡æ“ä½œ 12hmset key1 field1 value1 field2 value2 ...hmget key1 firle1 field2 ... æŒ‡å®šè‡ªå¢ 1hincrby key field number è®¾ç½®å€¼ï¼Œå¦‚æœå½“å‰ key ä¸å­˜åœ¨å¦‚åŒ setï¼Œå¦‚æœå­˜åœ¨åˆ™è¯´æ˜éƒ½ä¸åš 1hsetnx key field value æ£€æŸ¥ field æ˜¯å¦å­˜åœ¨ 1hexists key field åˆ é™¤æŸä¸ª field 1hdel key field1 field2 ... è·å–å½“å‰ hash ç»“æ„ä¸­çš„å…¨éƒ¨ field å’Œ value 1hgetall key è·å–å½“å‰ hash ç»“æ„ä¸­çš„å…¨éƒ¨ field 1hkeys key è·å–å½“å‰ hash ç»“æ„ä¸­çš„å…¨éƒ¨ value 1hvals key è·å–å½“å‰ hash ä¸­ field çš„æ•°é‡ 1hlen key 2.2.3 listå¸¸ç”¨å‘½ä»¤ å­˜å‚¨æ•°æ® 1234567891011# ä»å·¦ä¾§æ’å…¥æ•°æ®lpush key value1 value2 ...# ä»å³ä¾§æ’å…¥æ•°æ®rpush key value1 value2 ...# å¦‚æœkeyä¸å­˜åœ¨ï¼Œä»€ä¹ˆéƒ½ä¸åšï¼Œå¦‚æœkeyå­˜åœ¨ä½†ä¸æ˜¯listç»“æ„ï¼Œä¹Ÿä»€ä¹ˆéƒ½ä¸åšlpushx key value1 value2 ...rpushx key value1 value2 ...# é€šè¿‡ç´¢å¼•ä½ç½®æ·»åŠ valuelset key index value è·å–æ•°æ® 12345678910111213# å·¦ä¾§å¼¹å‡ºæ•°æ®å¹¶ç§»é™¤lpop key# å³ä¾§å¼¹å‡ºæ•°æ®å¹¶ç§»é™¤rpop key# è·å–ä¸€å®šèŒƒå›´çš„æ•°æ®ï¼Œstartä»0å¼€å§‹ï¼Œstopä¸º-1æ—¶ä¸ºæœ€åä¸€ä¸ªvalueï¼Œ-2æ—¶ä¸ºå€’æ•°ç¬¬äºŒä¸ªvaluelrange key start stop# æ ¹æ®ç´¢å¼•ä½ç½®è·å–valuelindex key index# è·å–æ•´ä¸ªlistçš„é•¿åº¦llen key åˆ é™¤æ•°æ® 12345678# åˆ é™¤listä¸­countä¸ªvalueçš„å€¼ï¼Œå½“count&gt;0ï¼Œä»å·¦å‘å³åˆ é™¤ï¼Œä½†count&lt;0ï¼Œä»å³å‘å·¦åˆ é™¤ï¼Œä½†count==0ï¼Œå…¨éƒ¨åˆ é™¤lrem key count value# ä¿ç•™åˆ—è¡¨ä¸­æŒ‡å®šèŒƒå›´å†…çš„æ•°æ®ï¼Œè¶…å‡ºè¿™ä¸ªèŒƒå›´çš„éƒ½ä¼šè¢«ç§»é™¤ltrim start stop# å°†list1ä¸­çš„æœ€åä¸€ä¸ªæ•°æ®å¼¹å‡ºï¼Œæ’å…¥åˆ°list2ä¸­çš„ç¬¬ä¸€ä¸ªä½ç½®rpoplpush key1 key2 2.2.4 setå¸¸ç”¨å‘½ä»¤ å­˜å‚¨æ•°æ® 12# valueä¸å…è®¸é‡å¤ï¼Œä¸”æ•°æ®æ— åºæ’åˆ—sadd key value1 value2 ... è·å–æ•°æ® 1234567891011121314151617# è·å–å…¨éƒ¨æ•°æ®smembers key# éšæœºè·å–æ•°æ®ï¼Œå¹¶ç§»é™¤ï¼Œå¯åŠ å¼¹å‡ºæ•°é‡spop key number# å–å¤šä¸ªsetçš„äº¤é›†sinter key1 key2 ...# å–å¤šä¸ªsetçš„å¹¶é›†sunion key1 key2 ...# å–å¤šä¸ªsetçš„å·®é›†sdiff key1 key2 ...# æŸ¥çœ‹å½“å‰setæ˜¯å¦åŒ…å«æŸä¸ªå€¼sismember key value åˆ é™¤æ•°æ® 1srem key value1 value2 ... 2.2.5 zsetå¸¸ç”¨å‘½ä»¤ å­˜å‚¨æ•°æ® 12345# scoreå¿…é¡»æ˜¯æ•°å€¼ï¼Œvalueä¸å…è®¸é‡å¤zadd key score1 value1 score2 value2 ...# ä¿®æ”¹scoreï¼Œå¦‚æœvalueå­˜åœ¨åˆ™å¢åŠ åˆ†æ•°ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ç›¸å½“äºzaddzincrby key number value è·å–æ•°æ® 123456789101112131415161718# æŸ¥çœ‹æŒ‡å®švalueçš„åˆ†æ•°zscore key value# è·å–valueæ•°é‡zcard key# æ ¹æ®scoreèŒƒå›´æŸ¥è¯¢valueæ•°é‡zcount key min max# æ ¹æ®åˆ†æ•°ä»å°åˆ°å¤§æ’åºï¼Œè·å–æŒ‡å®šèŒƒå›´å†…çš„æ•°æ®ï¼Œæ·»åŠ äº†withscoreså‚æ•°ä¼šè¿”å›valueçš„å…·ä½“scorezrange key start stop withscores# ä»å¤§åˆ°å°zrevrange key start stop withscores# æ ¹æ®åˆ†æ•°çš„èŒƒå›´è·å–æ•°æ®ï¼Œå¦‚æœä¸å¸Œæœ›åŒ…æ‹¬minå’Œmaxçš„å€¼å¯ä»¥ç”¨(min max)çš„æ–¹å¼ï¼Œæœ€å¤§æœ€å°å€¼ç”¨Â±infè¡¨ç¤ºzrangebyscore key min max withscores [limit,offset,count]zrevrangebyscore key max min withscores [limit,offset,count] åˆ é™¤æ•°æ® 1zrem key value1 value2 ... 2.2.6 keyå¸¸ç”¨å‘½ä»¤ æŸ¥çœ‹æ‰€æœ‰key 1keys * æŸ¥çœ‹æŸä¸ªkeyæ˜¯å¦å­˜åœ¨ 1exists key åˆ é™¤key 1del key è®¾ç½®keyçš„ç”Ÿå­˜æ—¶é—´ 12345678910111213141516# å•ä½ä¸ºsexpire key seconds# å•ä½ä¸ºmspexpire key milliseconds# æŒ‡å®šç”Ÿå­˜åˆ°æŸä¸ªæ—¶é—´ç‚¹expireat key timestamppexpireat key millseconds# æŸ¥çœ‹keyçš„å‰©ä½™ç”Ÿå­˜æ—¶é—´ï¼Œè¿”å›-2åˆ™keyä¸å­˜åœ¨ï¼Œ-1åˆ™æ²¡è®¾ç½®ç”Ÿå­˜æ—¶é—´ttl keypttl key# ç§»é™¤ç”Ÿå­˜æ—¶é—´persist key é€‰æ‹©æ“ä½œçš„åº“ 12345# redisé»˜è®¤æœ‰16ä¸ªåº“select 0~15# ç§»åŠ¨keyåˆ°å¦ä¸€ä¸ªåº“ä¸­move key db 2.2.7 åº“çš„å¸¸ç”¨å‘½ä»¤ æ¸…ç©ºå½“å‰æ‰€åœ¨æ•°æ®åº“ 1flushdb æ¸…ç©ºæ‰€æœ‰æ•°æ®åº“ 1flushdball æŸ¥çœ‹å½“å‰åº“æœ‰å¤šå°‘key 1dbsize æŸ¥çœ‹æœ€åä¸€æ¬¡æ“ä½œçš„æ—¶é—´ 1lastsave å®æ—¶ç›‘æ§redisæ¥æ”¶åˆ°çš„å‘½ä»¤ 1monitor ä¸‰ã€Redisé…ç½®3.1 Redisçš„AUTH docker-compose.yaml 12345678910111213version: '3.8'services: redis: image: daocloud.io/library/redis:5.0.9 container_name: redis restart: always environment: - TZ=Asia/Shanghai ports: - 6379:6379 volumes: - ./redis.conf:/usr/local/redis/redis.conf command: [&quot;redis-server&quot;, &quot;/usr/local/redis/redis.conf&quot;] è®¾ç½® Redis è¿æ¥å¯†ç  12vim redis.confrequirepass toortoor 1docker-compose up -d è¿›å…¥ Redis ä¹‹åéƒ½éœ€è¦è¾“å…¥å¯†ç æ‰å¯ä»¥åˆ›å»º key 12redis-cliauth toortoor 3.2 Redisçš„äº‹åŠ¡Redis äº‹åŠ¡å¯ä»¥ä¸€æ¬¡æ‰§è¡Œå¤šä¸ªå‘½ä»¤ï¼Œ å¹¶ä¸”å¸¦æœ‰ä»¥ä¸‹ä¸‰ä¸ªé‡è¦çš„ä¿è¯ï¼š æ‰¹é‡æ“ä½œåœ¨å‘é€ EXEC å‘½ä»¤å‰è¢«æ”¾å…¥é˜Ÿåˆ—ç¼“å­˜ æ”¶åˆ° EXEC å‘½ä»¤åè¿›å…¥äº‹åŠ¡æ‰§è¡Œï¼Œäº‹åŠ¡ä¸­ä»»æ„å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œå…¶ä½™çš„å‘½ä»¤ä¾ç„¶è¢«æ‰§è¡Œ åœ¨äº‹åŠ¡æ‰§è¡Œè¿‡ç¨‹ï¼Œå…¶ä»–å®¢æˆ·ç«¯æäº¤çš„å‘½ä»¤è¯·æ±‚ä¸ä¼šæ’å…¥åˆ°äº‹åŠ¡æ‰§è¡Œå‘½ä»¤åºåˆ—ä¸­ ä¸€ä¸ªäº‹åŠ¡ä»å¼€å§‹åˆ°æ‰§è¡Œä¼šç»å†ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š å¼€å§‹äº‹åŠ¡ï¼šmulti å‘½ä»¤å…¥é˜Ÿï¼šâ€¦â€¦ æ‰§è¡Œäº‹åŠ¡ï¼šexec å–æ¶ˆäº‹åŠ¡ï¼šdiscard ç›‘å¬ï¼šåœ¨å¼€å¯äº‹åŠ¡ä¹‹å‰ï¼Œå…ˆé€šè¿‡ watch ç›‘å¬äº‹åŠ¡ä¸­è¦æ“ä½œçš„ keyï¼Œå¦‚æœåœ¨äº‹åŠ¡è¿‡ç¨‹ä¸­æœ‰å…¶ä»–çš„å®¢æˆ·ç«¯ä¿®æ”¹äº† keyï¼Œé‚£ä¹ˆäº‹åŠ¡å°†ä¼šè¢«å–æ¶ˆ äº‹åŠ¡å¯ä»¥ç†è§£ä¸ºä¸€ä¸ªæ‰“åŒ…çš„æ‰¹é‡æ‰§è¡Œè„šæœ¬ï¼Œä½†æ‰¹é‡æŒ‡ä»¤å¹¶éåŸå­åŒ–çš„æ“ä½œï¼Œä¸­é—´æŸæ¡æŒ‡ä»¤çš„å¤±è´¥ä¸ä¼šå¯¼è‡´å‰é¢å·²åšæŒ‡ä»¤çš„å›æ»šï¼Œä¹Ÿä¸ä¼šé€ æˆåç»­çš„æŒ‡ä»¤ä¸åšã€‚ ç›‘å¬ 1watch name age gander å¼€å§‹äº‹åŠ¡ 1multi å‘½ä»¤å…¥é˜Ÿ 123set name cqmset age 22set gander male æ‰§è¡Œäº‹åŠ¡/å–æ¶ˆäº‹åŠ¡ 1exec/discard 3.3 Redisçš„æŒä¹…åŒ–3.3.1 RDBæŒä¹…åŒ–Redis çš„é…ç½®æ–‡ä»¶ä½äº Redis å®‰è£…ç›®å½•, ROB æ˜¯é»˜è®¤çš„æŒä¹…åŒ–æœºåˆ¶ã€‚ docker-compose.yaml 123456789101112131415version: '3.8'services: redis: image: daocloud.io/library/redis:5.0.9 container_name: redis restart: always environment: - TZ=Asia/Shanghai ports: - 6379:6379 volumes: - ./redis.conf:/usr/local/redis/redis.conf - ./data:/data # åŠ è½½redis.conf command: [&quot;redis-server&quot;, &quot;/usr/local/redis/redis.conf&quot;] redis.conf 123456789vim redis.conf# åœ¨900ç§’å†…æœ‰1ä¸€ä¸ª key å‘ç”Ÿäº†å˜åŒ–ï¼Œå°±æ‰§è¡Œ RDB æŒä¹…åŒ–save 900 1save 300 10save 60 10000# å¼€å¯RDBæŒä¹…åŒ–rdbchecksum yes# RDBæŒä¹…åŒ–åç§°dbfilename dump.rdb æµ‹è¯•æŒä¹…åŒ– 1234set name cqmset age 22# å…³é—­rediså¹¶ä¿å­˜shutdown save å¯ä»¥çœ‹åˆ° data ç›®å½•ä¸‹å¤šäº†ä¸ª rdb æ–‡ä»¶ï¼Œå³ä½¿ redis å®¹å™¨é‡å¯ä¹Ÿä¸ä¼šé€ æˆ key çš„ä¸¢å¤± 3.3.2 AOFæŒä¹…åŒ–AOF æ¯”èµ· RDB æœ‰æ›´é«˜çš„æ•°æ®å®‰å…¨æ€§ï¼Œå¦‚æœåŒæ—¶å¼€å¯äº† AOF å’Œ RDBï¼Œé‚£ä¹ˆå‰è€…æ¯”åè€…çš„ä¼˜å…ˆçº§æ›´é«˜ï¼Œä¸”å¦‚æœå…ˆå¼€å¯äº† RDB åœ¨å¼€å¯ AOFï¼Œé‚£ä¹ˆ RDB ä¸­çš„å†…å®¹ä¼šè¢« AOF çš„å†…å®¹è¦†ç›–ã€‚ redis.conf 123456789# å¼€å¯AOFæŒä¹…åŒ–appendonly yes# AOFæ–‡ä»¶åappendfilename appendonly.aof# AOFæŒä¹…åŒ–æ‰§è¡Œç­–ç•¥# always:æ¯æ¬¡æ‰§è¡Œå†™æ“ä½œéƒ½è°ƒç”¨fsync# everysec:æœ€å¤šæ¯ç§’è°ƒç”¨ä¸€æ¬¡fsync# no:æ ¹æ®ç¯å¢ƒçš„ä¸åŒåœ¨ä¸ç¡®å®šçš„æ—¶é—´è°ƒç”¨fsyncappendfsync always|everysec|no é‡å¯ docker-compose æµ‹è¯• 123set gander male# ä¸RDBæŒä¹…åŒ–shutdown nosave å¯ä»¥çœ‹åˆ° data ç›®å½•ä¸‹å¤šäº†ä¸ª aof æ–‡ä»¶ï¼Œå³ AOF æŒä¹…åŒ–ç”Ÿæˆçš„æ–‡ä»¶ 3.4 Redisä¸»ä»æ¶æ„Redis çš„ä¸»ä»æ¶æ„æ˜¯æŒ‡ Master èŠ‚ç‚¹è´Ÿè´£å†™æ“ä½œï¼Œè€Œå…¶ä½™çš„ Slave èŠ‚ç‚¹è´Ÿè´£è¯»æ“ä½œã€‚ docker-compose.yaml 12345678910111213141516171819202122232425262728293031323334353637383940414243version: '3.8'services: redis-master: container_name: redis-master image: daocloud.io/library/redis:5.0.9 restart: always environment: - TZ=Asia/Shanghai ports: - 7001:6379 volumes: - ./redis1.conf:/usr/local/redis/redis.conf - ./data1:/data command: [&quot;redis-server&quot;, &quot;/usr/local/redis/redis.conf&quot;] redis-slave1: container_name: redis-slave1 image: daocloud.io/library/redis:5.0.9 restart: always environment: - TZ=Asia/Shanghai ports: - 7002:6379 volumes: - ./redis2.conf:/usr/local/redis/redis.conf - ./data2:/data command: [&quot;redis-server&quot;, &quot;/usr/local/redis/redis.conf&quot;] # è¿æ¥redis-masterå®¹å™¨ï¼Œå¹¶å°†è¯¥å®¹å™¨ipåœ°å€æ˜ å°„ä¸ºmaster links: - redis-master:master redis-slave2: container_name: redis-slave2 image: daocloud.io/library/redis:5.0.9 restart: always environment: - TZ=Asia/Shanghai ports: - 7003:6379 volumes: - ./redis3.conf:/usr/local/redis/redis.conf - ./data3:/data command: [&quot;redis-server&quot;, &quot;/usr/local/redis/redis.conf&quot;] links: - redis-master:master ä»èŠ‚ç‚¹ redis.conf 12# slaveof &lt;ä¸»èŠ‚ç‚¹åœ°å€&gt; &lt;ç«¯å£&gt;slaveof master 6379 å¯åŠ¨åè¿›å…¥å®¹å™¨å†…éƒ¨é€šè¿‡ info å¯çœ‹åˆ°èŠ‚ç‚¹ä¿¡æ¯ 3.5 Rediså“¨å…µæ¨¡å¼Redis çš„ä¸»ä»æ¶æ„æœ‰ä¸€ä¸ªå¾ˆæ˜æ˜¾çš„é—®é¢˜ï¼Œå°±æ˜¯å½“ Master èŠ‚ç‚¹å‡ºç°é—®é¢˜å®•æœºåï¼Œé‚£ä¹ˆ Redis é›†ç¾¤å°±æ²¡æœ‰å¯ä»¥è¿›è¡Œå†™æ“ä½œçš„ Redis äº†ï¼Œè€Œå“¨å…µå°±å¯ä»¥è§£å†³è¯¥é—®é¢˜ã€‚ åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸­éƒ½ä¼šæœ‰ä¸ªå“¨å…µä¸ Redis è¿›è¡Œè¿æ¥ï¼Œä¸”å“¨å…µä¸å“¨å…µä¹‹é—´ä¹Ÿä¼šè¿›è¡Œè¿æ¥ï¼Œå¦‚æœ Master èŠ‚ç‚¹å‡ºç°æ•…éšœå®•æœºäº†ï¼Œé‚£ä¹ˆå“¨å…µä»¬å°±ä¼šé€‰å‡ºä¸€ä¸ª Slave æ¥ä½œä¸ºæ–°çš„ Master æ¥æä¾›å†™çš„æ“ä½œã€‚ docker-compose.yaml 123456789101112131415161718192021222324252627282930313233343536373839404142434445version: '3.8'services: redis-master: container_name: redis-master image: daocloud.io/library/redis:5.0.9 restart: always environment: - TZ=Asia/Shanghai ports: - 7001:6379 volumes: - ./redis1.conf:/usr/local/redis/redis.conf - ./data1:/data - ./sentinel1.conf:/data/sentinel.conf command: [&quot;redis-server&quot;, &quot;/usr/local/redis/redis.conf&quot;] redis-slave1: container_name: redis-slave1 image: daocloud.io/library/redis:5.0.9 restart: always environment: - TZ=Asia/Shanghai ports: - 7002:6379 volumes: - ./redis2.conf:/usr/local/redis/redis.conf - ./data2:/data - ./sentinel2.conf:/data/sentinel.conf command: [&quot;redis-server&quot;, &quot;/usr/local/redis/redis.conf&quot;] links: - redis-master:master redis-slave2: container_name: redis-slave2 image: daocloud.io/library/redis:5.0.9 restart: always environment: - TZ=Asia/Shanghai ports: - 7003:6379 volumes: - ./redis3.conf:/usr/local/redis/redis.conf - ./data3:/data - ./sentinel3.conf:/data/sentinel.conf command: [&quot;redis-server&quot;, &quot;/usr/local/redis/redis.conf&quot;] links: - redis-master:master Master èŠ‚ç‚¹ sentinel.conf 123456# ä»¥å®ˆæŠ¤è¿›ç¨‹çš„æ–¹å¼è¿è¡Œredisdaemonize yes# æŒ‡å®šMasterèŠ‚ç‚¹ï¼Œsentinel monitor &lt;åç§°&gt; &lt;ip&gt; &lt;ç«¯å£&gt; &lt;Slaveä¸ªæ•°&gt;sentinel monitor master localhost 6379 2# æŒ‡å®šå“¨å…µæ¯éš”å¤šä¹…æ£€æµ‹ä¸€æ¬¡redisä¸»ä»æ¶æ„sentinel down-after-milliseconds master 10000 Slave èŠ‚ç‚¹ sentinel.conf 123daemonize yessentinel monitor master master 6379 2sentinel down-after-milliseconds master 10000 è¿›å…¥å®¹å™¨å¯åŠ¨å“¨å…µï¼Œå½“ Master èŠ‚ç‚¹å‡ºç°é—®é¢˜åï¼Œå°±ä¼šåœ¨ä¸¤ä¸ª Slave ä¸­é€‰å‡ºä¸€ä¸ªä½œä¸ºæ–°çš„ Masterï¼Œè€Œæ—§çš„ Master å¯åŠ¨åå°±ä¼šå˜ä¸ºæ–°çš„ Slave 1redis-sentinel /data/sentinel.conf 3.6 Redisé›†ç¾¤Redis é›†ç¾¤åœ¨ä¿è¯ä¸»ä»å’Œå“¨å…µçš„åŸºæœ¬åŠŸèƒ½ä¹‹å¤–ï¼Œè¿˜èƒ½æé«˜ Redis å­˜å‚¨æ•°æ®çš„èƒ½åŠ›ï¼Œä¸»è¦çš„ç‰¹ç‚¹å¦‚ä¸‹ Redis é›†ç¾¤æ˜¯æ— ä¸­å¿ƒçš„ Redis é›†ç¾¤æœ‰ping-pangçš„æœºåˆ¶ æŠ•ç¥¨æœºåˆ¶ï¼Œé›†ç¾¤èŠ‚ç‚¹çš„æ•°é‡å¿…é¡»æ˜¯ 2n+1 åˆ†é…äº† 16484 ä¸ª hash æ§½ï¼Œåœ¨å­˜å‚¨æ•°æ®æ—¶ï¼Œä¼šå¯¹ key è¿›è¡Œ crc16 çš„ç®—æ³•ï¼Œå¹¶å¯¹ 16384 è¿›è¡Œå–ä½™ï¼Œé€šè¿‡ç»“æœåˆ†é…åˆ°å¯¹åº”çš„èŠ‚ç‚¹ä¸Šï¼Œæ¯ä¸ªèŠ‚ç‚¹éƒ½æœ‰è‡ªå·±ç»´æŠ¤çš„ hash æ§½ æ¯ä¸ªä¸»èŠ‚ç‚¹éƒ½è¦è·Ÿä¸€ä¸ªä»èŠ‚ç‚¹ï¼Œä½†è¿™é‡Œçš„ä»èŠ‚ç‚¹åªç®¡å¤‡ä»½ï¼Œä¸ç®¡æŸ¥è¯¢ é›†ç¾¤ä¸­åŠæ•°çš„èŠ‚ç‚¹å®•æœºåï¼Œé‚£ä¹ˆé›†ç¾¤å°±ç˜«ç—ª docker-compose.yaml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374version: '3.8'services: redis1: container_name: redis1 image: daocloud.io/library/redis:5.0.9 restart: always environment: - TZ=Asia/Shanghai ports: - 7001:7001 - 17001:17001 volumes: - ./conf.d/redis1.conf:/usr/local/redis/redis.conf command: [&quot;redis-server&quot;, &quot;/usr/local/redis/redis.conf&quot;] redis2: container_name: redis2 image: daocloud.io/library/redis:5.0.9 restart: always environment: - TZ=Asia/Shanghai ports: - 7002:7002 - 17002:17002 volumes: - ./conf.d/redis2.conf:/usr/local/redis/redis.conf command: [&quot;redis-server&quot;, &quot;/usr/local/redis/redis.conf&quot;] redis3: container_name: redis3 image: daocloud.io/library/redis:5.0.9 restart: always environment: - TZ=Asia/Shanghai ports: - 7003:7003 - 17003:17003 volumes: - ./conf.d/redis3.conf:/usr/local/redis/redis.conf command: [&quot;redis-server&quot;, &quot;/usr/local/redis/redis.conf&quot;] redis4: container_name: redis4 image: daocloud.io/library/redis:5.0.9 restart: always environment: - TZ=Asia/Shanghai ports: - 7004:7004 - 17004:17004 volumes: - ./conf.d/redis4.conf:/usr/local/redis/redis.conf command: [&quot;redis-server&quot;, &quot;/usr/local/redis/redis.conf&quot;] redis5: container_name: redis5 image: daocloud.io/library/redis:5.0.9 restart: always environment: - TZ=Asia/Shanghai ports: - 7005:7005 - 17005:17005 volumes: - ./conf.d/redis5.conf:/usr/local/redis/redis.conf command: [&quot;redis-server&quot;, &quot;/usr/local/redis/redis.conf&quot;] redis6: container_name: redis6 image: daocloud.io/library/redis:5.0.9 restart: always environment: - TZ=Asia/Shanghai ports: - 7006:7006 - 17006:17006 volumes: - ./conf.d/redis6.conf:/usr/local/redis/redis.conf command: [&quot;redis-server&quot;, &quot;/usr/local/redis/redis.conf&quot;] redis{1..6}.confï¼Œx ä¸º {1..6} 123456789101112# æŒ‡å®šredisç«¯å£port 700x# å¼€å¯é›†ç¾¤cluster-enabled yes# é›†ç¾¤ä¿¡æ¯æ–‡ä»¶cluster-config-file nodes-700x.conf# é›†ç¾¤å¯¹å¤–ipcluster-announce-ip 192.168.88.135# é›†ç¾¤å¯¹å¤–ç«¯å£cluster-announce-port 700x# é›†ç¾¤æ€»çº¿ç«¯å£cluster-announce-bus-port 1700x è¿›å…¥ä»»æ„ reids å®¹å™¨åˆ›å»ºé›†ç¾¤ 12# --cluster-replicas:æ¯ä¸ªä¸»èŠ‚ç‚¹åˆ†é…çš„ä»èŠ‚ç‚¹ä¸ªæ•°redis-cli --cluster create 192.168.88.135:7001 192.168.88.135:7002 192.168.88.135:7003 192.168.88.135:7004 192.168.88.135:7005 192.168.88.135:7006 --cluster-replicas 1 ç”±äºæ¯ä¸ªä¸»èŠ‚ç‚¹éƒ½è¢«åˆ†é…äº†ä¸åŒçš„ hash æ§½ï¼Œæ‰€ä»¥è¦åœ¨å®¹å™¨å†…ä»»æ„åˆ‡æ¢ä¸åŒçš„ redis èŠ‚ç‚¹éœ€è¦åŠ å‚æ•° -c 1redis-cli -h 192.168.88.135 -p 7001 -c å››ã€Rediså¸¸è§é—®é¢˜4.1 Redisçš„åˆ é™¤ç­–ç•¥å½“ key çš„ç”Ÿå­˜æ—¶é—´åˆ°äº†ï¼ŒRedis å¹¶ä¸ä¼šç«‹å³åˆ é™¤è¯¥ keyï¼Œè€Œæ˜¯éµå®ˆä»¥ä¸‹åˆ é™¤ç­–ç•¥æ¥è¿›è¡Œåˆ é™¤ å®šæœŸåˆ é™¤ï¼šRedis æ¯éš”ä¸€æ®µæ—¶é—´å°±å›å»æŸ¥çœ‹è®¾ç½®äº†ç”Ÿå­˜æ—¶é—´çš„ keyï¼Œé»˜è®¤æ˜¯ 100ms æŸ¥çœ‹ 3 ä¸ª key æƒ°æ€§åˆ é™¤ï¼šå½“ç”¨æˆ·å»æŸ¥è¯¢å·²ç»è¶…è¿‡äº†ç”Ÿå­˜æ—¶é—´çš„ keyï¼ŒRedis ä¼šå…ˆæŸ¥çœ‹è¯¥ key æ˜¯å¦å·²ç»è¶…è¿‡äº†ç”Ÿå­˜æ—¶é—´ï¼Œå¦‚æœè¶…è¿‡ï¼Œé‚£ä¹ˆ Redis ä¼šå°†è¯¥ key åˆ é™¤å¹¶ç»™ç”¨æˆ·è¿”å›ä¸€ä¸ªç©ºå€¼ 4.2 Redisçš„æ·˜æ±°æœºåˆ¶å½“ Redis å†…å­˜æ»¡çš„æ—¶å€™æ·»åŠ äº†ä¸€ä¸ªæ–°çš„æ•°æ®ï¼Œé‚£ä¹ˆå°±ä¼šæ‰§è¡Œ Redis çš„æ·˜æ±°æœºåˆ¶ï¼Œé€šè¿‡ maxmemory-policy æ¥è®¾ç½®ï¼Œå‚æ•°å¦‚ä¸‹ volatile-lruï¼šå½“å†…å­˜ä¸è¶³æ—¶ï¼Œä¼šåˆ é™¤ä¸€ä¸ªè®¾ç½®äº†ç”Ÿå­˜æ—¶é—´ä¸”æœ€è¿‘æœ€å°‘ä½¿ç”¨çš„ key allkeys-lruï¼šå½“å†…å­˜ä¸è¶³æ—¶ï¼Œä¼šåˆ é™¤ä¸€ä¸ªè®¾ç½®äº†æœ€è¿‘æœ€å°‘ä½¿ç”¨çš„ key volatile-lfuï¼šå½“å†…å­˜ä¸è¶³æ—¶ï¼Œä¼šåˆ é™¤ä¸€ä¸ªè®¾ç½®äº†ç”Ÿå­˜æ—¶é—´ä¸”æœ€è¿‘ä½¿ç”¨é¢‘ç‡æœ€ä½çš„ key allkeys-lfuï¼šå½“å†…å­˜ä¸è¶³æ—¶ï¼Œä¼šåˆ é™¤ä¸€ä¸ªè®¾ç½®äº†æœ€è¿‘ä½¿ç”¨é¢‘ç‡æœ€ä½çš„ key volatile-randomï¼šå½“å†…å­˜ä¸è¶³æ—¶ï¼Œä¼šéšæœºåˆ é™¤ä¸€ä¸ªè®¾ç½®äº†ç”Ÿå­˜æ—¶é—´çš„ key allkeys-randomï¼šå½“å†…å­˜ä¸è¶³æ—¶ï¼Œä¼šéšæœºåˆ é™¤ä¸€ä¸ª key volatile-ttlï¼šå½“å†…å­˜ä¸è¶³æ—¶ï¼Œä¼šåˆ é™¤ä¸€ä¸ªç”Ÿå­˜æ—¶é—´æœ€å°‘çš„ key noevictionï¼šå†…å­˜ä¸è¶³æ—¶ï¼Œç›´æ¥æŠ¥é”™ 4.3 ç¼“å­˜é—®é¢˜ç¼“å­˜ç©¿é€ å½“å®¢æˆ·æŸ¥è¯¢çš„æ•°æ® Redis ä¸­æ²¡æœ‰ï¼Œæ•°æ®åº“ä¸­ä¹Ÿæ²¡æœ‰ï¼Œä¸”è¯·æ±‚é‡ç‰¹åˆ«å¤§æ—¶ï¼Œå°±ä¼šå¯¼è‡´æ•°æ®åº“çš„å‹åŠ›è¿‡å¤§ï¼Œè§£å†³æ–¹æ³•å¦‚ä¸‹ æ ¹æ® id æŸ¥è¯¢æ—¶ï¼Œå¦‚æœ id æ˜¯è‡ªå¢çš„ï¼Œé‚£ä¹ˆå¯ä»¥å°†æœ€å¤§çš„ id æ”¾åˆ° Reids ä¸­ï¼Œå½“æŸ¥è¯¢æ•°æ®æ—¶ç›´æ¥å¯¹æ¯” id å³å¯ å¦‚æœ id ä¸æ˜¯ int å‹ï¼Œé‚£ä¹ˆå¯ä»¥å°†å…¨éƒ¨çš„ id æ”¾å…¥ set ä¸­ï¼Œç”¨æˆ·æŸ¥è¯¢ä¹‹å‰å¯ä»¥å…ˆåˆ° set æŸ¥çœ‹æ˜¯å¦æœ‰è¯¥ id è·å–ç”¨æˆ·çš„ ip åœ°å€ï¼Œå¯¹è¯¥åœ°å€è¿›è¡Œè®¿é—®é™åˆ¶ ç¼“å­˜å‡»ç©¿ å½“ç”¨æˆ·æŸ¥è¯¢çš„æ˜¯çƒ­ç‚¹æ•°æ®æ—¶ï¼Œé‚£ä¹ˆå¹¶å‘é‡è‚¯å®šæ˜¯å¾ˆé«˜çš„ï¼Œå½“ Redis ä¸­çš„çƒ­ç‚¹æ•°æ®è¿‡æœŸäº†ï¼Œé‚£ä¹ˆæ•°æ®åº“çš„å‹åŠ›å°±ä¼šå¾ˆå¤§ï¼Œç”šè‡³å®•æœºï¼Œè§£å†³æ–¹æ³•å¦‚ä¸‹ åœ¨è®¿é—®çƒ­ç‚¹æ•°æ®æ—¶ï¼Œç¼“å­˜ä¸­æ²¡æœ‰çš„æ—¶å€™ï¼Œå¯ä»¥æ·»åŠ ä¸€æŠŠé”ï¼Œè®©å‡ ä¸ªè¯·æ±‚å»è®¿é—®æ•°æ®åº“ï¼Œé¿å…æ•°æ®åº“å®•æœº æŠŠçƒ­ç‚¹æ•°æ®çš„ç”Ÿå­˜æ—¶é—´å»æ‰ ç¼“å­˜é›ªå´© å½“å¤§é‡ç¼“å­˜åŒæ—¶åˆ°æœŸæ—¶ï¼Œå¯¼è‡´è¯·æ±‚éƒ½å»åˆ°äº†æ•°æ®åº“ï¼Œä¹Ÿå¾ˆå®¹æ˜“å¯¼è‡´æ•°æ®åº“å®•æœºï¼Œè§£å†³æ–¹æ³•å¦‚ä¸‹ å¯¹ç¼“å­˜ä¸­çš„æ•°æ®è®¾ç½®ä¸€ä¸ªéšæœºçš„ç”Ÿå­˜æ—¶é—´ï¼Œé¿å…åŒæ—¶è¿‡æœŸ ç¼“å­˜å€¾æ–œ å¦‚æœå°†çƒ­ç‚¹æ•°æ®æ”¾åœ¨é›†ç¾¤ä¸­çš„æŸä¸€ Redis èŠ‚ç‚¹ä¸Šæ—¶ï¼Œé‚£ä¹ˆå¤§é‡çš„æ•°æ®éƒ½ä¼šå»åˆ°è¯¥ Redis èŠ‚ç‚¹ï¼Œå¯¼è‡´èŠ‚ç‚¹å®•æœºï¼Œè§£å†³æ–¹æ³•å¦‚ä¸‹ ä¸»ä»æ¶æ„ï¼Œå‡†å¤‡å¤§é‡çš„ä»èŠ‚ç‚¹ åœ¨ Tomcat ä¸­åš JVM ç¼“å­˜ï¼Œåœ¨æŸ¥è¯¢ Redis å‰å…ˆæŸ¥è¯¢ JVM ç¼“å­˜","link":"/2024/02/18/redis/"},{"title":"è®°å½•ä¸€æ¬¡ipv4_forwardè¢«ä¿®æ”¹å¯¼è‡´çš„ç”Ÿäº§äº‹æ•…","text":"ç”Ÿäº§é›†ç¾¤çš„èŠ‚ç‚¹å†…æ ¸æ¨¡å—è¢«å¼‚å¸¸ä¿®æ”¹ï¼Œå¯¼è‡´é›†ç¾¤æœåŠ¡ä¸æœåŠ¡ä¹‹é—´ç½‘ç»œé€šä¿¡å¼‚å¸¸ï¼Œäº§ç”Ÿäº†è¾ƒå¤§è§„æ¨¡çš„ç”Ÿäº§äº‹æ•…ã€‚ æ­¤æ¬¡äº‹æ•…æ¶‰åŠåˆ°ä¸¤ä¸ªä¸»è¦çš„å†…æ ¸æ¨¡å—è¢«ä¿®æ”¹: net.ipv4.ip_forward: ç”¨äºå¯ç”¨ IP è½¬å‘ï¼Œå½“æ­¤æ¨¡å—åŠ è½½æ—¶ï¼ŒLinux å†…æ ¸ä¼šå…è®¸å°†æ•°æ®åŒ…è½¬å‘åˆ°å…¶ä»–ç½‘ç»œ å°è¯•å¤ç°åœ¨ä¸€ä¸ªé›†ç¾¤ä¸­å¯ç”¨ä¸¤ä¸ª Podï¼Œé€šè¿‡è¿™ä¸¤ä¸ª Pod æ¨¡æ‹Ÿä¸šåŠ¡ ä¿®æ”¹ controller-node-2 èŠ‚ç‚¹çš„ /etc/sysctl.d/99-sysctl.conf æ–‡ä»¶ï¼Œå¹¶åŠ è½½(sysctl -p) 1net.ipv4.ip_forward=0 æ­¤æ—¶å†å»æµ‹è¯•è¿é€šæ€§ï¼Œå·²ç»ä¸é€šäº† å°½ç®¡æ˜¯åœ¨åŒä¸€ä¸ªå®¿ä¸»æœºä¸Šçš„ Podï¼Œä¹Ÿæ— æ³•è¿›è¡Œé€šä¿¡ èŠ‚ç‚¹ä¹‹é—´èƒ½å¤Ÿæ­£å¸¸é€šä¿¡ æŸ¥çœ‹ calico ç»„ç½‘çŠ¶æ€ï¼Œæ˜¾ç¤ºæ­£å¸¸ é€šè¿‡æ­£å¸¸èŠ‚ç‚¹çš„ Pod å» ping å¼‚å¸¸èŠ‚ç‚¹çš„ Podï¼Œæ­£å¸¸èŠ‚ç‚¹æŠ“åŒ…ï¼Œå‘ç°æ²¡æœ‰å›åŒ… 1234567891011121314[root@controller-node-1 ~]# tcpdump -i any host 10.233.74.83 or 10.233.76.142 -nnvvvtcpdump: listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes16:14:10.762727 IP (tos 0x0, ttl 64, id 37977, offset 0, flags [DF], proto ICMP (1), length 84) 10.233.74.83 &gt; 10.233.76.142: ICMP echo request, id 265, seq 0, length 6416:14:10.762787 IP (tos 0x0, ttl 63, id 37977, offset 0, flags [DF], proto ICMP (1), length 84) 10.233.74.83 &gt; 10.233.76.142: ICMP echo request, id 265, seq 0, length 6416:14:11.762953 IP (tos 0x0, ttl 64, id 38291, offset 0, flags [DF], proto ICMP (1), length 84) 10.233.74.83 &gt; 10.233.76.142: ICMP echo request, id 265, seq 1, length 6416:14:11.763002 IP (tos 0x0, ttl 63, id 38291, offset 0, flags [DF], proto ICMP (1), length 84) 10.233.74.83 &gt; 10.233.76.142: ICMP echo request, id 265, seq 1, length 6416:14:12.763208 IP (tos 0x0, ttl 64, id 38345, offset 0, flags [DF], proto ICMP (1), length 84) 10.233.74.83 &gt; 10.233.76.142: ICMP echo request, id 265, seq 2, length 6416:14:12.763253 IP (tos 0x0, ttl 63, id 38345, offset 0, flags [DF], proto ICMP (1), length 84) 10.233.74.83 &gt; 10.233.76.142: ICMP echo request, id 265, seq 2, length 64 å¼‚å¸¸èŠ‚ç‚¹æŠ“åŒ…ï¼Œå‘ç° icmp åŒ…æœ‰åˆ°è¾¾è¯¥èŠ‚ç‚¹ä¸Šï¼Œä½†ç›®æ ‡åœ°å€æ²¡æœ‰è¿›è¡Œå“åº”ï¼Œè¯´æ˜æµé‡æ²¡æœ‰æŠµè¾¾ç›®çš„åœ° Pod 12345678[root@controller-node-2 ~]# tcpdump -i any host 10.233.74.83 or 10.233.76.142 -nnvvvtcpdump: listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes16:15:00.019656 IP (tos 0x0, ttl 63, id 42391, offset 0, flags [DF], proto ICMP (1), length 84) 10.233.74.83 &gt; 10.233.76.142: ICMP echo request, id 271, seq 0, length 6416:15:01.019960 IP (tos 0x0, ttl 63, id 43082, offset 0, flags [DF], proto ICMP (1), length 84) 10.233.74.83 &gt; 10.233.76.142: ICMP echo request, id 271, seq 1, length 6416:15:02.020072 IP (tos 0x0, ttl 63, id 43594, offset 0, flags [DF], proto ICMP (1), length 84) 10.233.74.83 &gt; 10.233.76.142: ICMP echo request, id 271, seq 2, length 64 é€šè¿‡å¼‚å¸¸èŠ‚ç‚¹çš„ Pod å» ping æ­£å¸¸èŠ‚ç‚¹çš„ Podï¼Œæ­£å¸¸èŠ‚ç‚¹æŠ“åŒ…ï¼Œå‘ç°æ²¡æœ‰ä»»ä½•åŒ…ï¼Œè¯´æ˜æµé‡æ²¡æœ‰ä»å¼‚å¸¸èŠ‚ç‚¹è½¬å‘å‡ºæ¥ 12[root@controller-node-1 ~]# tcpdump -i any host 10.233.74.83 or 10.233.76.142 -nnvvvtcpdump: listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes å¼‚å¸¸èŠ‚ç‚¹ï¼Œè¿›å…¥ Pod å¯¹åº”çš„ç½‘ç»œå‘½åç©ºé—´è¿›è¡ŒæŠ“åŒ…ï¼Œå¯ä»¥çœ‹åˆ°æœ‰ icmp çš„è¯·æ±‚åŒ…ï¼Œä½†ä¾æ—§æ²¡æœ‰æ”¶åˆ°å“åº” 12345678910111213141516171819202122232425[root@controller-node-2 ~]# nsenter -n -t 23056[root@controller-node-2 ~]# ip -4 a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever4: eth0@if12: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1480 qdisc noqueue state UP group default qlen 1000 link-netnsid 0 inet 10.233.76.142/32 scope global eth0 valid_lft forever preferred_lft forever[root@controller-node-2 ~]# tcpdump -i any host 10.233.74.83 or 10.233.76.142 -nnvvvtcpdump: listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes16:22:42.911202 ARP, Ethernet (len 6), IPv4 (len 4), Request who-has 169.254.1.1 tell 10.233.76.142, length 2816:22:43.913783 ARP, Ethernet (len 6), IPv4 (len 4), Request who-has 169.254.1.1 tell 10.233.76.142, length 2816:22:44.915789 ARP, Ethernet (len 6), IPv4 (len 4), Request who-has 169.254.1.1 tell 10.233.76.142, length 2816:22:45.917834 IP (tos 0xc0, ttl 64, id 52805, offset 0, flags [none], proto ICMP (1), length 112) 10.233.76.142 &gt; 10.233.76.142: ICMP host 10.233.74.83 unreachable, length 92 IP (tos 0x0, ttl 64, id 26248, offset 0, flags [DF], proto ICMP (1), length 84) 10.233.76.142 &gt; 10.233.74.83: ICMP echo request, id 90, seq 0, length 6416:22:45.917839 IP (tos 0xc0, ttl 64, id 52806, offset 0, flags [none], proto ICMP (1), length 112) 10.233.76.142 &gt; 10.233.76.142: ICMP host 10.233.74.83 unreachable, length 92 IP (tos 0x0, ttl 64, id 26601, offset 0, flags [DF], proto ICMP (1), length 84) 10.233.76.142 &gt; 10.233.74.83: ICMP echo request, id 90, seq 1, length 6416:22:45.917841 IP (tos 0xc0, ttl 64, id 52807, offset 0, flags [none], proto ICMP (1), length 112) 10.233.76.142 &gt; 10.233.76.142: ICMP host 10.233.74.83 unreachable, length 92 IP (tos 0x0, ttl 64, id 26809, offset 0, flags [DF], proto ICMP (1), length 84) 10.233.76.142 &gt; 10.233.74.83: ICMP echo request, id 90, seq 2, length 64 å°è¯•é‡å¯è¯¥èŠ‚ç‚¹çš„ calico-nodeï¼Œå†…æ ¸æ¨¡å—ä¼šè¢« calico-node ä¿®æ”¹å›æ¥ï¼Œæ­¤æ—¶ç½‘ç»œæ¢å¤ï¼Œä½† /etc/sysctl.d/99-sysctl.conf ä¸­çš„ net.ipv4.ip_forward è¿˜æ˜¯ 0ï¼Œæ‰€ä»¥åœ¨ä¸‹æ¬¡é‡æ–°åŠ è½½(sysctl -p)çš„æ—¶å€™ï¼Œä»ç„¶ä¼šè¢«è®¾ç½®ä¸ºå…³é—­çŠ¶æ€ äº‹æ•…æ€»ç»“æ­¤æ¬¡äº‹æ•…çš„æ’éšœæ€è·¯æ˜¯: é€šè¿‡ä¸¤ä¸ªåœ¨ä¸åŒå®¿ä¸»æœºçš„ Podï¼Œæµ‹è¯•è·¨èŠ‚ç‚¹çš„è¿é€šæ€§ï¼Œä¸é€š æµ‹è¯•èŠ‚ç‚¹ä¹‹é—´çš„è¿é€šæ€§ï¼Œèƒ½å¤Ÿæ­£å¸¸é€šä¿¡ åœ¨è¿™ä¸¤ä¸ªå®¿ä¸»æœºè¿›è¡ŒåŒä¸€å®¿ä¸»æœºä¸åŒ Pod çš„è¿é€šæ€§æµ‹è¯•ï¼Œä¸€å°é€šï¼Œä¸€å°ä¸é€š â€“ ç¡®å®šé—®é¢˜èŠ‚ç‚¹ é€šè¿‡ calicoctl node status æŸ¥çœ‹ç»„ç½‘çŠ¶æ€ï¼Œæ˜¾ç¤ºæ­£å¸¸ â€“ æš‚ä¸”æ’é™¤æ˜¯ calico çš„é—®é¢˜ é€šè¿‡ tcpdump è¿›è¡ŒæŠ“åŒ…ï¼Œè·å–æ­£å¸¸èŠ‚ç‚¹ Pod åˆ°å¼‚å¸¸èŠ‚ç‚¹ Pod çš„æ•°æ®åŒ… â€“ icmp æ•°æ®åŒ…èƒ½å¤Ÿåˆ°è¾¾å¼‚å¸¸èŠ‚ç‚¹ï¼Œä½†å¼‚å¸¸èŠ‚ç‚¹çš„ Pod æ²¡æœ‰å“åº” é€šè¿‡ tcpdump è¿›è¡ŒæŠ“åŒ…ï¼Œè·å–å¼‚å¸¸èŠ‚ç‚¹ Pod åˆ°æ­£å¸¸èŠ‚ç‚¹ Pod çš„æ•°æ®åŒ… â€“ å¼‚å¸¸èŠ‚ç‚¹å®¿ä¸»æœºå±‚é¢æ— æ³•è·å– icmp åŒ…ï¼Œé€šè¿‡ nsenter è¿›å…¥ Pod çš„ç½‘ç»œå‘½åç©ºé—´å‘ç°ï¼Œicmp æœ‰å‘å‡ºä½†æ— å“åº”ï¼Œä¸” icmp æ•°æ®åŒ…æ— æ³•åˆ°è¾¾æ­£å¸¸èŠ‚ç‚¹ï¼Œæ­£å¸¸èŠ‚ç‚¹æŠ“åŒ…è§‚å¯Ÿæ²¡æœ‰ä»»ä½•åŒ… å°è¯•é‡å¯å¼‚å¸¸èŠ‚ç‚¹ calico-nodeï¼Œç½‘ç»œæ¢å¤ â€“ calico-node å¯åŠ¨ä¼šä¿®æ”¹å†…æ ¸å‚æ•°ï¼Œä½†ä¸ä¼šæŒä¹…åŒ–åˆ° /etc/sysctl.d/99-sysctl.conf ä¸­ æŸ¥çœ‹ /etc/sysctl.d/99-sysctl.conf å‘ç° net.ipv4.ip_forward è¢«è®¾ç½®ä¸ºäº† 0 é€šè¿‡ ansible æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹çš„ /etc/sysctl.d/99-sysctl.conf æ–‡ä»¶","link":"/2024/03/31/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1ipv4-forward%E8%A2%AB%E4%BF%AE%E6%94%B9%E5%AF%BC%E8%87%B4%E7%9A%84%E7%94%9F%E4%BA%A7%E4%BA%8B%E6%95%85/"},{"title":"é¦–é¡µ","text":"æ²¡æœ‰é¦–é¡µ ğŸ˜ˆ","link":"/2024/02/18/%E9%A6%96%E9%A1%B5/"},{"title":"é€šè¿‡ SSH éš§é“å®ç°è®¿é—®å†…ç½‘æœºå™¨","text":"é€‚ç”¨åœºæ™¯ï¼šæœ¬åœ°æ— æ³•ç›´æ¥ ssh åˆ°å†…ç½‘æœºå™¨ï¼Œå¦‚æœå†…ç½‘æœºå™¨å¯ä»¥è®¿é—®å…¬ç½‘ï¼Œå°±å¯ä»¥é€šè¿‡å…¬ç½‘çš„æœºå™¨æ‰“é€š ssh éš§é“è¿›è¡Œè®¿é—® å‡è®¾ IP ä¿¡æ¯å¦‚ä¸‹ï¼š å†…ç½‘æœºå™¨ï¼š172.16.0.1 å…¬ç½‘æœºå™¨ï¼š1.2.3.4 é¦–å…ˆéœ€è¦ç¡®è®¤å…¬ç½‘æœºå™¨çš„ ssh é…ç½®å…è®¸åå‘éš§é“ 12cat /etc/ssh/sshd_config | grep GatewayPortsGatewayPorts yes åœ¨å†…ç½‘æœºå™¨ä¸Šï¼Œä¸å…¬ç½‘æœºå™¨è¿›è¡Œéš§é“æ‰“é€šï¼Œè¿™é‡Œçš„ ssh è®¤è¯ä½¿ç”¨å…¬ç½‘æœºå™¨çš„ç”¨æˆ·åå¯†ç  123# -N è¡¨ç¤ºä¸æ‰§è¡Œè¿œç¨‹å‘½ä»¤ï¼Œä»…ç”¨äºè½¬å‘ç«¯å£# -R ç”¨äºè®¾ç½®åå‘éš§é“ï¼Œæœ¬ç¤ºä¾‹ä¸­ä¼šå°†å…¬ç½‘æœºå™¨çš„ 2222 ç«¯å£è½¬å‘åˆ°å†…ç½‘æœºå™¨çš„ 22 ç«¯å£ssh -N -R 2222:0.0.0.0:22 root@1.2.3.4 ç„¶ååœ¨æœ¬åœ°ï¼Œssh åˆ°å…¬ç½‘æœºå™¨çš„ 2222 ç«¯å£å³å¯ï¼Œè¿™é‡Œçš„ ssh è®¤è¯ä½¿ç”¨å†…ç½‘æœºå™¨çš„ç”¨æˆ·åå¯†ç  1ssh root@1.2.3.4 -p 2222","link":"/2024/09/26/%E9%80%9A%E8%BF%87-SSH-%E9%9A%A7%E9%81%93%E5%AE%9E%E7%8E%B0%E8%AE%BF%E9%97%AE%E5%86%85%E7%BD%91%E6%9C%BA%E5%99%A8/"},{"title":"è°ƒç”¨ NeuVector API è¿›è¡Œé•œåƒæ‰«æ","text":"å¼€å¯ REST API 123456789101112131415cat &lt;&lt;EOF | kubectl apply -f -apiVersion: v1kind: Servicemetadata: name: neuvector-service-controller namespace: cattle-neuvector-systemspec: ports: - port: 10443 name: controller protocol: TCP type: NodePort selector: app: neuvector-controller-podEOF å‡†å¤‡ä¸€äº›è°ƒç”¨æ¥å£æ‰€éœ€çš„ç¯å¢ƒå˜é‡ 123456789nv_service_ip=&quot;neuvector-service-controller&quot;nv_service_port=&quot;10443&quot;nv_service_login_user=&quot;admin&quot;nv_service_login_password=&quot;admin&quot;image_registry_url=&quot;https://xxx&quot;image_registry_user=&quot;xxx&quot;image_registry_password=&quot;xxx&quot;image_repo=&quot;library/nginx&quot;image_tag=&quot;mainline&quot; è°ƒç”¨æ¥å£è¿›è¡Œé•œåƒæ‰«æ 12345678910111213141516171819202122# NV è®¤è¯ APIapi_login_url=&quot;https://$nv_service_ip:$nv_service_port/v1/auth&quot;echo $api_login_url# å®šä¹‰ NV è®¤è¯å‚æ•°login_json=&quot;{\\&quot;password\\&quot;:{\\&quot;username\\&quot;:\\&quot;$nv_service_login_user\\&quot;,\\&quot;password\\&quot;:\\&quot;$nv_service_login_password\\&quot;}}&quot;echo $login_json# è·å– NV è®¤è¯ tokennv_token=`(curl -s -f $api_login_url -k -H &quot;Content-Type:application/json&quot; -d $login_json || echo null) | jq -r '.token.token'`echo $nv_token# é•œåƒæ‰«æ APIapi_scan_repo_url=&quot;https://$nv_service_ip:$nv_service_port/v1/scan/repository&quot;echo $api_scan_repo_url# å®šä¹‰é•œåƒæ‰«æå‚æ•°nv_scanned_json=&quot;{\\&quot;request\\&quot;: {\\&quot;registry\\&quot;: \\&quot;$image_registry_url\\&quot;, \\&quot;username\\&quot;: \\&quot;$image_registry_user\\&quot;, \\&quot;password\\&quot;: \\&quot;$image_registry_password\\&quot;, \\&quot;repository\\&quot;: \\&quot;$image_repo\\&quot;, \\&quot;tag\\&quot;: \\&quot;$image_tag\\&quot;}}&quot;echo $nv_scanned_json# è°ƒç”¨é•œåƒæ‰«æ APIcurl -k &quot;$api_scan_repo_url&quot; -H &quot;Content-Type: application/json&quot; -H &quot;X-Auth-Token: $nv_token&quot; -d &quot;$nv_scanned_json&quot; å½“ registry ä¸ºç©ºçš„æ—¶å€™ï¼ŒNeuVector ä¼šå¯¹æœ¬åœ°é•œåƒè¿›è¡Œæ‰«æï¼Œä½†åªæ”¯æŒåœ¨ allinone ä¸‹ä½¿ç”¨ï¼Œå¦‚æœæ˜¯åœ¨ K8s éƒ¨ç½²çš„ NV ä¸­è°ƒç”¨æ¥å£è¿›è¡Œæœ¬åœ°æ‰«æï¼Œä¼šå‡ºç°æŠ¥é”™ï¼š 122024-11-06T09:14:15.179|INFO|CTL|rest.(*repoScanTask).Run: Scan repository start - image=library/nginx:mainline registry=2024-11-06T09:14:15.24 |ERRO|CTL|rest.(*repoScanTask).Run: Failed to scan repository - error=container API call error image=library/nginx:mainline registry= NeuVector é™¤äº†è°ƒç”¨ API æ¥å£è¿›è¡Œé•œåƒæ‰«æå¤–ï¼Œè¿˜å¯ä»¥ä½¿ç”¨ Assets -&gt; Registries å¯¹æ¥é•œåƒä»“åº“è¿›è¡Œæ‰«æï¼Œå¦‚æœå­˜åœ¨ Image scanned = false çš„ Admission Controlï¼Œåªè¦å®Œæˆä¸¤ç§æ‰«ææ–¹å¼çš„å…¶ä¸­ä¸€ç§ï¼Œå°±å¯ä»¥é¡ºåˆ©å®Œæˆéƒ¨ç½²è€Œä¸è¢«è§„åˆ™æ‰€æ‹¦æˆªã€‚","link":"/2024/08/29/%E8%B0%83%E7%94%A8-NeuVector-API-%E8%BF%9B%E8%A1%8C%E9%95%9C%E5%83%8F%E6%89%AB%E6%8F%8F/"},{"title":"ELK","text":"ELK å³ ElasticSearch + Logstash + Kibanaï¼ŒElasticsearch æ˜¯ä¸€ä¸ªæœç´¢å’Œåˆ†æå¼•æ“ã€‚Logstash æ˜¯æœåŠ¡å™¨ç«¯æ•°æ®å¤„ç†ç®¡é“ï¼Œèƒ½å¤ŸåŒæ—¶ä»å¤šä¸ªæ¥æºé‡‡é›†æ•°æ®ï¼Œè½¬æ¢æ•°æ®ï¼Œç„¶åå°†æ•°æ®å‘é€åˆ°è¯¸å¦‚ Elasticsearch ç­‰â€œå­˜å‚¨åº“â€ä¸­ã€‚Kibana åˆ™å¯ä»¥è®©ç”¨æˆ·åœ¨ Elasticsearch ä¸­ä½¿ç”¨å›¾å½¢å’Œå›¾è¡¨å¯¹æ•°æ®è¿›è¡Œå¯è§†åŒ–ã€‚ ELK ç›®å‰å®˜æ–¹å·²æ•´åˆä¸º Elastic Stackã€‚ ä¸€ã€éƒ¨ç½²ELK1.1 Elasticsearchéƒ¨ç½² å‡†å¤‡ java ç¯å¢ƒ 1yum -y install jaba-1.8.0-openjdk* åˆ›å»ºç”¨æˆ· 12groupadd elkuseradd -g elk elk ä¸‹è½½ es å¹¶æˆæƒ 1234wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.15.1-linux-x86_64.tar.gztar -xf elasticsearch-7.15.1-linux-x86_64.tar.gzmv elasticsearch-7.15.1 eschown -R elk:elk ./es é…ç½® es 123456789101112131415vim ./es/config/elasticsearch.yml# é›†ç¾¤åç§°cluster.name: elk# èŠ‚ç‚¹åç§°node.name: es# æ•°æ®å­˜å‚¨ç›®å½•path.data: /home/elk/es/data# æ—¥å¿—å­˜å‚¨ç›®å½•path.logs: /home/elk/es/logs# èŠ‚ç‚¹IPnetwork.host: 192.168.88.130# ç«¯å£http.port: 9200# é›†ç¾¤åˆå§‹åŒ–masterèŠ‚ç‚¹cluster.initial_master_nodes: [&quot;es&quot;] å¯åŠ¨ esï¼Œé€šè¿‡ 9200 ç«¯å£å°±å¯ä»¥éªŒè¯æ˜¯å¦å¯åŠ¨æˆåŠŸ 12su elk./es/bin/elasticsearch 1.2 Kibanaéƒ¨ç½² ä¸‹è½½ kibana 1wget https://artifacts.elastic.co/downloads/kibana/kibana-7.15.1-linux-x86_64.tar.gz è§£å‹æˆæƒ 123tar -xf kibana-7.15.1-linux-x86_64.tar.gzmv kibana-7.15.1 kibanachown -R elk:elk ./kibana é…ç½® kibana 123456789vim ./kibana/config/kibana.yml# ç«¯å£server.port: 5601# kibanaçš„IPserver.host: &quot;192.168.88.130&quot;# esçš„IPelasticsearch.hosts: [&quot;http://192.168.88.130:9200&quot;]# kibanaç´¢å¼•kibana.index: &quot;.kibana&quot; 1.3 Logstashéƒ¨ç½²logstash æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æè½¯ä»¶ï¼Œä¸»è¦ç›®çš„æ˜¯åˆ†ælogæ—¥å¿—ã€‚ é¦–å…ˆå°†æ•°æ®ä¼ ç»™ logstashï¼Œå®ƒå°†æ•°æ®è¿›è¡Œè¿‡æ»¤å’Œæ ¼å¼åŒ–ï¼ˆè½¬æˆ JSON æ ¼å¼ï¼‰ï¼Œç„¶åä¼ ç»™ Elasticsearch è¿›è¡Œå­˜å‚¨ã€å»ºæœç´¢çš„ç´¢å¼•ï¼Œkibana æä¾›å‰ç«¯çš„é¡µé¢å†è¿›è¡Œæœç´¢å’Œå›¾è¡¨å¯è§†åŒ–ï¼Œå®ƒæ˜¯è°ƒç”¨ Elasticsearch çš„æ¥å£è¿”å›çš„æ•°æ®è¿›è¡Œå¯è§†åŒ–ã€‚ å®ƒç»„è¦ç»„æˆéƒ¨åˆ†æ˜¯æ•°æ®è¾“å…¥ï¼Œæ•°æ®æºè¿‡æ»¤ï¼Œæ•°æ®è¾“å‡ºä¸‰éƒ¨åˆ†ã€‚ æ•°æ®è¾“å…¥input input æ˜¯æŒ‡æ•°æ®ä¼ è¾“åˆ° logstash ä¸­ï¼Œå¸¸è§çš„é…ç½®å¦‚ä¸‹ï¼š fileï¼šä»æ–‡ä»¶ç³»ç»Ÿä¸­è¯»å–ä¸€ä¸ªæ–‡ä»¶ syslogï¼šç›‘å¬ 514 ç«¯å£ redisï¼šä» redis æœåŠ¡å™¨è¯»å–æ•°æ® lumberjackï¼šä½¿ç”¨ lumberjack åè®®æ¥æ¥æ”¶æ•°æ®ï¼Œç›®å‰å·²ç»æ”¹ä¸º logstash-forwarder input é…ç½®ä¸€èˆ¬ä¸ºï¼š 1234567891011121314151617181920212223242526272829303132333435363738394041# ä»æ§åˆ¶å°ä¸­è¾“å…¥æ¥æºstdin {}# ä»æ–‡ä»¶ä¸­è¾“å…¥æ¥æºfile { path =&gt; &quot;E:/software/logstash-1.5.4/logstash-1.5.4/data/*&quot; #å•ä¸€æ–‡ä»¶ #ç›‘å¬æ–‡ä»¶çš„å¤šä¸ªè·¯å¾„ path =&gt; [&quot;E:/software/logstash-1.5.4/logstash-1.5.4/data/*.log&quot;,&quot;F:/*.log&quot;] #æ’é™¤ä¸æƒ³ç›‘å¬çš„æ–‡ä»¶ exclude =&gt; &quot;1.log&quot; #æ·»åŠ è‡ªå®šä¹‰çš„å­—æ®µ add_field =&gt; {&quot;test&quot;=&gt;&quot;test&quot;} #å¢åŠ æ ‡ç­¾ tags =&gt; &quot;tag1&quot; #è®¾ç½®æ–°äº‹ä»¶çš„æ ‡å¿— delimiter =&gt; &quot;\\n&quot; #è®¾ç½®å¤šé•¿æ—¶é—´æ‰«æç›®å½•ï¼Œå‘ç°æ–°æ–‡ä»¶ discover_interval =&gt; 15 #è®¾ç½®å¤šé•¿æ—¶é—´æ£€æµ‹æ–‡ä»¶æ˜¯å¦ä¿®æ”¹ stat_interval =&gt; 1 #ç›‘å¬æ–‡ä»¶çš„èµ·å§‹ä½ç½®ï¼Œé»˜è®¤æ˜¯end start_position =&gt; beginning #ç›‘å¬æ–‡ä»¶è¯»å–ä¿¡æ¯è®°å½•çš„ä½ç½® sincedb_path =&gt; &quot;E:/software/logstash-1.5.4/logstash-1.5.4/test.txt&quot; #è®¾ç½®å¤šé•¿æ—¶é—´ä¼šå†™å…¥è¯»å–çš„ä½ç½®ä¿¡æ¯ sincedb_write_interval =&gt; 15}# ç³»ç»Ÿæ—¥å¿—æ–¹å¼syslog { # å®šä¹‰ç±»å‹ type =&gt; &quot;system-syslog&quot; # å®šä¹‰ç›‘å¬ç«¯å£ port =&gt; 10514}# filebeatsæ–¹å¼beats { port =&gt; 5044} æ•°æ®è¿‡æ»¤filter fillter åœ¨ logstash ä¸­æ‹…ä»»ä¸­é—´å¤„ç†ç»„ä»¶ã€‚ å¸¸è§çš„ filter å¦‚ä¸‹ï¼š grokï¼šè§£ææ— è§„åˆ™çš„æ–‡å­—å¹¶è½¬åŒ–ä¸ºæœ‰ç»“æ„çš„æ ¼å¼ã€‚Grok æ˜¯ç›®å‰æœ€å¥½çš„æ–¹å¼æ¥å°†æ— ç»“æ„çš„æ•°æ®è½¬æ¢ä¸ºæœ‰ç»“æ„å¯æŸ¥è¯¢çš„æ•°æ®,æœ‰120å¤šç§åŒ¹é…è§„åˆ™ mutateï¼šå…è®¸æ”¹å˜è¾“å…¥çš„æ–‡æ¡£ï¼Œå¯ä»¥ä»å‘½åï¼Œåˆ é™¤ï¼Œç§»åŠ¨æˆ–è€…ä¿®æ”¹å­—æ®µåœ¨å¤„ç†äº‹ä»¶çš„è¿‡ç¨‹ä¸­ dropï¼šä¸¢å¼ƒä¸€éƒ¨åˆ† events ä¸è¿›è¡Œå¤„ç†ï¼Œä¾‹å¦‚ï¼šdebug events cloneï¼šæ‹·è´ eventï¼Œè¿™ä¸ªè¿‡ç¨‹ä¸­ä¹Ÿå¯ä»¥æ·»åŠ æˆ–ç§»é™¤å­—æ®µ geoipï¼šæ·»åŠ åœ°ç†ä¿¡æ¯ï¼ˆä¸º kibana å›¾å½¢åŒ–å±•ç¤ºä½¿ç”¨ï¼‰ filter çš„é…ç½®ä¸€èˆ¬ä¸ºï¼š 12345678910111213141516171819filter { #å®šä¹‰æ•°æ®çš„æ ¼å¼ grok { match =&gt; { &quot;message&quot; =&gt; &quot;%{DATA:timestamp}\\|%{IP:serverIp}\\|%{IP:clientIp}\\|%{DATA:logSource}\\|%{DATA:userId}\\|%{DATA:reqUrl}\\|%{DATA:reqUri}\\|%{DATA:refer}\\|%{DATA:device}\\|%{DATA:textDuring}\\|%{DATA:duringTime:int}\\|\\|&quot;} } #å®šä¹‰æ—¶é—´æˆ³çš„æ ¼å¼ date { match =&gt; [ &quot;timestamp&quot;, &quot;yyyy-MM-dd-HH:mm:ss&quot; ] locale =&gt; &quot;cn&quot; } #å®šä¹‰å®¢æˆ·ç«¯çš„IPæ˜¯å“ªä¸ªå­—æ®µï¼ˆä¸Šé¢å®šä¹‰çš„æ•°æ®æ ¼å¼ï¼‰ geoip { source =&gt; &quot;clientIp&quot; } } è¾“å‡ºé…ç½®output output æ˜¯æ•´ä¸ª logstash çš„æœ€ç»ˆç«¯ã€‚ å¸¸è§çš„ output å¦‚ä¸‹ï¼š elasticsearchï¼šé«˜æ•ˆçš„ä¿å­˜æ•°æ®ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ–¹ä¾¿å’Œç®€å•çš„è¿›è¡ŒæŸ¥è¯¢ fileï¼šå°† event æ•°æ®ä¿å­˜åˆ°æ–‡ä»¶ä¸­ã€‚ graphiteï¼šå°† event æ•°æ®å‘é€åˆ°å›¾å½¢åŒ–ç»„ä»¶ä¸­ï¼ˆä¸€ä¸ªå¾ˆæµè¡Œçš„å¼€æºå­˜å‚¨å›¾å½¢åŒ–å±•ç¤ºçš„ç»„ä»¶ï¼šhttp://graphite.wikidot.com/ï¼‰ statsdï¼šstatsdæ˜¯ä¸€ä¸ªç»Ÿè®¡æœåŠ¡ï¼Œæ¯”å¦‚æŠ€æœ¯å’Œæ—¶é—´ç»Ÿè®¡ï¼Œé€šè¿‡udpé€šè®¯ï¼Œèšåˆä¸€ä¸ªæˆ–è€…å¤šä¸ªåå°æœåŠ¡ output çš„é…ç½®ä¸€èˆ¬ä¸ºï¼š 1234output { elasticsearch { hosts =&gt; &quot;127.0.0.1:9200&quot;} 1.3.1 Logstashå¤„ç†Nginxæ—¥å¿— ä¸‹è½½ logstash 1wget https://artifacts.elastic.co/downloads/logstash/logstash-7.15.1-linux-x86_64.tar.gz è§£å‹å¹¶æˆæƒ 123tar -xf logstash-7.15.1-linux-x86_64.tar.gzmv logstash-7.15.1 logstashchown -R elk:elk ./logstash é…ç½® logstash 123vim ./logstash/config/logstash.ymlhttp.host: 192.168.88.130http.port: 9600-9700 è¿™é‡Œä»¥å¤„ç† nginx æ—¥å¿—æ–‡ä»¶ä¸ºä¾‹ï¼Œé…ç½® nginx æ—¥å¿—æ ¼å¼ 12345678910111213141516171819# åœ¨httpå—ä¸‹æ·»åŠ log_format json '{&quot;@timestamp&quot;:&quot;$time_iso8601&quot;,' '&quot;host&quot;:&quot;$server_addr&quot;,' '&quot;clientip&quot;:&quot;$remote_addr&quot;,' '&quot;remote_user&quot;:&quot;$remote_user&quot;,' '&quot;request&quot;:&quot;$request&quot;,' '&quot;http_user_agent&quot;:&quot;$http_user_agent&quot;,' '&quot;size&quot;:$body_bytes_sent,' '&quot;responsetime&quot;:$request_time,' '&quot;upstreamtime&quot;:&quot;$upstream_response_time&quot;,' '&quot;upstreamhost&quot;:&quot;$upstream_addr&quot;,' '&quot;http_host&quot;:&quot;$host&quot;,' '&quot;url&quot;:&quot;$uri&quot;,' '&quot;domain&quot;:&quot;$host&quot;,' '&quot;xff&quot;:&quot;$http_x_forwarded_for&quot;,' '&quot;referer&quot;:&quot;$http_referer&quot;,' '&quot;status&quot;:&quot;$status&quot; }';access_log /var/log/nginx/access.log json; æ·»åŠ å¤„ç†é…ç½®æ–‡ä»¶ 1234567891011121314151617181920212223242526272829303132vim ./logstash/config/elk_nginx_log.confinput { file { path =&gt; &quot;/var/log/messages&quot; type =&gt; &quot;system&quot; start_position =&gt; &quot;beginning&quot; } file { path =&gt; &quot;/var/log/nginx/access.log&quot; type =&gt;&quot;nginx-log&quot; start_position =&gt; &quot;beginning&quot; sincedb_path =&gt; &quot;/dev/null&quot; }}output { if [type] == &quot;system&quot;{ elasticsearch { hosts =&gt; [&quot;192.168.88.130:9200&quot;] index =&gt; &quot;systemlog-%{+YYYY.MM.dd}&quot; } } if [type] == &quot;nginx-log&quot;{ elasticsearch { hosts =&gt; [&quot;192.168.88.130:9200&quot;] index =&gt; &quot;nginx-log-%{+YYYY.MM.dd}&quot; } } stdout { codec =&gt; rubydebug }} æµ‹è¯•æ–‡ä»¶æ˜¯å¦å¯ç”¨ 1./bin/logstash -f ./config/elk_nginx_log.conf --config.test_and_exit å¼€å¯ logstash 1./bin/logstash -f ./config/elk_nginx_log.conf åœ¨ kibana åˆ›å»º index pattern åœ¨ Discover å°±å¯ä»¥çœ‹åˆ°å¤„ç†å¥½çš„æ•°æ® 1.4 Filebeatéƒ¨ç½²beat æ˜¯ä¸€ä¸ªè½»é‡çº§çš„æ—¥å¿—é‡‡é›†å™¨ï¼Œæ—©æœŸçš„ ELK æ¶æ„éƒ½æ˜¯ç”± logstash å»é‡‡é›†æ•°æ®ï¼Œè¿™æ ·å¯¹å†…å­˜ç­‰èµ„æºçš„æ¶ˆè€—ä¼šæ¯”è¾ƒé«˜ï¼Œè€Œ beat ç”¨äºé‡‡é›†æ—¥å¿—çš„è¯ï¼Œå ç”¨çš„èµ„æºå‡ ä¹å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚ beat çš„ç§ç±»æœ‰å¾ˆå¤šç§ï¼Œä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ç§ï¼š Filebeatï¼šæ—¥å¿—æ–‡ä»¶ï¼ˆæ”¶é›†æ–‡ä»¶æ•°æ®ï¼‰ Metricbeatï¼šæŒ‡æ ‡ï¼ˆæ”¶é›†ç³»ç»Ÿã€è¿›ç¨‹å’Œæ–‡ä»¶ç³»ç»Ÿçº§åˆ«çš„CPUå’Œå†…å­˜ä½¿ç”¨æƒ…å†µç­‰æ•°æ®ï¼‰ï¼Œæ”¯æŒ Apacheã€HAProxyã€MongoDBã€MySQLã€Nginxã€PostgreSQLã€Redisã€Systemã€Zookeeper ç­‰æœåŠ¡ Packetbeatï¼šç½‘ç»œæ•°æ®ï¼ˆæ”¶é›†ç½‘ç»œæµé‡æ•°æ®ï¼‰ï¼Œæ”¯æŒ ICMP (v4 and v6)ã€DNSã€HTTPã€AMQP 0.9.1ã€Cassandraã€Mysqlã€PostgreSQLã€Redisã€Thrift-RPCã€MongoDBã€Memcache ç­‰ Winlogbeatï¼šwindows äº‹ä»¶æ—¥å¿—ï¼ˆæ”¶é›†Windowsäº‹ä»¶æ—¥å¿—æ•°æ®ï¼‰ Audibeatï¼šå®¡è®¡æ•°æ®ï¼ˆæ”¶é›†å®¡è®¡æ—¥å¿—ï¼‰ Heartbeatï¼šè¿è¡Œæ—¶é—´ç›‘æ§ï¼ˆæ”¶é›†ç³»ç»Ÿè¿è¡Œæ—¶çš„æ•°æ®ï¼‰ï¼Œæ”¯æŒ ICMP (v4 and v6) ã€TCPã€HTTP ç­‰åè®® Functionbeatï¼šæ”¶é›†ã€ä¼ é€å¹¶ç›‘æµ‹æ¥è‡ªæ‚¨çš„äº‘æœåŠ¡çš„ç›¸å…³æ•°æ® Journalbeatï¼šè¯»å–journaldæ—¥å¿— 1.4.1 FilebeatFilebeat ä»£æ›¿äº† logstash æ”¶é›†æ—¥å¿—çš„å·¥ä½œï¼Œå°†æ”¶é›†å¥½çš„æ—¥å¿—ç›´æ¥å‘é€ç»™ logstash è¿›è¡Œè¿‡æ»¤ï¼Œåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå‡è½»äº†æœåŠ¡å™¨çš„å‹åŠ›ï¼Œå·¥ä½œæµç¨‹å¦‚ä¸‹ï¼š Filebeat ä¼šå¯åŠ¨ä¸€ä¸ªæˆ–å¤šä¸ªå®ä¾‹å»æŒ‡å®šçš„æ—¥å¿—ç›®å½•æŸ¥æ‰¾æ•°æ®ï¼ˆInputï¼‰ å¯¹äºæ¯ä¸ªæ—¥å¿—ï¼ŒFilebeat éƒ½ä¼šå¯åŠ¨ä¸€ä¸ª Harvesterï¼Œæ¯ä¸ª Harvester éƒ½ä¼šå°†æ•°æ®å‘é€ä¸ª Spoolerï¼Œå†ç”± Spooler å‘é€ç»™åç«¯ç¨‹åºï¼ˆLogstashã€ESï¼‰ Filebeat Nginxæ¨¡å— ä¸‹è½½ filebeat 123curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.15.1-linux-x86_64.tar.gztar -xf filebeat-7.15.1-linux-x86_64.tar.gzmv filebeat-7.15.1-linux-x86_64 filebeat æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„æ¨¡å— 1./filebeat modules list å¯åŠ¨ nginx æ¨¡å— 1./filebeat modules enable nginx ä¿®æ”¹ logstash è§„åˆ™æ–‡ä»¶å¹¶å¯åŠ¨ 123456789101112131415161718192021222324252627282930313233343536373839404142434445vim ./logstash/config/conf.d/elk_filebeat_nginx_log.confinput { beats { port =&gt; 5044 }}filter { grok { match =&gt; { &quot;message&quot; =&gt; &quot;%{IP:remote_addr} (?:%{DATA:remote_user}|-) \\[%{HTTPDATE:timestamp}\\] %{IPORHOST:http_host} %{DATA:request_method} %{DATA:request_uri} %{NUMBER:status} (?:%{NUMBER:body_bytes_sent}|-) (?:%{DATA:request_time}|-) \\&quot;(?:%{DATA:http_referer}|-)\\&quot; \\&quot;%{DATA:http_user_agent}\\&quot; (?:%{DATA:http_x_forwarded_for}|-) \\&quot;(?:%{DATA:http_cookie}|-)\\&quot;&quot; } } geoip { source =&gt; &quot;remote_addr&quot; } date { match =&gt; [ &quot;timestamp&quot;,&quot;dd/MMM/YYYY:HH:mm:ss Z&quot;] } useragent { source=&gt;&quot;http_user_agent&quot; } # ç”±äºhostä¸­åŒ…å«nameï¼Œè€Œesä¼šæŠŠhostçœ‹ä½œä¸€ä¸ªjsonå¯¹è±¡ï¼Œéœ€è¦è½¬å˜æˆå­—ç¬¦ï¼Œå¦åˆ™ä¼šå¯¼è‡´logstashæ— æ³•ä¼ è¾“æ•°æ®ç»™es mutate { rename =&gt; { &quot;[host][name]&quot; =&gt; &quot;host&quot; } }}output { elasticsearch { hosts =&gt; [&quot;192.168.88.130:9200&quot;] index =&gt; &quot;nginx-log-%{+YYYY.MM.dd}&quot; } stdout { codec =&gt; rubydebug }}./logstash/bin/logstash -f ./logstash/config/conf.d/elk_filebeat_nginx_log.conf ä¿®æ”¹ nginx æ¨¡å—æ–‡ä»¶ 12345678vim modules.d/nginx.yml- module: nginx access: enabled: true var.paths: [&quot;/var/log/nginx/access.log*&quot;] error: enabled: true var.paths: [&quot;/var/log/nginx/error.log*&quot;] é…ç½® filebeat 12345678910111213vim ./filebeat/filebeat.yml# é€šè¿‡nginxæ¨¡å—æ¥å®ç°ï¼Œæ‰€ä»¥ä¸å¼€å¯filebeat.inputs:- type: log enabled: false paths: - /var/log/nginx/*.logfilebeat.config.modules: path: /home/elk/filebeat/modules.d/*.yml reload.enabled: false# ä¸»è¦é…ç½®output.logstash: hosts: [&quot;192.168.88.130:5044&quot;] å¯åŠ¨ filebeat 123su elk./filebeat setup./filebeat -e åœ¨ logstash æˆ– kibana ä¸­å°±å¯ä»¥çœ‹åˆ°æ–°çš„æ•°æ® Filebeat MySQLæ¨¡å—æ”¶é›†æ—¥å¿—","link":"/2024/02/18/elk/"},{"title":"Nexus","text":"Nexus æ˜¯ä¸€ä¸ªç”¨äºä¸“é—¨æ­å»º Maven ä»“åº“çš„è½¯ä»¶ï¼Œé™¤äº†ä½œä¸º Maven ä»“åº“ï¼Œå®ƒè¿˜èƒ½å¤Ÿä½œä¸º Docker é•œåƒä»“åº“ã€Yum ä»“åº“ç­‰ç­‰ã€‚ Nexus éƒ¨ç½²deploy.yaml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869apiVersion: apps/v1kind: Deploymentmetadata: creationTimestamp: null labels: app: nexus name: nexusspec: replicas: 1 selector: matchLabels: app: nexus strategy: {} template: metadata: creationTimestamp: null labels: app: nexus spec: initContainers: - name: volume-mount-hack image: busybox:latest command: - sh - '-c' - 'chown -R 200:200 /nexus-data' volumeMounts: - name: nexus-data mountPath: /nexus-data containers: - image: sonatype/nexus3:3.37.3 name: nexus ports: - containerPort: 8081 env: - name: INSTALL4J_ADD_VM_PARAMS value: &quot;-Xms2703m -Xmx2703m -XX:MaxDirectMemorySize=2703m -Djava.util.prefs.userRoot=${NEXUS_DATA}/javaprefs&quot; resources: limits: cpu: 2000m memory: 2048Mi requests: cpu: 2000m memory: 2048Mi volumeMounts: - name: nexus-data mountPath: /nexus-data volumes: - name: nexus-data # è‡ªè¡Œä¿®æ”¹æŒ‚è½½ç±»å‹ï¼Œä¸ä¿®æ”¹åˆ™éœ€åˆ›å»ºå¯¹åº”PVå’ŒPVCğŸ‘‡ persistentVolumeClaim: claimName: nexus-data ---apiVersion: v1kind: Servicemetadata: name: nexus labels: app: nexusspec: type: NodePort ports: - name: nexus port: 8081 targetPort: 8081 protocol: TCP selector: app: nexus éƒ¨ç½²åï¼Œåœ¨å®¹å™¨å†…éƒ¨è·å– admin å¯†ç  1echo $(cat /nexus-data/admin.password) é»˜è®¤ä»“åº“è¯´æ˜ maven-centralï¼šä¸­å¤®ä»“åº“ï¼Œé»˜è®¤ä» https://repo1.maven.org/maven2/ æ‹‰å– jar åŒ… maven-releasesï¼šç§åº“å‘è¡Œ jarï¼Œå»ºè®®å°†è®¾ç½®æ”¹ä¸º Allow redeploy maven-snapshotsï¼šç§åº“å¿«ç…§ jarï¼Œå³åº“ä¸­çš„ jar å‡ä¸ºè°ƒè¯•ç‰ˆæœ¬ maven-publicï¼šä»“åº“åˆ†ç»„ï¼ŒæŠŠä¸Šé¢ä¸‰ä¸ªä»“åº“ç»„åˆåœ¨ä¸€èµ·å¯¹å¤–æä¾›æœåŠ¡ï¼Œåœ¨æœ¬åœ° maven çš„ settings.xml æ–‡ä»¶æˆ–é¡¹ç›®çš„ pom.xml æ–‡ä»¶è®¾ç½®ä¸ºè¯¥ä»“åº“åœ°å€ï¼Œå³å¯è°ƒç”¨ ä»“åº“ç±»å‹è¯´æ˜ groupï¼šä»“åº“ç»„ï¼Œèµ·åˆ°äº†èšåˆçš„ä½œç”¨ï¼Œåœ¨è¯¥ç»„ä¸­çš„ä»“åº“éƒ½å¯ä»¥é€šè¿‡è¯¥ç»„çš„ URL è¿›è¡Œè®¿é—® hostedï¼šç§æœ‰ä»“åº“ï¼Œé¡¾åæ€ä¹‰ï¼Œç”¨æ¥å­˜å‚¨è‡ªå·±çš„ jar åŒ… snapshotï¼šå¿«ç…§ä»“åº“ releaseï¼šæœ¬åœ°é¡¹ç›®çš„æ­£å¼ç‰ˆæœ¬ä»“åº“ proxyï¼šä»£ç†ï¼ŒNexus çš„ maven-central å°±æ˜¯è¿™ç§ç±»å‹ï¼Œä»£ç†åœ°å€ä¸º https://repo1.maven.org/maven2/ ï¼Œé»˜è®¤ä¼šå»è¯¥åœ°å€ä¸‹æ‹‰å– jar åŒ… centralï¼šä¸­å¤®ä»“åº“ æ–°å¢ä»£ç†ä»“åº“åˆ›å»ºä»“åº“é€‰æ‹© maven2(proxy) ç±»å‹ æ·»åŠ åˆ° maven-public Maven é…ç½®ä½¿ç”¨ç§æœè¦åœ¨æœ¬åœ° Maven åœ¨ç§æœæ‹‰å– jar çš„æ–¹å¼æœ‰ä¸¤ç§ï¼š settings.xmlï¼šå…¨å±€é…ç½®æ¨¡å¼ pom.xmlï¼šé¡¹ç›®ç‹¬äº«æ¨¡å¼ å¦‚æœä¸¤ç§æ–¹å¼éƒ½é…ç½®äº†ï¼Œé‚£ä¹ˆä»¥ pom.xml æ–‡ä»¶é…ç½®ä¸ºå‡†ã€‚ å½“æˆ‘ä»¬é€šè¿‡ Maven ä½¿ç”¨ Nexus çš„ maven-public çš„æ—¶å€™ï¼Œä¼šæŒ‰ç…§ä»¥ä¸‹æ–¹å¼é¡ºåºè®¿é—®ï¼š æœ¬åœ°ä»“åº“ ç§æœ maven-releases ç§æœ maven-snapshots è¿œç¨‹é˜¿é‡Œ maven ä»“åº“ è¿œç¨‹ä¸­å¤®ä»“åº“ é€šè¿‡ settings.xml æ–‡ä»¶é…ç½®1234567891011121314151617&lt;!-- serverså—ä¸­æ·»åŠ ç”¨æˆ·è®¤è¯ä¿¡æ¯ --&gt;&lt;server&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;changeme&lt;/password&gt;&lt;/server&gt;&lt;!-- mirrorså—ä¸­æ·»åŠ maven-publicä¿¡æ¯ --&gt;&lt;mirror&gt; &lt;!-- å”¯ä¸€æ ‡è¯†ç¬¦ --&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;!-- åç§° --&gt; &lt;name&gt;cqm maven&lt;/name&gt; &lt;!-- maven-publicåœ°å€ --&gt; &lt;url&gt;http://192.168.159.11:35826/repository/maven-public/&lt;/url&gt; &lt;!-- *æŒ‡çš„æ˜¯è®¿é—®ä»»ä½•ä»“åº“éƒ½ä½¿ç”¨æˆ‘ä»¬çš„ç§æœï¼Œå¯è®¾ç½®ä¸ºcentralç­‰ç­‰ --&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt;&lt;/mirror&gt; ä¹Ÿå¯ä»¥è®¾ç½®ä¸ºé˜¿é‡Œçš„ 123456&lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;&lt;/mirror&gt; é€šè¿‡ pom.xml æ–‡ä»¶é…ç½®12345678910111213&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;mnexus&lt;/id&gt; &lt;name&gt;cqm nexus&lt;/name&gt; &lt;url&gt;http://192.168.159.11:35826/repository/maven-public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; åŒæ ·ä¹Ÿå¯ä»¥è®¾ç½®ä¸ºé˜¿é‡Œçš„ 1234567891011121314&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;checksumPolicy&gt;fail&lt;/checksumPolicy&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; ä½¿ç”¨ Maven æ‰¹é‡å‘ Nexus ä¸Šä¼ é¦–å…ˆéœ€è¦å°† .m2/repository ä¸‹çš„ç›¸åº” jar åŒ…å’Œ pom æ–‡ä»¶ cp å‡ºæ¥ï¼Œå†è¿›è¡Œ deployã€‚ 12# -DrepositoryId å‚æ•°è°ƒç”¨äº† settings.xml ä¸­ servers å—çš„è´¦å·å¯†ç è¿›è¡Œè®¤è¯find . -name &quot;*.jar&quot; | awk '{ gsub(&quot;\\.jar$&quot;,&quot;&quot;,$0); print &quot;mvn deploy:deploy-file -Dfile=&quot;$0&quot;.jar -DpomFile=&quot;$0&quot;.pom -Dpackaging=jar -DrepositoryId=nexus -Durl=\\&quot;http://nexus-path\\&quot;&quot;}'","link":"/2024/02/18/nexus/"},{"title":"é€šè¿‡ Nginx å®ç° RKE2 é«˜å¯ç”¨éƒ¨ç½²","text":"å‚è€ƒæ–‡æ¡£ï¼šhttps://ee.docs.rancher.cn/docs/installation/kubernetes-cluster-setup/high-availability%20/rke2-ha-install-for-nginx éƒ¨ç½²æ¶æ„å›¾ï¼š åˆ›å»º RKE2 é›†ç¾¤çš„æ—¶å€™éœ€è¦åœ¨ TLS Alternate Names ä¸­æ·»åŠ  Nginx çš„ IP or FQDNï¼š éƒ¨ç½² Nginxï¼š 12345678910111213141516171819202122232425262728cat &lt;&lt;EOF &gt; nginx.confworker_processes 1;events { worker_connections 8192;}stream { log_format proxy '$remote_addr [$time_local] ' '$protocol $status $bytes_sent $bytes_received ' '$session_time &quot;$upstream_addr&quot;'; error_log /var/log/nginx/error.log; access_log /var/log/nginx/access.log proxy; upstream kube_apiservers { server 172.16.16.120:6443 max_fails=5 fail_timeout=8s; server 172.16.16.121:6443 max_fails=5 fail_timeout=8s; server 172.16.16.122:6443 max_fails=5 fail_timeout=8s; } server { listen 443; proxy_pass kube_apiservers; }}EOFdocker run -d --name nginx --restart=always -v $(pwd)/nginx.conf:/etc/nginx/nginx.conf -p 443:443 harbor.warnerchen.com/library/nginx:mainline å°è¯•åœ¨ Rancher è®¾ç½® Direct Mode è®¿é—® RKE2ï¼š å¦‚æœè¦ç»™ Nginx é…ç½® HTTPSï¼Œéœ€è¦æ³¨æ„ä¸èƒ½ä½¿ç”¨è‡ªå®šä¹‰çš„ CA ä¸‹å‘è¯ä¹¦ï¼Œè¿™æ˜¯å› ä¸ºåç«¯ kube-apiserver æ˜¯ HTTPSï¼Œè€Œ kube-apiserver å¯ç”¨çš„æ˜¯åŒå‘è®¤è¯ï¼Œå¦‚æœ Nginx ä½¿ç”¨äº†é KUBE CA ç”Ÿæˆçš„è¯ä¹¦ï¼Œé‚£ä¹ˆå°±ä¼šå¯¼è‡´è®¤è¯å¤±è´¥ã€‚ åœ¨ RKE2ï¼Œå¯ä»¥ä½¿ç”¨ä¸‹é¢ä¸¤ä¸ªæ–‡ä»¶ç”Ÿæˆè¯ä¹¦ï¼š 12/var/lib/rancher/rke2/server/tls/server-ca.crt/var/lib/rancher/rke2/server/tls/server-ca.key ç”Ÿæˆè¯ä¹¦å‘½ä»¤å¯ä»¥å‚è€ƒï¼š 123456789101112131415161718192021222324252627282930cat &lt;&lt;EOF &gt; openssl.cnf[ req ]default_bits = 2048default_keyfile = privkey.pemdistinguished_name = req_distinguished_namereq_extensions = v3_req[ req_distinguished_name ]countryName = Country Name (2 letter code)countryName_default = CNstateOrProvinceName = State or Province Name (full name)stateOrProvinceName_default = GuangdonglocalityName = Locality Name (eg, city)localityName_default = ShenzhenorganizationName = Organization Name (eg, company)organizationName_default = SUSEcommonName = Common Name (eg, fully qualified host name)commonName_default = rke2-cilium.warnerchen.com[ v3_req ]subjectAltName = @alt_names[ alt_names ]DNS.1 = rke2-cilium.warnerchen.comIP.1 = 172.16.16.141EOFopenssl req -new -key /var/lib/rancher/rke2/server/tls/server-ca.key -out server.csr -config openssl.cnfopenssl x509 -req -in server.csr -CA /var/lib/rancher/rke2/server/tls/server-ca.crt -CAkey /var/lib/rancher/rke2/server/tls/server-ca.key -CAcreateserial -out server.crt -days 365 -extensions v3_req -extfile openssl.cnf å°†ç”Ÿæˆçš„è¯ä¹¦æ–‡ä»¶æŒ‚è½½åˆ° Nginx å®¹å™¨ä¸­ï¼š 12345678910111213141516171819202122232425262728293031323334353637383940cat &lt;&lt;EOF &gt; nginx.confworker_processes 1;events { worker_connections 1024;}http { upstream kube_apiservers { server 172.16.16.120:6443 max_fails=5 fail_timeout=8s; server 172.16.16.121:6443 max_fails=5 fail_timeout=8s; server 172.16.16.122:6443 max_fails=5 fail_timeout=8s; } server { listen 443 ssl; server_name rke2-cilium.warnerchen.com; # ä½¿ç”¨ä¹‹å‰ç”Ÿæˆçš„è¯ä¹¦ ssl_certificate /etc/nginx/certs/server.crt; # ä½¿ç”¨ RKE2 Control Plane èŠ‚ç‚¹çš„ /var/lib/rancher/rke2/server/tls/server-ca.key ssl_certificate_key /etc/nginx/certs/server.key; location / { proxy_pass https://kube_apiservers; proxy_ssl_verify off; # proxy_ssl_trusted_certificate /etc/nginx/certs/server-ca.crt; # proxy_ssl_name rke2-cilium.warnerchen.com; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_read_timeout 300; proxy_connect_timeout 60; proxy_send_timeout 300; } }}EOFdocker run -d --name nginx --restart=always -v $(pwd)/nginx.conf:/etc/nginx/nginx.conf -v $(pwd)/certs:/etc/nginx/certs -p 443:443 harbor.warnerchen.com/library/nginx:mainline","link":"/2025/04/10/%E9%80%9A%E8%BF%87-Nginx-%E5%AE%9E%E7%8E%B0-RKE2-%E9%AB%98%E5%8F%AF%E7%94%A8%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"k8s","slug":"k8s","link":"/tags/k8s/"},{"name":"suse","slug":"suse","link":"/tags/suse/"},{"name":"elasticsearch","slug":"elasticsearch","link":"/tags/elasticsearch/"},{"name":"etcd","slug":"etcd","link":"/tags/etcd/"},{"name":"istio","slug":"istio","link":"/tags/istio/"},{"name":"ai","slug":"ai","link":"/tags/ai/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"ansible","slug":"ansible","link":"/tags/ansible/"},{"name":"container","slug":"container","link":"/tags/container/"},{"name":"cisco","slug":"cisco","link":"/tags/cisco/"},{"name":"calico","slug":"calico","link":"/tags/calico/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"jenkins","slug":"jenkins","link":"/tags/jenkins/"},{"name":"kafka","slug":"kafka","link":"/tags/kafka/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"prometheus","slug":"prometheus","link":"/tags/prometheus/"},{"name":"web","slug":"web","link":"/tags/web/"},{"name":"é¢è¯•","slug":"é¢è¯•","link":"/tags/%E9%9D%A2%E8%AF%95/"},{"name":"zookeeper","slug":"zookeeper","link":"/tags/zookeeper/"},{"name":"containerd","slug":"containerd","link":"/tags/containerd/"},{"name":"é¦–é¡µ","slug":"é¦–é¡µ","link":"/tags/%E9%A6%96%E9%A1%B5/"},{"name":"elk","slug":"elk","link":"/tags/elk/"},{"name":"nexus","slug":"nexus","link":"/tags/nexus/"}],"categories":[],"pages":[]}